{"title": "Review for \"Effective Path: Know the Unknowns of Neural Network\"", "review": "This paper proposes a measure (\u201ceffective path\u201d) of which units and weights were most important for classification of a particular input or input class. Using the effective path, the authors analyze the overlap between paths across classes for CNNs and between adversarially modified and unmodified images. Finally, the paper proposes an adversarial defense method based on effective path which detects adversarially manipulated images with high accuracy and generality to a variety of settings. \n\nOverall, this paper is interesting and provides several novel observations. The clarity of the exposition is generally good, but can be improved in several places (mentioned below). As for significance, effective path is likely to inform future analyses of neural networks, and the adversarial defense may prove impactful, though ultimately, its impact will depend on if and when the defense is broken. \n\nHowever, there are several important controls missing from the analysis, several claims which are unsubstantiated, and experimental details are lacking in a few places. As such, in its current form, I can only weakly recommend this paper for acceptance. If in the revision the controls requested below are included, additional evidence is provided for the unsubstantiated claims (or if those claims are toned down), and exposition of missing experimental details is included, I\u2019d be happy to raise my score. \n\nMajor points:\n\n1) While the observation regarding path specialization is very interesting, one cannot gauge whether or not the degree of overlap observed between class-specific paths signals path specialization or simply high input-to-input path variance (which is similar both within and across classes). In order to distinguish between these possibilities, a measure of intra-class path similarity is necessary. In addition, an experiment similar to that in Figure 2 with CIFAR-10 would be quite helpful in evaluating whether this phenomenon exists in more natural datasets (the ImageNet results are difficult to interpret due to the large number of classes).\n\n2) Several claims in the path specialization section are unsubstantiated. \n\n2a) In particular, the claim that \u20181\u2019 has the highest degree of specialization \u201cbecause of its unique shape\u201d is made without evidence as is the similarity between \u20185\u2019 and \u20188\u2019. \u20186\u2019 is also similar to \u20188\u2019 and yet does not show the same similarity in the path specialization. These differences may very well simply be due to chance.\n\n2b) The claim that the path specialization in ImageNet matches the class hierarchy is made only based on the rough non-linearity of Figure 3. Please either measure the overlap within and across class categories or soften this claim.\n\n3) The similarity analysis for adversarial images is also very interesting, but a comparison between unmodified and randomly perturbed images with matched norms to the adversarially perturbed images is necessary to establish whether this effect is due to noise generally or adversarial noise.\nIt\u2019s unclear how the effective path is calculated when negative weights are involved. Further exposition of this aspect would be helpful.\n\nMinor points/typos: \n\n1) There are several places where confusing concepts are introduced in one paragraph but explained several paragraphs later. In particular, the distinction between synapses and weights is introduced halfway through page 2 but explained on page 3 and the fact that the coefficients for the defense metric are learned is unclear until page 4 even though they\u2019re introduced on page 3.\n\n2) Typos: \n\n2a) Section 1, fourth paragraph: \u201c...and adversarial images, we uncover...\u201d should be \u201c...and adversarial images, and we uncover...\u201d\n\n2b) Section 1, fourth paragraph: \u201c...by small perturbation, the network\u2026\u201d should be \u201c...by small perturbations, the network\u2026\u201d\n\n2c) Section 2, first paragraph: \u201c...the black-boxed neural\u2026\u201d should be \u201c...the black-box neural\u2026\u201d\n\n2d) Section 2, first paragraph: \u201cIn the high level\u2026\u201d should be \u201cAt a high level\u2026\u201d\n\n2e) Section 4, first paragraph: \u201c...as it does no modify\u2026\u201d should be \u201c...as it does not modify\u2026\u201d\n\n2f) Title, should be \"Neural Network\"? \n", "rating": "6: Marginally above acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}