{"title": "Extra Review: Excellent paper which thoroughly explores a very interesting question", "review": "This is an excellent analysis paper of a very interesting phenomenon in deep neural networks.\n\nQuality, Clarity, Originality:\nAs far as I know, the paper explores a very relevant and original question -- studying how the learning process of different examples in the dataset varies. In particular, the authors study whether some examples are harder to learn than others (examples that are forgotten and relearned multiple times through learning.) We can imagine that such examples are \"support vectors\" for neural networks, helping define the decision boundary.\n\nThe paper is very clear and the experiments are of very high quality. I particularly appreciated the effort of the authors to use architectures that achieve close to SOTA on all datasets to ensure conclusions are valid in this setting. I also thought the multiple repetitions and analysing rank correlation over different random seeds was a good additional test.\n\nSignificance\nThis paper has some very interesting and significant takeaways.\nSome of the other experiments I thought were particularly insightful were the effect  on test error of removing examples that aren't forgotten to examples that are forgotten more. In summary, the \"harder\" examples are more crucial to define the right decision boundaries. I also liked the experiment with noisy labels, showing that this results in networks forgetting faster.\n\nMy one suggestion would be to try this experiment with noisy *data* instead of noisy labels, as we are especially curious about the effect of the data (as opposed to a different labelling task.)\n\nI encourage the authors to followup with a larger scaled version of their experiments. It's possible that for a harder task like Imagenet, a combination of \"easy\" and \"hard\" examples might be needed to enable learning and define good decision boundaries.\n\nI argue strongly for this paper to be accepted to ICLR, I think it will be of great interest to the community.", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}