{"title": "Multimodal Joint Generative Discriminative Factorization for disentangled representations with good performance and practical application (noise robustness)", "review": "This paper presents 'Multimodal Factorization model' that factorizes representations into shared multimodal discriminative factors and modality specific generative factors. This work applies 'Wassertein Auto-Encoders' by Tolstikhin et al (with proofs that this setup works in the multimodal case) for handling factorized joint distributions over the multimodal space. Can this method be considered as a generalization of the wasserstein autoencoder based method with a broader application? - the authors should discuss this more broadly in the paper.\n\nPros:\n- There has been many recent work in the area of disentangling joint representations for improving generative auto-encoding architectures using VAEs, GANs, WAE and some variants of these. This work falls in this category with many interesting experiments showing SOTA generation and discrimination results on several tasks.\n- This work is practical due to its robustness to noisy and/or missing data for one or more of the modalities in a multimodal machine learning classification (or generation) problem. Application of this technique for continuous multimodal time series data modeling and prediction for high accuracy requirement applications is very promising.\n- The methods seems to be easily portable to other tasks. The authors say that they will make the code available to other researchers.\n\nCons:\n- Some more comparison to other disentangling approaches such as beta-VAE, InfoGAN and partitioned VAE methods would have been useful for understanding the advantages and disadvantages of this techniques. (The authors do add a note about comparison with partitioned VAE method in the Appendix)\n- For generation and classification tasks, the authors have chosen the tasks for digit recognition and sentiment analysis - I wonder if the results would hold for other types of multimodal tasks.\n\nOverall the paper is very well-written with many experiments to support the claims.", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}