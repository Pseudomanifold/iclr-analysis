{"title": "The topic is interesting but the overall technical contribution looks weak. ", "review": "The paper introduces an iterative method to generate deformed images for adversarial attack. The core idea is to perturb the correctly classified image by iteratively applying small deformations, which are estimated based on a first-order approximation step, until the image is misclassified. Experimental results on several benchmark datasets (MNIST, ImageNet) and commonly used deep nets (CNN, ResNet, Inception) are reported to show the power of adversarial deformations. \n\nThe idea of gradually adding deformations based on gradient information is somewhat interesting, and novel as far as the reviewer knows about. The method is clearly presented and the results are mostly easy to access.  However, the intuition behind the proposal does not make strong sense to the reviewer: since the main focus of this work is on model attack, why not directly (iteratively or not) adding random image deformations to fool the system? Particularly, the first-order approximation strategy (as shown in Eq.4 and Eq.5) is quite confusing. On one side (see Eq.4), the deformation \\tau should be small enough in scale to make an accurate approximation. On the other side (see Eq. 5), \\tau is required to be sufficiently large in order to generate misclassification. Such seemingly conflicting rules for estimating the deformation makes the proposed method less rigorous in math. \nAs another downside, the related adversarial training procedure is not fully addressed. The authors briefly discussed this point in the experiment section and provided a few numerical results in Table 2. These results, as acknowledged by the authors, do not well support the effectiveness of deformation adversarial attack and defense. In the meanwhile, the mentioned adversarial training framework follows straightforwardly from PGD (Madry et al. 2018), and thus the novelty of this contribution is also weak. More importantly, it is not clear at all, both in theory and algorithm, whether the advocated gradual deformation attack and defense can be unified inside a joint min-max/max-min learning formulation, as what PGD is rooted from.\n\nPros: \n\n- The way of constructing deformation adversarial is interesting and novel\n- The paper is mostly clearly organized and presented.\n\nCons:\n\n- The motivation of approach is questionable. \n- The related adversarial training problem remains largely unaddressed.\n- Numerical study shows some promise in adversarial attack, but is not supportive to the related defense capability. ", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}