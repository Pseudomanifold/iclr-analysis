{"title": "Interesting contribution but still rudimentary", "review": "Summary: This paper proposes a novel knowledge extraction method using M-of-N rules\nto help interpret hidden features in a Convolutional Neural Network (CNN). While the idea itself is interesting, I think that the paper is still in a very early stage and needs more work before it can be accepted. Detailed comments below.\n\nPros: \n1. The paper proposes a new algorithm to interpret CNNs.\n2. The paper is reasonably well written.\n\nCons: \n1. The experimental evaluation is quite weak. The authors present their (partial) results on a single dataset and also seem to generalize some of the findings in a rather misleading way. \n2. The proposed method is not compared against any baseline though there are ample rule-based methods to understand NNs in literature.\n2. It seems like the literals in the generated rules are actually outputs of previous stages of NNs. Are the rules even human understandable in that case? \n\nDetailed Comments:\n1. I think that the paper is missing a very clear discussion on what is novel about the proposed method in contrast with recent work on explaining NNs (or black box models) using rule based approaches. Examples of relevant papers include \"Anchors: High-Precision Model-Agnostic Explanations\" by Ribeiro et. al. and \"Interpretable & Explorable Approximations of Black Box Models\" by Lakkaraju et. al. among others. \n2. Another important piece of discussion that is missing is how the proposed search technique for extracting M-of-N rules is novel compared to a lot of prior literature which deals with the same problem\n3. I would strongly encourage the authors to experiment with at least three different datasets and multiple CNN architectures. \n4. I would really like to see the output of the proposed approach. What kinds of rules are being generated at each stage? It seems like the literals in the generated rules are actually outputs of previous stages of NNs. Are the rules even human understandable in that case? \n5. It would be good to do a simple user study to demonstrate that human users are able to understand something useful from the generated explanations. ", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}