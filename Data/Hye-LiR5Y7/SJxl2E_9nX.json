{"title": "Interpretation needed for the weights", "review": "This is an interesting paper claiming that on assumptions are made (or explicitly made) on the similarity of distributions. Traditionally, we learned the weights for transfer learning by matching the distributions. I am wondering if there are any relationships between those two methods. It is necessary to show the differences between the weighted source domain and the target domain, and compare them with the traditional matching methods.\n\nMy another concern is about the technical contribution. The model is very intuitive and simple. Some analyses are made for optimization. However, theoretical justifications are lacking, making the technical contribution weak and looks like a simple combination of two existing techniques. I would like to know if the weights are identifiable and what kinds of weights are preferred. \n\nBy searching, I found related papers on transfer learning with label noise and learning with label noise by importance reweighting, e.g., Yu, Xiyu, et al. \"Transfer Learning with Label Noise.\" arXiv preprint arXiv:1707.09724 (2017). and Liu, Tongliang, and Dacheng Tao. \"Classification with noisy labels by importance reweighting.\" IEEE Transactions on pattern analysis and machine intelligence 38.3 (2016): 447-461. However, they are not discussed in the submission. It is curious to see the relationships and differences.", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}