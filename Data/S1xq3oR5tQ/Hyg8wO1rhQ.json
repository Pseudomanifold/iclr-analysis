{"title": "Interesting application of deep neural nets to neuroscience.", "review": "This paper addresses questions about the representation of visual information in the retina. The authors create a deep neural network model of the visual system in which a single parameter (bandwidth between the \u201cretina\u201d and \u201cvisual cortex\u201d parts) is sufficient to qualitatively reproduce retinal receptive fields observed across animals with different brain sizes, which have been hard to reconcile in the past. \n\nThis work is an innovative application of deep neural networks to a long-standing question in visual neuroscience. While I have some questions about the analyses and conclusions, I think that the paper is interesting and of high quality.\n\nMy main concern is that the authors only show single examples, without quantification, for some main results (RF structure). For example, for Fig. 2A and 2B, an orientation selectivity index should be shown for all neurons. A similar population analysis should be devised for Fig 2C, e.g. like Fig 3 in [1]\n\nMinor comments:\n1. Page 4: \u201cThese results suggest that the key constraint ... might be the dimensionality bottleneck..\u201d: The analyses only show that the bottleneck is *sufficient* to explain the differences, but \u201cthe key constraint\u201d also implies *necessity*. Either soften the claim or provide control experiments showing that alternative hypotheses (constraint on firing rate etc.) cannot explain this result in your model.\n\n2. I don\u2019t understand most of the arguments about \u201ccell types\u201d (e.g. Fig. 2F and elsewhere). In neuroscience, \u201ccell types\u201d usually refers to cells with completely different connectivity constraints, e.g. excitatory vs. inhibitory cells or somatostatin vs. parvalbumin cells. But you refer to different CNN channels as different \u201ctypes\u201d. This seems very different than the neuroscience definition. CNN channels just represent different feature maps, i.e. different receptive field shapes, but not fundamentally different connectivity patterns. Therefore, I also don\u2019t quite understand what you are trying to show with the weight-untying experiments (Fig. 2E/F).\n\n3. It is not clear to me what Fig. 3B and the associated paragraph are trying to show. What are the implications of the nonlinearity being due to the first or second stage? \n\n4. Comment on Fig 3F: The center-surround RFs probably implement a whitening transform (which is linear). Whitened inputs can probably be represented more efficiently in a network trained with L2-regularization and/or SGD. This might explain why the \u201cquasi-linear\u201d retina improves separability later-on.\n\n[1] Cossell, Lee, Maria Florencia Iacaruso, Dylan R. Muir, Rachael Houlton, Elie N. Sader, Ho Ko, Sonja B. Hofer, and Thomas D. Mrsic-Flogel. \u201cFunctional Organization of Excitatory Synaptic Strength in Primary Visual Cortex.\u201d Nature 518, no. 7539 (February 19, 2015): 399\u2013403. https://doi.org/10.1038/nature14182.", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}