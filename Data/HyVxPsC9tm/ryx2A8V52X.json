{"title": "Needs more analysis and explanation", "review": "Summary - This paper proposes a technique to reduce the compute cost when applying recognition models in surveillance models. The core idea is to analytically compute the pixels that changed across frames and only apply the convolution operation to those pixels. The authors term this as dynamic convolution and evaluate this method on the SSD architecture across datasets like PETS, AVSS, VIRAT.\n\nPaper strengths\n- The problem of reducing computational requirements when using CNNs for video analysis is well motivated. \n- The authors analyze a standard model on benchmark datasets which makes it easier to understand and place their results in context.\n\nPaper weaknesses\n- A simple baseline that only processes a frame if \\sum_{ij} D_{ij} exceeds a threshold is never mentioned or compared against. In general, the paper does not compare against any other existing work which reduces compute for video analysis, e.g., tracking. This makes it harder to appreciate the contribution or practical benefit of using this method.\n- The paper has many spelling and grammar mistakes - \"siliarlity\", \"critiria\" etc.\n- Continuous convolutions - It is not clear to me what is meant by this term. It is used many times and there is an entire section of results on it (Table 6), but without clearly understanding this concept, I cannot fully appreciate the results.\n- Section 5.2 - what criteria or metric is used to compute scene similarity?\n- Overall, I think this paper can be substantially improved in terms of providing details on the proposed approach and comparing against baselines to demonstrate that Dynamic-Convolutions are helpful.\n- Design decisions such as cell-based convolution (Figure 3) are never evaluated empirically.", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}