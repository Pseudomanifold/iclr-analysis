{"title": "A solid contribution with some presentation issues: scope of applicability, clarity, technical correctness", "review": "* Summary\n\nThe paper proposes an improved method for computing derivatives of the expectation. Such problems arises with many probabilistic models with noises or latent variables. The paper proposes a new gradient estimator of low variance applicable in certain scenarios, in particular it allows training of generative models in which observations and/or latent variables are discrete. \nThe submission clearly improves the state-of-the-art, experimentally demonstrates the method on several problems comparing with the alternative techniques. In what concerns the optimization, the method achieves a better objective value much faster, confirming that it is a lower variance gradient estimator. \nThe clarity of the presentation (in particular the description of when the method is applicable) and the technical correctness of the paper are somewhat lacking. In terms of applicability, it seems that many cases where discrete latent variables would be really interesting are not covered (e.g. sigmoid belief networks); the paper demonstrates experiments with discrete images (binary or 4-bit) not particularly motivated in my opinion. It also contains lots of additional technical details and experiments in the appendix, which I unfortunately did not review.\n\n* Clarity\n\nIn the abstract the paper promises more than it delivers. Many problems can be cast as optimizing an expectation-based objective. The result does not at all apply to all of them. The reparameterization trick does not apply to all continuous random variables, only to such that the reparameterization satisfies certain smoothness conditions. Discrete variables are supported by the method only in the case that the distribution factors over all discrete variables conditionally on any additional \u201ccontinuous variables\u201d (to which the reparameterization trick is applicable). This very much limits the utility of the method. In particular it is not applicable to learning e.g. sigmoid belief networks [Neal, 92] (with conditional Bernoulli units) and many other problems. \n\n\u201creparametrizable distributions\u201d\nA Bernoulli(p) random variable is discrete, yet it is reparametrizable as [Z>p] with Z following standard logistic distribution, whose density and cdf is smooth. \n\nBecause of the above many discussions about discrete vs. continuous variables are missleading.\n\nSection 2. The notation of the true distribution as \u201cq\u201d the model as p and the approximate posterior of the model as \u201cq\u201d again is inconsistent. I find the background on ELBO and GANs unnecessary occluding the clarity at this point. For the purpose of introduction, it might be better to give examples of expectation objectives such as: \n- dropout: q is the distribution of NN outputs given the input image and integrating out latent dropout noises, gamma are parameters of this NN.\n- VAE, GAN: q is the generative model defined as a mapping of a standard multivariate normal distribution by a NN.\n- sigmoid belief networks: q is a Bayesian network where each conditional distribution is a logistic regression model.\nThen to state to which of these cases the results of the paper are applicable, allow for an improvement of the variance and at what additional computational cost (considering the cost of evaluating the discrete derivatives).\n\nSection 3.\nContrary to the discussion, there are examples of non-negative distributions to which the reparameterization trick can be applied, including log-Normal and Gamma distributions.\n\nMethod:\nIn the case when Rep trick is applicable, is it identical to GO? The difference seems to be only in that the mapping tau may be different from Q^-1. However, this only affects the method of drawing the samples from a fixed known distribution and should have no more effect on the results than say a choice of a pseudo-random number generator. Yet, in Fig.1 some difference is observed between the methods, why is that so?\n\nSec 7.1\n\u201cWe adopt the sticking approach hereafter\u201d. Does it mean it is applied with all experiments with GO?\n\n* Related Work\n\nThe state of the art allows combining differentiable and non-differentiable pieces of computation:\n[Schulman, J., Heess, N., Weber, T., Abbeel, P.: Gradient estimation using stochastic computation graphs.]\nI believe it should be discussed in related work. Limitations / where the proposed method brings an improvement should be highlighted.\n\n* Technical Correctness\nEquations (5) and (6) require a theorem of differentiating under integral (expectation), such as Leibnitz rule, which in case of (6) requires q_gamma(y)f(y) to be continuous in y and q_gamma(y) continuously differentiable in gamma.\nEquation (7) (integration by parts) holds only with some additional requires on f.\nTheorem 1 does not take account for the above conditions.\n\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}