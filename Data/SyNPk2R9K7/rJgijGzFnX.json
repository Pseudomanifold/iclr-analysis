{"title": "Review", "review": "This paper presents a system that infers programs describing 3D scenes composed of simple primitives. The system consists of three stages each of which is trained separately. First, the perceptual module extracts object masks and their attributes. The objects are then are split into several groups. Finally, each group is mapped to a corresponding DSL program using a sequence-to-sequence network similar to the ones typically employed in neural machine translation.\n\nPros:\n+ The paper is written clearly and easy to read.\n+ Visual program synthesis is very exciting and important direction both for image understanding and generation.\n+ The results on synthetic datasets are good. The authors also demonstrate the applicability of the approach to real-world data (albeit significantly constrained).\n+ I find it surprising that a seq2seq is good at producing an accurate program for a group of objects.\n+ Visual analogy making experiments are impressive.\n\nCons:\n- The proposed model requires rich annotation of training data since all the components of the systems are trained in a supervised fashion. It\u2019s not clear how to use the method on the in-the-wild data without such annotation.\n- Related to the previous point, even when it\u2019s possible to synthesize data, it is non-trivial to obtain the ground-truth grouping of objects. Judging by Table 2, it seems that the system breaks in absence of the grouping information.\n- The data used in the paper is quite simplistic (limited number of primitives located in a regular grid). I\u2019m wondering if there is a natural way to extend the approach to more complex settings. My guess is that the performance will drop significantly.\n\nNotes/questions:\n* Section 2, paragraph 1: The paper by [Ganin et al., 2018] presents both a system for reproducing an image as well as for sampling from a distribution; moreover, it presents experiments on 3D data (i.e., not limited to drawing).\n* Section 3.4, paragraph 2: I\u2019m not sure I understand the last sentence. How can we know that we successfully recovered the scene at test time? Could the authors elaborate on the stopping criterion for sampling?\n* Section 4.2, paragraph 2: Do I understand correctly that the main difference between the test set and the generalization set is the number of groups? (i.e., 2 vs 3). If so, it\u2019s a fairly limited demonstration of generalization capabilities of the system.\n* Section 4.2, paragraph 4: \u201cwe search top 3 proposals ...\u201d \u2013 How do we decide which one is better? Do we somehow have an access to the ground truth program at test time?\n* Could the authors explain the representation of a program more clearly? How are loops handled? How can one subtract/add programs in the analogy making experiment?\n\nOverall, I think it is a interesting paper and can be potentially accepted on the condition that the authors address my questions and concerns.", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}