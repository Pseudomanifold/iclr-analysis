{"title": "Improving MAML", "review": "Paper summary - This paper provides a bag of sensible tricks for making MAML more stable, faster to learn, and better in final performance.\nQuality - The quality of the work is strong: the results demonstrate that tweaks to MAML produce significant improvements in performance. However, I have some concern that certain portions of the text overclaim (see concerns section below).\nClarity - The paper is reasonably clear, with some exceptions (see concerns section).\nOriginality - The techniques described in the paper range from only mildly novel (e.g. MSL, DA), to very obvious (e.g. CA). Additionally, the paper's contributions amount to tweaks to a previously existing algorithm. \nSignificance - The quality of the results make this a significant contribution in my view.\nPros - Good results on a problem/algorithm of great current interest.\nCons - Only presents (in some cases obvious) tweaks to a previous algorithm; clarity and overclaiming issues in the writeup.\n\nConcerns (please address in author response)\n- The paper says  \"we \u2026 propose multiple ways to automate most of the hyperparameter searching required\". I'm not sure that this is true. The only technique that arguably removes a hyperparameter is LSLR. Even in this case, you still have to initialize the inner loop learning rates, so I'm not convinced that even this reduces hyperparameters. Perhaps I've missed something, please clarify.\n- Section 4's paragraph on LSLR seems to say that you have a single alpha for each layer of the network. If this is right, then saying your method has a \"per layer gradient direction\" is very confusing. Each layer's alpha modulates the magnitude of that layer's update vector, but not its direction. The per-layer alphas together modify the direction of the global update vector. Perhaps I've misunderstood; equations describing exactly what LSLR does would be helpful. In any case, this should be clarified in the text.\n\nSuggestions (less essential than the concerns above)\n- The write-up is redundant and carries unnecessary content. The paper would be better shorter (8 pages is not a minimum :)\nSection 1 covers a lot of background on the basics of meta-learning background that could be skipped. Other papers you cite (e.g. the MAML paper cover this). \n    - Section 2 goes into more detail about e.g. matching nets than is necessary. \n    - Section 2 explains MAML, which is then covered in much more detail in Section 3; better to leave out the Section 2 MAML paragraph. \n    - Sections 3 and 4 are very redundant. Combine them for a shorter (i.e., better!) paper.\n- The paper says, \"Furthermore, for each learning rate learned, there will be N instances of that learning rate, one for each step to be taken. By doing this, the parameters are free to learn to decrease the learning rates at each step which may help alleviate overfitting.\" Does this happen empirically? Space could be freed up (see above) to have a figure showing whether or not this happens.\n- The paper says, \"we propose MAML++, an improved meta-learning framework\" -- it's a little too far to call this a new framework. it's still MAML, with improvements.\n\nTypos\n- \"4) increase the system\u2019s computational overheads\" -> overhead\n- \"composed by\" -> composed of\n- \"Santurkar et al. (2018).\", \"Krizhevsky et al. (2012),\",  \"Finn et al. (2017) \" -> misplaced citation parens\n- \"a method that reduce\" -> reduces\n- \"An evaluation ran consisted\" -> evaluation consisted\n- The Loshchlikov and Hutter citation in the bibliography isn't right. It should be \"Sgdr: Stochastic gradient descent with restarts.\" (2016) instead of \"Fixing weight decay regularization in adam\" (2017).\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}