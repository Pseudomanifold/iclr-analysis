{"title": "Interesting idea in improving data transformation generalization across input data distributions in an unsupervised way", "review": "The authors proposed a novel method of making data transformation that is much easier to extend to the cases where the input distribution is different from the one that is used to the train the model (in-sample vs out-sample). This has a lot of application in removing experimental noise in biological data (also known as batch effects).\nThe idea is to learn a representation that separates background (dimensions that do NOT vary across data points, but may be subject to change in a data transformation) and foreground (dimensions that vary between data points under the same background) and then apply a *fixed* linear transformation in the learned representation space. This is different from other approaches, such as GAN, where the transformation is learned entirely based on the data. In addition, it mitigates some known problems, such as the \"mode collapse\" in GAN, by just learning a good representation. This is proposed to be done by an autoencoder trained on both in-samples and out-samples (the transformation is however adjusted based on the in-samples only). Experimental results are appealing in different applications compared to GAN, ResnetGAN, and CycleGAN. \nHere are my major concerns:\n- The idea seems to be very general and indeed is applicable to any latent representation learning method, and not just autoencoders. Is there any reason that other more complicated unsupervised representation learning methods were not used for benchmarking in the paper?\n\n- The method heavily relies on the quality of the unsupervised learned representation. How one is guaranteed that the transformation in the learned space be simple and piecewise linear? Shouldn't we consider a regularization method to guide the unsupervised learning more appropriately? \n\n- The method also implicitly assumes that the same neurons model background and foreground in the in-sample and out-sample data points. How is that guaranteed in practice?", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}