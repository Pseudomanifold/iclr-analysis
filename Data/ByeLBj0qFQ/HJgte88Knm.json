{"title": "The evaluation is weak to show its usefulness, despite a nice idea in the underexplored subject", "review": "To generate a sequence of high-level visual elements for recreation or translation of images, the authors propose differentiable \"canvas\" networks and \"drawer\" networks based on convolutional neural networks. One of the main ideas is the replacement of the \"canvas\" networks instead of non-differentiable \"renderer\" to end-to-end train the whole model with mean-squared error loss. It seems to be a novel approach to optimize drawing actions. It is reasonable to use separate networks to approximate the behavior of renderer and to fix the parameters of the \"canvas\" networks to maintain the pretrained rendering capability.\n\nIntegrating the high-level visual constructs for recreation or translation of images is to eliminate or attenuate visual artifacts and blurriness, as mentioned in the introduction of the paper. Qualitative comparison with the other state-of-the-art methods is shown in Figure 6f; however, it fails to show significant improvement over them. Quantitative results do not include in the comparison, but only for the ablation study to determine the proposing method. Although the paper proposes an interesting approach to enhance an image generation task, the provided evidence is weak to support the argument, which should be useful for their criteria.\n\nMoreover, experimental details fall short to ensure the validity of experiments. How do you split the dataset as train/val/test? Are the reporting figures (L2 loss) from test results? How are the statistics of the datasets you used?\n\nIn Related Work, the authors describe \"reinforcement learning methods can be unstable and often depend on large amounts of training samples.\" Many RL methods use various techniques to stabilize the learning, and this argument alone cannot be the grounding that the supervised approach is better than RL. Unsupervised learning also needs a large amount of data. What is the point of this paragraph (the second paragraph in Related Work)?\n\n\nQuality: \n  Figure 1-3 are taking too much space, which might lead to exceeding 8 pages. \n\nClarity:\n  The experimental procedure is not clear. Please clarify the issues mentioned above. It is not hinder to understand the content; however, the writing can be improved by proof-reading and correcting a few grammatical errors.\n\nOriginality and significance:\n  Using the differentiable \"canvas\" networks to avoid non-differentiable \"renderer\" is a novel approach as far as I know. \n\nPros:\n  Differentiable drawing networks are underexplored in our community.\n\nCons:\n  It failed to show the excellency over pixel-wise generation methods and limited to simple visual elements, line drawings or box generations. This work does not explore \"brush strokes\" in paintings.\n\n\nMinor comments:\n\n- In Related Work, the inline citation should be \"Simhon & Dudek (2004)\" instead of \"(Simhon & Dudek, 2004)\", and this may apply to the others.\n\n- In Figure 2, the Hint should be x_n, the current state, or target image X for regeneration (X' for translation)?\n\n- In 4.1, a typo, \"Out state consists of\" to \"Our state consists of\".", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}