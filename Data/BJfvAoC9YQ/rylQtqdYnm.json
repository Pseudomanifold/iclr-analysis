{"title": "The work present a framework for dealing with life long learning, yet it violates two important constraints which every life long learner has to obey: limited memory and computation. ", "review": "Summary:\n a method is presented for on-going adaptation to changes in data, task or domain distribution. The method is based on adding, at each timed step, an additional network module transforming the features from the previous to the new representation. Training for the new task/data at time t relies on re-training with all previous data, stored as intermediate features. The method is shown to provide better accuracy than na\u00efve fine tuning, and slightly inferior to plain re-training with all the data.\nWhile the method is presented as a solution for life long learning, I think it severely violates at least two demands from a feasible solution: using finite memory and using finite computational capacity (i.e. a life-long learning cannot let memory or computation demands to rise linearly with time). Contrary to this, the method presented induces networks which grow linearly in time (in number of layers, hence computation requirements and inference time), and which use a training set growing indefinitely, keeping (representations of) all the examples ever seen so far. If no restrictions on memory and computation time are given, full retraining can be employed, and indeed it provides better results that the suggested method. In the bottom line, I hence do not see the justification for using this method, either as a life-long learner or in another setting.\n\nPros:\n+ the method shows that for continuous adaptation certain representations can be kept instead of the original examples \nCons:\n- The method claims to present a life long learning strategy, yet it is not scalable to long time horizon (memory and inference costs rise linearly with time)\n- Some experiments are not presented well enough to be understood.\n\nMore detailed comments:\nPage 3:\n-\tEq. 2 is not clear. It contains a term \u2018classification loss\u2019 and \u2018feature_loss\u2019 which are not defined or explained. While the former is fairly standard, leaving the latter without definition makes this equation incomprehensible. \no\tI later see that eq. 7 includes the details. Therefore eq.2 is redundant. \nPage 4:\n-\tEq. 5 seems to be flawed, though I think I can understand what it wants to say. Specifically, it states two sets: one of examples (represented by the previous feature extractor) and one of labels (of all the examples seen so far). The two sets are stated without correspondence between examples and labels \u2013 which is useless for learning (which requires example-label correspondence). I think the intention was for a set of (example, label) pairs, where the examples are represented using feature extractor of time t-1.\n-\tAlgorithm 1 seems to be a brute force approach in which the features of all examples from all problems encountered so far are kept (with their corresponding labels). This means keeping an ever growing set of examples, and training repeatedly at each iteration on this set. These are not realistic assumptions for a life-long learner with finite capacity of memory and computation.\no\tFor example, for the experiment reported at page 6, including 25 episodes on MNist, each feature transformer is adding 2 additional FC layers to the network. This leads to a network with >50 FC layers at time step 25 \u2013 not a reasonable and scalable network for life ling learning\nPage 6:\n-\tThe results show that the feature transformer method achieve accuracy close to cumulative re-training, but this is not too surprising, since feature transformer indeed does cumulative re-training: at each time step, it re-trains the classifier (a 2 stage MLP) using all the data at all times steps (i.e. cumulative retraining). The difference from pure cumulative re-training, if I understand correctly, is that the cumulative re-training is done not with the original image representations, but with the intermediate features of time t-1. What do we earn and what do we loose from this? If I understand correctly, we earn that the re-training is faster since only a 2-layer MLP is re-trained instead of the full network. We loose in the respect that the model gorws larger with time, and hence inference becomes prohibitively costly (as the network grows deeper by two layers each time step). Again, I do not think this is a practical or conceptual solution for life long learning.\n-\tThe experiment reported in figure 3 is not understandable without reading Lopez-Paz et al., 2017 (which I didn\u2019t). the experiment setting, the task, the performance measurements \u2013 all these are not explained, leaving this result meaningless for a stand-alone read of this paper.\n-\tPage 8: it is stated that \u201cwe only store low dimensional features\u201d. However, it is not reported in all experiment exactly what is the dimension of the features stored and if they are of considerably lower dimension than the original images. Specifically for the MNIst experiments it seems that feature stored are of dimension 256, while the original image is of dimension 784 \u2013 this is lower, but no by an order of magnitude (X10).\n-\tThe paper is longer than 8 pages.\n", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}