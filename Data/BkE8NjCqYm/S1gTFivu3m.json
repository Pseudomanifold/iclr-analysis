{"title": "A thorough analysis of (and two heuristic solutions to) the failures of beam search when applied to modern neural models", "review": "Pros:\n- The paper generalizes upon past observations by Ott et al. that NMT models might decode \"copies\" (of the source sentence) when using large beam widths, which results in degraded results. In particular, the present paper observes similar shortcomings in two additional tasks (summarization and captioning), where decoding with large beam widths results in \"training set predictions.\" It's unclear if this observation is novel, but in any case the connection between these observations across NMT and summarization/captioning tasks is novel.\n- The paper draws a connection between the observed degradation and \"label bias\", whereby prefixes with a low likelihood are selected merely because they lead to (nearly-)deterministic transitions later in decoding.\n- The paper suggests two simple heuristics for mitigating the observed degradation with large beam widths, and evaluates these heuristics across three tasks. The results are convincing.\n- The paper is very well written. The analysis throughout the paper is easy to follow and convincing.\n\nCons:\n- Although the analysis is very valuable, the quantitive impact of the proposed heuristics is relatively minor.\n\nComments/questions:\n- In Eq. 2, consider using $v$ or $w$ for the max instead of overloading $y$.\n- To save space, you might compress Figure 1 into a single figure with three differently-styled bars per position that indicate the beam width (somewhat like how Figure 3 is presented). You can do this for Figure 2 as well, and these compressed figures could then be collapsed into a single row.\n- In Section 5, when describing the \"Discrepancy gap\" constraint, you say that you \"modify Eq. 3 to include the constraint\", but I suspect you meant that you modify Eq. 1 to include this constraint.\n- In Table 4, why didn't you tune $\\mathcal{M}$ and $\\mathcal{N}$ separately for each beam width?", "rating": "7: Good paper, accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}