{"title": "A formal framework for representation learning.", "review": "This paper builds on the (Alemi et al 2018) ICML paper and presents a formal framework for representation learning. The authors use a graphical model for their representation learning task and use basic information theoretic inequalities to upper-bound their measure of performance which is a KL divergence. The authors then define the optimal frontier which corresponds to the lowest possible upper-bound and write it as an optimization problem. Written with Lagrange multipliers, they obtain several known cost functions for different particular choices of these parameters.\nThen the authors make a parallel with thermodynamics and this part is rather unclear to me. As it is written, this section is not very convincing:\n- section 4.1 after equation (27) which function is 'smooth and convex'? please explain why.\n- section 4.1 '...the actual content of the law is fairly vacuous...'\n- section 4.2 the explanation of equation (30) is completely unclear to me. Please explain better than 'As different as these scenarios appear (why?)...'\n- section 4.2 'Just as in thermodynamics, these susceptibilities may offer useful ways to characterize...'\n- section 4.2 'We expect...'\n- section 4.3 ends with some unexplained equations.\nAs illustrated by the examples above, the reader is left contemplating this formal analogy with thermodynamics and no hint is provided on how to proceed from here. \n\n", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}