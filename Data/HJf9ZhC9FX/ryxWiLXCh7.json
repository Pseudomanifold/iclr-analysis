{"title": "Very insightful paper but some essential details are missing. ", "review": "This is a very interesting paper and it suggests a novel way to think of \"implicit regularization\". The power of this paper lies in its simplicity and its inspiring that such almost-easy arguments could be made to get so much insight. It suggests that minimizers of the Bregrman divergence are an alternative characterization of the asymptotic end-points of  \"Stochastic Mirror Descent\" (SMD) when it converges. So choice of the strongly convex potential function in SMD is itself a regularizer!  \n\nIts a very timely paper given the increasing consensus that \"implicit regularization\" is what drives a lot of deep-learning heuristics. This paper at its technical core suggests a modified notion of Bregman-like divergence (equation 15) which on its own does not need a strongly convex potential. Then the paper goes on to show that there is an invariant of the iterations of SMD along its iterations which involves a certain relationship (equation 18) between the usual Bregman divergence and their modified divergence. I am eager to see if such relationships can be shown to hold for more complicated iterative algorithms! \n\nBut there are a few points in the paper which are not clear and probably need more explanation and let me list them here. ( and these are the issues that prevent me from giving this paper a very high rating despite my initial enthusiasm )\n\n1. \nCan the authors explain how is the minimax optimality result of Theorem 6 (and Corollary 7) related to the main result of the paper which is probably Proposition 8 and and 9? Is that minimax optimiality a different insight separate from the main line of the arguments (which I believe is Proposition 8 and 9)? \n\n2.\nIs the gain in Proposition 9 over Proposition 8 is all about using loss convexity to ensure that the SMD converges and w_\\infty exists? \n\n3. \nThe paper has highly insufficient comparisons to many recent other papers on the idea of \"implicit bias\" like, https://arxiv.org/abs/1802.08246, https://arxiv.org/abs/1806.00468 and https://arxiv.org/abs/1710.10345. It seems pretty necessary that there be a section making a detailed comparison with these recent papers on similar themes. ", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}