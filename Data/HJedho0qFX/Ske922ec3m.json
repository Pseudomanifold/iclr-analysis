{"title": "Too incremental", "review": "The authors apply an existing method (mainly 2 vs 2 test) to explore the representations learned by CNNs both during/after training. \n\n## Strength\n\nThe analysis of misclassification and adversarial examples is interesting. The authors also propose potential ways of improving the robustness of DNNs for adversarial examples. \n\n\n## Weakness\n1. It seems to me that the methodological novelty is limited, which mainly follows [The Emergence of Semantics in Neural Network Representations of Visual Information](http://aclweb.org/anthology/N18-2122). For example this paper extensively applies 2 vs. 2 test which was established in previous works. \nFurthermore, the first claimed contribution of 5 times more concepts than previous work does not result in any significant difference from the previous approaches. \n\n2. The analysis presented in this work does not really give new insights. For example, isn\u2019t \u201ca network fitting to noise does not learn semantics\u201d obvious to the community?\n\nSome of the subsection titles are misleading. For example in Section 5, the claim of \u201cCNNs Learn Semantics from Images\u201d is mainly proposed in a previous work, but the way of presentation sounds like this is a contribution of this work. \n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}