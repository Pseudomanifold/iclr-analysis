{"title": "Official review", "review": "\nThe paper proposes a detailed empirical evaluation of the trade-offs achieved by various convolutional neural networks on the super resolution problem. The paper provides an extensive evaluation of different architectural changes and the trade-off between savings in terms of memory and computational cost and performance, measured in terms of PSNR and SSIM.\n\nThis is an empirical paper, thus it does not provide technical contributions. I do think that the insights obtained from such an empirical evaluation could be of interest for practitioners and researchers working on the problem. My main concern is the method only evaluates the trade-offs between model efficiency (in terms of memory and/or computation) and performance measured using metrics that are known to not be well correlated with perceptual quality. Thus it is not obvious to me that the insights obtained in this work would translate to the other case.\n\nIt is well known that PSNR favors blurry solutions over perceptually more appealing solutions. This comes from the fact that there is no information in the low resolution image to produce the missing high resolution details. Filling up plausible details in a way that is different from the original image would lead to high PSNR. Models that treat the super resolution problem as a regression task using similarity in pixel space, tend to produce blurry solutions and require very large models to improve the score.  \n\nIn recent years, many works have been studying the use of perceptual losses to mitigate this issue or simply treating the super resolution problem as conditional generative modeling.  For instance, models using L2 losses in a perceptually more relevant (or learned) feature spaces [A, B], or including GAN losses [C, D] (to list a few). To my knowledge, these models are the current state of the art in terms of perceptual quality. This has been evaluated empirically via perceptual tests [D].  \n\nThis line of work needs to be cited. In my view, the paper needs to provide a detailed justification on why models using these losses are not considered. Would the conclusions drawn on this work transfer to that setting? Furthermore, it would be good to perform perceptual tests to perform this evaluation. It would be good to provide some canonical examples in the appendix.\n\nThe overall writing of the paper could be improved. Several sentences are difficult to read, due to typos or the construction of the sentences. The paper evaluates many architectural modifications proposed by other works. It would be good to add an appendix with a small description of what these are. This would make the paper self-contained an easier to read (I had too look up a few of them).\n\nThe authors mentioned that they first train models for scaling factor of x2 and then use them for training settings higher magnification. How is this exactly done? Please provide details.\n\nI am curious of weather using some for of distillation techniques would be useful here.\n\nDid you try scaling factors larger than x4? Scaling factors of x2 does not seem very relevant, as simpler methods can achieve already quite competitive results (such as simple interpolation methods)\n\nThe authors seem to be citing Zhang et al (2018) as a reference to attention mechanisms. To my knowledge the paper that proposed these mechanisms is [E].\n\nThe citation style is not used properly throughout the manuscript. As an example:\n\n\u201c\u2026 proposed in StrassenNets Tschannen et al (2017).\u201d Should be \u201c\u2026 proposed in StrassenNets (Tschannen et al, 2017).\u201d Or \u201c\u2026 proposed in StrassenNets proposed by Tschannen et al (2017).\u201d\n\n[A] Johnson, J. et al. \"Perceptual losses for real-time style transfer and super-resolution.\"\u00a0ECCV, 2016.\n[B] Bruna, J. et al \"Super-resolution with deep convolutional sufficient statistics.\"\u00a0ICLR 2016.\n[C] Ledig, C. et al. \"Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network.\"\u00a0CVPR. Vol. 2. No. 3. 2017.\n[D] S\u00f8nderby, C. K., et al. \"Amortised map inference for image super-resolution.\"\u00a0arXiv preprint arXiv:1610.04490(2016).\n[E] Bahdanau, D. et al \"Neural machine translation by jointly learning to align and translate.\"\u00a0arXiv (2014).", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}