{"title": "New smoothness constraint to Cycle-GAN formulation. ", "review": "Summary: The paper proposes a new smoothness constraint in the original cycle-gan formulation. The cycle-gan formulation minimizes reconstruction error on the input, and there is no criterion other than the adversarial loss function to ensure that it produce a good output (this is in sync with the observations from Gokaslan et al. ECCV'18 and Bansal et al. ECCV'18). A smoothness constraint is defined across random patches in input image and corresponding patches in transformed image. This enables the translation network to preserve edge discontinuities and variation in the output, and leads to better outputs for medical imaging, image to labels task, and horse to zebra and vice versa.\n\nPros: \n\n1.  Additional smoothness constraints help in improving the performance over multiple tasks. This constraint is intuitive.\n\n2. Impressive human studies for medical imaging.\n\n3. Improvement in the qualitative results for the shown examples in paper and appendix.\n\nThings not clear from the submission: \n\n1. The paper is lacking in technical details: \n\na. what is the patch-size used for RGB-histogram?\n\nb. what features or conv-layers are used to get the features from VGG (19?) net? \n\nc. other than medical imaging where there isn't a variation in colors of the two domains, it is not clear why RGB-histogram would work?\n\nd. the current formulation can be thought as a variant of perceptual loss from Johnson et al. ECCV'16 (applied for the patches, or including pair of patches). In my opinion, implementing via perceptual loss formulation would have made the formulation cleaner and simpler? The authors might want to clarify as how it is different from adding perceptual loss over the pair of patches along with the adversarial loss. One would hope that a perceptual loss would help improve the performance. Also see, Chen and Koltun, ICCV'17.\n\n2. The proposed approach is highly constrained to the settings where structure in input-output does not change. I am not sure how would this approach work if the settings from Gokaslan et al. ECCV'18 were considered (like cats to dogs where the structure changes while going from input to output)? \n\n3. Does the proposed approach also provide temporal smoothness in the output? E.g. Figure-6 shows an example of man on horse being zebrafied. My guess is that input is a small video sequence, and I am wondering if it provides temporal smoothness in the output? The failure on human body makes me wonder that smoothness constraints are helping learn the edge discontinuities. What if the edges of the input (using an edge detection algorithm such as HED from Xie and Tu, ICCV'15) were concatenated to the input and used in formulation? This would be similar in spirit to the formulation of deep cascaded bi-networks from Zhu et al . ECCV'16.", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}