{"title": "interesting approach for a very specific task", "review": "This paper tackles the task of content transfer. For a given type of images (frontal face shots), the goal is to transfer a particular localized property (e.g. glasses or facial hair) extracted from one image to another image of the same type (difference face). This is also known as the problem of guided image-to-image translation. \nThe problem is formalized as the one of learning to map two different domains, one domain being composed of images with the property/attribute of interest, the other one containing images without it. The problem is said to be \u2018unsupervised\u2019, i.e. there is no pairwise correspondences between images of the two domains (with/without attributes).\nThe novelty of the approach lies on\n-\tthe loss, which is composed of three terms: two reconstruction losses and a domain confusion loss\n-\tthe overall architecture and in particular the fact that images are represented as a combination of the output of two encoders: one encodes the face and the other encodes the property (e.g. glasses).\n\nOverall comments:\n+ a theoretical part discusses generalization bounds and the emergence of disentangled representations\n+ visual results are appealing showing the suitability of the method to the considered task\n- the discussion of the advantages of the proposed method could be improved\n- the motivation for some of the experimental results is unclear (choice of experimental protocol and baselines). \n- the scope of the method seems limited\n\nDetailed comments:\n\nI personally like the described model. The disentanglement mechanism is intuitive to understand, and seems well suited for this particular task, as qualitative evidence suggests. I am not sure if this approach would be applicable beyond the very specific scenario considered in the paper. \n\nThe paper emphasizes that the strength of the method lies on its simplicity w.r.t. competitors, and its better results. These two aspects could be better discussed. \n\nSimplicity: \nIn several places the paper claims that the proposed approach is considerably simpler. Some parts hint to criteria for the \u2018complexity\u2019 comparison, such as Table 1 or a few sentences (e.g. \u201cthis allows us to train with many less parameters and without the need to applying excessive tuning\u201d). It would be more convincing to have a dedicated discussion of the practical advantages of the simplicity claimed by this method, discussing e.g. training/testing time, memory footprint of the models, convergence properties, stability, etc. \n\nComparison: \nThe chosen baselines, i.e. MUNIT and DRIT are experimentally shown to perform poorly on the considered task. Yet although these methods were also developed for guided image translation, they were designed for a rather different application: style transfer. I am not sure these comparisons bring much insight on the performance of the method.\nExperiments are conducted for a very specific task, on a single dataset. Would the method have broader application?\n\nExperimental protocol:\nI understand that such an approach is difficult to evaluate quantitatively but I am not sure what there is to learn from experiments reported in Table 3, as there is no point of comparison on this task. This could be clarified. \n\nAdditional comments:\n-\tThe paper relies on the assumption that the distribution of persons with sunglasses and that of persons without them is the same, except for the sunglasses. This sounds like a strong requirement for the data used to train the network; it would be interesting to discuss the practical impact of this assumption, especially on the data requirement for the method to perform well\n-\tI found Figure 1 quite useful. A visual representation of the architecture and its associated description help follow the technical part. \n-\tI got confused with some of the claims in section 4.2. More generally, I found the technical part hard to follow.\n-\tThe user study seems small: only 10 pairs of images are considered. How were those pair chosen? Is the set representative?\n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}