{"title": "A small idea, with poor comparisons", "review": "\nSummary:\n\nThis paper presents a simple auxiliary loss term for model-based RL that attempts to enforce consistency between observed experience trajectories and hallucinated rollouts.  Simple experiments demonstrate that the constraint slightly improves performance.\n\nQuality:\n\nWhile I think the idea of a consistency constraint is probably reasonable, I consider this a poorly executed exploration of the idea.  The paper makes no serious effort to compare and contrast this idea with other efforts at model-based RL.  The most glaring omission is comparison to very old ideas (such as dyna) and new ideas (such as imagination agents), both of which they cite.\n\nClarity:\n\nThe paper is reasonably clear, although there are some holes.  For example, in the experimental section, it is unclear what model-based RL algorithm is being used, and how it was modified to support the consistency constraint.  (I did not read the appendix).\n\nOriginality:\n\nIt is not clear how novel the central idea is.\n\nSignificance:\n\nThis idea is not significant.\n\nPros:\n+ A simple, straightforward idea\n+ A good topic - progress in model-based RL is always welcome\n\nCons:\n- Unclear how this is significantly different from other related work (such as imagination agents)\n- Experimental setup is poorly executed.\n  - Statistical significance of improvements is unclear\n  - No attempt to relate to any other method in the field\n  - No explanation of what algorithms are being used\n", "rating": "3: Clear rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}