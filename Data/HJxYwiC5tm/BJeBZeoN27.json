{"title": "Although the general idea is interesting, experimental evaluation is not convincing. Similarly, some explanations like the photographer's bias as reason for susceptability to very small image transformation is not entirely convincing. ", "review": "Paper summary: \n\nAs is made clear in the title, this paper sets out to answer the following question: \u201cWhy do deep convolutional networks generalize so poorly to small image transformations?\u201d. It focuses on natural image transformations on translation and scaling (rotation is missing though).\n\nThe paper proposes two main explanations: \n-\tStrided convolution, called subsampling in the paper, ignores the classical sampling theorem,\n-\tCNNs will not learn invariance because of the (photographers') biases contained in the datasets.\n\nOn a general level, the paper is a good read, it is well written and the figures clearly convey the message they\u2019re intended to. Adversarial attacks and robustness of CNNs in general is a very interesting and important topic in ML. The originality of this work is in the approach of the problem, the paper tries to explain the reasons why CNNs are vulnerable. Related works put more emphasis on coming up with novel attacks/defense strategies. Considering natural attacks as done in this submission is particularly interesting as it is probably a more surprising shortcoming of CNNs compared to optimally designed attacks or highly unnatural perturbations. The argument about subsampling (stride) being the reason of not having translational invariance is nice, especially the theoretical insight with the Shannon-Nyquist theorem and the more figurative example on part detectors. There are nevertheless a few major concerns about this work:\n\nMajor Concerns:\n\nTheoretical arguments:\nThe theoretical argument made in this paper is interesting but to make the point stronger a more in-depth explanation would be needed.\n-\tThe step from Eq (2) to Eq (3) is not entirely clear \u201cK does not depend on x_i\u201d, maybe one extra sentence to explain this step would be useful. \n-\tTerms introduced such as the basis function B and the set of transformations T could be better defined.\n-\tFor the extension to other types of transformations \u201cWhile the claim focuses on global translation, it can also be extended to piecewise constant transformations.\u201d it would be important to point out what type of natural transformations can be included in this set.\n\nEmpirical evidence:\nExperiments are not fully convincing. Additional empirical evidence would be beneficial and necessary to support the claims of this:\n-\t\u201cA natural criticism of these results is that they are somehow related to the image resizing and inpainting procedures that we used.\u201d This is a very good point and the authors following arguments are not fully convincing. Results with different transformation procedures mentioned in the rest of the paragraph (and probably more) should be included to convince the reader.\n-\tThe theoretical argument that translation invariance is not guaranteed because of the stride (subsampling) is not fully convincing and needs further explanation and experimental verification. In fact, feature maps of the CNNs that the authors consider do indeed contain many high frequencies.\n-\tThe argument made in part 4 about the photographer\u2019s bias seems valid for general natural transformations, but it does not apply to small transformations such as 1-pixel translations presented in the paper. Also, evidence that datasets without (or less) photographers' bias are less susceptible to natural attacks would make the argument in the paper a lot stronger. \n-\tWhen using 6x6 avg pooling for the VGG16 architecture \u201drecognition performance decreases somewhat\u201d . Results are only preliminary in the paper, but this statement needs a more thorough experimental backing. It should come with convincing quantitative evidence.\n-\tPlease include some results or citation on other work about test time augmentation to support the statement \u201cstill only provides partial invariance\u201d.\n\nReferences and phrasing:\nGenerally previous work is well referenced in this paper, although there are some formulations that can be slightly modified to make a clear distinction between what is novel and what is previous work:\n-\tAs is very well shown in the introduction, there is a lot of work on generating adversarial examples that drastically change the output of a CNN. This should be made clear in the abstract, in fact the sentence \u201cIn this paper we show that modern CNNs [...] also happens with other realistic small image transformations\u201d  seems to indicate that this is the novel work in the paper. This is also why I believe the first sentence \u201cDeep convolutional network architectures are often assumed to guarantee generalization for small image translations and deformations.\u201d is somewhat contestable. \n-\t\u201cWe find that modern deep CNNs are not invariant to translations, scalings and other realistic image transformations\u201d as the paper points out earlier this is not a novel finding, so I would use a formulation that makes that clear and gives more emphasis to your own arguments as of why this happens.\n\nFurther Comments :\n-\tPart 5 \"Implications for Practical Systems\" could be moved to discussion as there is no new point and it seems more a reflection on what was already stated.\n-\tThe final sentence of the abstract \u201cTaken together our results suggest that the performance of CNNs in object recognition falls far short of the generalization capabilities of humans.\u201d is not necessary, this is clearly true but it isn\u2019t really contested in the ML community.\n-\t\u201cdespite the architecture being explicitly designed to provide such invariances\u201d I agree that this has motivated the use and design of CNNs in the first place, but modern architectures are mostly designed to surpass the results on the common benchmarks rather than to provide such invariances.\n-\t\u201djaggedness is greater for the modern, deeper, networks compared to the less modern VGG16 network\u201d might be worth interesting to consider if the residuals have anything to do with it.\n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}