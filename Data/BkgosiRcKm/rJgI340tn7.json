{"title": "Combination of known ideas, hard to read", "review": "This paper proposes deep recurrent GP models based on the existing DRGP framework, two works on sparse spectrum approximation as well as that of inducing points. In these models, uncertainty is propagated by marginalizing out the hidden inputs at every layer.\n\nThe authors have combined a series of known ideas in the proposed work. There is a serious lack of discussion or technical insights from the authors for their technical formulations: in particular, what are the non-trivial technical challenges addressed in the proposed work? Furthermore, the authors are quite sloppy in referencing equations and inconsistent in the use of their defined notations and acronyms. I also find it hard to read and understand the main text due to awkward sentence structures.\n\nHave the authors revealed their identity on page 2 of the paper? I quote: \"We refer to the report Foll et al. (2017) for a detailed but preliminary formulation of our models and experiments.\" and \"DRGP-(V)SS code available from http://github.com/RomanFoell/DRGP-VSS.\"\n\n\n\nDetailed comments are provided below:\n\nFor the first contribution stated by the authors, what are the theoretical and practical implications of the different regularization terms/properties between the lower bounds in equations 10 vs. 8? These are not described in the paper.\n\nCan the authors provide a detailed derivation of DVI for equation 13 as well as for the predictive distributions in Sectio 6.3.5?\n\nCan the authors provide a time complexity analysis of all the tested deep recurrent GPs?\n\n\nWould the authors' proposed approach be able to extend the framework of Hoang et al. (2017) (see below) that has generalized the SS approximation of Lazaro-Gredilla et al. (2010) and the improved VSS approximation of Gal & Turner (2015)?\n\nHoang, Q. M.; Hoang, T. N.; and Low, K. H. 2017. A generalized stochastic variational Bayesian hyperparameter learning framework for sparse spectrum Gaussian process regression. In Proc. AAAI, 2007\u20132014.\n\n\n\nMinor issues:\nJust below equation 6, equation 9, and throughout the entire paper, the authors need to decide whether to italicize their notations in bold or not.\n\nEquations are not properly referenced in a number of instances.\n\nThe authors have used their commas too sparingly, which makes some sentences very hard to parse.\n\nWhat is the difference between REVARB-(V)SS(-IP), DRGP-(V)SS(-IP), and DRGP-VSS-IP?\n\nEquation 7: LHS should be conditioned on U.\nPage 4:  (V)SSGP does not have the same...\nEquation 8: q_a and q_Z should be placed next to the expectation.\nPage 4: choosen?\nPage 5: will makes it possible?\nPage 5: DRGP-SSGP, -VSSGP, -SSGP-IP, -VSSG-IP?\nPage 5: to simplify notation, we write h^{L+1}_{Hx+1:} = y_{Hx+1:}? Such a notation does not look simplified.\n\nEquation after equation 12: On LHS, should U^(l) be a random variable?\n\nPage 17: Should the expressions begin with >=?\n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}