{"title": "End-to-end task oriented system: An encoder-decoder approach with a shared external knowledge base", "review": "This is, in general, a well-written paper with extensive experimentation. \n\nThe authors tried to describe their architecture both with equations as well as graphically. However, I would like to mention the following: \n\nIn Section 2.1 I am not sure all the symbols are clearly defined. For example, I could not locate the definitions of n, l etc. Even if they are easy to assume, I am fond of appropriate definitions. Also, I suspect that some symbols, like n, are not used consistently across the manuscript.\n\nI am also confused about the loss function. Which loss function is used when?\n\nI am missing one more figure. From Fig 2 it's not so straightforward to see how the encoder/decoder along with the shared KB work at the same time (i.e. not independently)\n\nIn Section 2.3, it's not clear to me how the expected output word will be picked up from the local memory pointer. Same goes for the entity table.\n\nHow can you guarantee that that position n+l+1 is a null token?\n\nWhat was the initial query vector and how did you initialise that? Did different initialisations had any effect on performance?\n\nIf you can please provide an example of a memory position.\n\nAlso, i would like to see a description of how the OOV tasks are handled.\n\nFinally, your method is a NN end-to-end one and I was wondering how do you compare not with other end-to-end approaches, but with a traditional approach, such as pydial?\n\n\nAnd some minor suggestions:\n\nNot all the abbreviations are defined. For example QRN, GMN, KVR. It would also be nice to have the references of the respective methods included in the Tables or their captions.\n\nParts of Figs. 1&2 are pixelised. It would be nice to have everything vectorised.\n\n I would prefer to see the training details (in fact, I would even be favorable of having more of those) in the main body of the manuscript, rather than in the appendix.\n\nThere are some minor typos, such as \"our approach that utilizing the recurrent\" or \"in each datasets\"", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}