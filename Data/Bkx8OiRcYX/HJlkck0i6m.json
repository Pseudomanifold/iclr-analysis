{"title": "review", "review": "The paper presents a new loss function for survival analysis based\non proper scoring functions to less then penalty wrong predictions\nthat are confident make under the log-loss. The paper is interesting\nhowever the benefit over the traditional maximum likelihood estimator is small and the writing needs a bunch of work. I would also like to see an eval on data with far less censoring.\n\n\nA couple of comments\n\n1) EHRs have only been generally adopted in the last couple of years. Only A couple of places have more.\n\n2) Binary classifier citation on page 1 (Avati, Rajkomar) should also cite the plethora of recent machine\nlearning for healthcare results in this field\n\n3) Likelihoods are calibrated (as is any error measured by a proper scoring loss)\n\n4) There are other methods to fit survival functions such as \"Adversarial Time-to-Event Modeling\"\nby Chapfuwa in ICML 2018. There are probably also moment methods\n\n5) I think the evaluation might also want utilty because sharpness is a utility claim\n\n6) Some of the statements in the writing are funny like probability distributions are uniquely identified by parameters. I'm not sure this is true with neural nets with symmetries. The paper doesn't need such claims\n\n7) Instead of log-normals, I would like to see something nonparametric like the categoricals\u00a0 used for maximum likelihood estimation without latents in the limiting model in \"Deep Survival Analysis: Missingness and Nonparametrics\" by Miscouridou at MLHC 2018\n", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}