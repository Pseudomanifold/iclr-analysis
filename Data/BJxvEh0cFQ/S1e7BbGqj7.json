{"title": "Interesting idea and fair evaluation. Accept with minor changes.", "review": "Summary: the paper introduces a new way of fine-tuning neural networks. Instead of re-training the whole model or fine-tuning the last few layers, the authors propose to fine-tune a small set of model patches that affect the network at different layers. The results show that this way of fine-tuning is superior to above mentioned typical ways either in accuracy or in the number of tuned parameters in three different settings: transfer learning, multi-task learning and domain adaptation.\n\nQuality: the introduced way of fine-tuning is interesting alternative to the typical last layer re-training. I like that the authors present an intuition behind their approach and justify it by an illustrative example. The experiments are fair, assuming the authors explain the choice of hyper-parameters during the revision.\n\nClarity: in general the paper is well-written. The discussion of multi-task and domain adaptation parts can be improved though.\n\nOriginality: the contributions are novel to my best knowledge.\n\nSignificance: high, I believe the paper may facilitate a further developments in the area.\n\nI ask the authors to address the following during the rebuttal stage:\n* explain the choice of the hyper-parameters of RMSProp (paragraph under Table 1).\n* fix Figure 3, it's impossible to read in the paper-printed version\n* explain how the average number of parameters per model in computed in Tables 4 and 5. E.g. 700K params/model in the first column of Table 4 is misleading - I suppose the shared parameters are not taken into account. The same holds for 0 in the second column, etc.\n* add a proper discussion for domain adaptation part. The simple \"The results are shown in Table 5\" is not enough. \n* consider leaving the discussion of cost-efficient model cascades out. The presented details are too condensed and do not add value to the paper.\n* explain how different resolutions are managed by the same model in the domain adaptation experiments.", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}