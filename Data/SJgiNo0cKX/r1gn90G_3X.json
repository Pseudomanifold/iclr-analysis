{"title": "The topic is interesting, but the submission is still a draft", "review": "\n# Summary\nThis work deals with a computer vision task specific to autonomous vehicles, namely detection of lane markings on the road. The authors propose an encoder-decoder CNN architecture  (typically used for semantic segmentation) for which a parts of the encoder and the encoder are instanced several times (with different weights) in order to better capture the semantic and spacial information from intermediate feature maps. The method is tested on the recent Lane Detection dataset (Pan et al.) and report qualitative results.\n\n\n# Paper strengths\n- the paper deals with a topic of interest for the autonomous driving community\n- the authors identify a flaw in the IoU accuracy evaluation metric for lane detection\n\n# Paper weakness\n- The paper could be written better. It seems unfinished and some additional proof-reading is necessary to correct the multiple typos across the paper\n\n- There are no quantitative results and no comparisons with baselines and related works, making it difficult to evaluate the performances of this work.\n\n- The authors mention that the current IoU accuracy evaluation metric is flawed on some cases and then propose scanning manually results from 500 prediction maps and report results on that. There is no baseline or other related method considered for this evaluation. Also the original dataset from Pan et al. has ~88k train images, ~9.5k validation images and ~35k test images. It is not clear from which set where the 500 images taken and how representative they are for the entire dataset\n\n- The structure of the proposed architecture is not clear, in particular the merging of the feature maps across multiple encoders. From the diagram in Figure 2 b) it seems that the feature maps are transferred to the neighbour encoder/decoder branch similarly with RNNs. Is this right or only the features maps from the first branch are transferred? Furthermore, the merging is done by element-wise addition or concatenation?\nGiven the application domain, an important aspect is the computational complexity of the proposed architectures. I would welcome such an analysis in the current work as well.\n\n- I enumerate a few other unclear aspects and improvable points in the paper:\n  + why standard encoder-decoder architecture are limited to small receptive field (cf. Section 2), while this approach is not and can use large kernels? Do the authors use kernels of different sizes in the branch? This problem is usually addressed with dilated convolutions or parallel sub-networks of different kernel sizes like in Inception. \n  + there is no description of the task and of the meaning of the 4 lane markings. \n  + in Section 1 the authors mention that \"CNNs show the robust capacity to capture object localization on image classification ... and object detection, but less explored on semantic image segmentation due to strong prior information is needed.\". This is not true as semantic segmentation is addressed by means of CNNs since several years already by most of community.\n  + why the label of lane pixels is set to 0.5? Such problems are typically addressed with binary-cross entropy and the output of the sigmoid is used as classification score at test time.\n\n# Recommendation\nThis paper deals with an interesting task, but it's still in a rather draft state. There are several shortcomings of the work that I've mentioned above. I recommend the submission for rejection.\n", "rating": "2: Strong rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}