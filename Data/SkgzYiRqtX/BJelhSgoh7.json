{"title": "The paper describes a Graph NN method for information extraction from sentences. Some interesting innovations in the paper. The evaluation analysis and the comparison with other models are still preliminary.", "review": "The paper describes a Graph NN method for information extraction from sentences. The objective is to label couples of entities (token or multiple tokens)  according to a given set of relations. The GNN processes token representations through one or more layers and a final classification layer scores the relations between entity couples in the sentence. Parameters of GNN \u2013 transition matrices between layers operating on node representations \u2013 are learned from the data.  Experiments are performed on different variants of an extraction corpus, for the task consisting in extracting all the relations between identified token couples in a sentence. \n\nThe description is clear. The main original contribution is the scheme used for learning the transition matrices between layers from the text input.  Overall, the proposed system is a new mechanism for classifying relations between items in a sentence using GNN. Note that the current title is misleading w.r.t. this goal.\nThe authors claim that the model allows relational reasoning on text. This is somewhat exaggerated, the model performs relation classification and that\u2019s it. There is nothing indicating any form of reasoning and this argument could be removed without reducing the value of the paper.\n\nThe experiments show that the proposed model outperforms, on this classification task baselines, including a recent model. The analysis here should be developed and improved: as it is, it does not provide much information.\nBelow are some questions concerning this evaluation.\nWhy not using mono sentence evaluation on the two distantly labeled datasets? \nThe performance of the two CNN baselines on the hand labeled dataset are extremely low, what is the reason for that?\nThe improved performance of the proposed model w.r.t. the baselines is attributed to the \u201creasoning\u201d potential of the model, but this explanation falls short. There is no fact in the paper to support this idea, and the Context-aware RE model making use of sentence attention has also the potential of exploiting contextual information and thus might also infer more complex relations. The reason for the improvement has to be found somewhere else.\nOverall, there is some interesting innovation in the paper. The evaluation analysis and the comparison with other models are still preliminary.\n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}