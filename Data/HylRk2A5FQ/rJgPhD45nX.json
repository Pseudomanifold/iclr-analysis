{"title": "Heuristic method without real data application.", "review": "Authors propose a supervised method for predicting adjacency matrix for a set of points. Loss function consists of 4 terms: intersection over union loss with respect to target adjacency, cross entropy loss, symmetry penalty and L2 regularization of parameters. Learning process consists of alternating node feature updates parametrized by GCN-like layers and updates of the adjacency matrix (different across layers).\n\nMy main concern is the heuristic nature of the method without any successful real data application. I do not see this work as impactful or of interest to ICLR community.\n\nDirectly regarding the content I have following comments and questions:\n\nWord \"structure\" seems to be used in several meanings. For example \"We consider the problem of predicting the structure of a given set of points (which we assume are the nodes of a graph) and an initial structure (connections of the points).\" It only becomes somewhat clear later what is actually the learning problem studied in this paper.\n\n\"The learned convolutions\" - convolution is a particular mathematical operation. I believe authors should refer to the weights of their architecture instead.\n\nSymmetry penalty of equation 14 seems unnecessary. When optimizing for symmetric matrix it should be recognized that corresponding symmetric entries are identical variables. Hence it is sufficient, and mathematically appropriate, to correct the gradient computed without symmetric consideration. Correction is simply sum of the gradient with itself transposed (without diagonal entries).\n\n\"We compare against traditional generative models for graphs: mixed-membership stochastic block models (MMSB) \" - could you please elaborate on how you use MMSB for graph generation. The use-case I am familiar with is community detection.\n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}