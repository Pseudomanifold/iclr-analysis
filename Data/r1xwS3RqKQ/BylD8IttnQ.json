{"title": "Differential Equation Networks", "review": "This paper proposes an intriguing idea, that of using solutions to a differential equation as activation functions in a neural network. Coefficients of the differential equation (five parameter equations in implementations done) are trainable, realising different activation functions on different nodes. Back propagation is used with the ADMA optimiser to train the parameters of the DE as well as the remaining weights. What the network implements is shown to achieve universal approximation by considering a second order differential equation producing different sinusoidal functions which can add up to a desired function. The paper is written clearly and easy to follow. The idea is novel. The work is illustrated on three problems: (a) a toy dataset, (b) MNIST classification problem and (c) a regression task from a diabetes problem.\nWhile the idea is novel and the paper is clear, the empirical work presented in the paper does not go far enough to be supportive of its acceptance. Firstly, Tables 1 and 2 do not provide any uncertainty in results. Simply saying accuracy of one method is marginally higher (in the second decimal place in Table 1) than another method is not persuasive. This is particularly so when no training set results are reported. I would strongly urge to report uncertainty coming from cross validation (three fold is too small; the data is large enough to do ten-fold). Second, some sort of error analysis has to be carried out to understand how the improved performance is attributable to the new idea being advanced. Confusion matrices on the classification problem might help. Is there a specific part of the task in which the new method separates characters that the more classic ones fail to do? Similar criticisms apply to the regression task; is the improvement across all examples or localized to some particularly hard ones; this is an issue when comparing (squared) errors because a few outliers can dominate the evaluation/comparison.\nIn summary, the paper has a novel idea, but has to be better developed in its empirical part.    ", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}