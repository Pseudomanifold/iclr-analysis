{"title": "limited novelty", "review": "In this paper, the authors proposed a new domain adaptation setting for adaptation between single source but multiple target domains. To address the setting, the authors proposed a so-called information theoretic approach to disentangle shared and private features and meanwhile to take advantage of the relationship between multiple target domains. \n\nPros:\n- This paper conducts comprehensive empirical studies.\n\nCons:\n- The motivation for this new domain adaptation setting is not clear to me. In the real world, the domain adaptation between multiple source domains and single target domain is in desperate need, as like human beings an agent may gradually encounter many source domains which could altogether benefit a target domain. However, I do not think that the adaptation between single source and multiple targets is intuitively in need.\n- The proposed framework is quite similar to DSN, which limits this work's novelty. Though the authors take a large paragraph to illustrate the connections and differences between this work and DSN, I cannot be convinced. Especially during empirical study, the comparison is not fair. The adapted mp-DSN models multiple encoders for multiple target domains, while it is correct to extend DSN with a shared encoder for multiple target domains just like MDTA-ITA.\n- There are technical flaws. The authors claimed that this work is different from ELBO optimisation, but follows an information theoretical approach. Actually, the right way to optimise the proposed loss in Eqn. (1)(2) is exactly the ELBO. Instead, the authors replace the probability/distribution q(x|z) and q(d|z) with concrete terms, which is technically wrong. such concrete term ||x-F(z;\\phi)|| cannot represent a probability/distribution. \n- In the experiments for feature visualisation, I do not think such comparison with original features makes any sense. The features by DSN which also separates private from shared features  should be compared. \n- The presentation is in a quite poor quality, including many typos/grammatical errors. \n   - The most annoying is the inappropriate citations. Every citation should be included in a brace, e.g. \"the same underlying distribution Sun et al. (2016)\" -> \"the same underlying distribution (Sun et al. (2016))\". Please kindly refer to other submissions to ICLR 2019. \n   -  Typos: in the beginning of Section 2, \"without loss of generalizability\" -> \"without loss of generality\"; in the end of Page 3,  the last equation is not right, where p(y|z_s) should be q(y|z_s).\n   - The font in Table 2 is too small to read. \n", "rating": "6: Marginally above acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}