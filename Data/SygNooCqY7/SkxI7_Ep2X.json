{"title": "Interesting results, but missing comparison to earlier work and questionable theory", "review": "This paper presents a new GAN training objective to stabilize training and prevent mode collapse. The new objective trains the generator and discriminator with multiple scales of fixed additive noise, neural network generated noise, and no noise. They experimentally demonstrate the robustness of their approach to hyperparameters, perform extensive ablation studies, and show improvements in FID and IS over prior approaches on CIFAR-10 and CelebA.\n\nOverall, this was a clear paper that presented an interesting idea of combining multiple scales and types of noise to stabilize GAN training. The experiments and ablations were far more thorough than most GAN papers and helped to show which components of the model were most important. However, I have two major concerns: (1) there is a very related and uncited paper from ICML 18 with a similar name and method: Tempered Adversarial Networks from Sajjadi et al., and (2) there is a gap between the theory and practice, in particular the discriminator should depend on the noise being added and vary for different noise types. Given these two concerns, I cannot recommend acceptance at this time. If the authors can clear up the relationship between their approach and Sajjadi et al., and addresss my theoretical complaint then I could be persuaded to increase my rating.\n\nStrengths:\n+ Interesting idea of combining multiple noise types along with learned noise\n+ Clearly written, includes details of architectures and experiments.\n+ Thorough experiments and ablation studies, including sensitivity to optimizer, types of noise, hyerparaemters, and generator architecture. Compares to recent SN-GAN and GAN-GP modelss.\n\nWeaknesses:\n- Missing prior work: no discussion of Tempered Adversarial Networks from Sajjadi et al. They add a neural network that transforms samples and adjust how large the transformations are over the course of training. Please discuss how your work is related to theirs and what the tradeoffs are between these approaches.\n- Theory: The optimal discriminator depends on the distribution of the real and generated images being fed to it. This means that the optimal discriminator for eps1 ~ N(0, 1) will be different than the optimal discriminator for eps2 ~ N(0, 1). However, you train the same shared discriminator across all scales and types of noise. How does this impact the theory presented and the interpretation of your approach? As an alternative, you could imagine conditioning the generator on an an additional input specifying the type of noise, i.e. D(x, noise_type) and then you could learn a D that is optimal for all noise types.\n- No evaluation of how having the multiple losses for different noise types impacts the training time. Even if iteration time is the same as standard GANs, adding more noise could result in slower training. Please add a plot of FID or IS vs. wall clock time to get a better sense of the tradeoffs in different approaches. \n- It looks like clean + noise with fixed or learned sigma (variants d/e) performs quite well, and has much less overhead vs. NTGAN. Can you discuss this result more? Would you advocate using this approach over NTGAN?\n\nMinor comments:\n- Why does NTGAN + SGD (variant b) perform much better than other approaches? Can you provide more details with how you chose the variants in Table 4?\n- Might want to cite Generative Adversarial Trainer, another approach for learning additive noise distributions in the context of adversarial examples", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}