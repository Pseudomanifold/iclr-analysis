{"title": "missing references and comparisons, unclear evaluation", "review": "Summary\nThis paper proposes an extension of Progressive Networks [Rusu et al. NIPS 2016] (unfortunately, not cited) where the task id is not given at test time. This is inferred by a battery of classifiers trained on data produced by generative models trained on task specific data.\nThe authors argue strong connections to similar mechanisms in the human brain and demonstrate this method on a stream of 2 or 3 vision tasks. However, the interpretation of these results is dubious.\n\nNovelty: given prior work on Progressive Nets and other methods using generative models for continual learning, novelty is limited.\n\nRelevance: the motivation and aim of this work is certainly relevant for ICLR.\n\nClarity: the paper is overall clear, although it needs a bit of rewriting to improve fluency (see for instance sec. 3.4.1).\n\nReferences: the authors should definitely cite Progressive Networks and their extension \"Progress and Compress\" (Schwarz ICML 2018), as their approach is an extension of the former with the only difference that the task id is inferred at test time by using a battery of binary classifiers.\n\nEmpirical validation: The empirical validation is limited because of:\na) lack of comparison to Progressive Nets, \nb) lack of simple baselines (e.g., how about replacing H-Net with an inference process like task_id = argmin_i=1..T loss(C-Net, task = i) ),\nc) unclear interpretation of the provided results (how can the accuracy on MNIST be 100%? are the authors reporting training accuracy?)\nd) very limited number of tasks considered (up to 3)\n\nGeneral comments\nMajor drawbacks of the proposed approach are: 1) training on new tasks can never improve performance on past tasks (unlike other methods like GEM (Lopez-Paz et al. NIPS 2017), 2) the number of parameters grow linearly with the number of tasks (an issue addressed by the Progress and Compress paper above), and 3) the overall approach is not efficient as it requires lots of data from each task in order to train the generative models.\nFinally, I think all the connections and inspiration from how the human brain works should be toned down.  Statements like \"the C-Net corresponds to the human cortex...\" should be at the very least rephrased appropriately.", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}