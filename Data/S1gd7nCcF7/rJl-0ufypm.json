{"title": "The paper is an incremental contribution for an artificially sounding problem", "review": "This paper proposes an algorithm for auxiliary learning. Given a target prediction task to be learned on training data, the auxiliary learning utilizes external training data to improve learning. The authors focus on a setup where both target and external training data come from the same distribution but differ in class labels, where each class in the target data is a set of finer-grained classes in the auxiliary data. The authors propose a heuristic for learning from both data sets through minimization of a joint loss function. The experimental results show that the proposed methods works well on this particular setup on CIFAR data set.\n\nStrengths:\n+ a new auxiliary learning algorithm\n+ positive results on CIFAR data set\n\nWeaknesses:\n- novelty is low: the proposed algorithm is a heuristic similar to previously proposed algorithms in the transfer learning and auxiliary learning space\n- there is no attempt to provide a theoretical insight into the performance of the algorithm\n- the problem assumptions are too simplistic and unrealistic (feature distributions of target and auxiliary data are identical), so it is questionable if the proposed algorithm has practical importance\n- experiments are performed using a synthetic setup on a single data set, so it remains unclear if the algorithm would be successful in a real life scenario\n- the paper is poorly written and sentences are generally very hard to parse. For example, section 3.1 is opened by statements such as \"(we use) a multi-task evaluator which trains on the principal and auxiliary tasks, and evaluates the performance of the auxiliary tasks on a meta set\"??", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}