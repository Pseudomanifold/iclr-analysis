{"title": "Interesting idea of using parameter sharing scheme to explore network structure; experiments can be stronger ", "review": "Authors propose a parameter sharing scheme by allowing parameters to be reused across layers. It further makes connection between traditional CNNs with RNNs by adding additional regularization and using hard sharing scheme.\n\nThe way of parameter sharing is similar to the filter prediction method proposed in Rebuff et al\u2019s work, where they model a convolutional layer\u2019s parameters as a linear combination of a bank of filters and use that to address difference among multiple domains.\n\nSylvestre-Alvise Rebuffi, Hakan Bilen, Andrea Vedaldi, Learning multiple visual domains with residual adapters, NIPS 2017.\n\nThe discussion on the connection between coefficients for different layers and a network\u2019s structure and visualization of layer similarity matrix is interesting. Additional regularization can further encourage a recurrent neural network to be learned. \n\nHowever, they only experiment with one or two templates and advantage on accuracy and model size  over other methods is not very clear.", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}