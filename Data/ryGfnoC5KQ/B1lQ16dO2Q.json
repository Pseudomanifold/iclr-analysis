{"title": "An interesting idea of improving BPTT by kernel recurrent learning. Skip in backpropagation is proposed and illustrated.", "review": "The proposed kernel recurrent learning (KeRL) provides an alternative way to train recurrent neural network with backpropagation through time (BPTT) where the propagation of gradients can be skipped over different layers. The authors directly assume the sensitivity function between two layers with a distance of tau in a form of Eq. (7). The algorithm of BPTT is then approximated due to this assumption. The model parameters are changed to learn the network dynamics. The optimization problem turns out to estimate beta and gamma of the kernel function. The learned parameters are intuitive. There are a set of timescales to describe the memory of each neuron and a set of sensitivity weights to describe how strongly the neurons interact on average. The purpose of this study is to save the memory cost and to reduce the time complexity for online learning with comparable performance. \n\nPros:\n1. KeRL only needs to compute a few tensor operations at each time step, so online KeRL learns faster than online BPTT for the case with a reasonably long truncation length.\n2. Biologically plausible statements are addressed.\n3. A prior is imposed for the temporal sensitivity kernel. The issue of gradient vanishing is mitigated.\n4. Theoretical illustration for KeRL in Sections 3 and 4 is clear and interesting.\n\nCons:\n1. The proposed method is an approximation to BPTT training. Suppose the system performance is constrained. Some guesses are made. The system performance can be further improved.\n2. The experiment on time cost due to online learning is required so that the reduction of time complexity can be illustrated.\n3. The format of tables 1 and 2 can be improved. Caption is required in Table 1. Overlarge size of Table 2 can be fixed.\n4.  A number of assumptions in Sections 3 and 4 are assumed.  When addressing Section 3, some assumptions in Section 4 are used. The organization of Sections 3 and 4 can be improved.", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}