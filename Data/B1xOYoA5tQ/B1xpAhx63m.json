{"title": "Novel approach to classification for resiliance against adversial attacks, supported by multiple experiments.", "review": "This paper argues that a random orthogonal output vector encoding is more robust to adversarial attacks than the ubiquitous softmax. The reasoning is as follows:\n\n1. different models that share the same final softmax layer will have highly correlated gradients in this final layer\n2. this correlation can be carried all the way back to the input pertubations\n3. the use of a multi-way encoding results in a weaker correlation in gradients between models\n\nI found (2) to be a surprising assumption, but it does seem to be supported by the experiments. These show a lower correlation in input gradients between models when using the proposed RO encoding. They also show an increased resiliance to attack in a number of different settings. \n\nOverall, the results seem to be impressive. However, I think the paper would be a lot stronger if there was a more thorough investigation of the correlation between gradients in all layers of the models. I did not find the discussion around Figure 1 to be very compelling, since it is only relevant to the encoding layer, while we are only interested in gradients at the input layer. The correlation numbers in Table 2 are unexpected and interesting. I would like to see a deeper investigation of these correlations.\n\nI am not familiar with the broader literature in this area, so giving myself low confidence.\n", "rating": "6: Marginally above acceptance threshold", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}