{"title": "The authors propose a method to improve stability/performance of manifold learning algorithms like SNE and t-SNE. However, the method could do with more extensive empirical validation.", "review": "Summary of contributions:\nThe authors carefully study the objective function used in popular nonlinear embedding (or manifold learning) algorithms, and identify a specific failure mode that they call \"pressure points\". This arises due to conflicting terms in the objective function, and a simple derivative check reveals which data points are \"pressured\" and which are not. This also motivates two modifications of the original algorithms to check for data points that might have sub-optimal embeddings, and appropriately adjust them by using an extra auxiliary dimension that helps gradient descent over the objective bypass minima.\n\nEvaluation Criteria:\nThe problem is significant, and as far as I know the approach is novel. However, the authors do not provide enough evidence that the method improves upon existing approaches.\n\nComments:\n\nThe \"pressure points visualization\" results in Section 4 are nice but it is unclear how useful this technique is here. One can detect poorly clustered points presumably by other techniques too (e.g. do a k-means clustering and detect points far away from cluster centers).\n\nThe proposed optimization method (Alg 1) works for only 2 out of the 3 studied algorithms (and not for t-SNE, which is arguably the most popular of the three). So it is unclear whether the idea generalizes at all.\n\nThe weakest part of the paper, in my opinion, are the empirical evaluations. Small, not-very-challenging datasets (Coil-20 and MNIST); no real quantitative benefits; unclear how exactly the new approach improves upon previous visualization methods. Figures 4 and 5 show very little improvement in objective function value over standard EE and standard SNE. (For SNE, the improvement is in the second decimal point).", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}