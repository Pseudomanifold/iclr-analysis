{"title": "Some interesting experiments and observations, but novelty is lacking", "review": "\n\nThe authors propose to train deep convolutional neural networks in a layerwise fashion. This is contrary to the traditional joint end-to-end training of deep CNNs. As their motivation, the authors quote computational and memory benefits at the time of training in addition to being able to extend shallow-network analytical frameworks to the individual network layers thus allowing for a theoretical interpretation of their optima.\n\nTheir method is simple and clearly explained. (Note: In the 10th line on Pg. 4, is there a 'j' missing in the subscript of x^n?)\nThe experimental results are interesting. The authors are able to demonstrate 'some' architecture that, in solely a layerwise training, is able to show competitive results with respect to AlexNet when trained in an end-to-end manner on ImageNet. These results can seem questionable as both the architectures and training routines are being varied and hence the precise contribution of the layerwise training is unclear. However, as per my understanding, the aim of the paper wasn't to show that a layerwise training can work better that end-to-end training. The aim was, on the contrary to show, that 'even' a layerwise training can offer competitive performance for 'some' network and hence may come handy when memory is limited. Their underlying claim, which could be more clearly stated is that the memory benefits during training can be enjoyed when the individual layers of a network (net1) are smaller in parameter count as compared to another net (net2) although the net1 in totality maybe larger than net2. This is because net1 will be trained in a layerwise fashion, while net2 would be trained in an end-to-end manner. I would like to see the authors confirm or reject this understanding and rationalise their experimental regimen.\n\nFurther, I would like to know how their work compares to the following:\nhttps://arxiv.org/abs/1703.07115\nhttps://arxiv.org/abs/1611.02185\n\nFinally, while the authors state that the layerwise training makes the individual layers amenable to theoretical analysis/interpretation, no such discussion is presented/initiated in the paper. The only analysis presented is on the ability of the individually trained layers to linear separate the data. To round the analysis, it should also be extended to the representations learned by end-to-end trained networks.  \n\nAll in all, while the paper raises some interesting ideas, its execution in terms of a method that learns a classifier on each individual layer is rather simplistic. Don't get me wrong, simple can indeed be elegant, but at the minute the comparisons are not very convincing.\n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}