{"title": "The contribution is not ready to be published in ICLR", "review": "Summary:\nThe authors present an open-source framework TensorFlow-based named Dopamine to facilitate the task of researchers in deep reinforcement learning (deep RL). It allows to build deep RL using existing components such as reinforcement learning agents, as well as handling memory, logs and providing checkpoints for them.\nEmphasis is given on providing a unified interface to these agents as well as keeping the framework generic and simple (2000 lines of code).\nThe framework was demonstrated on Atari games notably using Deep Q-network agents (DQN).\nThe authors provide numerous examples of parameter files that can be used with their framework.\nPerformance results are reported for some agents (DQN, C51, Rainbow, IQN).\n\nGiven the actual trends in deep learning works, unified frameworks such as that proposed is welcome.\nThe automatization of checkpointing for instance is particularly useful for long running experiments.\nAlso, trying to reduce the volume of code is beneficial for long-term maintenance and usability.\n\nMajor concerns:\n* This type of contribution may not match the scope of ICLR.\n* In the abstract and a large fraction of the text, the authors claim that their work is a generic reinforcement learning framework. However, the paper shows that the framework is very dependent on agents playing Atari games. Moreover, the word \"Atari\" comes out of nowhere on pages 2 and 5.\nThe authors should mention in the beginning (e.g. in the abstract) that they are handling only agents operating on Atari games.\n* The positioning of the paper relative to existing approaches is unclear: state of the art is mentioned but neither discussed nor compared to the proposal.\n* The format of the paper should be revised:\n                - Section 5 (Related Works) should come before presenting the author's work. When reading the preceding sections, we do not know what to expect from the proposed framework.\n                - All the code, especially in the appendices, seems not useful in such a paper, but rather to the online documentation of the author's framework.\n* What is the motivation of the author's experiments?\n                - Reproduce existing results (claimed on page 1)? Then, use the same settings as published works and show that the author's framework reaches the same level of performances.\n                - Show new results (such as the effect of stickiness)? Then the authors should explicitly say that one of the contributions of the paper is to show new results.\n* The authors say that they want to compare results in Figure 3. They explain why the same scale is not used. To my opinion, the authors should find a way to bring all comparisons to the same scale.\n\nFor all these reasons, I think the paper is not ready for publication at ICLR.", "rating": "3: Clear rejection", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}