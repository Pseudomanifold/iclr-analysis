{"title": "The paper presents an unsupervised sentence encoding method trained to classify consistent (original) and inconsistent (corrupted) sentences. The trained encoders are used in a variety of tasks with good performance.", "review": "The paper presents an unsupervised sentence encoding method based on automatically generating inconsistent sentences by applying various transformations either to a single sentence or a pair and then training a model to classify the original sentences from the transformed ones.\n\nOverall, I like the paper as it presents a simple method for training unsupervised sentence models which then can be used as part of further NLP tasks.\n\nA few comments on the method and results:\n\n- The results on Table 2 shows that supervised methods outperform unsupervised methods as well as the consistency based models with MultiTask having the largest margin. It would've been interesting to experiment with training multi-task layers on top of the sentence encoder and see how it would've performed.\n- The detail of the architecture is slightly missing in a sense that it's not directly clear from the text if the output of the BiLSTMs is the final sentence encoding or the final layer before softmax?\n- Also I would've thought that the output of LSTMs passed through nonlinear dense layers but the text refers to two linear layers.\n- When I first read the paper, my eyes were looking for the result when you combine all of the transformations and train a single model :) - any reason why you didn't try this experiment?\n- The paper is missing comparison and reference to recent works on universal language models (e.g. Radford et al 2018, Peters et al 2018, Howard et al 2018) as they rely on more elaborate model architectures and training compared to this paper but ultimately you can use them as sentence encoders. \n- One final note, which could be a subsequent paper is to treat these transformations as part of an adversarial setup to further increase the robustness of a language model such as those mentioned previously.", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}