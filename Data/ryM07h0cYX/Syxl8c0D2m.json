{"title": "Lacking meaningful baselines and some claims are dubious", "review": "Pros:\n+ Improving joint training of non-differentiable pipelines is a meaningful and relevant problem\n+ Using the stochastic computation graph structure to smooth a pipeline in a structured way is a plausible idea\n\nCons:\n+ The main result of the paper concerning sufficient conditions for optimality of the method seems dubious\n+ It is not obvious why this method would outperform simple baselines, and baselines for joint training were tried\n+ The notation seems unnecessarily bloated and overly formal\n+ The exposition spends too much time on prior work, too little on the contribution, and the description of the contribution is confusing\n\nThe submission describes a method for smoothing a non-differentiable machine learning pipeline (such as the Faster-RCNN detector), so that gradient-based methods may be applied to jointly train all the parameters of the pipeline.  In particular, the proposal involves recasting the pipeline as a stochastic computation graph (SCG), adding stochastic nodes to this graph, and then using REINFORCE-style policy gradients to perform parameter learning on the SCG.  It is claimed that under certain conditions, the optimal parameters of the resulting SCG are also optimal for the original pipeline.  The method is applied to optimizing the parameters of Faster-RCNN.\n\nI think making non-differentiable pipelines differentiable is an intuitively appealing concept.  A lot of important, practical machine learning systems fall into this category, so devising a nice way to do global parameter optimization for such systems could potentially have significant impact.  In general, we can\u2019t hope to make much meaningful progress on the problem of optimizing general nonlinear, differentiable functions, but it is plausible that a method that targets key non-differentiable components for smoothing\u2014such as this paper\u2014could outperform a generic black-box optimizer.  So, I think the basic idea here is plausible and addresses an important problem.\n\nUnfortunately, I think this work loses sight of that high-level goal: to me, the key question is whether the proposed approach outperforms any other simple method for global parameter optimization in the presence of nonlinearities and nondifferentiability.  The paper fails to answer this question because no baselines for global parameter optimization were tried.  We can just treat the pipeline as a black box mapping parameters to training set performance, and so any black-box optimization method can be applied to this problem.  It is not clear that the proposed method would outperform an arbitrary black box optimization method such as simulated annealing, Nelder-Mead, cross-entropy method, etc.\n\nI think there are also much simpler methods in a similar vein to the proposed method that might also perform just as well as the proposal.  One key conceptual issue here is that reducing the problem to a reinforcement learning problem, as the submission does, is not much of a reduction at all.  First, if the goal is to do global parameter optimization, then we don\u2019t really have to smooth the pipeline itself: we can just smooth the black box mapping parameters to performance, and then optimize that with SGD.  There are many ways to do this--if we want to use policy gradient, we can just express the problem as something in this form:\n\nmin_\\phi E_{\\theta ~ q_\\phi} C(\\theta)\n\nwhere C is the black-box mapping parameters \\theta to a performance index (such as mean AP), q_\\phi is a distribution over parameters (e.g., Gaussian), and \\phi are the distribution parameters (e.g., mean, covariance of the Gaussian).  We can then optimize this using REINFORCE policy gradients.\n\nIf we want to really smooth the pipeline itself, then it is also easy to do this by devising a suitable MDP and then applying REINFORCE with the usual MDP structure.  We simply identify the state s_t at time t with the output of the t\u2019th pipeline stage, introduce a new \u2018action\u2019 variable a_t representing a \u2019stochastified output\u2019, and trivial dynamics (P(s_{t+1} | s_t, a_t) = \\delta(s_{t+1} - a_t)).  If the policy is a Gaussian (P(a_t | s_t) = N(a_t; s_t, \\Sigma)), then this is similar to relaxing the constraint that one stage\u2019s output is equal to the input of the next stage, and somehow quadratically penalizing their difference.  In fact, there is a neural network training method based explicitly on this penalization view [A], and it would make yet another great baseline to try.\n\nIn fact, the proposed method is essentially similar to what I have just described, but it is unfortunately described in an overcomplicated way that obscures the true nature of the method.  I think the whole SCG framework is overkill here.  Too much of the paper is spent just rehashing the SCG framework, and the very heavy notation again just obscures the essential character of the method.\n\nIf there were, as the paper claims, some interesting condition under which the method produces solutions that are optimal under the original pipeline, that would be remarkable and interesting.  However, I have serious doubts about this part of the paper.  The key problem is the statement that \u201cIt follows that c(k_c, DEPS_c - k_c) = c(\u2026) + z_c\u201d.  The paper seems to be claiming that if E z = 0, then c(k + z) = c(k) + z, which can\u2019t possibly be true in general.  \n\nThe heavy and opaque notation makes it very difficult to understand this section.  Perhaps it would help to consider a very simple example.  Suppose we want to minimize E_{x ~ q} c(y(x)) (where x ~ q means x is distributed as q).  We can introduce only one new stochastic node (k = y + z), between y and c.  Clearly c(y + z) is not generally equal to c(y) + z, even if E z = 0.\n\nIn summary, I think the submission needs a lot of work on multiple axes before it can make a significant impact.  The most important issues are a complete lack of relevant baselines and the dubious claims about sufficient conditions for optimality.  The idea could have merit, but it needs to be carefully compared and motivated with respect to existing work (such as [A]) as well as the simple baselines I have mentioned.  The presentation also needs to be revised to find the simplest expression of the method and to focus on the interesting parts.\n\n[A] Taylor, Gavin, et al. \"Training neural networks without gradients: A scalable admm approach.\" International Conference on Machine Learning. 2016.", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}