{"title": "Strong results on NER, but not an interesting approach", "review": "This submission tackles the named entity recognition (NER) task.\nIt formulates the task as sequence labeling (through BIO-tagging), and applies CNN+BILSTM encoder followed by self attention components to extract the representations used in local classification. Strong performance is achieved on benchmark datasets.\n\nThe key of the claimed modeling novelty seems to be the self-attention mechanism.\nI'm not entirely familiar with the sequence labeling literature, but I would be very surprised if there is no existing work applying a similar model a such tasks. Further, some of the arguments seem to be over-claimed. For example, `theoretical justification` is mentioned for many times in abstract and intro, but I don't see any theory through the paper.\n\nPros:\n- Nice numbers.\n\nCons:\n- Noting else to learn other than nice numbers.\n\nDetails:\n- Section 3.3. Does the model try to force consistency during decoding (e.g., by using constrained beam search)? If not, could the authors comment on how often does the model produces ill-formed predictions.\n\n- Two of the claimed contributions involve `theories`. But I don't see any theory through the paper. To be honest, the analysis in Section 6 can be some nice intuition, but it has nothing to do with theory. \n\n- Contribution.2, self-attention is something `applied` in this paper, but not `proposed`.\n\n- I'm confused by Section 6. Is the model proposed here actually used in the experiments? If it is, isn't it better to put it before Section 5?\n\n- Figures 2 are extremely hard to read.\n\n- I'm not sure what points Section 5.4 is trying to make.\n\nMinor:\n\n- \\sigma is usually used to indicate the sigmoid function.", "rating": "3: Clear rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}