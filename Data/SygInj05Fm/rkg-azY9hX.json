{"title": "This paper presents an approach to produce embeddings for physiological signals that are interpretable.", "review": "The authors claim contributions in three areas:\n1) Learning representations on physiological signals. The proposed approach  uses LSTMS with a loss function that aims at predicting the next five minutes of the physiological signals. Based on their experiments, using this criteria outperforms \n LSTM autoencoder approaches that are tuned to reconstruct the original signals. The description of this work needs more details. It would be good to have clarity on these loss functions and also on the architecture of the LSTM autoencoder that is claimed here. Is it a standard seq2seq model? Is it something else?\n\n2) They use the hidden state of the LSTMs as a representation of the inputs signals. From this representation, they have setup a set of supervised/predictive tasks to measure the efficacy of the representation. For this, they used gradient boosting machines. \n\n3) They propose a way to estimate interpretability by tracking the impact of the input data on the predictions using an model agnostic approach using Shapley values. I have found this part of the paper particularly obscure. I recommend shedding some light on the structure of this model that generates these Shapley values. \n\nThe experimental result section also needs work in my opinion. First of all, the authors may want to better describe the data used. How many patients are in this set? How was the data partitioned for training, testing, validation? Any hyper-paremeter tuning? I have found the \u201ctransference\u201d arguments a bit weak. First of all, the physical distance between hospital should not be mentioned as a way to compare \u201chospitals\u201d. How did the authors select these features shown on Figure 2? MIMIC has more features than this. Why were these additional features discarded? Is the data coming from the same type of operating rooms in the case of hospital 0 and 1? I am somehow skeptical on the transfer of embeddings learned in an ICU setting to an OR setting. It would be great to provide details on the type of patients that are being monitored. \n\nIt is quite hard to argue from what\u2019s presented in 4.3.3 that the proposed approach is interpretable. Can the authors explain how a visual inspection of Figure 5 \u201cmakes sense\u201d as stated in the paper? What is the point that\u2019s being made here? Any reason why more conventional attention mechanisms have not been looked at for interpretability?\n\nOverall, I have found the problem addressed here interesting. However, I think that the paper needs work, both on the presentation of the methodology and also on the presentation of more convincing experimental arguments. ", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}