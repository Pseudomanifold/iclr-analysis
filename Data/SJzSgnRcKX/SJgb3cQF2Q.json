{"title": "Nice discussion of what type of information is actually encoded by contextualized word embeddings", "review": "This paper provides new insights on what is captured contextualized word embeddings by compiling a set of \u201cedge probing\u201d tasks.  This is not the first paper to attempt this type of analysis, but the results seem pretty thorough and cover a wider range of tasks than some similar previous works.  The findings in this paper are very timely and relevant given the increasing usage of these types of embeddings.  I imagine that the edge probing tasks could be extended towards looking for other linguistic attributes getting encoded in these embeddings.\n\nQuestions & other remarks:\n-The discussion of the tables and graphs in the running text feels a bit condensed and at times unclear about which rows are being referred to.\n-In figures 2 & 3: what are the tinted areas around the lines signifying here? Standard deviation?  Standard error?  Confidence intervals?\n-It seems the orthonormal encoder actually outperforms the full elmo model with the learned weights on the Winograd Schema.  Can the authors comment on this a bit more?\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}