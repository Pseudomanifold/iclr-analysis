{"title": "A spatial-temporal attention model, missing some baselines. ", "review": "The paper propose an end-to-end technique that applies both spatial and temporal attention. The spatial attention is done by training a mask-filter, while the temporal-attention use a soft-attention mechanism.  In addition the authors propose several regularization terms  to directly improve attention. The evaluated datasets are action recognition datasets, such as HMDB51, UCF10, Moments in Time, THUMOS\u201914. The paper reports SOTA on all three datasets. \n\n\n\nStrengths:\n\nThe paper is well written: easy to follow, and describe the importance of spatial-temporal attention. \n\nThe model is simple, and propose novel attention regularization terms. \n\nThe authors evaluates on several tasks, and shows good qualitative behavior. \n\n\nWeaknesses:\n\nThe reported number on UCF101 and HMDB51 are confusing/misleading.  Even with only RGB, the evaluation miss numbers of models like ActionVLAD with 50% on HMDB51 or Res3D with 88% on UCF101. I\u2019ll also add that there are available models nowadays that achieve over 94% accuracy on UCF101, and over 72% on  HMDB51. The paper should at least have better discussion on those years of progress. The mis-information also continues in THUMOS14, for instance R-C3D beats the proposed model. \n\nIn my opinion the paper should include a flow variant. It is a common setup in action recognition, and a good model should take advantage of these features. Especially for spatial-temporal attention, e.g., VideoLSTM paper by Li. \n\nIn general spatial attention over each frame is extremely demanding. The original image features are now multiplied by 49 factor, this is more demanding in terms of memory consumption than the flow features they chose to ignore.  The authors reports on 15-frames datasets for those short videos. But it will be interesting to see if the model is still useable on longer videos, for instance on Charades dataset. \n\nCan you please explain why you chose a regularized making instead of Soft-attention for spatial attention? \n\nTo conclude: \nThe goal of spatial-temporal attention is important, and the proposed approach behaves well. Yet the model is an extension of known techniques for image attention, which are not trivial to apply on long-videos with many frames. Evaluating only on rgb features is not enough for an action recognition model. Importantly, even when considering only rgb models, the paper still missed many popular stronger baselines. \n\n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}