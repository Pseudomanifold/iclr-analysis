{"title": "Review", "review": "This paper proposes to use GAN to address the image compression problem. It is shown to achieve superior results over the past work in two different settings (GC and SC). \n\nNovelty:\n\nIt has been well discovered in the literature of GANs that they can resolve the problem of blurriness in generation, compared to the traditional MSE loss. This paper proposes to combine a GAN loss with MSE, together with an entropy loss. However similar approaches were used such as video prediction [1] from 2016. The paper lacks a few references like this.\n\nMajor questions:\n\n- How do the different loss terms play against each other? The entropy term and the MSE apparently conflict with each other. And how would this affect L_gan? I would like to request some more analysis of this or ablation study on different terms.\n\n- How well does the GAN converge? A plot of G and D loss is often presented with GAN approaches.\n\n- Discrete latent variable is in itself an interesting problem [2]. I see the image compression as a task to discover a discrete latent variable with minimal storage. Perhaps one most important problem is how to estimate the gradient through the discrete bottleneck. But the paper doesn't provide much insights or experiments on this. \n\n- I'm not fully convinced by the claim of the noise that this paper uses to combine the code can act as a regularizer. Adding the noise makes the decoder output stochastic, but the compression problem seems to be deterministic by nature, unlike many other generation problems.\n\n[1] https://arxiv.org/abs/1511.05440\n[2] https://arxiv.org/abs/1711.00937", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}