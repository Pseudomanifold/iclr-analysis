{"title": "The significance of the proposed method is limited", "review": "A model compression framework, DeepTwist, was proposed which makes the weights zero if they are small in magnitude. They used different model compression techniques in this framework to show the effectiveness of the proposed method. \n\nThis paper proposes a framework intending to use fewer hardware resources without compromising the model accuracy. However, when the weights are set to zero the weight matrix became sparser but still requires the whole weight matrix to be used by the computing resources, as removing some of the weights based on the sorting will not remove a node, only removes some of the connection with that node. Therefore, it is not clear how the proposed framework is helping the model compression techniques.  \n", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}