{"title": "Interesting work but requires more thorough experiment", "review": "This paper proposes to use a  stochastically quantized network combined with adversarial training to improve the robustness of models against adversarial examples. The main finding is that, compared to a full precision network, the quantized network can generalize to unseen adversarial attacks better while training only on FGSM-perturbed input. This provides a modest speedup over traditional adversarial training.\n\nWhile the findings are certainly interesting, the method lacks experimental validation in certain aspects. The comparison with other adversarial training methods is not standardized across networks, making the efficiency claims questionable. Furthermore, I am uncertain whether the authors implemented expectation over transformations (EoT) for the C&W attack.  Since the network produces randomized output, vanilla gradient descent against an adversarial loss is likely to fail. It is conceivable that by taking an average over gradients from different quantizations, the C&W adversary would be able to circumvent the defense better. I would be willing to reconsider my review if the authors can address the above weaknesses.\n\nPros:\n- Surprising result showing that quantization leads to improved generalization to unseen attack methods.\n\nCons:\n- Invalid comparison to other adversarial training techniques since the evaluated models are very different.\n- Lack of evaluation against EoT adversary.\n- Algorithm 1 is poorly presented. I'm sure there are better ways of expressing such a simple quantization scheme.\n- Figures 2 and 3 are uninteresting. The fact that the model is robust against adversaries implies that the activations remain unchanged when presented with perturbed input.", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}