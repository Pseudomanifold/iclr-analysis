{"title": "Good paper", "review": "This paper presents a (meta-)solver for particular program synthesis problems, where the model has access to a (logic) specification of the program to be synthesized, and a grammar that can change from one task instance to another. The presented model is an RL-based model that jointly trains 1) the joint graph-based embedding of the specification and the grammar, and 2) a policy able to operate on different (from instance to instance) grammars. Interestingly, not only can the model operate as a stand-alone solver, but it can be run as a meta-solver - trained on a subset of tasks, and applied (with tuning) on a new task. Experiments show that the model outperforms two baselines (one being a (near-to-)SOTA model) in the stand-alone setting and that the model successfully transfers knowledge (considers fewer candidates) in the meta-solving mode.\n\nFirst, I enjoyed reading the paper. I think the problem is interesting, particularly due to the model being able to train and operate on various grammars (from task to task), and not on a single, pre-specified grammar. The additional bonus is that the problem the paper solves does not require program as supervision, but an external verifier.\nThe evaluation shows that this approach not only makes sense but (significantly) outperforms, under same conditions, specialized program synthesis programs. However, there\u2019s one issue here, and that\u2019s what the comparison hasn\u2019t been done to SOTA model but to a less performant model (see issues). \nThe particular approach of jointly training a specification+grammar graph embedding and learning a policy that acts on different grammars seems original and significant enough for publication.\nThe paper is well (with a few kinks) written, and mostly clear. There are still some issues in the paper.\n\nIssues:\n- The dataset used is 210 cryptographic circuit synthesis tasks from SyGuS 2017. Why only this particular subset of all the tasks, and not the other tasks/categories (there is 569 of them in total, no)?\n- Alur et al mention 214 examples in the said tasks, yet the paper says 210. Why?\n- The SyGuS results paper https://arxiv.org/abs/1711.11438 mentions EUSolver as the SOTA model, solving 152 tasks (out of 214). Why didn\u2019t you compare your model to EUSolver?\n- The same paper reports CVC4 solving 117 tasks (out of 214), as opposed to 129 (out of 210) reported in your paper. Could you comment on the (possible) differences in the experimentation protocol?\n- you mention global graph embedding, but you never describe how you calculate it\n- abstract mentions outperforming two SOTA engines, but later you say ESymbolic is a baseline (which it seems by description)\n\nQuestions:\n- W for different edge types and different propagation steps t? Why is there a need for such a large number of parameters? What is the number of propagation steps?\n- In the extreme case where all inputs can be enumerated - how often does this happen in the tasks you solve?\n- figure 2 is not clear. There is too much information on one side (grammar) and too little on the other (what is the meaning of \\tau^(t-1)?)? Is the tree on the right a generated subtree?\n- details of the state s are unclear - it is tracked by an LSTM? Is there a concrete training signal for s, or is it a part of the architecture and everything is end-to-end trainable from the final reward? The same for s0=MLP(h(G)) - is that also trained in the same way?\n- can you provide some intuition on why you chose that particular architecture (state-tracking LSTM,  s0 as such, instead of something simpler?)\n- can you provide details on the state value estimator MLP architecture, as well as the s0 MLP, and the state-tracking LSTM?\n- the probability of each action (..) is defined as \u2026.H_\\alpha^(i) - what does the i stand for? Was that supposed to be the t or \\alpha_t was supposed to be \\alpha_i?\n\nMinor stuff:\n- Figure 5a is referred to as Table 5a in the text\n- out-of-out-solver\n- global graph embedding, figure 1 - G(phi, G), figure 2 - h(G)\n- a figure of the policy architecture would be beneficial\n- Figure 1\n  - d_1 ->X OR Y in the graph is d1T, why isn\u2019t it d1_OR, and connected to the OR node?\n  - why isn\u2019t d1_OR connected to OR node?\n  - AST edge - but grammar is a DAG - (well, multigraph)\n  - what are the reversed links? e.g. if A->B, reversed link is B->A ?\n  - what is the meaning of the concrete figures in \u2018one step\u2019?\n- consider relating to \u2018DREAMCODER: Bootstrapping Domain-Specific Languages for Neurally-Guided Bayesian Program Learning\u2019 (https://uclmr.github.io/nampi/extended_abstracts/ellis.pdf), as it\u2019s another model that steps away from the fixed-DSL story", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}