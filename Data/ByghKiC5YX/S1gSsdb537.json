{"title": "Exciting advance in discrete adversarial attacks", "review": "In this work the authors introduce two new state-of-the-art adversarial attacks on discrete data based on a two-stage probabilistic process: the first step identifies key features which are then replaced in the second step through choices from a dictionary.\n\nOverall the manuscript is very well written and easy to follow. The evaluation is extensive and contains all previous attacks I am aware of. The greedy attack outperforms all prior work by a large margin while the Gumbel attack works on par with the previous state-of-the-art while being significantly faster. \n\nI only have a few questions and remarks:\n\n* What\u2019s the \u201crandom attack\u201d baseline in these tasks? In computer vision it\u2019s often sufficient to add a little bit of salt-and-pepper noise or Gaussian noise to change the model decision.\n\n* Another thing I am wondering is what the human evaluation scores would be on adversarials from other adversarial attacks? Adversarial attacks in general (e.g. in computer vision) can work in two ways: one being actually changing the semantic content (thus also \u201cfooling humans) while the other changes background features / add noise to which humans are pretty insensitive (unless you add too much of it). The greedy attack does seem to change some semantics as can be seen in the increased error rate of humans (which is pretty rare for computer vision adversarials). It might be that other attacks are rather changing words or characters which are not as semantically meaningful, as would be revealed by the accompanying human scores.\n\n* Are you planning to release the code? Will it be part of CleverHans or Foolbox?\n\nOverall, I find this work to be a really exciting advance on discrete adversarial attacks.", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}