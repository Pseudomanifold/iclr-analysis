{"title": "Good paper, clearly written and has some interesting ideas", "review": "Summary:\nThis paper introduces an encoder-decoder neural net architecture for arbitrary graphs. The core contribution is pooling and un-pooling operations for respectively graph down and up sampling.\n\nPros:\n+ U-Net like architectures indeed are very successful in vision applications, and having a model that was similar properties on graphs would be very useful.\n+ The paper is clearly written. \n+ I really liked the idea behind the pooling operation: it is simple, seems easy to implement efficiently, and generally makes sense (although see concerns below). \n+ The choice of the baselines is reasonable, and experimental results seem convincing. Ablation studies are also there.\n\nCons:\n- It is not clear why the evaluation seem to only be done for the transductive learning settings. I understand that some of the previous work might have done that, but this application scenario is quite limited.\n- One concern about the g-pool operation is that it is not local: unlike e.g. max pool on 2D which produces local maxima, here the selection is done globally, which could lead to situations where the entire parts of the graph are completely ignored. \n- Another concern, which has \fbeen partially addressed in section 3.4 is that the connectivity is not really taken into account when downsampling the adjacency matrix. The solution which introduces previously non-existing edges and thus kind of modifies the original graph is not very satisfying. \n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}