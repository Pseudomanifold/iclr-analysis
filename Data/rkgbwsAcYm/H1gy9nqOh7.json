{"title": "Interesting approach but not yet clearly demonstrating a significant boost in performance", "review": "Authors present a new regularisation approach named DELTA (Deep Learning Transfer using feature map with attention). What it does is preserving the outer layer outputs of the target network (in a transfer learning scenario) instead of constraining the weights of the neural network. I am not sure how this approach helps preserve the semantics. Authors state that the distance between source/target networks is characterised by DELTA using their outer layer outputs. This distance is then used in the loss function and through back-propagation incorporates knowledge from the source network. The results demonstrate some marginal improvement in the datasets used when compared with L^2 and L^2-SP.\nMore importantly I think the paper needs some attention in its format as the concepts are not very clear. It has some elements of novelty but not yet there.\n\nAuthors have addressed most of my issues and hence I have revised my decision.", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}