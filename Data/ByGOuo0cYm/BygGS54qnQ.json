{"title": "This is not \"meta domain adaptation\" but \"few-shot learning +domain adaptation\"", "review": "This paper proposes to combine unsupervised adversarial domain adaptation with prototypical networks and finds that the proposed model performs well on few-shot learning task with domain shift, much better than other few-shot learning baselines that do not consider. Specifically it tests on Omniglot with natural image background and cliparts to real images.\n\nIt is true that current meta-learning approaches do not address the problem of domain shift, and as a result, the testing domain has to be the same with the training domain. However, this paper rather than proposing solution address the meta-learning problem, albeit the title \u201cmeta domain adaptation\u201d, only brings few-shot learning to domain adaptation. Here\u2019s why:\n\nIn order for a meta-learning model to be called \u201cmeta domain adaptation,\u201d the type of adaptation cannot be seen during training, and the goal is to test on adaptation that the model has not seen before. Indeed, each task in meta domain adaptation should be seen as a pair of source task and target task. \n\nThe problem with the current model is that during training, it is trained to target at one specific type of test domain--the generator network G aims to generated images that align with the unsupervised  test domain X_test. Thus, the trained model will also only be able to handle one test domain, not much different than regular meta-learning models.\n\nIn short, the meta-learning part stays in the regular few-shot learning module (which is implemented as a prototypical network), and has nothing related to domain adaptation. Therefore, the paper cannot be qualified for ``meta domain adaptation\u2019\u2019 and has very limited novelty in terms of its contribution to meta-learning; however, the combination of domain adaptation and few-shot learning is fair. For the rest of my review, I will treat the paper as \u201cfew-shot learning with domain adaptation\u201d for more appropriate analysis.\n\nFor the experiments, there seems to have a great win of the proposed algorithm against the baselines. However, I think since this is few-shot learning with domain adaptation, there is no domain adaptation baselines being mentioned in comparison. Specifically, what if the few-shot learning component is removed, and the network is trained with standard domain adaptation. Then use the same network to extract the features and then using the nearest neighbor to retrieve the classes. Also it seems that the regular batch normalization could be very sensitive to domain shifts, and it would be good if the authors can test other normalization schemes such as layer/group normalization as baselines.\n\nAnother concern is that the evaluation of domain adaptation does not have much varieties. Only two domains shifts are evaluated in the paper, specifically Omniglot + BSD500 and Office-Home. BSD 500 only contains 500 images, and it would be good if more diverse set of images are considered. Other domain transfer settings such as synthetic rendered vs. real (e.g. visDA challenge) could have been considered.\n\nIn conclusion, the paper presents a interesting combination of ProtoNet + Adversarial DA + Cycle consistency. However, unlike as advertised, the paper does not address the domain shift issue in meta-learning, and the experiments lack thorough evaluation as the paper considers itself as a meta-learning paper and only compares to other meta-learning approaches without much comparison to domain adaptation papers. Therefore, I recommend reject.\n\n---\nNote: after reading the comments updated by authors, I remain my opinions: even though exact meta-testing data is unseen during training, the domain is seen during training, and therefore it cannot be qualified for being \"meta domain adaptation\".\n\n===\nAfter rebuttal:\n\nI would like to thank the authors for the response and updating the draft. They have addressed 1) the title issue and 2) adding domain adaptation baselines. Considering these improvements, I would like to raise the score to 5, since the setting of combining few-shot learning and domain adaptation is interesting and the proposed model outperforms the baselines. \n\nHowever, my criticisms remain that the paper is a simple combination of cycle GAN and prototypical networks, and lacks new insights/novelty. The experiments use fairly small datasets, where the performance can be largely influenced by how good the feature extractor backbone is (e.g. training on more data and using deeper architecture would warrant better performance, and thus may change the conclusion).", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}