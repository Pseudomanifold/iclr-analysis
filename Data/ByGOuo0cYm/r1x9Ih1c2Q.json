{"title": "Interesting setting. Method seems to work, though is not very principled. Questions about reproducibility ", "review": "The authors consider the few-shot / meta-learning scenario in which the test set of interest is drawn from a different distribution from the training set. This scenario is well-motivated by the \"researcher example\" given throughout the paper. The authors assume access to a large unlabelled set in test (target) domain, and a large labelled (few-shot) set in the source domain. Thus, the paper is concerned with unsupervised version of the meta-learning problem under domain shift (i.e., a large amount of data unlabelled are available from the target domain).\n\nThe key idea is to learn a mapping from the source domain to the target domain. This mapping is learned jointly with the meta-learner, who performs the meta-learning in the target domain, on examples from the labelled domain. In practice however, it appears from the experimental section that the domain mapping is learned offline, and then frozen for the meta-learning phase.  Thus, at test time, given examples from the target domain, the meta-learner can perform few-shot learning.\n\nPros:\n- The paper addresses an important scenario which has not been addressed to this point: namely, meta-learning without the assumption that the train and test sets are drawn from the same domain/distribution.\n- The authors propose a novel task and experimental framework for considering their method, and show (somewhat unsurprisingly) that their method outperforms standard meta-learning methods that do not properly account for domain shift.\n- The paper reads well and is easy to follow.\n\nCons:\n- My main concern is reproducibility: the authors employ a number of large architectures, complex loss functions, and regularizers / \"additional improvements\". Further, there a number of experimental details that need to be further elaborated upon. e.g., architectures and hyper-parameters used, and training procedures (I encourage the authors to utilize the appendices for this). It is unclear to me how difficult/easy these results would be to reproduce. Do the authors intend to release code for their implementations and experiments?\n- Some assumptions are not explicitly stated. In particular, it is unclear what the assumption on the size of the unlabelled test set is. This is also lacking from the description of the experimental protocol, which does not address the data-splits (how many classes were used for each) and size of the unlabelled test set.\n- While the method is presented as jointly learning all the components, in the experimental section it is stated that the embedding network (the meta-learner) and the GAN-based domain adaptation are done separately. Can the authors comment on this further? Is this different from first learning a image translation mapping (using the unlabelled data in the target domain), and then applying existing meta-learning models/algorithms to the labelled data in the target domain?\n- The overall method seems to be not very principled, and requires a lot of \"tweaks and tunes\", with additional losses and regularizers, to work.\n\nOverall, the paper proposes a method combining a number of existing useful works (prototypical networks for meta-learning and image-to-image translation for domain adaptation) to tackle an important problem setting that is not currently addressed in existing meta-learning research. Further, it establishes a useful experimental benchmark for this task, and provides what appear to be reasonable results (though this is somewhat difficult to judge due to the lack of baseline approaches). Hopefully, such a benchmark will inspire more researchers to explore this setting, and perhaps propose simpler, more principled approaches to perform this task. It is my impression that, if the authors elaborate on the experimental protocol and implementation details, this paper would be a good fit for the venue.\n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}