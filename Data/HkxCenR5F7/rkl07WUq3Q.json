{"title": "Incremental contribution of variational recurrent models; big volume of extensions of the proposed method and experiments", "review": "This paper proposes a new variational recurrent model for learning sequences. Comparing to existing work, instead of having latent variables that are dependent on the neighbors, this paper proposes to use independent latent variables with observations that are generated from multiple latent variables. \nThe paper further combined the proposed method with multiple existing ideas, such as the shared/prviate representation from VAE-CCAE, adding the hierarchical structure, and prior updating. \n\nPros:\nThe proposed method seems technical correct and reasonable. \nThere are many extensions which are potentially useful for many applications \nThere are many experimental results showing promising performance. \n\nCons:\nThe framework is very incremental. It is novel but limited. \nThe paper claim that the main point to use the simpler variations distribution is to speed up the inference. But no speed comparisons are shown in the experiments section. \nThe evaluation shows that prior updating (one extension) seems contributes to the biggest performance gain, not the main proposed method. \n\n", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}