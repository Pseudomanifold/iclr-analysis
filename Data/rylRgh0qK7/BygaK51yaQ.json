{"title": "Interesting idea but the presentation is unclear ", "review": "In this paper, the authors studied a modification of deterministic policy gradient in which the transition function consists of both the deterministic part and the stochastic part. Leveraging the existing result in DDPG and arguing that the original result has convergence issue for general \\gamma, they showed a new DPG theoretical result for deterministic transition function under certain conditions. Furthermore they also extended this result to general hybrid transition function, as well as including model-based/model-free gradient interpolation to improve sample complexity of DDPG. To illustrate the effectiveness of this work, the authors also compare GDPG with other baselines in several benchmarks. \n\nWhile I find this topic potentially interesting, I do have several concerns. \n\nFirst of all, the gradient result in Theorem 1 only holds when \\gamma\\in[0,1/nc], how restrictive is that? Can the authors provide more intuitions on this restriction to a more general gamma? \n\nSecond, while the PG result is extended in theorem 2 to the hybrid transition function, and the authors proposed a complicated gradient formulation, at the end it seems that resembles the standard DDPG result, so what is the novelty here, especially this result only holds under restrictions on gamma and specific ranges of eigen-values on transition? How can one check that conditions i) and ii) hold in practice? While the hybrid transition model presents theoretical interests how practical is this transition model? \n\nThird, to reduce sample complexity, the authors proposed interpolating model-based PG with model-free ones. While I appreciate the idea of augmenting the MDP to transform the original problem to one with deterministic transition, and the motivation of justifying the PG interpolation via a constrained problem, how does the DPG result in Theorem 1 relate to the model-based gradient estimate (in first part of equation 5), in particular does the restriction of gamma also apply to the gradient estimate here? How does this approach compare with the interpolated PG approach (https://arxiv.org/abs/1706.00387)? Does this model-based gradient term act as a control variate to reduce variance of PG? \n\nFourth, is the resulting gradient estimate still unbiased? If not, does the improvement come from bias-injection/variance-reduction?\n\nPresentation of this paper: this paper contains numerous typos (for example a) M_* versus M^*, b) what is MDPG exactly in the experiment section, c) grammatical errors etc.). While the presentation of this paper is technical, it lacks intuition on the assumptions made as well as the conditions posed. (For example, what are the intuitions behind condition A1 and A2, and how restrictive is the condition of Theorem 1, when \\gamma needs to be in [0,1/nc]?) Furthermore the DPG result in Theorem 2 is for a complicated transition function, but I am not sure how practical/novel it is, can the authors provide more insights and examples to justify this hybrid transition function?\nUnfortunately given the current presentation I find it rather difficult to grasp the general ideas presented in this paper. I would recommend putting the rest of the theoretical proofs in the appendix and increasing the context on explaining the results.", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}