{"title": "Some interesting proposals, with weak justification and experimental verification.", "review": "In this paper the authors introduce a novel method to defend against adversarial attacks that they call feature smoothing. The authors then discuss feature smoothing and related \u201ccheap\u201d data augmentation-based defenses against adversarial attacks in a nice general discussion. Next, the authors present empirical data comparing and contrasting the different methods they introduce as a means of constructing models that are robust to adversarial examples on MNIST and CIFAR10. The authors close by attempting to theoretically motivate their strategy in terms of reducing variance of the decision boundary.\n\nOverall, I found this paper pleasant to read. However, it is unclear to me exactly how novel its contributions are. As discussed by the authors, there are strong similarities between feature smoothing and mixup although I did enjoy the unifying exposition presented in the text. It also seems as though the paper suffers from some simplifying assumptions considered by the authors. For example, in sec. 2 the authors claim that \\tilde x will be closer to the decision boundary than x. However, this is only true if the decision boundary is convex. \n\nI appreciated the extensive experiments run by the authors. However, I wish they had included results from adversarial training. It seems (looking at Madry\u2019s paper) that the defense offered by these cheap methods is still significantly worse than adversarial training. I feel that some discussion of this is warranted even if the goal is to reduce computational complexity.\n\nFinally, I am not sure what to make of the theory presented. While it is nice to see that the variance of the decision boundary is reduced by regularization in the case of 1-dimensional linear regression, I am not at all convinced by the authors generalization to neural networks. In particular, their discussion seems to only hold for one-hidden-layer networks. Although the authors don\u2019t offer much clarity here. For example eq. 2 is literally just a statement that ReLU is a convex function. However, it is clearly the case that multiple layers of the network will violate this hypothesis. Overall, I did not find this discussion particularly compelling. ", "rating": "5: Marginally below acceptance threshold", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}