{"title": "Official review", "review": "Summary:\nThe paper proposes a variant of GAN, called Gaussian Mixture GAN (GM-GAN), which essentially replaces the simple, unimodal prior over latent spaces of standard GAN with a mixture of Gaussians, motivated by the goal of increasing diversity of samples. The number of mixture components is fixed, but parameters of each component can be learned. Experiments show that, given the right number of mixture components, GM-GAN can produce better results than standard GAN. In addition, the paper proposes to score GANs based on two separate measures: 1) quality score, which reports the Euclidean distance in feature space (of some pretrained classifier) between a given generated image and its nearest-neighbor in training set (again, nearest neighbor according to same feature space), and 2) diversity score, which combines intra-class diversity using MS-SSIM metric and inter-class diversity using entropy of a pre-trained classifier\u2019s predictions. Finally, the paper proposes applying the GM-GAN model as a clustering method, and shows that it can achieve competitive results on 3 image datasets.\n\nStrengths:\n-\tThe problem of lack of diversity/mode dropping is an important problem in GANs and the proposed approach seems like an intuitive way to address it.\n-\tThe lack of a proper metric for evaluating generative models is indeed a very important research problem. Decomposing desired qualities of generated data into separate metrics seems like a sensible approach.\n-\tProposed approach achieves state-of-the-art results on clustering in MNIST.\n\nWeaknesses:\n-\tThe novelty of the proposed approach is questionable, especially given a published work which propose exactly the same idea of using a Gaussian Mixture as prior for GANs in CVPR 2017 [1]. \n-\tThe paper does not address an important limitation of this approach: how to decide the number of mixture components. A more recent paper [2] (accepted at NIPS 2018 \u2013 possibly was not available at the time of this submission) addresses this issue.\n-\tThe proposed evaluation metrics do not seem to be quite different from current metrics, e.g. Inception score and FID, except that it explicitly tries to disentangle diversity vs. quality aspects\n\nOverall recommendation: \nGiven the aforementioned weaknesses, especially the lack of novelty, I do not recommend acceptance of this paper.\n\nReferences:\n[1] Gurumurthy, Swaminathan, Ravi Kiran Sarvadevabhatla, and R. Venkatesh Babu. \"DeLiGAN: Generative Adversarial Networks for Diverse and Limited Data.\" CVPR. 2017.\n[2] Khayatkhoei, Mahyar, Maneesh Singh, and Ahmed Elgammal. \"Disconnected Manifold Learning for Generative Adversarial Networks.\" NIPS (2018).\n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}