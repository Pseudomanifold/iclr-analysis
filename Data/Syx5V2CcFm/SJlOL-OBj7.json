{"title": "An interesting attempt trying to analyze the practical learning rate setting of SGD", "review": "In the paper, the authors try to analyze the convergence of stochastic gradient descent based method with stagewise learning rate and average solution in practice. The paper is very easy to follow, and the experimental results are clear. The following are my concerns:\n\n1. In function (3), for any x in R^d, if \\hat x  = prox_\\gamma f (x), then f(\\hat x ) <= f(x). This inequality looks not correct to me. If x = argmin_x f(x), the above inequality is obviously wrong.  It looks like that function (3) is a very important basis for the whole paper.\n \n2. By using the weakly convex assumption and solving f_s, the authors transform a nonconvex nonsmooth problem to a convex problem. However, the paper didn't mention how to select \\gamma in the algorithm. This parameter is nontrivial, if you set a small value, the problem is not convex and the analysis does not hold. In the experiment, the authors tune \\gamma from 1 to 2000, which means that u < 1 or u < 1/2000.  Given neural network is a u-weakly convex problem or u-smooth problem, the theory does not match the experiment. \n\n3. The authors propose a universal stagewise optimization framework and mention that the stagewise ADAGRAD obtains faster convergence than other analysis. My question is that, if it is a generic framework, how about the convergence rate for other methods? is there also acceleration for SGD or momentum SGD? \n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}