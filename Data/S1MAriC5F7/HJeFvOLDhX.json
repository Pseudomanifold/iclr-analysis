{"title": "Massively parallel hyperparameter tuning ", "review": "\n\nAuthors describe a massively parallel implementation of the successive halving algorithm (SHA). Basically, the difference between SHA and its asynchronous version ASHA, is that the later can promote configurations to the next rung, without having to wait that a previous rung is completed. \n\nI think this is a valuable contribution, although I am not sure if it has the level required by ICLR. The technical contribution of the paper is minor: it is a simple modification to an existing  methodology. However, authors perform an extensive evaluation and show that the implementation reaches SOTA performance. \n\nAuthors list 5 bullets as contributions of this paper. Whereas it is clear that the main contribution is the ASHA algorithm, the rest of contributions are in fact results that show the validity of the first contribution. I mean those contributions are the experimental evaluation to prove ASHA works. \n\nCan authors provide more details on what a configuration is? I could think of as a snapshot of a model (with fixed architecture and hyperaramenters), but I do not think my understanding is totally correct: the x-axis in Figure 1 has 9 configurations which are explored throughout rungs, hence the same configuration is evaluated many times?  \n\nAuthors claim that the method can find a good configuration in the time is required to train a network. How is this possible?, I guess is because the evaluation of each configuration is done in a small validation subset, this, however is not stated by the authors. Also, depending on the size of the validation set and implementation details, this is not necessarily an \"amazing\" result. \n\nWhy results from Section 4.1 are a contribution?, what is the impact of these results? Basically you compare existing methodologies (plus the proposed ASHA method). \n\n\n\nState-of-the ART (abstract)\nAuthors mention the theoretical benefits of SHA, but they do not emphasize these in the paper, can they elaborate on this?\n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}