{"title": "Problem of limited scope, with interesting domains but uncompelling final performance", "review": "Summary/Contributions:\nThis paper focuses on an imitation learning setup where there some of the provided demonstrations which are irrelevant to the task being considered. The stated contribution of the paper is a MAML based algorithm to imitation learning which automatically determines if the demonstrations are \"suitable\".  The authors also employ a mutual information based maximization term between the demonstrations and the pre-update and post update trajectories.  \n\nPros:\n- The tasks proposed in the problem seem interesting.\n\nCons:\n- The problem statement seems to be of limited scope.\n- The use of the task heuristics seems a bit ad-hoc. \n- The final policies are unimpressive\n\nJustification for rating:\nThe major weakness of this paper in my view are that the setup is of somewhat limited scope since receiving irrelevant demonstrations in the form used by the paper would be unnecessarily costly. The domains considered by the paper seem interesting, but the learned policies are not very compelling. I also feel that the MAML baselines + avg finetuning baselines are somewhat limited giving the new domains. I would appreciate for instance a comparison to off-policy learning methods with demonstrations which the authors discuss in the related work (Hester et al. 2017, Nair et al. 2017, Yang et al. 2018). The justification between using mutual information regularization term also does not seem well-motivated and orthogonal to the problem statement. For instance, a diversity of demonstrations should in principle allow for more information between the demonstrations and the induced change.\n\nOther:\nThe writing and grammar of the paper needs serious revision. There are error throughout the paper starting from the abstract. ", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}