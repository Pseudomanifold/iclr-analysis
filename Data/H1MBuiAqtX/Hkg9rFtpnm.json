{"title": "Presentation hard to parse. ", "review": "I tried to parse the paper's details multiple times but it really seems like a hard task. From what I understand, the paper is doing off-policy learning across several environments. The actors are parallelized across the environments (tasks), collecting rollouts, and the update to the learner is done on a GPU which trains on all these rollouts asynchronously collected. The learner uses a UVFA with an LSTM as its architecture. The authors learn on a set of training environments with various goals (associated with picking specific objects in an order) and test this policy's ability to work on new environments with a different set of goals. \n\nOverall, I find the writing really a pain to parse. I wish the authors directly wrote what they are doing quickly: \"We take Schaul's UVFA, make it recurrent, use the IMPALA set up of Esspholt, and show generalization to new combinations of objects to be collected as goals\".\n\nI am still trying to evaluate the paper, but for now, my rating for this is low given that the main novelty in the paper: the environments, the evaluations, the tasks are so unclear because of the verbose presentation style on trying to tell us what we already know, such as goal-conditioned learning, off-policy learning, IMPALA, etc. \n\n", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}