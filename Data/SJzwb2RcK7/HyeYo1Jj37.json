{"title": "The model seems to be really intriguing but the formulation ...", "review": "The paper presents a model to separately learn two parts of sentence representation in vectors: meaning and form. Why this is needed is easy to underatand and well explained. On the contrary, the forumulation of the model is indeed unnecessarely complex. It seems the authors want to convince that the model is extremely complicated. Yet, the formulation does not help in explaining the complexity of the model. \n\nThe formulation (Section 3) is a really difficult part to understand. It does not follow an easy path. First of all, what is the diffence beween \\textbf{X} and \\mathcal{X}. More importantly, where \\textbf{X} used in the formulation? What is p(.) in the main equation of the formulation? Is it a probabilistic distribution over vectors \\vec{f}^a \\vec{f}^b. Then, if p(.) is a probabilistic distribution and \\alphas are scalars, \\vec{f}_i is a scalar? \np(.) shuold be better described. \n\nIf the aim of furmulation is to help readers to go into the paper, it does not seem to be reached. On the contrary, it makes reading more complex.\n\nThe main innovation of the paper seems the introduction of two layers in a standard GAN. These two layers are: (1) the Motivator; (2) the Discriminator. These two models should address two different perspectives for sentence modeling. To better explain the model, the athors could use Fig. 1 by adding the outputs and the inputs of the layers. If the input and the output of the generator are intuitive, the output of the Motivator and the Discriminator is not that clear. An example could be very useful to clarify the model. What is exactly the output of the Discriminator? And the one of the Motivator? These two layers force the separation of the meaning and the form, respectively. But how? What is the target output for the first and the target output for the second?\n\nMinor issues\n====\nThere are some abbreviations that are not explained or are explained after their first use, e.g., Natural Language Processing (NLP), CV?, Generative Adversial Network (GAN), Long-Short Term Memory (LSTM), ...\n ", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}