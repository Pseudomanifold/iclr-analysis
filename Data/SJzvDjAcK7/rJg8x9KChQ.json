{"title": "Interesting augmentation of training procedure to induce low-rank activations at intermediate layers, but unable to evaluate the significance", "review": "Synopsis: \nOverall, this paper was fairly well written and seems to have an original approach towards inducing low-rank structure on the space of activations in some intermediate layer in a computationally efficient way without changing the underlying model. This training modification does not seem to affect test performance and the low-rank embeddings that are learned seem useful at discriminative tasks. Adversarial robustness also appears improved.\n\nPros:\n--While I am not familiar enough with the background literature on model compression in neural networks, I thought the augmented optimization problem used to induce low-rank structure on the space of activations was interesting and worthy of investigation. The authors appear to get great results in Table 1 & Table 2.\n\nCons:\n--I cannot really gauge the significance of the result against other existing approaches towards low-dimensional representations because of my limited familiarity with the relevant literature. However, I didn\u2019t feel quite convinced by the discussion in the paper that low-rank activations were superior to other kinds of low-rank approximations, for instance to the network weights (c.f. discussion in Appendix A). I think the discussion on this topic could be a bit improved.\n--With respect to the writing, I\u2019m a bit uncertain as to the primary message of the paper. While it seems to introduce a new augmented training approach for generating compressed representations which potentially has practical utility, based on the paper title and scattered discussion it seems to suggest that the representations themselves are interesting, e.g. the idea of having low-rank activations while largely maintaining test performance. I didn\u2019t fully understand the extent to which the results are intriguing or helpful in understanding neural networks. Could this be developed a bit more?\n\nMiscellaneous comments:\n--In Figure 2, the accuracy with respect to adversarial perturbations seems to drop more for VGG19 2-LR (pink curve) than the model VGG19 N-LR (brown), which seems counter to your point on robustness?\n--In Figure 4, why is the behavior of ResNet 2-LR (blue curve) similar to ResNet N-LR (red curve)? I would\u2019ve expected any number of LR layers to increase the sensitivity in intermediate layers to adversarial input perturbations.\n\n\n", "rating": "6: Marginally above acceptance threshold", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}