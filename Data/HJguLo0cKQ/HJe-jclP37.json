{"title": "Simple but effective variant on training ensemble of independently adversarially trained models", "review": "The paper proposes to train an ensemble of models jointly, where the coupling lies in that at each time step, a set of examples that are adversarial for the ensemble itself is incorporated in the learning.\n\nThe experiments are thorough and compare multiple types of attacks, although they are all based on gradients (while the paper does mention recent attacks that do not rely on gradients so much). The results are rather convincing and show a clear difference between the proposed method and independently training the models of the ensemble (even if each one is training with examples adversarial to itself).\n\nThe paper is clear and well-written.\n\nPros:\n- The superior performance of the proposed method\n- The method is simple and thus could have a practical impact\n- Clear and thorough analysis\n\nCons:\n- Only gradient based attacks (which are somewhat criticized in the introduction) \n- Novelty may be a bit limited: this is a rather small variation on existing stuff (but it works rather well)\n\nRemarks:\n- Fig 2c could use the same line styles and order as Fig 2a/2b\n- \"a gap 7 accuracy\"?", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}