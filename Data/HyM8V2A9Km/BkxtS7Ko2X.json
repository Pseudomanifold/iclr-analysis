{"title": "Simple and intuitive idea but evaluation seems to be quite lacking", "review": "This paper considers the assumption implicit in hindsight experience replay (HER), namely that we have access to a mapping from states to goals. Rather than satisfying this requirement by defining goals as states, which involves great redundancy, the paper proposes a natural language goal representation. Concretely, for every state a teacher is used to provide a natural language description of the goal achieved in that state, which can be used to directly relabel the goal so the episode can be used as a positive experience.   \n\nStrengths:\n- the proposed idea is simple and intuitively appealing, and shows much better results than the DQN baseline.\n\nWeaknesses:\n- In the VizDoom task, the goal specification is already in (templated) language. Given that this is the case, and the mapping from states to goals can be extracted from the environment anyway, it seems like the method that is applied really just reduces to a vanilla implementation of HER. There seems to be little novelty in this. From reading the introduction and method, I expected the ACTRCE approach to be applied to a task where the goal was not originally specified in language, perhaps by collecting language from human teachers. This would be a much more interesting experiment, addressing the question of whether human feedback in natural language can help the agent learn more quickly.\n- Even leaving aside the previous concern, it seems very difficult to put this work in the context of previous work on the same tasks. For example, it is not clear why there are no comparisons to the previous work on instruction following in VizDoom, as the setting appears to be exactly like Chaplot et al. 2017. It would seem like a natural comparison would be to take the model from Chaplot (leaving the task and architecture etc unchanged) and train it using ACTRCE. Is there any reason why this can\u2019t be done? There is already so much existing work in this space, it seems quite unusual that the proposed new method is not compared to any existing work on an existing task.\n\n\nSummary:\nThis is a simple and intuitively appealing idea, but I find the evaluation to be quite lacking because the tasks already use a language specification (such that ACTRCE seems to be vanilla HER in application) and there are no comparisons to previous work. These two concerns seem quite substantial to me and make it difficult to recommend acceptance. \n\nSmaller issues:\n- ACTRCE - possibly the most tortured acronym in recent memory! How should it be pronounced?", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}