{"title": "Review", "review": "This paper consists of two contributions: (1) using a fixed pre-trained network as a discriminator in feature matching loss ((Salimans et al., 2016). Since it's fixed there is no GAN-like training procedure. (2) Using \"ADAM\"-moving average to improve the convergency for the feature matching loss.\n\nThe paper is well written and easy to follow but it lack of some intuition for the proposed approach. There also some typo, e.g. \"quiet\" -> quite. Overall, it's a combination of several published method so I would expect a strong performance/analysis on the experimental session.\n\nDetailed Comment:\n\nFor contribution (1):\n\nThe proposed method is very similar to (Li et al. (2015)) as the author pointed out in related work besides this work map to data space directly. Is there any intuition why this is better? \n\nThe proposed loss (the same as (Salimans et al., 2016)) only try to matching first-order momentum. So I assume it is insensitive to higher-order statistics. Does it less successful at producing samples with high visual fidelity?\n\nFor contribution (2):\n\n\"one would need big mini-batches which would result in slowing down the training.\" why larger batch slowing down the training? Is there any qualitative results? Based recent paper e.g. big gan, it seem the model can benefit a lot from larger batch. In the meanwhile, even larger batch make it slower to converge, it can improve throughput. \n\nAgain, can the author provide some intuition for these modification? It's also unclear to me what is ADAM(). Better to link some equation to the original paper or simply write down the formulation and give some explanation on it.\n\nFor experiments:\n\nI'm not an expert to interpret experimental results for image generation. But overall, the results seems not very impressive. Given the best results is using ImageNet as a classifier, I think it should compare with some semi-supervised image generation paper.\n\nFor example, for CIFAR results, it seems worse than (Warde-Farley & Bengio, 2017), Table 1, semi-supervised case. If we compare unsupervised case (autoencoder), it also seems a lot worse. \n\nAppendix A.8 is very interesting / important to apply pre-trained network in GAN framework. However, it only say failed to train without any explanation.\n\nI think even it just comparable with GAN, it is interesting if there is no mode collapsing and easy to train. However, it has no proper imagenet results (it has a subset, but only some generated image shows here). \n\nIn summary, this paper provide some interesting perspectives. However, the main algorithms are very similar to some existing methods, more discussion could be used to compare with the existing literature and clarify the novelty of the current paper. The empirical results could also be made more stronger by including more relevant baseline methods and more systematic study of the effectiveness of the proposed approach. I tend to give a weak reject or reject for this paper.\n\n---\n\nUpdate post in AC discussion session.\n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}