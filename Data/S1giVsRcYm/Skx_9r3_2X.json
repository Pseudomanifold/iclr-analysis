{"title": "Theoretically grounded work but lacking convincing results", "review": "The authors are tackling sample efficiency in the reinforcement learning setting by designing a reward function that encourages exploration. To achieve this they propose you use the successor function which basically counts how often a state has been visited. At first the show this for discrete settings and extend their approach to the continuous state spaces in the Atari 2600 environments. \n\nThe paper is well written and the motivation and methods are clear from the beginning. \n\nMy biggest concerning is regarding the experimental results of this work. In Table 1 the authors show the results for the tabular games River Swim and Six Arms and copare their approach which they dub ESSR to three methods (E3, R-MAX, MBIE). The numbers in the table indicate that their method ESSR is outperforming E3 and R-MAX on both environments but is itself outperformed by MBIE. The authors don't mention this at al in the respective paragraph nor do the provide a reason as to why this could be case. Also, they neither introduce any of these methods nor do the explain the meaning of the acronyms. Only in the section 6 (of 7) they talk about related works are R-MAX and E3 introduced briefly. But yet again, MBIE is not mentioned. \n\nI have similar concerns about the results presented for the Atari benchmarks. In table 2 the authors compare their method to the classic DQN approach and two more approaches. While their approach outperforms DQN in almost all tasks, this does not hold for the remaining algorithms. Their method is being outperformed in all but one (Venture) task, where they report a higher variance and a small performance boost compared to DQN_e^MMC. Also it is not clear to me where the numbers for the DNQ_e^MMC come from. The authors just say \"[...] denotes another baseline used in the comparison\". Is this the proposed method of this work but without the successor representation?\n\nIn my opinion this work is lacking some clear and convincing results.  Is the main benefit of this method that it does not rely on domain-specific knowledge? If so, then it is not communicated clearly. The authors mention this briefly in the conclusion but provide no further analysis", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}