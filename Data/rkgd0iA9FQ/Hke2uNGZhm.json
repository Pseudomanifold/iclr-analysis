{"title": "Missing a very relevant reference that discusses the exact same issue", "review": "*Summary:\nThis paper analyzes the convergence of ADAM and RMSProp to stationary points\nin the non convex setting.\nIn the second part the authors experimantally compare the performance of these methods to Nesterov's Accelerated method.\n\n\n\n*Comments:\n\n-The paper does not tell a coherent story and the two parts of the paper are somewhat unrelated.\n\n-The authors claim that they are the first to analyze adaptive methods in the non-convex setting, yet this was recently done in \n[Xiaoyu Li, Francesco Orabona; On the Convergence of Stochastic Gradient Descent with Adaptive Stepsizes]\nThe authors should cite this paper and compare their results to it.\n\n-The above paper of [Li and Orabona] demonstrates a nice benefit of AdaGrad in the non-convex setting. Concretely they show that in the noisless setting adaptive methods give a faster rate of $O(1/T)$ compared to the standard rate of $O(1/\\sqrt{T})$ of SGD.\n\nUnfortunately, the results of the current paper do not illustrate the benefit of adaptive methods over SGD, since the authors provide similar rates to SGD or even worse rates in some situations.\nI think that in light of [Li and Orabona] one should expect a $O(1/T)$ rate also for ADAM and RMSProp.\n\n\n-The experimental part is not so related to the first part. And the experimental phenomena is only demonstrated for the MNIST dataset, which is not satisfying. \n\n\n*Summary:\nThe main contribution of this paper is to provide rates for approaching stationary points.\nThis is done for ADAM and RMSProp, two adaptive training methods.\nThe authors do not mention a very relevant reference, [Li and Orabona].\nAlso, the authors do not show if ADAM and RMSProp have any benefit compared to SGD in the non-convex setting, which is a bit disappointing. Especially since [Li and Orabona] do demonstrate the benefit of AdaGrad in their paper.\n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}