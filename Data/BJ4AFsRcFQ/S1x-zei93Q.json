{"title": "Interesting extension but lack of meaningful evaluation", "review": "The submission proposes a new model for the task of fast style transfer with arbitrary input images.\nThe model combines the existing approach of Li et al. 2017 [1] and the idea of inter-layer correlations into a new model architecture for fast style transfer. Notably the idea of inter-layer correlations is not new, it was first proposed by Novak and Nikulin [2] and recently picked up by Yeh and Tang[3] (both methods are not referenced in the present submission).\nTo evaluate the model, visual comparisons with other methods are shown and quantitative loss values for content and style loss are computed. \n\nMy main issue with the submission is that the scope of the evaluation is not suited to demonstrate a clear advantage of the proposed method over existing work. The qualitative comparison remains highly subjective. Based on figure 7 I could not tell which method performs the best style transfer and this might well be because the systematic perceptual differences between the methods are small. \nTo demonstrate a clear advance of the method in style transfer, I do believe it is necessary to run a user study showing that users systematically prefer the output of the proposed method over that of competing methods.\n\nAdditionally the quantitative evaluation leaves several open questions:\n- Why is there no comparison with Ghiasi et al. 2017 [4]? This is the natural extension of Dumoulin et al. 2017 [5] for arbitrary fast style transfer.\n- What exactly is the content and style loss that these methods are compared on? Is it the one used for the models in this submission? If so, were the compared methods also trained to minimise this loss function? If not this does not seem to be a fair comparison. \n- Even if all methods were trained to minimise the same loss function, without user study it is unclear if that loss function is a good approximation of perceptual preference, which is the actual underlying target that style transfer aims to optimise.\n\nAs a side note, the provided baseline of the Gatys et al. [6] method is somewhat misleading because it is using the Adam optimiser. The original work used LBFGS to optimise the loss function and it is fairly well known that the choice of optimiser can have significant impact on the quality of the results.\nI do not think this comparison is critical for the submission because the proposed method mainly competes with other fast style transfer methods, but I would recommend more care to be taken when reproducing existing work. \n\nAll in all I think the submission proposes an interesting combination of existing methods leading to reasonable extension of the body of work in fast style transfer. However, given the lack of meaningful evaluation I am not convinced that the proposed method substantially advances the field of fast style transfer to warrant publication at ICLR.\n\n\n[1] Yijun Li, Chen Fang, Jimei Yang, Zhaowen Wang, Xin Lu, and Ming-Hsuan Yang. Universal style transfer via feature transforms. In Advances in Neural Information Processing Systems, pp. 385\u2013 395, 2017b.\n[2] Improving the Neural Algorithm of Artistic Style. R Novak, Y Nikulin\u00a0- arXiv preprint arXiv:1605.04603, 2016 - arxiv.org\n[3] Improved Style Transfer by Respecting Inter-layer Correlations MC Yeh, S Tang\u00a0- arXiv preprint arXiv:1801.01933, 2018 - arxiv.org\n[4] Golnaz Ghiasi, Honglak Lee, Manjunath Kudlur, Vincent Dumoulin, and Jonathon Shlens. Explor- ing the structure of a real-time, arbitrary neural artistic stylization network. In British Machine Vision Conference (BMVC), Sep 2017. \n[5] Vincent Dumoulin, Jonathon Shlens, and Manjunath Kudlur. A learned representation for artistic style. In International Conference on Learning Representations (ICLR), Apr 2017. \n[6] Leon A. Gatys, Alexander S. Ecker, and Matthias Bethge. Image style transfer using convolutional neural networks. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2016.\n", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}