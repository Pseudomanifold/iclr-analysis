{"title": "Unclear description of algorithm, experiments could be improved. ", "review": "Summary: \n- In this paper, an algorithm to improve the catastrophic forgetting of the model is proposed. The key idea consists of 1) introducing the dynamic parameter generator (DPG) for \"model's adaptation\" to data at test time and 2) data generator (DG) for remembering previously trained dataset. \n\nPros: \n- Empirical results seem strong. The proposed result outperforms existing algorithms by quite large margin.\n\nCons:\n- In general, I felt that the paper is unorganized and hard to read. Clarity should be definitely improved if this paper is to be published as a conference paper.\n\n- Output of dynamic parameter generator is very high dimensional (it requires weight with dimension of input dim x NN weight dim). I think this approach is not scalable to higher dimension and typically requires even more memory than storing the whole dataset. \n\n- Although auto-encoder and generative replay was considered to reduce memory consumption, there is no description of how much memory is saved by them. In order to make the argument more convincing, the authors should explicitly describe the amount of memory consumed by each algorithms. \n\n- There seems to be a lot of ideas introduced, i.e, DPG for generation of weights, auto-encoders for generation of data and layer output constraint, i.e., Equation (7).  I think each of introduced method deserves some amount of empirical evaluation to validate its contribution to the performance.  \n\n- Experiments only consider 2~3 tasks, which does not seem very representative for the lifelong learning tasks.\n", "rating": "6: Marginally above acceptance threshold", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}