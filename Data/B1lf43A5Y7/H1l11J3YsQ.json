{"title": "Interesting analysis, but...", "review": "This paper studies the behavior of memory network in the task of multi-hop reasoning. Although memory network was advertised to be capable of multi-hop reasoning, this paper argues that memory network fails to learn reasonable multi-hop reasoning. However, by incorporating the supervision of reasoning path by encouraging attentions to appropriate sentences, memory network was able to perform multi-hop reasoning.\n\nThe analysis in the paper is interesting. Especially, some of them I found very interesting is\n(i) Attention targets show that memory network does not attend to the appropriate sentences.\n(ii) On WikiHop, `NoText` (which doesn\u2019t read given document at all) achieves 59.7, which is only 5.1 lower than SOTA.\n(iii) Encouraging attention to appropriate sentence leads to a dramatic performance gain (on bAbI path-finding and Wikihop Masked).\n\nHowever, I found some limitations as follows.\n\nFirst of all, bAbI QA and Wikihop are insufficient to draw attention.\n- bAbI QA is synthetic \u2014 If current models are struggling with synthetic datasets, it\u2019s great to work on synthetic datasets, since working on the easier dataset and later move on to the harder, real dataset makes sense. However, bAbI QA was solved a while ago (2 years ago, in this venue) and people are less interested in synthetic multi-hop reasoning now.\n- WikiHop is pretty noisy \u2014 the authors of the original WikiHop paper has mentioned only 36% of questions have a unique multi-step answer (9% have a single-step answer, and 55% either have multiple possible answers or are noisy). In addition, this papers shows the model gets 59.7% without document, which means this task is not for multi-hop reasoning.\n\nSecond, this paper studies memory network in particular, but memory network is not used for multi-hop reasoning in a real dataset. For example, on Wikihop Masked, Memory network without supervision achieves 14.2 which means it doesn\u2019t work at all. Even after adding supervision, it is worse than standard QA models (models designed for the single-hop task).\n\nLastly, the analysis of the attention targets without supervision does not give a new intuition about the incapability of the model in multi-hop reasoning, because the performance of the model is already bad (on bAbI path-finding and Wikihop Masked, since Wikihop standard seems to be meaningless).\n\nTo summarize, their motivation and the idea of encouraging attention to the right sentences is neat. In particular, since memory network has drawn a lot of attention, this study might give a new intuition to people who have been working on memory network. However, some limitations mentioned above made this paper not sufficient to be presented at ICLR main conference.\n\nI think the authors can try one of these to make the paper better.\n\n(i) Choose a pair of dataset and the model which the model performs reasonably on the dataset. (For example, bAbI except for path-finding & memory network, or Wikihop & Wikihop SOTA models), and try the same analysis. Then, the story will be \u201cThough memory network performs well on this task, it turns out that it is not doing right multi-hop reasoning\u201d. Also, it would be awesome if adding supervision can lead to a even higher performance by doing appropriate reasoning, but it shouldn\u2019t be necessary.\n(ii) Try the same analysis in more widely used tasks and models. I think a pair of (Wikihop Masked, Wikihop Masked SOTA model) is sufficient.\n\nEven though the authors do not revise the paper (since it would take too long to revise), I think this paper is worth to be presented at ICLR workshop.", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}