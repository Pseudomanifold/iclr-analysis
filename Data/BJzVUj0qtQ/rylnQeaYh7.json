{"title": "The motivation of the method is unclear", "review": "This paper argues the expansion of the attentive regions (attention shift) as a mechanism of several defense models, then proposes an attention-invariant attack method by convolving attack gradients with the Gaussian filter. The technique demonstrates its effectiveness against various defense models.\n\nThe main concerning to me is that the motivation of using shifting operation to solve the attention \"shift\" is entirely unclear.  As shown in Figure 1, the expansion of the attentive regions seem to be fairly large, so it is difficult to say if shifting the image by several pixels (or convolving the gradients by a 15x15 kernel) can mitigate the effects of attention \"shift\". The true mechanism of this attack could be very different in my opinion.\n\nSecondly, as shown in Figure 2, the patterns of adversarial perturbations of the proposed method seem to be reasonably easier to be detected, or more perceptible to humans (at least to me). I wonder if the authors could training a detection network to distinguish if an image is attacked by the proposed method and report the results.", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}