{"title": "An interesting problem : active learning for anomaly detection; method suffering from a lack of novelty; questions about experiments", "review": "The paper provided a convincing and intuitive motivation regarding the need for active learning in unsupervised anomaly detection. \nHowever the proposed approach of requesting expert feedback for the top ranked anomalies is straightforward and unsurprising, given past work on active learning. \nThe experiments on synthetic data are also unsurprising. Moreover these are based on a questionable premise: the instances that are \"hard\" to classify are treated as anomalies. This is not very realistic.\nRegarding the real data experiments: In Table 1 the results for DAE_uai are based on which budget b?  How does the result vary with b? \n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}