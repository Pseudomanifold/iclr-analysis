{"title": "An approach to learn lifted transition rules using neural networks that take advantage of relational structure", "review": "An approach is proposed that learns transition rules in terms of local contexts. Specifically, transition rules make predictions as a distribution over the set of possible states based on local context of objects. A learning algorithm is described that learns the transition rules by maximizing the conditional likelihood. To learn the rules jointly with selecting the right samples for the transition rule, and EM algorithm is proposed. \n\nThe paper is well-written. The contribution seems significant considering that relational structure is integrated with neural networks in a systematic manner. Though written from the perspective of learning transition rules for tasks such as robotic manipulation, I think similar ideas can be for general tasks that can benefit from both relational structure and neural network representation.  Learning lifted rules has also been studied in  domains such as ILP and Statistical Relational Learning (Getoor and Taskar 07)(lifted rules with uncertainty). I think including their perspective and commenting on their relationship with the proposed work will be useful.\n\nExperiments are performed on a robotic manipulation task involving pushing a stack of blocks in a cluttered environment. A method that does not take object relations into account and simply predicts the state transition is used as baseline for comparison. The proposed approach shows the benefits of exploiting the structure between objects. There is not too much discussion on scalability. Does the propose method scale up for learning transition rules in real tasks? Are there any tradeoffs involved, etc. would be good to know.\nIn summary, this seems to be a well-written and novel contribution.", "rating": "7: Good paper, accept", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}