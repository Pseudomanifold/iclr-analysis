{"title": "Discriminative out-of-distribution detection for semantic segmentation", "review": "Summary:\nThis paper addresses the problem of out-of-distribution detection for helping the segmentation process. Therefore, the detection is performed on a pixel basis. The application of the approach is to datasets used for autonomous driving, where semantic segmentation of the view of the road is a typical application. Since in a road view there will be pixels that are projections of objects that are likely not in the set of classes known by the semantic segmentation algorithm, it makes sense to flag them as being out of distribution (OOD), or not known, or to assign to them a low confidence level. The proposed approach is trivial: train a binary classifier that distinguishes image patches from a known set of classes from image patches coming from an unknown (background class). The classifier output applied at every pixel will give the confidence value. While there are different dataset options to represent the known classes, the background class is represented by images from ILSVRC. The results show that for the segmentation application the approach works better than using an adaptation of more elaborate out-of-distribution methods.\n\nQuality and clarity:\nThe paper is well organized and is described very clearly and provides an ok set of results, despite the simplicity of the approach.\n\nOriginality and significance:\nUnfortunately, I do not see any relevant technical novelty, and this is a major issue. Perhaps the only significant conclusion about this paper is that before designing a new OOD detector, if representing the set of \u201cunknown\u201d classes with ILVRC is reasonable, then it makes sense to simply train a binary classifier and see how it works.\n\nBesides the novelty, I disagree with the way the paper has been positioned and motivated. It brings into play epistemic and aleatoric uncertainty concepts to justify (the simplicity of) the approach, and it overlooks a large body of machine learning (novelty detection, one-class classification, \u2026). This is also a major issue.\n\n\nAdditional comments:\n\nOne of the biggest motivations for this work is that other approaches do not distinguish between epistemic and aleatoric uncertainty and this is why they do not work. This is regarded as a distinctive advantage of the proposed approach. It is claimed that the proposed formulation is insensitive to any aleatoric uncertainty. On the other hand, the paper is written in a way that ignores a large body of literature that goes under the name of \u201cnovelty detection\u201d, \u201canomaly detection\u201d, \u201cone-class classification\u201d, and related names. So, I am wondering how the approaches just mentioned compare with the proposed method, when epistemic and aleatoric uncertainty become part of the discussion. Isn\u2019t every novelty detector insensitive to aleatoric uncertainty as well? Could the Authors clarify what they claim with that statement, while considering a broader view? \n\nThe paper should relate to the literature mentioned above. In particular, I would point the Authors to a couple of recent works that seem to precisely contradict the premises of the proposed approach, which are given at the beginning of section 3:\n\n- Adversarially Learned One-Class Classifier for Novelty Detection, CVPR 2018\n- Generative Probabilistic Novelty Detection with Adversarial Autoencoders, arXiv, July 2018.\n\n\nAgain, related to novelty detection, it looks like the proposed approach still requires tuning one or more thresholds. Therefore, it would not be that different from tuning the threshold of a novelty detector, or a one-class classifier. It would have strengthened the paper if the approach was compared also to a novelty detector.\n\nIt is not clear if the fully convolutional OOD detector is working on a patch or on the entire image. If it is a patch, of what size?\n\nPage 4, define the \u201cID\u201d acronym. \n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}