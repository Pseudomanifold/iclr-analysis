{"title": "Unconvincing experimental results and theoretical arguments ", "review": "The paper proposes yet another variant of the celebrated Dropout algorithm. Specifically, the proposed method attempts to address the obvious drawbacks of Dropout: (i) the need to heuristically select the Dropout rate; and (ii) the universality of this selection across a layer. \n\nAs the authors have admitted in the paper (Sec. 1.2), there is a variety of methods already addressing the same problem. They argue that contrary to some of these methods \"jumpout does not rely on additional trained models: it adjusts the dropout rate solely based on the ReLU activation patterns. Moreover, jumpout introduces negligible computation and memory overhead relative to the original dropout methods, and can be easily incorporated into existing model architectures.\"\n\nHowever, this is argument is certainly untrue and rather misleading. The works of Kingma et al. (2015) and Molchanov et al. (2017), that the authors cite, does not introduce additional trained models. In addition, there is additional related work that the authors do not cite, but ought to: \n\n[1] Yarin Gal, Jiri Hron, Alex Kendall, \"Concrete Dropout,\" Proc. NIPS 2017.\n[2] Yingzhen Li, Yarin Gal, \"Dropout Inference in Bayesian Neural Networks with Alpha-divergences,\" Proc ICML 2017.\n[3] Harris Partaourides, Sotirios Chatzis, \u201cDeep Network Regularization via Bayesian Inference of Synaptic Connectivity,\u201d J. Kim et al. (Eds.): PAKDD 2017, Part I, LNAI 10234, pp. 30\u201341, 2017. \n\nThese methods also address a similar problem, without introducing extra networks or imposing extra costs art inference time. Thus, citing them, as well as COMPARING to them, is a necessity for this paper to be convincing.\n\nThese crucial shortcoming aside, there are various theoretical claims in this paper that are not sufficiently substantiated. To begin with, the arguments used in the last paragraph of page 4 seem at least speculative; then,  the authors proceed to propose a solution to the alleged problem in the beginning of page 5. They suggest sampling from a truncated Gaussian, but they do not elaborate on why this selection solves the problem; they limit themselves to noting that other selections, such as the Beta distribution, may also be considered in the future. We must also underline that [3] have suggested exactly that; sampling from a Beta. \n\nFinally, the last two modifications the authors propose seem reasonable, yet they are extremely heuristic. No one knows (which can be guaranteed through theoretical proofs or solid experimental evidence) that without these the method would not work. In addition, previous papers, e.g. [1-3] achieve similar goals in a principled fashion (ie by inferring proper posterior densities); without experimental comparisons, nobody knows which paradigm is best to adopt. \n\n", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}