{"title": "Method clarity can be improved, and lacks some key comparisons experimentally.", "review": "In this paper, the authors introduce a neural network architecture that has three components.\nFirst a VAE is used to encode images in to two latent states \\hat{y} and \\hat{z}, with \\hat{z}\nintended to be class (e.g. face attribute) agnostic. The decoder reconstructs images from \\hat{y}\nand \\hat{z} concatenated together. A GAN style discriminator attempts to distinguish the \ndecoded image from the original input image as real or fake, allowing the decoder to produce \nhigher quality decoded images. An auxiliary network A attempts to classify the face attribute y\nfrom the class agnostic features \\hat{z}, with the idea being that the encoder should try to produce \n\\hat{z} vectors from which the class cannot be predicted. An additional classifier is trained\nusing a classification loss \\hat{L}_{class} on the encoded reconstructed image, the use of which \nI don't understand.\n\nI think additional work on section 2.5 through section 3 would be helpful to improve clarity.\nAs one example, \"y\" is unnecessarily overloaded: y denotes a specific attribute, \\hat{y}\ndenotes a latent vector that is intended to not be class agnostic, \\tilde{y} denotes the\nprediction of an auxiliary network on an intended class-agnostic latent vector \\hat{z} of\nthe presence of the original attribute y, and \\hat{\\hat{y}} denotes the non agnostic latent\nvector achieved by passing the decoded image back through the encoder.\n\nThis notational complexity is compounded by the fact that a number of steps in the method are\nnot well motivated in the text, and left to the reader to understand their purpose. For example,\nthe authors state that \"we incorporate a classification model into the encoder so that our model may\neasily be used to perform classification tasks.\" What does this mean? In the diagram (Figure 1),\nwhere is this classification model? Why in the GAN loss is there a term that compares the\nfake loss with the result of classifying a decoded z vector? Is this z \\hat{z}, or a latent vector\ndrawn from a distribution p(z)? If it is the former, how does this term differ from the second\nterm in the GAN loss. If it is the latter, then shouldn't it be concatenated with some y in order to\nbe used as input to the decoder D_{\\theta}?\n\nWhy is it important to extract \\hat{\\hat{y}} from \\hat{x}? In the paper you state that the loss\n\"provides a gradient containing label information to the decoder,\" but why can't we use the known label y\nof the original input x to ensure that the encoder and decoder preserve this information if it is used as \\hat{y}?\nLater in the paper, you explicitly state that \\hat{\\mathcal{L}_{class}} \"does not provide any clear benefit.\"\nIf that is the case, then you should ideally include it neither in the model nor in the paper. If it was\nincluded primarily because previous models included it, then I would recommend you introduce its use\nin a background section on Bao et al., 2017 rather than including it in your model description with an\nexplanation like \"so that our model may easily be used to perform classification tasks.\"\n\nUltimately, this last point brings us to a good summary of my concerns with the model: the inclusion\nof too many moving parts, some of which the authors explicitly say later on provide no benefit.\n\nMoving on to experimental results, I think this is another area where I have a few concerns. First, in\nFigure 2, the authors argue that your model is \"better for 6 out of 10 attributes\" and comparable results for most others. The authors include a gap of 0.1 in the \"Gray_hair\" category as \"better\" but label a gap of 0.5\nin the Black hair category as \"comparable.\" I think results in several of the categories are sufficiently close\nthat error bars would be necessary to draw actual conclusions. If \"better\" were to mean \"better by 0.5\" for example,\nthen the authors method is better on 4 tasks (smiling, blonde hair, heavy makeup, mustache) and worse on 3 (black hair, brown hair, wavy hair).\n\nWith respect to the actual attribute editing, my main concern here is a lack of comparison to models other than Bao et al., despite the fact that face attribute changing is an exhaustively studied task. A number of papers like Perarnau et al., 2016, Upchurch et al., 2017, Lample et al., 2017 and others study this task from machine learning perspectives, and in some cases can perform photorealistic image attribute editing without complicated machinery on megapixel face\nimages. At least the images in Figure 3 and 4 are substantially downsampled from the typical resolution found in the Celeba dataset, suggesting that there was some failure mode on full resolution images.\n\n----\n\nEdit: I've reviewed the authors' addressing my concerns in their paper and am happy to increase my rating as a result.", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}