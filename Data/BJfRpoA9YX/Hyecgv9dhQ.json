{"title": "missing references to previous work ", "review": "Summary: \n\nThis paper builds upon the work of Boa et al (2017 ) (Conditional VAE GAN) to allow attribute manipulation in the synthesis process. \n\nIn order to disentangle the identity information from the attributes the paper proposes adversarial information factorization : let z be the latent code and y be the attribute the paper proposes to have p(y) =  p(y|z= E_phi(x)), i.e to have z independent of y.  This disentanglement is implemented through a GAN on the variable y  min _phi Distance (p(y), p(y|z)), the distance is defined via a discriminator on y.  \n\nExperiments are presented on celeba dataset,  1) on attribute manipulation from smiling to non smiling for example, on 2) attribute classification results are presented , 3) ablation studies are given to study the effect of each component of the model highlighting the effect of the adversarial information factorization. \n\nOriginality Novelty: \n\nThere is a large body of work on disentanglement that the paper does not cite or compare to for instance, InfoGAN,  Beta- VAE https://openreview.net/pdf?id=Sy2fzU9gl and disentangled latent concepts https://arxiv.org/pdf/1711.00848.pdf\n\nNote that for example that in beta- VAE it is a similar idea where but it is on z and z|x and the distance used is KL (since it is has closed form with gaussian) , min_phi Loss+ beta KL (p(z), p(z|x)), a discussion of the previous related work in the paper is necessary.  \n\nThe work is also related to MINE https://arxiv.org/pdf/1801.04062.pdf where one would like to minimize the mutual information I(z;y)  this mutual information is estimated through a min/max game.\n \nQuestions: \n\n-  why is RMSprop used for optimization, your model and the Bao et al baseline might benefit from the use of Adam?\n\n- (Table 3 in appendix ) Have you tried higher values of alpha the weight of KL, with the model of Bao et al (it is recommended in beta VAE to have high value of what you call alpha)?\n\nOverall assessment: \n\nThe paper novelty is using min/max game to estimate the mutual information between y (attribute) and z (identity code). Disentanglement and use of min/max games for estimating mutual information has been explored before.  Further discussion and comparaison to previous work is needed. \n\n\n\n \n\n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}