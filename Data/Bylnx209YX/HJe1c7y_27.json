{"title": "Used meta-learning by treating graph structure as hyperparameter to get the poisoned graph. Achieved reasonable results on three graph datasets.", "review": "This paper studies the problem of learning a better poisoned graph parameters that can maximize the loss of a graph neural network. The proposed using meta-learning to compute the second-order derivatives to get the meta-gradients seems reasonable. The authors also proposed approximate methods to compute the graph as learning parameters, which could be more efficient since the second-order derivatives are no longer computed. The experimental results on three graph datasets show that the proposed model could improve the misclassification rate of the unlabeled nodes.\n\nThe paper is well-written. It would be good if the authors could address the following suggestions or concerns:\n\n1) The proposed attack model assumes the only the graph structure are accessiable to the attackers, which might limit the proposed model in real applications. Joint study with the graph features would be useful to convince more audience and potentially have larger impacts.\n\n2) In the self-learning setting, in order to define l_atk, l_self is used, however, l_self is using v_u, which is the ground truth label of the test nodes based on my understanding, so this approach is using labels of the unlabeled data, which might be not applicable in real world.\n\n3) About the action space, based on the constraints of the attacker's capability, the possible attacks will be significantly smaller than O(N^2 delta), might be O(N^delta).\n\n4) Change 'treat the graph structure as a hyperparameter' to 'treat the graph structure tensor/matrix as a hyperparameter' would be earier to understand. And is the graph structure tensor with shape (NXN)? \n\n5) What's the relationship between T and S? Are T in theta_T is the same as the S in G_S?\n\n6) The title of section 4.2 is misleading. It would be better to name it as 'Greedy Computing Meta-Gradients'. \n\n7) It lacks intuition of why define S(u,v)=delta . (-2.a_uv+1). '(-2.a_uv+1)' looks lack of intuition. Please also change 'pair (i,j), we define S(u,v)' -> 'pair (u,v)'.\n\n8) In the experiments, what's the definition of meta-train? l_atk=-l_train?\n\n9) In the experiments, it would be interesting to study the impact of unnoticaability constraints on the model results.\n\n10) In figure 1, it is not surprising that when increasing the number of edges changed, the misclassification rates will increase. A graph NN considers more graph features rather than the structure is expected to show the impact of the graph structure change.\n\nI have read the authors' detailed rebuttal. Thanks.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}