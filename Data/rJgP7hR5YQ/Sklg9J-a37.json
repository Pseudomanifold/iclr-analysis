{"title": "interesting paper, but missed quantitative analysis and comparisons.", "review": "[Overview]\n\nIn this paper, the authors studied the problem of composition and decomposition of GANs. Motivated by the observations that images are naturally composed of multiple layouts, the authors proposed a new framework to study the compositional image generation and its decomposition by defining several tasks. On those various tasks, the authors demonstrate the possibility of the proposed model to composing image components and decompose the images afterwards. These results are interesting and insightful to some extent.\n\n[Strengthes]\n\n1. The authors proposed a framework for compose images from components and decompose the images into components. Based on this new framework, the authors tried different settings, by fixing the learning of one or more modules in the model. The experiments on various tasks are appreciated.\n\n2. In the experiments, the authors tried both image and text to demonstrate the concepts in this paper. Moreover, some qualitative results are presented.\n\n[Weaknesses]\n\n1. The authors performed multiple experiments regarding various tasks defined in this paper.However, I can hardly find any quantitative evaluation for the results. It is not clear to me that how the quality of the composed images and the decomposed components from images are. I would suggest the authors derive some metric to measure quality quantitatively, provide some statistics on the whole datasets.\n\n2. In this paper, the authors proposed multiple tasks in terms of which parts are fixed and known in the training process. However, dominated by so many different tasks, the core idea is losses in the paper. From the paper, I cannot get the core idea the authors want to deliver. I would suggest the authors focus on one certain task and perform more qualitative and quantitative analysis and comparisons, as also mentioned above.\n\n3. The proposed model has several tricky parts. First, the number of components are pre-determined. However, in realistic cases, the number of components are unknown, and thus how many component generators should be used is ill-posed. Second, the composing operation is simple and tricky. Such a simple composing operation make it hard to adapt to some more complicated data, such as cifar10 or so. Thirdly, almost all tasks need some components known. Even for the Task 4, c is known, and the model performs poorly for generating the disentangled components.\n\n4. The authors missed one very relevant paper:\n\nLR-GAN: Layered Recursive Generative Adversarial Networks for Image Generation. Yang et al.\n\nIn the above paper, the authors proposed an end-to-end model for generating images with background and foreground compositionally. It can be applied to a number of realistic datasets. Regardless of the decomposition part in this paper, the proposed method in the above paper seems to be clearly superior to the composition part in this paper considering this paper fails on Task 4. The authors should give credit to the above paper (even the synthesized MNIST dataset looks similar ) and pay some efforts to explain the advantages in comparison it.\n\n[Summary]\n\nThis paper proposed a new framework to study the compositionally of images during generation and decomposition. Through several experiments on various tasks, the authors presented some interesting results and provided some insights on the potentials and difficulties in this direction. However, as pointed above, I think this paper lacks enough experimental analysis and comparison. Its core idea hard to capture. Also, it missed a comparison to some related work.", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}