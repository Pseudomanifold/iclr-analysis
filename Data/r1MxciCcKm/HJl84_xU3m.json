{"title": "Interesting unifying perspective, but lacklustre experiments", "review": "This paper introduces an interesting unifying perspective on several sequence generation training algorithms, exposing both MLE, RAML and SPG as special cases of this unified framework. This enables insightful new interpretations of standard issues in MLE training in terms of exploration for instance.\nBased on this new perspective, a new algorithm is introduced. Its performance is analysed on a machine translation and a text summarisation task.\n\n==> Quality and clarity\nThe paper is overall well-written, although it can be improved upon (see details below). The bibliography for instance does not reference the conference/journals where the articles were published and lists many (>10) published papers as arXiv preprints.\n\nThe ideas are clearly presented, which is crucial in a paper trying to unify different approaches, and the new perspective on exploration is well motivated.\n\n==> Originality and significance\nThe unifying framework is interesting, and helps shed new light on some standard issues in sequence generation.\nOn the other hand, the new algorithm and its analysis seem like a slightly rushed attempt at leveraging the unifying framework. \nThe experiments, in particular, present several issues.\n- For instance, it's clear from Figure 3 that both MLE and RAML are overfitting and would benefit from more dropout (in the literature, 0.3 is commonly used for this type of encoder-decoder architecture). Having access to these experimental results is important, since it would enable the reader to understand whether the benefits of the new approach are subsumed by regularisation or not.\n- Further, the performance of the competing methods seems a bit low. MLE reports 26.44 BLEU, which is a bit surprising considering that: \n   - with beam-search (beam of size 10, not 5, admittedly), Bahdanau et al (2016) get 27.56 BLEU, and this is without dropout.   \n   - with dropout 0.3 (but without beam search), Leblond et al (2018) get 27.4 BLEU.\nMaking a strong case for the benefits of the new algorithm requires more thorough experiments.\n\nOverall, the first half of the paper is interesting and insightful, while the second would benefit from more time. \n\nPros\n- clarity of the ideas that are presented\n- interesting unifying perspective on sequence generation algorithms\n- insightful new interpretations of existing algorithms in terms of exploration\n\nCons\n- the example new algorithm is not very original\n- the associated experiments are incomplete\n\n==> Details\n1. page 2, \"Dayan & Hinton (1997); Levine (2018); Abdolmaleki et al. (2018) study in a probabilistic inference perspective.\" is an incomplete sentence.\n2. at the beginning of section 3.1, policy optimisation is a family of algorithmS\n3. page 7 in the setup of the experiments, \"We use the Adam optimizer for SGD training\" is incorrect since SGD is not a family but a specific algorithm, which is different from Adam.", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}