{"title": "outlier detection using decision forest", "review": "The paper proposes a decision forest based method for outlier detection and claims that it is better than current methods. \n\nA few questions:\nWhat is the precise definition of maximum weighted sum? Why not using maximum probability instead in Figure 1? Are they equivalent? What does this 8.1701 threshold refer to? What architectures you use for the experiment in Section 2?\n\nComments: \nThe observation that simple methods for outlier detection are not good enough is interesting, and deserves deeper understanding. \nHowever, directly calculating max. prob. may be a weak baseline. A stronger method to compare with would be using dropout during testing, see [1], which is easy to calculate and very practical (can easily be deployed to other tasks such as sequence tagging). \nThe extensibility of the proposed method is not clear to me. \n\nAlso, the reason that the observed failure of detection happens may due to the optimization procedure, i.e., how you train the model matters. The authors should provide the details of the training methods and architectures, along with the observation. \n\nThe baseline compared in the experiments are methods that do not use the classification feature. It would be necessary to compare with stronger baselines, such as using dropout. \n\nTypo:\n'a sample x $\\in$ based on its features'\n\nReference:\n[1] Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning, by Yarin Gal, Zoubin Ghahramani ", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}