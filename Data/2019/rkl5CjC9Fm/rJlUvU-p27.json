{"title": "Insufficient motivation, evaluation, and comparison to prior work", "review": "Summary:\nThis paper proposes an approach to tackle mode collapse in GANs by using a pretrained autoencoder. Kernel density estimators are used to approximate the density of the generated and the real samples in the feature space of the autoencoder, using a buffer of samples over multiple iterations. A new regularization term is added to the generator loss that pulls together random real and generated samples in the embedding space, with a weight proportional to their distance and the product of their likelihoods. The approach is evaluated on a number of low-d toy problems, stacked MNIST, and CIFAR-10. \n\nOverall, I found the paper fairly confusing and poorly written, with unconvincing experiments. The added regularization term is not well-motivated, not theoretically grounded, and it\u2019s not clear whether it even helps on any of the image datasets (Fig 5f exhibits clear mode collapse of the proposed approach). There are also a number of related papers that were not discussed but exhibit similarities to this technique (matching in the feature space of an autoencoder). The authors should review the related work, elaborate on the theoretical justification and properties of the proposed regularizer, and perform more quantitative evaluations on image datasets.\n\nStrengths:\n+ I appreciated the quantitative comparison on the low-d toy datasets (2d and 3d MoGs), reporting modes captured, and JSD.\n+ The idea of combining non-parametric density estimators with GANs is interesting and underexplored.\n\nWeaknesses:\n- Poorly written, incorrect grammar throughout that distracts from the content along with a number of factually incorrect statements about concepts and related work.\n- Missing discussion/comparison to numerous related works: (1) autoencoders and GANs: ALI/BiGAN, MMD (e.g. Generative Moment Matching Networks) that leverage IPMs on top of feature spaces often learned by autoencoders, FID/KID that match densities in feature space, VAE-GANs that incorporate a reconstruction loss in feature space. (2) dynamics-based approaches for avoiding mode collapse, e.g. Numerics of GANs. (3) Kernel-density based approaches to GAN training kernel (Sinn & Rawat, 2017), (4) connections to continual learning in GANs where buffers of data are used (Seff et al., 2017).\n- The proposed approach is poorly motivated and presented. Are there any theoretical guarantees when using the extra dual importance-weighted distance? Why do you need a time-varying KDE estimate for the the fixed data density? Why pull arbitrary real and generated pairs together in the feature space? \n- Experiments looking at proposed approach over steps give the proposed technique an unfair advantage as you have to train an autoencoder first and that does not count towards the step count. You should evaluate wall time vs. a quantitative metric (# modes?) and offset your technique by the time it takes to train the autoencoder.\n- No quantitative metrics on image experiments (e.g. # modes on stacked MNIST, FID/KID for CIFAR-10).\n- Fig 5f shows that the proposed technique has horrible problems with mode collapse (row 5 has the same green 4 repeated).\n\nMinor nits:\n- \u201cTrained to generate a sample image\u201d -> distribution of images, not a single image\n- \u201cMain reason of mode collapsing problem is that the discriminator is incapable of delivering any information...\u201d citation? That is one of many hypothesis. The explanation that follows does not make sense as the discriminator is continually updated over training, not fixed.\n- \u201cAuto-encoder trained with real dataset optimally reduces the dimension of the dataset\u201d -> optimal in what sense? Citation or more explanation needed.\n- Eq 2 should be ||s_r - s_g|| as s_r and s_g are vectors, not scalars\n- I found the panels on your technique in Fig 2 confusing. I think presenting an example in 1d could be simpler to understand.\n- Missing details on KDE. What Kernel? How many samples did you use in the buffer?\n- Fig 6: how did you choose these panels? Were they random? Cherry picked? The DCGAN paper does not exhibit nearly as extreme mode collapse in their figures.\n- How did you choose alpha? How did you choose parameters of the KDE?\n", "rating": "3: Clear rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}