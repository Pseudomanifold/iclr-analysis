{"title": "A nice paper questioned by the significance of the results", "review": "Review:\n\nThis paper proposes a method for finding optimal architectures for deep neural networks based on a teacher network. The optimal network is found by removing or shrinking layers or adding skip connections. A Bayesian Optimization approach is used by employing a Gaussian Process to guide the search and the acquisition function expected improvement. A special kernel is used in the GP to model the space of network architectures. The method proposed is compared to a random search strategy and a method based on reinforcement learning.\n\t\nQuality: \n\n\tThe quality of the paper is high in the sense that it is very well written and contains exhaustive experiments with respect to other related methods\n\nClarity: \n\n\tThe paper is well written in general with a few typos, e.g., \n\n\t\"The weights of the Bi-LSTM \u03b8, is learned during the search process. The weights \u03b8 determines\"\n\nOriginality: \n\n\tThe proposed method is not very original in the sense that it is a combination of several known techniques. May be the most original contribution is the proposal of a kernel for network architectures based on recurrent neural networks.\n\n\tAnother original idea is the use of sampling to avoid the problem of doing kernel over-fitting. Something that can be questioned, however, in this regard is the fact that instead of averaging over kernels the GP prediction to account for uncertainty in the kernel parameters, the authors have suggested to optimize a different acquisition function per each kernel. This can be problematic since for each kernel over-fitting can indeed occur, although the experimental results suggest that this is not happening.\n\t\nSignificance:\n\n\tWhy N2N does not appear in all the CIRFAR-10 and CIFAR-100 experiments? This may question the significance of the results.\n\n\tIt also seems that the authors have not repeated the experiments several times since there are no error bars in the results.\n\tThis may also question the significance of the results. An average over several repetitions is needed to account for the randomness in for example the sampling of the network architectures to learn the kernels.\n\n\tBesides this, the authors may want to cite this paper\n\n\tHern\u00e1ndez-Lobato, D., Hernandez-Lobato, J., Shah, A., & Adams, R. (2016, June). Predictive entropy search for multi-objective Bayesian optimization. In International Conference on Machine Learning (pp. 1492-1501).\t\n\n\twhich does multi-objective Bayesian optimization of deep neural networks (the objectives are accuracy and prediction time).\n\nPros:\n\n\t- Well written paper.\n\t\t\n\t- Simply idea.\n\n\t- Extensive experiments.\n\nCons:\n\t\n\t- The proposed  approach is a combination of well known methods.\n\n\t- The significance of the results is in question since the authors do not include error bars in the experiments.", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}