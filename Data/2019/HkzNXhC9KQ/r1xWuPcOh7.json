{"title": "Is it the loss or the quantization that matters?", "review": "The paper proposes Adaptive Sample-space & Adaptive Probability (ASAP) coding for image compression based on neural networks. In contrast to most prior methods, which adhere to a fixed quantization scheme (i.e. with fixed number of quantization levels, and fixing the level themselves), the proposed method jointly learns a probability model of the quantized representation (the bottleneck of an autoencoder model) for coding and a corresponding adaptive quantization scheme. The distribution of each entry in the bottleneck before quantization is modeled as a Gaussian, whose mean and variance are predicted by a neural network conditionally on bottleneck entries on a grid at different scales (similar as in Nakanishi et al. 2018). The same network also predicts quantization intervals to adaptively quantize the respective entry of the bottleneck. Together, the predicted means, variances, and quantization intervals are used to obtain an estimate of the code length. The proposed compression networks are trained with a novel multiplicative loss, showing clear improvements over prior methods Rippel & Bourdev 2017, Nakanishi et al. 2018 on the Kodak and Raise1k data sets in terms of MS-SSIM.\n\nPros:\n\nThe results presented in this paper seem to be state-of-the-art, and innovation on quantization, which has not attracted a lot of attention in the context of neural network-based image compression is a welcome contribution. The method also seems to outperform the recent method [1], which should be included for comparison.\n\nQuestions:\n\nA major issue is, however, that it is unclear from the results whether the gains are due to the novel quantization system, or due to the novel loss. From Fig. 7 it looks like the loss BPP + \\lambda (1-MS-SSIM) (assuming the formula in (6)) is correct, and the legend in Fig. 7 incorrect) that is used in most other works performs essentially on par with  Rippel & Bourdev 2017, Nakanishi et al. 2018. For example at 1 bpp, this loss yields an MS-SSIM of 0.992 which is essentially the same as Rippel & Bourdev 2017, Nakanishi et al. 2018 obtain, cf. Fig. 2. To show that the improvement is due to the learned quantization and not just because of the loss (8) an ablation experiment should be done. One could e.g. train the proposed method with the same predictor, but without the employing the learned quantization scheme, and compare to the results obtained for the proposed method.\n\nFurthermore, a better understanding of the loss (8) would be desirable. How is the MSE factor justified?\n\nAlso, it would be good to present visual examples at rates 0.1-1.0 bpp. All visual examples are at rates below 0.08 bpp, and the proposed method is shown to also outperform other methods at much higher rates.\n\n\n[1] Ball\u00e9, J., Minnen, D., Singh, S., Hwang, S.J. and Johnston, N. Variational image compression with a scale hyperprior. ICLR 2018.\n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}