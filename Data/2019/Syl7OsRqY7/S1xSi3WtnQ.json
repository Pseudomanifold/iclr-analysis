{"title": "Good work; could be more interesting to see application in other related tasks", "review": "This paper proposes an interesting coarse-grain fine-grain coattention network architecture to address multi-evidence question answering and achieves the new state-of-the-art results on the Qangaroo WikiHop dataset.  The main idea is to divide the task across the coarse-grain and fine-grain modules in a complimentary manner such that the coarse-grain module learns from efficient modeling of support documents and the query whereas the fine-grain module learns from associations of candidate mentions in the support documents with the query. \n\nThe major strength of the model is observed with learning effective representations of larger numbers of long support documents and the state-of-the-art results are achieved without the use of pretrained contextualized embeddings. The main novelty lies in how the coattention and self-attention strategies are combined hierarchically to learn relevant representations in a complimentary fashion (rather than serial). Overall, the paper is very well-written and presents solid results with meaningful ablation study, quantitative and qualitative analyses. I have a few comments/suggestions:\n\n- It would be interesting to see how the inclusion of pretrained contextualized embeddings such as ELMo, ULMFit, BERT would help the current model. \n\n- \"This is likely because coreference resolution captures intra-document and inter-document dependencies more accurately than hierarchical attention.\" --> Please clarify why this is the case.\n\n- \"We hypothesize that ways to reduce this type of error include using more robust pretrained contextual encoders (McCann et al., 2017; Peters et al., 2018) and coreference resolution.\" --> I agree; also, it would be worth considering some commonsense knowledge to alleviate this issue, because the fact that Scotland is a part of UK and has a border with England should be learned. Here is a relevant work: \"Knowledgeable Reader: Enhancing Cloze-Style Reading Comprehension with External Commonsense Knowledge\" by Mihaylov and Frank, 2018.\n\n- \"The second type (28% of errors) results from questions that are not answerable. For example, the support documents do not provide the narrative location of the play \u201cThe Beloved Vagabond\u201d for the query narrative location the beloved vagabond.\" --> It would be great if you could release the set of unanswerable questions for the community.\n\n- Please include the memory network-based QA works in the related work section because they involve some forms of reasoning. Also, I would suggest to cover the query-focused multi-document summarization area in the related work section because they also require evidence synthesis from multiple documents to address a query. It would be very interesting if authors can apply their model for the query-focused multi-document summarization task as well, as this would further validate the effectiveness of the proposed architecture for reasoning across multiple documents.", "rating": "7: Good paper, accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}