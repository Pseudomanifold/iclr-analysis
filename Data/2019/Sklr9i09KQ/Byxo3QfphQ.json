{"title": "Promising work for a new task", "review": "Although the subject of the task is not quite close to my area and the topic of programming language edit is relatively new to me, it is a comfortable reviewing for me thank to the well-written paper. This paper formalize a new but very interesting problem that how to learn from and predict edit sequence on programming language. \n\nPros:\n+ This paper proposed two different data representation for the tokens in text, implicit and explicit. The paper starts with a very interesting problem of programming language editing, in that the intend of source code developer's intent is predicted. \n+ The two different representations are well described, and dis/advantages are well elaborated.\n+ The writing is very technical and looks solid.\n+ Both synthetic dataset and real source code dataset are exploit to evaluate the performance of all models proposed. \n\nQuestions:\n1.\tThe content of text supposed to be programming language, but neither the model design nor synthetic dataset generation specify the type of text. \n2.\tFurther, if the text type is specified to be source code, I suppose each token will has its own logical meaning, and a line of source code will have complex logic structures that is not necessarily a flat sequence, such an \u201cif\u2026else\u2026\u201d, \u201ctry\u2026catch\u2026\u201d, \u201cswitch\u2026case\u2026\u201d etc. How do you address this issue with sequence models such as LSTM?\n3.\tIn generating synthetic dataset, where is the vocabulary from?\n\nMinor issues:\n1.\tThe first sentence in Abstract doesn\u2019t look right: \u201cProgramming languages are emerging as a challenging and interesting domain for machine learning\u201d. I suppose you meant: \u201cProgramming language generation/edit\u2026.\u201d\n", "rating": "6: Marginally above acceptance threshold", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}