{"title": "Missing critical references; lacking novelty", "review": "The first abstract reads, \"The field of deep learning has been craving for an optimization method that shows outstanding property for both optimization and generalization\", what does it mean to say that the field is \"craving\"? Yes, a rigorously (mathematically proven or empirically tested extensively) better algorithm (compared to the existing algorithm) to optimize the ERM problems that appear in training deep neural networks is always valuable. But I find that this paper is not delivering on both these ends. To summarize, the main idea of the paper is to view ERM optimization in continuous time to develop algorithm to train neural networks. Section 2 introduces geodesic flows with NO references which can easily mislead readers that the math is new. For a field that is known in mathematics for essentially essentiall hundreds of years, I'd expect that the section is filled with references. Here's one in the recent years that tries to give a good overview -- https://arxiv.org/abs/1609.03890.\n\nEssentially Theorem 2.1 is a restatement of Gronwall's Lemma with the implications of Theorem 2.1 not clear at all. Yes, we can choose F(t) to be anything and get exponential convergence rate in the continuous time, but it is *not* true that it is possible to get such exponential convergence in the discrete time (which is where training happens eventually). The technical difficulty is in figuring out the right discretization that can achieve the maximum possible convergence rate. See https://arxiv.org/abs/1805.00521 for example. The authors Euler's explicit discretization which is not the best even in simple settings.  \n\nAll the modification the authors propose in Section 3, 4 and 5 are generic and straight out of standard numerical linear algebra textbooks.\n\nAs far as I can see, the experiments are setup in a somewhat standard way with CIFAR 10/100. I think MSGD should be tested with mini-batch 64 not 250 since smaller batch size leads to better generalization performace as recent works indicate (See for example, https://openreview.net/forum?id=HyWrIgW0W). ", "rating": "3: Clear rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}