{"title": "simple regularization reduces overconfidence", "review": "This paper introduces two methods of adjusting the overconfidence error for predictions on novel data. The ensemble distillation approach is to penalize the distillation loss on a potentially unlabeled general dataset.  The second approach (NCR) detects the novelty first and reweigh the prediction based on the familiarity to training data. \n\n*stationarity*\nFrom the statistical perspective, the overconfidence of extrapolation can kick in from two sources: a)the epistemic uncertainty.  The point estimation of softmax ignores the uncertainty of prediction at all.  A full Bayesian approach will remedy this though computationally impractical.  b) the generative distribution p(y|x) might not be identical on training data and test data.  To see the difference, if the training sample size goes to infinity, the uncertainty in a) will go to zero, but b) may still exist.  Section 3 assumes the invariant p(y|x) in novel data.  But theoretically, both methods do not require such invariance?\n\nSlightly related here, there can be novel data for classification, and in principle, there can also be novel data for novelty detection?  That will make NCR fail.\n\n*why the distillation helps uncertainty adjustment*\nI am not convinced how the g-distillation works for this task.  In the extreme case if the ensemble model itself is totally wrong for novel data and the unlabeled general data used in training, how can I learn any extra uncertainty information from that noise? To be fair, when the temperature goes high enough, the ensemble will make uniform prediction and then the distillation loss is merely a loss function that enforces uniformity.  If I replace the ensemble softmax by a uniform prior for unlabeled general data, do I achieve the same effect?  That is essentially the same regularization as method 2, except g-distillation is on logit scale.  \n\n*robustness-accuracy tradeoff*\nThe experiments do not reveal too much robustness-efficiency conflict, as the new methods still perform good enough on familiar dataset. Indeed they can be even better than the baseline in E99 loss. Does it suggest the over-confidence is even a concern for familiar data/ iid data?\n\nIn general, the paper is well-written and well-motivated. It would be more interesting to make some theoretical explanation why/when this simple approach works.   I would recommend a weak accept at this point.\n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}