{"title": "Interesting idea looking at generative models and its effect on defense against adversarial attacks. However, there are some key questions left unanswered.", "review": "This paper is clearly written and in an interesting domain. The question asked is whether or not pretrained mean-field RBMs can help in preventing adversarial attacks. However, there are some key issues with the paper that are not clear.\n\nThe first is regarding the structure of the paper. The authors combine two ideas, 1: the training of MF RBMs and 2: the the ability to prevent adversarial attacks. The combination of ideas is ok, however, it is unclear how novel or how good is the proposed MF training of the RBMs. It would make the paper much stronger if the authors perform quantitative + qualitative evaluation on the MF training of RBMs first.  Without doing so, it leaves the reader wondering why not simply a standard RBM trained using a standard method (e.g. contrastive divergence).\n\nIn a related note, using MF for training BMs have been proposed previously and found to not work due to various reasons:\nsee paragraph after equation 8 of the Deep BM paper: http://proceedings.mlr.press/v5/salakhutdinov09a/salakhutdinov09a.pdf \n\nIt would be very interesting to contrast the proposed method with other previously proposed MF based method, in particular using Free energy to approximate the expectation of the model without constraints.\n\nIt is also unclear how the calculation of relative entropy \"D\" was performed in figure 3. Obtaining the normalized marginal density in a BM is very challenging due to the partition function.\n\nThe second part of the paper associate good performance in preventing adversarial attacks with the possibility of denoising by the pretrained BM. This is a very good point, however the paper do not compare or contrast with existing methods. For example, it is curious to see how denoising Auto encoders would perform. In addition, it could be worthwhile to compare and benchmark on existing evaluations: https://arxiv.org/pdf/1802.06806.pdf\n\n- The authors should make a distinction on what kinds of attack is considered: white box, black box or grey box. Defending against black box attacks is considerably easier than defending against white-box attacks.\n\nIn summary, the paper is interesting, however, more experiments could be added to concretely demonstrate the advantage  of the proposed MF BMs in increasing robustness against adversarial attacks.", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}