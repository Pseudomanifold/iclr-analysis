{"title": "Well motivated simple approach but need more analysis and stronger experiments.", "review": "In the paper, the authors tackle the problem of representation learning and aim at building reusable and structured representation. They argue that co-adaption between encoder and decoder in traditional AE yields poor representation and they introduce community based auto-encoders CbAEs. the approach is motivated by linguistic communication and it is straightforward to implement.\n\nHowever, some points deserve to be clarified:\n1. For classification tasks, what is the absolute value of classification accuracy? what happens if we consider larger number of iterations? only few iterations are shows in plots. \n2. Are linear classifiers learned separately and then are their outputs averaged in testing time? Is the observed gain of sample complexity really due to community based training or it is just an effect of averaging an ensemble of AEs?\n3.  How the entropy regularization is tuned in experiments ?  \n4. Experiments would be more convincing if they could show benefits for more challenging transfer learning task such that few-shot learning/ semi-supervised learning.  ", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}