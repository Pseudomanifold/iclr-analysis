{"title": "Review for \"Generative Feature Matching Networks\"", "review": "The paper proposes a non-adversarial feature matching generative model (GFMN). In feature matching GANs, the discriminator extract features that are employed by the generator to match the real data distribution. Through the experiments, the paper shows that the loss function is correlated with the generated image quality, and the same pretrained feature extractor (pre-trained on imagenet) can be employed across a variety of datasets. The paper also discusses the choice of pretrained network or autoencoder as the feature extractor. The paper also introduces an ADAM-based moving average. The paper compares the results with on CIFAR10 and STL10 with a variety of recent State-of-the-art approaches in terms on IS and FID. \n\n+ The paper is well written and easy to follow. - However, there are some typos that should be addressed. Such as:\n\u201cThe decoder part of an AE consists exactly in an image generator \u201d\n\u201cOur proposed approach consists in training G by minimizing\u201d\n\u201cDifferent past work have shown\u201d -> has\n\u201cin Equation equation 1 by\u201d\n\u201chave also used\u201d better to use the present tense.\n\n+ It suggests a non-adversarial approach to generate images using pre-trained networks. So the training is easier and the quality of the generated images, as well as the FID and IS, are still comparable to the state-of-the-art approaches.\n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}