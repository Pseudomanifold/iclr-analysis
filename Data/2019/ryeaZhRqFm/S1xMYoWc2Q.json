{"title": "Interesting problem, but incremental contribution", "review": "[Relevance] Is this paper relevant to the ICLR audience? yes\n\n[Significance] Are the results significant? somewhat\n\n[Novelty] Are the problems or approaches novel? rather incremental\n\n[Soundness] Is the paper technically sound? yes\n\n[Evaluation] Are claims well-supported by theoretical analysis or experimental results? marginal\n\n[Clarity] Is the paper well-organized and clearly written? okay\n\nConfidence: 2/5\n\nSeen submission posted elsewhere: No\n\nDetailed comments:\n\nIn this work, the authors propose an approach to the (hyper-) link prediction problem in both directed and undirected hypergraphs. The approach first applies an existing dual transformation to the hypergraph such that the link prediction problem (in the primal) becomes a node classification problem in the dual. They then use GCNs to classify the (dual) nodes. Experimentally, the proposed approach marginally outperforms existing approaches.\n\n=== Major comments\n\nI found the novelty of the proposed approach rather limited. The proposed approach essentially just concatenates three existing strategies (dual reformulation from Scheinerman and Ullman, GCNs from Kipf and Welling, and negative sampling which is common in many communities, e.g., Han and Chen, but many others, as well). I believe the contribution for link prediction in directed hypergraphs is a more novel contribution, however, I had difficulty following that discussion.\n\nIt is difficult to interpret the experimental results. Tables 3 and 6 do not include a measure of variance. Thus, it is not clear if any of the results are statistically significant. It is also not clear whether the \u201c10 trials\u201d mentioned in the figure captions correspond to a 10-fold cross-validation scheme or something else. It is unclear to me what the random feature matrix for the metabolic network is supposed to me or do. It is also unclear to me why \u201cfake papers\u201d are needed for the citation networks; it is clear that \u201cfake author lists\u201d are needed for negative sampling, but it seems they could be attached to existing papers. Similarly, it is unclear how the set of candidate edges (\\mathcal{E}) was chosen.\n\nI appreciate that the authors made the code available. I did not run it, but I did have a look, and I believe it could be adapted by others without an unreasonable amount of work.\n\n=== Minor comments\n\nThis work is very similar to the arXiv submission 1809.09401. To the best of my knowledge, though, that work has not yet been published in a peer-reviewed venue, so I do not consider it a problem that it is not cited here.\n\nAccording to Tables 1 and 2, iAF692 and iHN637 datasets are smaller than the other datasets except DBLP; those two are also less dense than DBLP. According to Table 3, NHP-U seems noticeably better than SHC and CMM on the, while does not appear very significant in the other cases. Is there some relationship between NHP\u2019s performance and the size/density of the graph? or is there some other explanation for this behavior?\n\nRelated to the above point, Table 3 shows that the performance on the undirected versions for those two datasets is better than on the other two metabolic networks, while Table 6 shows the opposite for the directed versions. Is there some explanation for this? For example, are there qualitative differences in the size of the hypernodes?\n\nThe described strategy for negative sampling seems as though it selects \u201ceasy\u201d negative samples, in the sense that they are far away from observed positives; thus, they are also likely far away from any sort of decision boundary. How does the performance change if more \u201cdifficult\u201d (or just uniformly random) negative samples are chosen?\n\nI believe Recall@100 (or Precision@100, or @$\\Delta E$, etc.) is a more meaningful value to report in Tables 4 and 7, rather than the raw number of edges. That is, it would be more helpful to report something so that numbers across datasets are at least somewhat comparable.\n\n=== Typos, etc.\n\nIn Equation (4), the \u201ck\u201d index in d_{ijk} is in {1,2}, but in the text, it is in {0,1}.\n\n\u201ctable 2\u201d -> \u201cTable 2\u201d, and many other similar examples throughout the paper.\n\n\u201chigher-order etc.\u201d -> \u201chigher-order, etc.\u201d\n\u201cGCN based\u201d -> \u201cGCN-based\u201d, and similar in several places in the paper\n\u201ca incomplete\u201d -> \u201can incomplete\u201d\n", "rating": "6: Marginally above acceptance threshold", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}