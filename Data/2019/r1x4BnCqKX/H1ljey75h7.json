{"title": "Potentially interesting and novel ideas but impossible to tell if they are significant due to low-quality results section", "review": "Review of \"A Generative Model for Electron Paths\"\n\nPaper summary:\n\nThe paper proposes a new model for predicting arrow-pushing chemical\nreaction diagrams from raw reaction data.\n\nSection 1 summarizes the motivation: whereas other models only predict\nchemical reaction products from reactants, the proposed model attempts\nto also predict the reaction mechanism.\n\nSection 2 provides a background on related work. Previous models for\nmechanism prediction are limited to work which require expert-curated\ntraining sets. The proposed model is designed for a subset of\nreactions called \"linear electron flow\" (LEF) which is\nexplained. Contributions of this paper are an end-to-end model, a\ntechnique for identifying LEF reactions/mechanisms from\nreaction/product data, and an empirical study of how the model learns\nchemical knowledge.\n\nSection 3 explains the proposed generative model, which represents a molecule\nusing a graph (nodes are atoms and edges are bonds). It is proposed to\nlearn a series of electron actions that transform the reactants into\nthe products. The total probability is factorized into three parts:\nstarting location, electron movement, and reaction\ncontinuation. Figure 2 and Algorithm 1 are helpful.\n\nSection 4 explains the proposed method for creating mechanism data\nfrom chemical reactant/product databases. Figure 3 is helpful.\n\nSection 5 discusses results of predicting mechanisms and products on\nthe USPTO data set.\n\nComments:\n\nStrong points of the paper: (1) it is very well written and easy to\nunderstand, (2) the chemical figures are very well done and helpful,\nand (3) the method for predicting mechanisms seems to be new.\n\nThe major weak point of the paper is the results section, which needs\nto be improved before publication.\n\nIn particular Tables 2-3 (comparison of prediction accuracy) need to\nshow some measure of variance (standard deviation or confidence\ninterval) so the reader can judge if there is any significant\ndifference between models. Please use K-fold cross-validation, and\nreport mean/sd of test accuracy over the K test folds.\n\nThe term \"end-to-end\" should be defined. In section 2.2 it is written\n\"End-to-End: There are many complex chemical constraints that limit\nthe space of all possible reactions. How can we differentiate through\na model subject to these constraints?\" which should be clarified using\nan explicit definition of \"end-to-end.\"\n\nAlso there needs to be some comparison with baseline methods for\npredicting mechanisms.  It is claimed that no comparison can be made\nagainst the previous methods for mechanism prediction (Section 2.2),\nbecause \"they require expert-curated training sets, for which organic\nchemists have to hand-code every electron pushing step.\" However the\ncurrent paper proposes a method for generating such steps/data for LEF\nreactions. So why not use those data to train those baseline models,\nand compare with them? That would make for a much stronger paper. Please\nadd at least one of the methods discussed in section 2.2 to your\naccuracy comparison in Table 2.\n\nIt would additionally be helpful to know what the \"uninformed\nbaseline\" / \"ignore the inputs\" / \"random guessing\" accuracy rates are\non your data set. For example in classification the uninformed\nbaseline always predicts the class which is most frequent in the\ntraining data, and in regression it predicts the mean of the\nlabels/outputs in the training data. What would the analogy be for\nyour two problems? (product and mechanism prediction)\n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}