{"title": "The Laplacian in RL: Learning Representations with Efficient Approximations", "review": "The authors propose a Laplacian in the context of reinforcement learning, together with learning the representations. Overall the authors make a nice contribution. The insight of defining rho to be the stationary distribution of the Markov chain P^pi and connecting this to eq (1) is interesting. Also the definition of the reward function on p.7 in terms of the distance between phi(s_{t+1}) and phi(z_g) looks original. The method is also well illustrated and compared with other methods, showing the efficiency of the proposed method.\n\nOn the other hand I also have further comments and suggestions:\n\n- it would be good if the authors could comment on the choice of d. This is in fact a model selection problem. According to which criterion is this selected?\n\n- the authors define D(u,v) in eq (4). Why this choice? Is there some intuition or interpretation possible related to this expression?\n\n- in (6) beta is called a Lagrange multiplier. Given that a soft constraint (not a hard constraint) is added for the orthonormality constraint it is not a Lagrange multiplier.\n\nHow sensitive are the results with respect to the choice of beta in (6) (or epsilon in the eq above)? The orthonormality constraint will only be approximately satisfied. Isn't this a problem?\n\nWouldn't it be better in this case to rely on optimization algorithm on Grassmann and Stiefel manifolds?\n\n- The authors provide a scalable approach related to section 2 by stochastic optimization. Other scalable methods related to kernel spectral clustering (related to subsets/subgraphs and making out-of-sample extensions) were proposed in literature, e.g.\n\nMultiway Spectral Clustering with Out-of-Sample Extensions through Weighted Kernel PCA, IEEE Transactions on Pattern Analysis and Machine Intelligence, 32(2), 335-347, 2010.\n\nKernel Spectral Clustering for Big Data Networks, Entropy, Special Issue: Big Data, 15(5), 1567-1586, 2013.\n\n\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}