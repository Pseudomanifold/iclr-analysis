{"title": "The paper presents RSGD algorithm on TT based RNN, which is interesting but the quality and significance is limited. ", "review": "In this paper, the authors proposed a new method to update the weights in RNN by SGD on Riemannian manifold.  Due to the properties of manifold learning, the updated weights in each iteration are contracted with a low-rank structure, such that the number of the parameters of TT can be automatically decreased during the training procedure. By using the new algorithm, the authors modified two types of sophisticated RNNs, i.e., bi-directional GRU/LSTM and Encoder-Decoder RNN. The experimental results validate effectiveness of the proposed method. How to determine the rank of the tensor networks in weight compression problem is indeed an important and urgent task, this paper does not clearly illustrate how RSGD can efficiently solve this problem.\n\n1. Compared to the conventional SGD, not only the convergence rate of the proposed method seems slower (mentioned in the paper,), but also additional computational operations should be done in each iteration like exponential mapping (with multiple QR and SVD). I\u2019m worried about the computational efficiency of this method, but  this paper neither discusss the  computational complexity nor illustrate the results in the experimental section.\n\n2. In proof of proposition 1, I\u2019m confused why the input tensor X should belong to M, and why the eq. (8) holds?\n\n3. In the convergence analysis, I don\u2019t know why the eq.  $Exp^{-1}(y)=-\\eta\u2026.$ holds even though the authors claims the it is not hard to find. So that, I cannot find the relationship between Theorem 3 and the proposed method.  Furthermore, can Theorem 3 be used to prove the convergence of the proposed method?\n\n4. Eq. (16) would make no sense because the denominator might be very small. \n\n5. In the experiment, please compare with other existing (tensor decomposition based) compression methods to demonstrate how the proposed method makes sense in this task.\n\nMinior:\n1. By the definition in Oseledets\u2019 paper, the tensor decomposition model used in this paper should be called TT-matrix rather than TT.\n2. 9 ->(9) in Definition 2, and 15->(15) in the proof of Theorem 3.", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}