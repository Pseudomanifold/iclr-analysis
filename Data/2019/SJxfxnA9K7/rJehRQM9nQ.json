{"title": "Not enough here", "review": "This paper proposes a new method to input data to a conditional discriminator network. The standard setup would simply concatenate the \"condition\" image with the \"output\" image (i.e., the real image, or the generator's output corresponding to the condition). The setup here is to feed these two images to two separate encoders, and gradually fuse the features produced by the two. The experiments show that this delivers superior performance to concatenation, on three image-to-image translation tasks.\n\nI think this is a good idea, but it's a very small contribution. The entire technical approach can be summarized in 2-3 sentences, and it is not particularly novel. Two-stream models and skip connections have been discussed and explored in hundreds of papers. Applying these insights to a discriminator is not a significant leap. \n\nThe theoretical \"motivation\" equations in Sec. 3.1 are obvious and could be skipped entirely. \n\nIn summary, the paper makes sense, but it does not present substantively new ideas. I do not recommend the paper for acceptance. ", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}