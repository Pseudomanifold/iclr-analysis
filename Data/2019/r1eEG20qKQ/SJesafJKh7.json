{"title": "The idea is interesing, but the explaination and experiment can be better", "review": "First, the writing can be better. I had a hard time to understand the paper. It has many symbols, but some of them are not explained. For instance, in  formula (9), what are Q or s? Also, formula (14). I probably can guess them. Is it possible to simplify the notations or use a table to list the symbols? \n\nFinding good models is a bi-level or tri-level optimization problem. The paper describes a gradient-based hyperparameter optimization method, which finds model parameters, hyperparameter schedules, and network structure (limited) the same time. It is a interesting idea. Comparing random search, grid search and Spearmint, it seems to be better them. The paper rules out the performance gain is from the randomness of the hyperparameters, which is a good thought. \n\nMore evidences are needed to show this method is superior. The paper doesn't explain well why it works, and the experimental results are just ok. The network architecture search part is limited to number of filters in the experiments. Certainly, the results is not as good as  PNASNet or NASNet. \n\nEvolution algorithm or GA shows good performance in hyperparameter optimization or neural architecture search. Why not compare with them? Random and grid search are not good generally, and Bayesian optimization is expensive and its performance depends on implementation.   \n\nIn Table 2 and figure 4, should \"Loss\" be \"Error\"? \n\n\n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}