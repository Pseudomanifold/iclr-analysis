{"title": "Good idea, not clear if it is easy to apply.", "review": "\n========\\\\\nSummary\\\\\n========\\\\\n\nThe paper deals with hyper-parameter optimization of neural networks. The authors formulate the problem as a bilevel optimization problem: minimizing the validation loss over the hyperparameters, subject to the parameters being at the minimum of the training loss. The authors propose an approximation of the so-called best-response function, that maps the hyperparameters to the corresponding optimal parameters (w.r.t the minimization of the training loss), allowing a formulate as a single-level optimization problem and the use gradient descent algorithm. The proposed\napproximation is based on shifting and scaling the weights and biases of the network. There are no guarantee on its quality except in some very simple cases. The approach assumes a distribution on the hyperparameters, governed by a parameter, which is adapted during the course of the training to achieve a compromise between the flexibility of the best-response function and the quality of its local approximation around the current hyperparameters. The authors show\nthat their approach beats grid-search, random search and Bayesian optimization on the CIFAR-10 and PTB datasets. They point out that the dynamic update of the hyperparameters during the training allows to reach a better performance than any fixed hyperparameter. \\\\\n\n\n======================\\\\\nComments and questions\\\\\n======================\\\\\n\nCan cross-validation be adapted to this approach? \\\\\n\nCan this be used to optimize the learning rate? Which is of course a crucial hyperparameter and that needs an update schedule during the training. \\\\\n\nSection 3.2:\\\\\n\n\"If the entries are too large, then \u03b8\u0302 \u03c6 will not be flexible enough to capture the best- response over the sampled neighborhood. However, its entries must remain sufficiently large so that \u03b8\u0302 \u03c6 captures the local shape around the current hyperparameter values.\" Not clear why -- more explanations would be helpful. \\\\\n\n\"minimizing the first term eventually moves all probability mass towards an optimum \u03bb\u2217 ,resulting in \u03c3 = 0\". I can't see how minimizing the first term w.r.t \\phi (as in section \"2.2.Local approximation\") would alter \\sigma. \\\\\n\n\"\u03c4 must be set carefully to ensure...\". The authors still do not explain how to set \\tau. \\\\\n\nSection 3.3: \\\\\n\nIf the hyperparameter is discrete and falls in Case 2, then REINFORCE gradient estimator is used. What about the quality of this gradient? \\\\\n\nSection 5, paragraph Gradient-Based HO: \"differentiating gradient descent\" needs reformulation -- an algorithm cannot be differentiated. \\\\\n\nPros \\\\\n- The paper is pretty clear \\\\\n- Generalizes a previous idea and makes it handle discrete hyperparameters and scale better. \\\\\n- I like the idea of hyperparameters changing dynamically during the training which allows to explore a much larger space than one value \\\\\n- Although limited, the experimental results are convincing \\\\\n\nCons \\\\\n- The method itself depends on some parameters and it is not clear how to choose them. Therefore it might be tricky to make it work in practice. I feel like there is a lot of literature around HO but very often people still use the very simple grid/random search, because the alternative methods are often quite complex to implement and make really work. So the fact that the method depends on \"crucial\" parameters but that are not transparently managed may be a big drawback to its applicability. \\\\\n- No theoretical guarantee on the quality of the used approximation for neural networks \\\\\n- Does not handle the learning rate which is a crucial hyperparameter (but maybe it could) \\\\\n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}