{"title": "Review", "review": "A nice paper that clarifies the difference between the clean accuracy (accuracy of models on non-perturbed examples) and the robust accuracy (accuracy of models on adversarially perturbed examples) and it shows that changing the marginal distribution of the input data P(x) while preserving its semantic P(y|x) fixed affects the robustness of the model. Therefore, testing the robustness of the model should be performed in a careful manner. Comprehensive experiments were performed to show that changing the distribution of the MINST (smoothing) and CIFAR (saturation) data could lead to a significant difference in robust accuracy while the clean accuracy is almost steady. In addition, a set of experiments were performed in an attempt to search for the criteria required for choosing a proper dataset for testing adversarial attack to measure the robustness. \n\nAlthough I\u2019m not expert in the field of adversarial attack but the paper is very nice to read and easy to follow (I have not checked the proof of the theorems though). \n", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}