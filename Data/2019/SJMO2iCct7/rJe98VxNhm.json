{"title": "Incremental technical contribution but with extensive experimental evaluation", "review": "The paper presents a variational inference approach for locally linear dynamical models. In particular,  the latent dynamics are drawn from a Gaussian approximation of the parent variational distribution,  enabled by Laplace approximations with fixed point updates, while the parameters are optimized the resulting stochastic ELBO. Experiments demonstrate the ability of the proposed approach to learning nonlinear dynamics, explaining data variability, forecasting and inferring latent dimensions.  \n\nQuality: The experiments appear to be well designed and support the main claims of the paper. \n\nClarity: The clarity is below average. In Section 2 the main method is introduced. However, the motivation and benefits of introducing a parent and child variational approximation are not discussed adequately. It would be helpful to move some of the stuff in the appendix to the main text, and present in a neat way. I also struggled a little to understand what is the difference between forward interpolate and filtering. \n\nOriginality: Given the existing body of literature, I found the technical novelty of this paper rather weak. However, it seems the experiments are thoroughly conducted. In the tasks considered, the proposed method demonstrates convincing advantages over its competitors.  \n\nSignificance: The method shall be applicable to a wide variety of sequential data with nonlinear dynamics. \n\nOverall, this appears to be a board-line paper with weak novelty. On the positive side, the experimental validation seems well done. The clarity of this paper needs to be strengthened.  \n\nMinor comments: \n- abstract: uncover nonlinear observation? -> maybe change \"observation\" to \"latent dynamics\"?\n\n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}