{"title": "Simple method with good empirical results and some insightful discussion", "review": "This paper proposes a simple method for knowledge distillation. The teacher and student models are matched using MMD objectives, the author demonstrates different variants of matching kernels specializes to previously proposed variants of knowledge distillation.\n\n- The extensive evaluation suggests that the MMD with polynomial kernel provides better results than the previously proposed method.\n-  It is interesting to see that MMD based transfer has more advantage on the object detection tasks.\n- Can the author provides more insights into the behavior of different kernels, for example visualizing, the gradient map might help us to understand why certain kernel works better than another one?\n- Did you consider translation invariance or other spatial properties when designing your kernels?\n\nIn summary, this is an interesting paper with good empirical results. The technique being used generalization is quite straightforward, but the paper also includes a good amount of discussion on why the proposed approach could be better and I think that really helps the reader.\n", "rating": "6: Marginally above acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}