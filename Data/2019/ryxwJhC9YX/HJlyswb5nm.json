{"title": "Nice formulation, good results! ", "review": "Post rebuttal: I am satisfied by the points mentioned by authors!\n\n----------------------------------------------------------------\nSummary: The paper proposes to add instance-aware segmentation masks for the problem of unpaired image-to-image translation. A new formulation is proposed to incorporate instance masks with an input image to generate a new target image and corresponding mask. The authors demonstrate it on multiple tasks, and show nice results for each of them.\n\nPros: \n\n1. The formulation is intuitive and well done!\n\n2. The idea of sequential mini-batch translation connects nicely to the old school of making images by layering. \n\n3. Nice qualitative analysis, and good results in comparison with Cycle-GAN (an obvious baseline for the formulation). I would make an observation that two domains for translation (such as sheep to giraffe, jeans to skirts etc) are thoughtfully selected because Cycle-GAN is somewhat bound to fail on them. There is no way Cycle-GAN can work for jeans to skirts because by design the distribution for images from both set would be mostly similar, and it is way too hard for the discriminator to distinguish between two. This ultimately leads the generator to act as an identity mapping (easily observed in all the qualitative examples).\n\n4. The proposed approach can easily find direct application in places where a user-control is required for image editing or synthesis.\n\n5. The literature review is extensive.\n\nCons: \n\n1. My biggest criticism of this work is the absence of simple baselines.  Given the fact that the formulation use an instance segmentation map with the given input, the following obvious baseline need consideration: \n\nSuppose the two domains are sheep and giraffe: \n\na. given the input of sheep and its instance mask, find a shape/mask in giraffe from the training images that is closest (it could be same location in image or some other similarity measure).\n\nb. mask the input image using the sheep mask. Use giraffe mask and add corresponding RGB components of the masked giraffe (from the training set) to the masked input image. \n\nThe above step would give a rough image with some holes.\n\nc. To remove holes, one can either use an image inpainting pipeline, or can also simply use a CNN with GAN loss.\n\nI believe that above pipeline should give competitive (if not better) outputs to the proposed formulation. (Note: the above pipeline could be considered a simpler version of PhotoClipArt from Lalonde et al, 2007).\n\n2. Nearest neighbors on generated instance map needs to be done. This enables to understand if the generated shapes are similar to ones in training set, or there are new shapes/masks being generated. Looking at the current results, I believe that generated masks are very similar to the training instances for that category. And that makes baseline described in (1) even more important.\n\n3. An interesting thing about Cycle-GAN is its ability to give somewhat temporally consistent (if not a lot) -- ex. Horse to Zebra output shown by the authors of Cycle-GAN. I am not sure if the proposed formulation will be able to give temporally consistent output on shorts/skirts to jeans example. It would be important to see how the generated output looks for a given video input containing a person and its segmentation map  of jeans to generate a video of same person in shorts? \n\n", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}