{"title": "Poorly motivated, vague, and low-quality.", "review": "Summary: The authors propose a type of black box (gradient free) optimization algorithm for training neural networks. The method is a type of genetic algorithm (similar to particle swarm optimization), with particular choices for how to generate new proposals (perturbations) and how to combine them at every iteration (generation). The authors apply their method to some standard non-convex low-dimensional test functions, as well as to train a CNN on MNIST.\n\nMajor concerns: There are serious issues with the quality, clarity, originality and significance of this work.\n\nFirst and foremost, the ideas are vague and poorly motivated. In the abstract, the authors propose that their algorithm will be used to train deep networks, and \"eventually act as an alternative to Stochastic Gradient Descent (SGD)\". However, this overlooks theory in the optimization literature on how convergence rates for first-order (gradient) methods are *independent* of the parameter dimension. This amazing fact is why they are so powerful for solving high-dimensional optimization problems. On the other hand, gradient-free search methods are not independent of the parameter dimension, and slow down considerably when the effective parameter dimension is large. From the abstract, and parts of the text, it seems as if the authors think that gradient-free algorithms can be used to train neural networks even when gradient information is available (e.g. for training image recognition models, like their example application of training a CNN on MNIST). However, there are fundamental theoretical reasons why this is not a good idea, which are glossed over or ignored by the paper.\n\nIf the authors want to target problems which are non-differentiable (they reference a couple of examples where gradient-free optimization has been used for non-differentiable problems such as in reinforcement learning or architecture search), then they should apply their algorithm directly to these problems. Related to this point, after referencing papers on gradient-free algorithms applied to reinforcement learning, the authors state that this \"reflects the awareness within the broader research community about ... the need for alternatives to SGD.\" I strongly disagree with this reading of that literature, rather, those papers point out that gradient-free algorithms are useful/competitive with other techniques for a particular domain (RL) which contains non-differentiable optimization problems. Equating that with the field at large needing alternatives to SGD is an over-generalization.\n\nAdditionally, it is unclear if the authors are proposing an optimization algorithm particularly for neural networks, or something more general. The state that they are interested in training neural networks, but then why compare their algorithm on low-dimensional test functions (such as Rastrigin or Ackley) which have very a different loss landscape compared to that of neural networks?\n\nWhen it comes to the algorithm itself, the presentation is vague, introduces unnecessary complexity, and fails to reference significant related work.  The algorithm is introduced using a lot of colloquial language (Elites, Anchors, Probes, and Blends) which are hard to follow. It seems as if, at a high level, the authors are proposing a genetic algorithm--one where there is a procedure to generate new proposal iterates, and a method for combining them to form the next generation. A lot of the particular choices for how to generate these proposals and combine them seem arbitrary (a lot of hyperparameters are introduced). Finally, it is unclear how many function evaluations are required to evaluate one step (generation) of their algorithm, which is critical to comparing performance to other algorithms.\n\nWhen it comes to comparing performance, there are fundamental flaws with the study. One, the authors compare do not tune hyperparameters for the algorithms they compare against (going as far as to state that \"tuning those parameters is beyond the scope of this paper\"), but presumably tune the hyperparameters for their algorithm. This results in unfair comparisons. Two, the authors report performance in terms of \"generations\", but they should be reporting performance in terms of the number of function evaluations, since different algorithms may require more function evaluations (and thus take more time) per iteration/generation. This is particularly problematic for the comparison against SGD, where every step of SGD only requires one forward/backward pass but presumably their algorithm requires many forward passes per \"generation\". This makes the comparisons that are currently in the paper meaningless.", "rating": "1: Trivial or wrong", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}