{"title": "principled approach to sparsification of neural network weights", "review": "The authors propose to reduce the size of fully connected neural networks, defined as the total number of nonzeros in the weight matrices, by calculating sensitivity scores for each incoming connection to a neuron, and randomly keeping only some of the incoming connections with probability proportional to their share of the total sensitivity. They provide a specific definition for the sensitivity scores and establish that the sparsified neural network, with constant probability for any sample from the training population, provides an output that is a small multiplicative factor away from the output of the unsparisfied neural network. The cost of the sparsification is essentially the application of the trained neural network to a small number of data points in order to compute the sensitivity scores\n\nPros:\n- the method works empirically, in that their empirical evaluations on MNIST, CIFAR, and FashionMNIST classification problems show that the drop in accuracy is lower when the neural net is sparsified using their CoreNet algorithm and variations than when it is randomly sparsified or the neural network size is reduced by using SVD.\n- theory is provided to argue the consistency of the sparsified neural network\n\nCons:\n- no comparison is made to the baseline of using matrix sparsification algorithms on the weight matrices themselves. I do not see why CoreNet should be expected to perform empirically better than simply using e.g. the entry-wise sampling scheme from \"Near-optimal entrywise sampling for data matrices\" by Achlioptas and co-authors, or earlier works addressing the same problem of sparsifying matrices.\n- the theory makes very strong assumptions (Assumptions 1 and 2) that are not explained or justified well. Both depend on the specific weight matrices being sparsified, and it isn't clear a priori when the weight matrices obtained from whatever optimization procedure was used to train the neural net will be such that these assumptions hold.\n- despite the suggestions of the theory, the accuracy drop can be quite large in practice, as in the CIFAR panel of Figure 1\n\nI think the ICLR audience will appreciate the attempt to provide a principled approach to decreasing the size of neural networks, but I do not think this approach is widely compelling as :\n(1) no true guaranteed control on the trade-off between accuracy loss and network size is available\n(2) empirically the method does not perform well consistently\n(3) comparisons with reasonable and informative baselines are missing\n\nUpdated in response to author response: the inclusion of experimental comparisons with linear algebraic sparsification baselines, showing that the proposed method can be significantly more accurate, strengthens the appeal of the method.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}