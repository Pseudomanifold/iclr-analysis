{"title": "A subset of the input edges for each neuron is subsampled with probability proportional to the relative importance of each edge.", "review": "Given an additively decomposable function F(X, Q) = sum_over_x_in_X cost(x, Q), one can approximate it using either random sampling of x in X (unbiased, possibly high variance), or using importance sampling and replace the sum_over_x with a sum_over_coreset importance_of_a_point * cost(x, Q) which if properly defined can be both unbiased and have low variance [1]. In this work the authors consider the weighted sum of activations as F and suggest that for each neuron we can subsample the incoming edges. To construct the importance sampling strategy the authors adapt the classic notion of sensitivity from the coreset literature. Then, one has to carefully balance the approximation quality from one layer to the next and essentially union bound the results over all layers and all sampled points. The performed analysis is sound (up to my knowledge).\n\nPro:\n- I commend the authors for a clean and polished writeup.\n- The analysis seems to be sound (apart from the issues discussed below)\n- The experimental results look promising, at least in the limited setup.\n\nCon:\n- There exists competing work with rigorous guarantees, for example [2].\n- The analysis hinges on two assumptions which, in my opinion, make the problem feasible: having (sub) exponential tails allows for strong concentration results, and with proper analysis (as done by the authors), the fact that the additively decomposable function can be approximated given well-behaving summands is not surprising. The analysis is definitely non-trivial and I commend the authors for a clean writeup.\n- While rigorous guarantees are lacking for some previous work, previously introduced techniques were shown to be extremely effective in practice and across a spectrum of tasks. As the guarantees arguably stem from the assumptions 1 and 2, I feel that it\u2019s unfair to not compare to those results empirically. Hence, failing to compare to results of at least [2, 3] is a major drawback of this work.\n- The result holds for n points drawn from P. However, in practice the network might receive essentially arbitrary input from P at inference time. Given that we need to decide on the number of edges to preserve apriori, what are the implications?\n- The presented bounds should be discussed on an intuitive level (i.e. the number of non zero entries is approximately cubic in L).\n\nI consider this to be a well-executed paper which brings together the main ideas from the coreset literature and shows one avenue of establishing provable results. However, given that no comparison to the state-of-the-art techniques is given I'm not confident that the community will apply these techniques in practice. On the other hand, the main strength -- the theoretical guarantees -- hinge on the introduced assumptions. As such, without additional empirical results demonstrating the utility with respect to the state-of-the-art methods (for the same capacity in terms of NNZ) I cannot recommend acceptance.\n\n[1] https://arxiv.org/abs/1601.00617\n[2] papers.nips.cc/paper/6910-net-trim-convex-pruning-of-deep-neural-networks-with-performance-guarantee\n[3] https://arxiv.org/abs/1510.00149\n\n\n========\nThank you for the detailed responses. Given the additional experimental results and connections to existing work, I have updated my score from 5 to 6. ", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}