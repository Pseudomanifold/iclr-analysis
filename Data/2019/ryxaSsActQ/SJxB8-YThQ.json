{"title": "An idea worth exploring but the paper has flaws.", "review": "The paper describes a new loss function for training, that can be\nused as an alternative to maximum likelihood (cross entropy), or\nas a metric that is used to fine-tune a model that is initially\ntrained using ML.\n\nExperiments are reported on the WMT 2014 English-German and\nEnglish-French test sets.\n\nI think this is an idea worth exploring but overall I would not\nrecommend acceptance. I have the following reservations:\n\n* I found much of the motivation/justification for the approach\nunconvincing - too heuristic and informal. What does it mean\nto \"overgeneralize\" or \"plunge into local optima\"? Can we say\nanything semi-formal about this alternative objective? \n\n* The improvements over ML are marginal, and there are a lot of moving\nparts/experimental settings in these models, i.e., a lot of\ntweaking. The results in tables 2 and 3 show a 0.36/0.34 improvement\nover ML using DSD. (btw, what is meant by \"DSD-deep\" or \"ML-deep\"? I'm\nnot sure these terms are explained?)\n\n* The comparison to related work is really lacking. The \"Attention is\nall you need\" paper (Vaswani et al.) reports 28.4/41.0 BLEU for these\ntest sets, respectively 3.4/5.96 BLEU points better than the results\nin this paper. That's a huge gap. It's not clear that the improvements\n(again, less than 0.5 BLEU points) will remain with a state-of-the-art\nsystem. And I think the paper is misleading in how it cites previous\nresults on these data sets - there is no indication in the paper that\nthese better results are in the literature.\n\nSome small things:\n\n* unplausible -> implausible\n\n* \"Husz (2015) showed that D(P || Q) is not identical to its inverse form\nD(Q || P)\" this is well known, predating 2015 for sure.\n", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}