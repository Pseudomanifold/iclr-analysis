{"title": "interesting extension to GCNs, somehwat lacking a comprehensive evaluation", "review": "I appreciate the author response and additional effort to provide comparison with MoNet. I have raised my rating by 1 point. It should be noted that the edits to the revision are quite substantial and more in line of a journal revision. My understanding is that only moderate changes to the initial submission are acceptable.\n\n-----------------------------------------------\n\nThe paper introduces a new regularization approach for graph convolutional networks. A transposed GCN is appended to a regular GCN, resulting in a trainable, graph specific regularization term modelled as an additional neural network.\n\nExperiments demonstrate performance en par with previous work in the case where sufficient labelled data is available. The SRGCNs seem to shine when only few labelled data is available (few shot setting).\n\nThe method is appealing as the regularization adapts to the underlying graph structure, unlike structure-agnostic regularization such as L1.\n\nUnclear why the results are not compared to MoNet (Monti et al. 2017) which seems to be the current state-of-the-art for semi-supervised classification of graph nodes.\n\nOverall, well written paper with an interesting extension to GCN. The paper is lacking a comprehensive evaluation and comparison to latest work on graph neural networks. The results in the few shot setting are compelling.", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}