{"title": "Evaluation of dropout regimes for DenseNets", "review": "The paper studies the effect of different dropout regimes (unit-wise, channel-wise and layer-wise), locations and probability affect the performance of DenseNet classification model. The experiments are performed on two datasets: CIFAR10 and CIFAR100.\n\nIn order to improve the paper, the authors could take into consideration the following points:\n\n1. The experimental validation is rather limited. Additional experiments on large scale datasets should be performed (e. g. on ImageNet).\n2. The design choices are rather arbitrary. The authors study three different probability schedules. Wouldn't it be better to learn them using recent advances in neural architecture search or in RL.\n3. \"The test error is reported after every epoch and ...\". This suggest that the authors are monitoring the test set throughout the training. Thus, the hyper parameters selected (e. g. the dropout regimes) might reflect overfitting to the test set.\n4. Table 1 misses some important results on CIFAR10 and CIFAR100, as is, the Table suggest that the method described in the paper is the best performing method on these datasets (and it is not the case). Moreover, the inclusion criteria for papers to appear in Table 1 is not clear. Could the authors correct the Table and add recent results on CIFAR10 and CIFAR100?\n5. Section 4.1: \"... a perfect size for a model of normal size to overfit.\"  This statement is not clear to me. What is a normal size model? Moreover, claiming that CIFAR10 and CIFAR100 is of perfect size to overfit seems to be a bit misleading too. Please rephrase.\n6. Section 3.3: what do the authors mean by deterministic probability model?\n7. Abstract: \"DenseNets also face overfitting problem if not severer\". I'm not aware of any evidence for this. Could the authors add citations accordingly?\n8. Some discussions on recent approaches to model regularizations and connections to proposed approach are missing. The authors might consider including the following papers: https://arxiv.org/pdf/1708.04552.pdf, https://arxiv.org/pdf/1802.02375.pdf, among others.\n\nOverall, the paper is easy to understand. However, the originality of the paper is rather limited and it is not clear what is the added value to for the community from such paper. I'd encourage the authors to include additional experiments, correct misleading statements and add a discussion of model regularization techniques in the related work section.", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}