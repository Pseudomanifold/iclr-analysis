{"title": "A reasonable approach for visualizing states of interest.", "review": "Summary.\nThe paper proposes an approach that involves two stages: (1) a variational autoencoder that learns to reconstruct the state space (i.e., input images in Atari games) and (2) an optimization step that finds a set of conditioning parameters to generate a synthetic image. The effectiveness of the proposed method is qualitatively evaluated on Atari games and a driving simulator. Though the approach looks interesting, clarification on claims/evaluations is required. \n\nStrengths.\n- An interesting problem in the current CV/RL community.\n- Well-surveyed related work.\n\nGenerative models vs. Query-based models.\nThough the authors mention several different target functions (T) can be chosen, the paper only explores only one simple function that could easily be achieved in other ways. For example, given a trained agent, it could be feasible to collect observations where the agent outputs high or low Q-values for all possible actions. Also, the following existing paper successfully finds a few critical states in which a certain action is important to be taken. This was done by computing entropy over the policy\u2019s output and by computing the baselined maximum Q-value. \n\n[1] Huang et al., \u201cEstablishing Appropriate Trust via Critical States\u201d, IROS 2018.\n\nProviding other possible target functions will be helpful to convince readers about its usefulness.\n\nSynthesizing unseen scenarios.\nI fully agree that synthesizing unseen scenarios is an important and interesting problem (especially for self-driving vehicle controls). However, I am worried about the ability of VAE in generating novel images, which is basically trained to reconstruct the manifold of a domain of training data. Counting the number of different pixels would not be sufficient evaluation metric especially in vehicle controls where small visual cues (i.e., pedestrians, vehicle, etc)  plays an important role. Can authors provide more detailed analysis of the ability to synthesize unseen scenarios?\n\nClarification in the Section Methods.\nNotations are used without providing a careful definition, which makes hard to understand the methodology. For example, \u2018z\u2019 and \u2018d\u2019 in the definition (2). Also, can authors clarify the term pi(s) - which is defined as a scalar value from the agent network\u2019s output - with the del operator? \n\nMinor concerns.\nTypos", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}