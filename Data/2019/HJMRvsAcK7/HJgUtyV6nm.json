{"title": "Interesting and relevant, but still needs work", "review": "This paper presents a reinforcement learning approach to dynamically set the price of items on sale on an e-commerce website, based on a state description consisting of several kinds of features: price, sales, customer traffic and competitiveness. The actions (possible prices) are constrained to lie in item-specific lower and upper bounds. Against a proposed method relying a continuous action space (an implementation of the Deep Deterministic Policy Gradient of Lillicrap et al., 2015), alternatives relying on multi-armed bandits and Deep Q Networks are evaluated. Experimental results from an online deployment are presented.\n\nThe paper is at times hard to understand. In particular, it would benefit from a thorough review of English grammar and style. For instance, the alternating descriptions between the past and present tenses (e.g. the abstract and the introduction) are quite non-natural and somewhat irritating [see specific instances in the detailed comments, below]. \n\nFrom an algorithmic standpoint, the paper does not introduce new methods and relies on well-known reinforcement learning techniques. The proposed methodology of applying specific RL techniques such as DDPG to pricing appears novel. However, there is an abundant literature on optimal pricing and discounting in operations research, much of it based on dynamic programming techniques, and more links to this literature could be provided.\n\nOne could question the choice of the reward function chosen (eq. 1): since it is a ratio, it is extremely sensitive to variations in the denominator, and this could severely impact convergence. \n\nThe primary weakness of the paper lies in the experimental evaluation: at least the following informations are missing to truly understand the methodological impact and economic benefits of the proposed approach:\n\n1. A complete description of the experimental setting, i.e. how many SKUs (stock keeping units) were evaluated, over which product categories, over what time horizon. Of those, how are they distributed in the fast-mover / slow-mover plane (Syntetos et al., 2005)? What special events were material during the time period? How many of those were predicted and incorporated into the state representation?\n2. One or more tables of results giving expected utility gains over baseline of the proposed methods, along with confidence intervals.\n3. For an ICLR submission, there should be additional investigations as to the structure of the learned representations, at least by the DQN and the DDPG models \u2014 is the state embedding learned by the networks somewhat suggestive of economically meaningful properties of the items or the sales environment?\n\nAs such, even though the paper is interesting, it is in too early a state to recommend acceptance at ICLR.\n\nDetailed comments:\n\n* p. 1: many past tenses that should be in the present tense, e.g. (just in the abstract): modeled ==> models, defined ==> defines, then it introduced ==> it then introduces, were designed ==> are designed. Many other cases in the rest of the paper.\n* p. 1: has draw ==> has drawn\n* p. 2: Forth ==> Fourth\n* p. 2: overtime ==> over time\n* p. 2: is assumed, to ==> is assumed to\n* p. 2: described ==> describe\n* p. 3: \u201clooks deep inside learning while earning approaches\u201d ==> sentence not clear\n* p. 3: this is not clear: \u201csince the number of page visitors may \ufb02uctuate dramatically and this could lead to non-concavity\u201c ==> why would it lead to non-concavity?\n* p. 4: The whole paragraph before eq. (1) is not clear\n* p. 5: The D in eq. (5) should be explained immediately, not after eq. (6).\n* p. 5: In eq. (5), $\\theta\u2019$ is not explained: how does it differ from $\\theta$ ?\n* p. 5: In eq. (6), how is $\\theta^{Q\u2019}$ different from $\\theta^{Q}$ ?\n* p. 6: in eq. (8), the denominator r_t could be a small number, leading to a noisy error; this should be discussed.\n* p. 6: Below eq. (12), these sentences are not clear: \u201cFor dynamic pricing problem, we particularly concern the outcome from changing between prices. To have a well knowledge between two prices before and after pricing.\u201d", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}