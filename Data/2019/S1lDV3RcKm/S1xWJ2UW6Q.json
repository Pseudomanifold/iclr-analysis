{"title": "Good paper but need to rectify few things", "review": "This is a good paper, as we have good experimental evidence that the proposed method seems to have some advantage over baseline methods.\n\nThe authors measure the success of their algorithm by computing FID scores for the randomly inputed images. That is the authors use a metric which measures a distance between the distribution of the generated images and images in a dataset. This is fine and interesting to know, but people also care about the distance of the completed pixels from the ground truth (missing) values. (E.g. https://www.cs.rochester.edu/u/jliu/paper/Ji-ICCV09.pdf)\n\nThis is important, because in a real life application, one would pick the mode of the distribution of the missing samples, and not sample from that distribution as the authors seems to be doing in this paper. \n\nI would therefore suggest adding experiments where authors pick the mode of the distribution and estimate an error metric such as root mean square error (RMSE or PSNR https://en.wikipedia.org/wiki/Peak_signal-to-noise_ratio ) \n\nI also found the 'marketing'/presentation of the algorithm little misleading, especially in the introduction, given that there exists another GAN based imputation algorithm. I think the authors should clearly state in the introduction that the other algorithm, abbreviated GAIN, exists as a GAN based missing data completion method. Then they should point out the differences of this algorithm from GAIN. Namely they should elaborate verbally on why learning the missing data distribution helps. Overall, what I am trying to say is, the key idea of this paper - that is learning the mask distribution - is not well motivated in this paper. \n\nDespite my concerns above, I recommend an accept. The algorithm seems novel, and there is some experimental results to back it up.  \n\n\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}