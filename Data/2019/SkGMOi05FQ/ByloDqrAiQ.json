{"title": "No novelty and very poor/limited experiments.", "review": "The paper describes the application of generative adversarial networks for modeling textual data with the help of skip-thought vectors. The authors experiment with different flavors of GANs and show experimental results for two different datasets.\n\nThe paper suffers from different weaknesses as listed below:\n-\tThe paper lacks novelty. The presented architecture is just a specialization of adversarial autoencoders where, in this specialized version, the noise vector is processed by some conv. layers before given as input to the discriminator. It is also very similar to \u201cAdversarially Regularized Autoencoders\u201d (Zhao et al., 2018)\n-\tThe paper is poorly written. For instance, the method is not properly described. Sec. 3.3 is quite short and confusing. Fig. 1 is not even referred to inside the text.\n-\tThe experimental setup used is quite weak and do not give real evidence of the advantages of the proposed method.\n-\tThere is no comparison with previous text generation methods. The authors only present results for different versions of their own approach.\n\nDue to the many issues listed above, my recommendation is for rejection.\n\nMinor question: What do the authors mean by: \u201cUnknown tokens are not included in the vocabulary.\u201d? By definition, \u201cunknown\u201d tokens aren\u2019t exactly the ones that do not appear in the vocabulary?", "rating": "2: Strong rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}