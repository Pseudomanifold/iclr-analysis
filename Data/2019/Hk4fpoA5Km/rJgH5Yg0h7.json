{"title": "A Review on Adversarial Inference by Matching Priors and Conditionals Discriminator-Actor-Critic: Addressing Sample Inefficiency and Reward Bias in Adversarial Imitation Learning", "review": "The authors find 2 issues with Adversarial Imitation Learning-style algorithms: I) implicit bias in the reward functions and II) despite abilities of coping with little data, high interaction with the environment is required. The authors suggest \"Discriminator-Actor-Critic\" - an off-policy Reinforcement Learning reducing complexity up to 10 and being unbiased, hence very flexible. \n\nSeveral standard tasks, a robotic, and a VR task are used to show-case the effectiveness by a working implementation in TensorFlow Eager.\n\nThe paper is well written, and there is practically no criticism.\n\n", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}