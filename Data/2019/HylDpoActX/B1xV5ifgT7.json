{"title": "in-depth analysis is needed for this paper", "review": "This paper is about CNN model compression and inference acceleration using quantization. The main idea is to use 'nest' clustering for weight quantization, more specifically, it partitions the weight values by recurring partitioning the weights by arithmetic means and negative of that of that weight clustering.\n\nI have several questions for this paper:\n\n1) the main algorithm is mainly based on the hypothesis that the weights are with Gaussian distribution. What happens if the weights are not Gaussian, such as skewed distribution? Seems the outliners will bring lots of issues for this nest clustering  for partitioning the weight values.\n\n2) Since the paper is on inference acceleration, there is no real inference time result. I think having some real inference time on these quantized models and showing how their inference time speedup is will be interesting.\n\n3) Activation quantization in Section 4 is a standard way for quantization, but I am curious how to filter out the outliner, and how to set the clipping interval?\n\n4) I am not sure what does the 'sparsity' mean in Table 2? Does this quantization scheme introduce many zeros? Or sparsity is corresponding to the compression ratio? If that is the case, then many quantization algorithms can actually achieve better compression ratios with 2 bits quantization.", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}