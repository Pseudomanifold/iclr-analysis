{"title": "Incremental method of applying greedy algorithm to the outputs of a shallow network, without strong support from experimental comparisons", "review": "This paper proposes a neural network that aims to select a subset of elements, for example, selecting k sentences that are mostly related to a claim from a set of retrieved docs. It firstly computes a multi-dimensional similarity score vector per element. The proposed network, DGN, takes the score vectors of all the candidates as inputs, processes them by linear+ReLU, and then runs the forward greedy algorithm maximizing a submodular function, which selects a subset of score vectors. The submodular function is defined as a weighted sum of multiple submodular functions, each corresponding to a dimension of the score vector, and is a concave function of the sum of the selected elements' scores on that dimension. The weights used to produce the weighted sum are learnable parameters of the submodular function. They show that DGN outperforms some baseline methods on FEVER dataset. \n\nMajor concerns:\n\n1) The idea is incremental: it applies the greedy algorithm to the outputs of a Linear+ReLU layer, whose inputs are the pre-computed similarity scores. Unfolding the greedy algorithm produces a simple RNN with each unit computing the marginal gain conditioned on the previously selected elements (the previous state), but it does not increase the depth and thus does not improve representativeness. \n\n2) Since the transformation applied to the input similarity scores is linear, it might not be very helpful and the final performance might largely depend on the quality of the similarity metric used to compute the input scores. In addition, the idea of learning the weights in a submodular function has been studied in many previous works such as learning submodular mixture and deep submodular functions, and the idea can be applied to more general submodular functions rather than the specific one used in this paper. Hence, the contribution and novelty of this paper are very limited.\n\n3) During training, softmax is used to approximate argmax and make the computational graph differentiable. Why not using Gumbel-softmax (which was studied in the paper that the authors cited to support their use of softmax here), which is a better approximation of argmax? In addition, the differentiability comes from using softmax, but this makes the training not exactly optimizing for the original greedy algorithm but a soft version of it.\n\n4) None of any previous works has been compared in the experiments except baselines created by the authors. At least, attention-based models and RNN such as Transformer and LSTM should be compared, since the proposed model is similar to them on some main ideas: it can be explained as an attention mechanism using the marginal gain of the submodular function as the attention score function; and it can be also explained as an unfolded simple RNN.\n\n5) In experiments, the proposed DGN has the same performance or shows slight advantages when comparing to \"Encoder\", which does not use any greedy procedure at all. Does this suggest that the greedy procedure is not necessary?\n\nMinor comments:\n\n1) Proposition 1 had already been proved in classical submodular textbooks.\n\n2) Is the ground truth labels L in Eq.(5) a subset (as defined above the equation) or a subsequence (as indexed in the equation)? Which one provides better training signals?", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}