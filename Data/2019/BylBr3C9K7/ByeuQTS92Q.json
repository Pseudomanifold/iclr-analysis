{"title": "The good paper, there are several questions", "review": "The paper is dedicated to energy-based compression of deep neural networks. While most works on compression are dedicated to decreasing the number of parameters or decreasing the number of operations to speed-up or reducing of memory footprint, these approaches do not provide any guarantees on energy consumption. In this work the authors derived a loss for training NN with energy constraints and provided an optimization algorithm for it. The authors showed that the proposed method achieves higher accuracy with lower energy consumption given the same energy budget. The experimental results are quite interesting and include even highly optimized network MobileNetV2.\n\nSeveral questions and concerns.\n\u2018Our energy modeling results are validated against the industry-strength DNN hardware simulator ScaleSim\u2019. Could the authors please elaborate on this sentence?\n\nOne of the main assumptions is the following. If the value of the data is zero, the hardware can skip accessing the data. As far as I know, this is a quite strong assumption, that is not supported by many architectures. How do the authors take into account overhead of using sparse data formats in such hardware in their estimations? Is it possible to simulate such behavior in ScaleSim? Moreover, in many modern systems DRAM can only be read in chunks. Therefore it can decrease number of DRAM accesses in (4).\n\nSmall typos and other issues:\nPage 8. \u2018There exists an algorithm that can find an an \\epsilon\u2019\nPage 8.\u2019 But it is possible to fan approximate solution\u2019\nPage 4.  It is better to put the sentence \u2018where s convolutional stride\u2019  after (2).\nIn formulation of the Theorem 3, it is better to explicitly state that A contains rational numbers only since gcd is used.\nOverall, the paper is written clearly and organized well, contains interesting experimental and theoretical results.\n", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}