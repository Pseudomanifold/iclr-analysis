{"title": "Needs a lot of work on improving technical rigor and clarity", "review": "Note to Area Chair: Another paper submitted to ICLR under the title \u201cDo Deep Generative Models Know What They Don\u2019t Know?\u201d shares several similarities with the current submission.\n\nThis paper highlights a deficiency of current generative models in detecting out-of-distribution based samples based on likelihoods assigned by the model (in cases where the likelihoods are well-defined) or the discriminator distribution for GANs (where likelihoods are typically not defined). To remedy this deficiency, the paper proposes to use ensembles of generative models to obtain a robust WAIC criteria for anomaly detection.\n\nMy main concern is with the level of technical rigor of this work. Much of this has to do with the presentation, which reads to me more like a summary blog post rather than a technical paper.\n- I couldn\u2019t find a formal specification of the anomaly detection setup and how generative models are used for this task anywhere in the paper.\n- Section 2 seems to be the major contribution of this work. But it was very hard to understand what exactly is going on. What is the notation for the generative distribution? Introduction uses p_theta. Page 2, Paragraph 1 uses q_theta (x). Eq. (1) uses p_theta and then the following paragraphs use q_theta.\n- In Eq. (1), is theta a random variable?\n- How are generative ensembles trained?  All the paper says is \u201cindependently trained\u201d. Is the parameter initialization different? Is the dataset shuffling different? Is the dataset sampled with replacement (as in bootstrapping)?\n- \u201cBy training an ensemble of GANs we can estimate the posterior distribution over model deciscion boundaries D_theta(x), or equivalently, the posterior distribution over alternate distributions q_theta. In other words, we can use uncertainty estimation on randomly sampled discriminators to de-correlate the OoD classification errors made by a single discriminator\u201d Why is the discriminator parameterized by theta? What is an ensemble of GANs? Multiple generators or multiple discriminators or both? What are \u201crandomly sampled discriminators\u201d? What do the authors mean by \"posterior distribution over alternate distributions\"?\n\nWith regards to the technical assessment, I have the following questions for the authors:\n- In Figure 1, how do the histograms look for the training distribution of CIFAR? If the histograms for train and test have an overlap much higher than the overlap between the train of CIFAR and test set of any other distribution, then ensembling seems unnecessary and anomaly detecting can simply be done via setting a maximum and a minimum threshold on the likelihood for a test point. In addition to the histograms, I'd be curious to see results with this baseline mechanism.\n- Why should the WAIC criteria weigh the mean and variance equally?\n- Did the authors actually try to fix the posterior collapse issue in Figure 3b using beta-VAEs as recommended? Given the simplicity of implementing beta-VAEs, this should be a rather easy experiment to include.\n\nMinor typos:\n- ODIN and VIB are not defined in the abstract\n- Page 3: \u201cdeciscion\u201d\n- Page 2, para 2: \u201clog_\\theta p(x)\u201d", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}