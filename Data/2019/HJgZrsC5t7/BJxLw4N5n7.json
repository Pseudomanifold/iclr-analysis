{"title": "Potentially interesting idea but lacking clarity and explanations", "review": "This paper centers around adding a reward term that, as I understand it, rewards the agent for having seen sequences of rewards that have low variability. This is an interesting idea, however I find the clarity of the main part of the paper (section 4.1, where this new term is defined) quite poor. That section makes several seemingly arbitrary choices that are not properly explained, which makes one wonder if those choices were made mostly to make the empirical results look good or if there are some more fundamental and general concepts being captured there. In particular, I have to wonder where the 100 in the definition of R_H comes from, and also how sigma_max would be determined (it is very hard to get a good intuition on such quantities as an RL practitioner).  \n\nThe paper also introduces \u201chot-wire exploration\u201d, basically trying the same action for a while during the initial stage, which is a nice exploration heuristic for Atari, but I am not sure how generally applicable the idea is beyond the Atari testbed.\n\nIn general, I am always a bit wary of experimental results that were obtained as a result of introducing additional hyper-parameters or functional forms. However, the results look pretty good, and the authors do manage to show some amount of hyperparameter robustness, which makes me wish the design choices had been more clearly explained..\n", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}