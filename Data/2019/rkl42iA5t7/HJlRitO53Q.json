{"title": "Interesting approach, second time reviewing", "review": "This paper proposes a compression method based on spectral analysis. The basic idea is to analyse correlation between responses of difference layers and select those that are more relevant discarding the others. That, in principle (as mentioned in the paper) differs from other compression methods based on compressing the weights independently of the data being used. Therefore, in theory (nothing shown), different task would provide different outputs while similar works would compress in the same manner. \n\nThen, the paper proposes a greedy algorithm to select those filters to be kept rather than transforming the layer (as it has been usually done in the past [Jaderberg et al]). This is interesting (from a practical point of view) as would lead to direct benefits at inference time. \n\nThis is the second time i review this paper. I appreciate the improvements from the first submission adding some interesting results. \n\nI still miss results in larger systems including imagenet. How all this approach actually scales with the complexity of the network and the task?\n\nThere have been recent approaches incorporating low-rank approximations that would be interesting to couple with this approach. I am surprissed these are not even cited ('Compression aware training' at NIPS 2017 or Coordinating filters at ICCV2017 both with a similar approach (based on weights tho). Pairing with those approaches seems a strong way to improve your results. \n\n\n", "rating": "5: Marginally below acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}