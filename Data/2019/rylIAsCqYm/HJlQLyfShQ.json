{"title": "questions about theories", "review": "This paper studies the combination of the asynchronous parallelization and the accelerated stochastic coordinate descent method. The proved convergence rate is claimed to be consistent with the non parallel counterpart. The linear speedup is achievable when the maximal staleness is bounded by n^{1/2} roughly, that sounds very interesting result to me. However, I have a few questions about the correctness of the results:\n\n- Theorem 1 essentially shows that every single step is guaranteed to improve the last step in the expectation sense. However, this violates my my experiences to study Nesterov's accelerated methods. To my knowledge, Nesterov's accelerated methods generally do not guarantee improvement over each single step, because accelerate methods essentially constructs a sequence z_{t+1} = A z_t where A is a nonsymmetric matrix with spectral norm greater than 1.\n\n- The actual implemented algorithm is using the sparse update other than the analyzed version, since the analyzed version is not efficient or suitable for parallelization. However, the sparse updating rule is equivalent to the original version only for the non asynchronous version. Therefore, the analysis does not apply the actual implementation.\n\nminors:\n- pp2 line 8, K(epsilon) is not defined \n- Eq. (1.4), the index is missing.\n- missing reference: An Asynchronous Parallel Stochastic Coordinate Descent Algorithm, ICML 2014.", "rating": "7: Good paper, accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}