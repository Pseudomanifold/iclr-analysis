{"title": "Robustness and Equivariance of Neural Networks", "review": "This paper empirically studies the robustness of equivariant CNNs to rotations as well as adversarial perturbations. It also studies their sample efficiency, parameter efficiency, and the effect of rotation- and adversarial augmentation during training and/or testing. \n\nThe main findings are:\n1) Rotation-equivariant networks are robust to small rotations, even if equivariance to small rotations is not directly built into the architecture\n2) Applying rotational data augmentation increases robustness to rotations\n3) Equivariant networks are more sample efficient than CNNs and outperform them for all dataset sizes.\n4) Applying rotational data augmentation decreases robustness to adversarial perturbations, and this effect is more pronounced for GCNNs.\n\nIf true, this is a valuable addition to the literature. It is one of the first independent validations of claims regarding sample complexity and accuracy made by the authors of the various equivariant network papers, performed by a party that does not have their own method to promote. Many of the findings do not have an obvious explanation, so the data from this paper could conceivably prompt new theoretical questions and investigations.\n\nThe authors chose to highlight one finding in particular, namely that GCNNs become more sensitive to adversarial perturbations as they are trained on more heavily rotation-augmented data. However, this appears to be true for both CNNs and GCNNs, the difference being only in degree (see fig 4, 10, 11). This is not apparent from the text though, as e.g. the abstract notes that \"robustness to geometric transformations in these models [equivariant nets] comes at the cost of robustness to small pixel-wise perturbations\".\n\nSince HNets, GCNNs and RotEqNets should be exactly equivariant to 90 degree rotations (and some others, perhaps), it is surprising that figure 1 shows a continuing decline in performance with bigger and bigger random rotations. If the network is made rotation invariant through some pooling layer at the end of the network, one would expect to see a decline in performance up to 45 degrees, followed by an increase back to baseline at 90 degrees, etc. \n\nPolar transformer networks achieve good results in fig. 1, but I wonder if this is still true for rotations around points other than the origin.\n\nSince CNNs and GCNNs differ in terms of the number of channels at a certain number of parameters, and differ in terms of number of parameters at a certain number of channels, it could be that channel count or parameter count is the more relevant factor, rather than equivariance. So it would be good to make a scatterplot where each dot is a network (either CNN or GCNN, at various model sizes), the x-axis is parameter count (or in another plot, 2d channel count), and the y-axis corresponds to the accuracy. This can be done for various choices of augmentation / perturbation. The type of network (CNN or GCNN) could be color coded. If indeed the CNN/GCNN variable is relevant, that should be clearly visible in the plot, and similarly if the parameter count or channel count is relevant. One could also do a linear regression of accuracy or log-accuracy or something using CNN/GCCN, param-count, channel-count as covariates, and report the variance explained by each. \n\nIn several plots, e.g. fig 4, 8, the y-axes do not have the same range, making it hard to compare results between subplots. \n\nThe experiments have some weaknesses. For one thing, it seems like each accuracy value reported comes from a single training run. It would be much preferable to plot mean and standard deviation / error bars. Another weakness is that all experiments are performed on MNIST. Even just a simple validation of the main findings on CIFAR would significantly strengthen the paper.\n\nBecause of the limited scope of the experiments, it is not clear to me how generalizable and robust the experimental results are. With deep network performance it can be hard to know what the relevant hyperparameters are, and so we may well be reading tea leaves here.\n\nIt is also unfortunate that no explanation for the observed phenomena is available. However, it is conceivable that the findings presented in this paper could help researchers who are trying to understand adversarial attacks / robustness, so it is not a fatal flaw. I am certainly glad the authors did not make up some unsupported story to explain the findings, as is all too common in the literature these days.\n\nOverall, I consider this a borderline paper, and am tending towards a reject. My main considerations are:\n1. Uncertainty about generalizability\n2. Uncertainty about usefulness to practitioners or theorists (admittedly, this is hard to predict, but no clear use-case is available at this point)\n3. A lot of data, but no clear central finding of the paper", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}