{"title": "Review", "review": "Revision:\n\nThe addition of new datasets and the qualitative demonstration of latent space interpolations and algebra are quite convincing. Interpolations from raster-based generative models such as the original VAE tend to be blurry and not semantic. The interpolations in this paper do a good job of demonstrating the usefulness of structure.\n\nThe classification metric is reasonable, but there is no comparison with SPIRAL, and only a comparison with ablated versions of the StrokeNet agent. I see no reason why the comparison with SPIRAL was removed for this metric.\n\nFigure 11 does a good job of showing the usefulness of gradients over reinforcement learning, but should have a better x range so that one of the curves doesn't just become a vertical line, which is bad for stylistic reasons.\n\nThe writing has improved, but still has stylistic and grammatical issues. A few examples, \"there\u2019re\", \"the network could be more aware of what it\u2019s exactly doing\", \"discriminator loss given its popularity and mightiness to achieve adversarial learning\". A full enumeration would be out of scope of this review. I encourage the authors to iterate more on the writing, and get the paper proofread by more people.\n\nIn summary, the paper's quality has significantly improved, but some presentation issues keep it from being a great paper. The idea presented in the paper is however interesting and timely and deserves to be shared with the wider generative models community, which makes me lean towards an accept.\n\nOriginal Review:\n\nThis paper deals with the problem of strokes-based image generation (in contrast to raster-based). The authors define strokes as a list of coordinates and pressure values along with the color and brush radius of a stroke. Then the authors investigate whether an agent can learn to produce the stroke corresponding to a given target image. The authors show that they were able to do so for the MNIST and OMNIGLOT datasets. This is done by first training an encoder-decoder pair of neural networks where the latent variable is the stroke, and the encoder and decoder have specific structure which takes advantage of the known stroke structure of the latent variable.\n\nThe paper contains no quantitative evaluation, either with existing methods or with any baselines. No ablations are conducted to understand which techniques provide value and which don't. The paper does present some qualitative examples of rendered strokes but it's not clear whether these are from the training set or an unseen test set. It's not clear whether the model is generalizing or not.\n\nThe writing is also very unclear. I had to fill in the blanks a lot. It isn't clear what the objective of the paper is. Why are we generating strokes? What use is the software for rendering images from strokes? Is it differentiable? Apparently not. The authors talk about differentiable rendering engines, but ultimately we learn that a learnt neural network decoder is the differentiable renderer.\n\nTo improve this paper and make it acceptable, I recommend the following:\n\n1. Improve the presentation so that it's very clear what's being contributed. Instead of writing the chronological story of what you did, instead you should explain the problem, explain why current solutions are lacking, and then present your own solutions, and then quantify the improvements from your solution.\n\n2. Avoid casual language such as \"Reason may be\", \"The agent is just a plain\", \"since neural nets are famouse for their ability to approximate all sorts of functions\".\n\n3. Show that strokes-based generation enables capabilities that raster-based generation doesn't. For instance, you could show that the agent is able to systematically generalize to very different types of images. I'd also recommend presenting results on datasets more complex than MNIST and OMNIGLOT.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}