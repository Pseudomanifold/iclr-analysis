{"title": "Extensive experiments and results, but not enough contribution", "review": "Summary:\nThe authors propose an extension of dual learning (DL). In DL, one leverages the duality of a dataset, by predicting both forward and backward, e.g. English to German, and German back to English. It\u2019s been shown that training models using this duality is beneficial. This paper extends DL by introducing multiple models for the forward and backward, and using their output to regularise the training of the two main agents.\n\nThe authors show that this setup improves on the SotA, at only a training computation expense (inference/test time remains the same).\n\nReview:\nThe paper shows extensive experimentation and improves the previous result in all cases. The proposed method is a straightforward extension and can be readily implemented and used.\n\nI have difficulty understanding equation 8 and the paragraph below. It seems like the authors use an equal weighting for the additional agents, however they mention using Monte Carlo to \u201ctackle the intractability resulting form the summation over the exponentially large space y\u201d. According to the paper the size of y is the dataset, is it exponentially large? Do the authors describe stochastic gradient descent? Also what do the authors mean by offline sampling? Do they compute the targets for f_0 and g_0 beforehand using f_1\u2026n and g_1\u2026n?\n\nThe results mention computational cost a few times, I was wondering if the authors could comment on the increase in computational cost? e.g. how long does \u201cpre-training\u201d take versus training the dual? Can the training of the pre-trained agents be parallelised? Would it be possible to use dropout to more computationally efficient obtain the result of an ensemble?\n\nIn general I think the authors did an excellent job validating their method on various different datasets. I also think the above confusions can be cleared up with some editing. However the general contribution of the paper is not enough, the increase in performance is minimal and the increased computational cost/complexity substantial. I do think this is a promising direction and encourage the authors to explore further directions of multi-agent dual learning.\n\nTextual Notes:\n- Pg2, middle of paragraph 1: \u201cwhich are pre-trained with parameters fixed along the whole process\u201d. This is unclear, do you mean trained before optimising f_0 and g_0 and subsequently held constant?\n- Pg2, middle last paragraph: \u201ctypical way of training ML models\u201d. While the cross entropy loss is a popular loss, it is not \u201ctypical\u201d.\n- Pg 3, equation 4, what does \u201cbriefly\u201d mean above the equal sign?\n- Perhaps a title referring to ensemble dual learning would be more appropriate, given the possible confusion with multi agent reinforcement learning. \n\n\n################\nRevision:\n\nI would like to thank the authors for the extensive revision, additional explanations/experiments, and pointing out extensive relevant literature on BLUE scores. The revision and comments are much appreciated. I have increased my score from 4 to 6.", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}