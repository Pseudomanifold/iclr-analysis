{"title": "The paper is an extension of tensor parametrizing CNN. It is interesting but with limited originality. ", "review": "The paper propose fully parametrizing CNNs with a single, low-rank tensor. As compared to the previous work which parametrizing individual layer by tensor representation, this paper combine all parameters from each layers and model them as one tensor. This allows to regularize the whole network and drastically reduce the number of parameters by imposing a low-rank structure on that tensor. The experiments show higher compression rates with negligible drop in accuracy for human pose estimation. \n\nThe paper is well written by firstly introducing basic tensor decomposition and operations, then presenting how to use them to parametrizing CNN.  However, the concept of using tensor decomposition to parametrize the CNN is known, this paper is an extension by considering all layers together. Therefore, the originality is limited and incremental. \n\nThe parameters from different layers may have very different sizes, which make this method not very practical. Although we can manually use the same size of parameters for all layers, the problem of redundant information will become more severe. \n\nIn general, the parameters in different layers are supposed to be very different and uncorrelated. In this paper, the parameters from different layers are put together and low-rank structure is assumed. Hence, one question of why this will work well is not clear.  Furthermore, there is no theoretical support for the method to obtaining the higher compression. \n\nThe authors claim Tucker is easy to control the rank thus considered as the most flexible compression method. The justification of this claim should be provided, or the detailed experiment comparisons should be given. Why Tucker is more flexible is not clear. \n\n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}