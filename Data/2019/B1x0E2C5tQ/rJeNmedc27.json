{"title": "Weak reject", "review": "This paper investigates the representations learned by NMT models.  Specifically it compares the representations learned by NMT models with different types of input/output units.  The representations are compared by concatenating the hidden states into a feature vector and training classifiers for 3 different tagging tasks (morphology, syntax, semantics) on those features.\n\nThe study is complete and rigorous, and the methods are clearly explained.\n\nOne finding that is somewhat surprising is that word representations performed worst across the board.   A few concerns arise from this finding:\n-- Is this a consequence of limiting the vocabulary to 50K?  Are the word representations somewhat handicapped by this limitation?\n--  As the authors state, word vectors are currently the representation of choice in NLP applications.  Are the authors suggesting that subword representations would be preferable in these applications?  If so, it would be more convincing if the representations were compared in the context of one of these applications, such as question answering or entailment.  If this is not what the authors are suggesting, then what is the broader significance of this finding?\n\nLearning pre-trained representations of language is certainly important in many NLP applications, particularly those for which there is little available labeled data.  This appears to be the first study comprehensively comparing different units in terms of the representation quality.  It is thorough and original.  However, the authors have measured performance on morphological, syntactic, and semantic tagging.  While these tasks seem to have been chosen as being representative of raw language understanding, I'm not sure these would also reflect performance in actual NLP applications.\n\nPros\n- Experiments are rigorous and comprehensive.\n- Very clearly written and easy to understand.\n\nCons\n- Significance/relevance of these particular tasks is limited.\n- Limiting word vocabulary to 50K may be impacting results.\n", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}