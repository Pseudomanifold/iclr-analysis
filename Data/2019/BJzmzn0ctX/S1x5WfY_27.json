{"title": "Interesting paper and contributions.", "review": "This paper propose an extension of the Neural Theorem Provers (NTP) system that addresses the main issues of this method. The contributions of this paper allow to use this model on real-word datasets by reducing the time and space complexity of the NTP model. \n\nPro:\n\nThe paper is clear and well written and the contribution is relevant to ICLR. NTP systems by combining the advantages of neural models and symbolic reasoning are a promising research direction. Even though the results presented are lower than previous studies, they present the advantage of being interpretable.\n\nCons:\n\nI'm not convinced by the model used to integrate textual mentions. The evaluation proposed in section 6.3 proposes to replace training triples by textual mention in order to evaluate the encoding module. However, it seems to me that, in this particular case, these mentions are very short sentences.  This could explained why such a simplistic model that simply average word embeddings is sufficient. I wonder if this would still work for more realistic (and thus longer) sentences.\n\nMinor issues:\n\n-Page 1: In particular [...] (NLU) and [...] (MR) in particular, ...\n", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}