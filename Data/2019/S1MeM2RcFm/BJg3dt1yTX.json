{"title": "Review", "review": "A method for multi-bit watermarking of neural networks in a black-box setting is proposed. In particular, the authors demonstrate that the predictions of existing models can carry a multi-bit string that can later be used to verify ownership.\nExperiments on MNIST, CIFAR-10 and ImageNet are presented in addition to a robustness assessment w.r.t. different WM removal attacks.\n\nQuestions/Comments:\n\nRegarding the encoding scheme, a question that came up is whether one needs to perform clustering on the last layer before the softmax? In principle, this could be done at any point, right?\n\nAnother question is how the method scales with the key length. Did you experiment with large/small values of K (e.g., 100,200,...)? It would be interesting, e.g., to see a plot that shows key length vs. accuracy of the marked model, or, key\nlength vs. detection success (or BER).\n\nApart from these comments, how does the proposed model compare to zero-bit WM schemes? I am missing a clear comparison to other, related work, as part of the experiments. While there might not exist other \"black-box multi-bit\"\nschemes in the literature, one could still compare against non-multi-bit schemes. \n\nIn light of a missing comparison, my assessment is \"Marginally below acceptance threshold\", but I am willing to vote\nthis up, given an appropriate response.\n\n\n\n\n\n", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}