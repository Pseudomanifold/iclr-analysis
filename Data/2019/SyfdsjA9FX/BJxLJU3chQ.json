{"title": "Non-trivial results on an interesting problem", "review": "The submission proposes a method for face de-identification. \nA network is trained to transform an input face image to simultaneously stay close to the low- and mid-level representations  while maximising the distance of the high-level representation of the input image in a face recognition network. Additionally an adversarial loss and reconstruction losses both in terms of the input image as well as its horizontal and vertical gradients are employed.\nThe network learns to transform faces to be maximally different in identity from a given reference image while preserving low-level features. Thus, at inference the network can de-identify face images from arbitrary new people given a single reference image of each person.\n\nThe method is evaluated in three different ways. \na) It is shown that humans have difficulties discriminating between transformed and non-transformed videos.\nb) In a fine-discrimination experiment human subjects are asked to re-identify faces from a given reference image among five dark-haired caucasian males. The subjects could re-identify the images without face de-identification but had substantial problems after the transformation was applied.\nc) In a quantitative study it is shown that a state-of-the-art face recognition network cannot recognise faces of celebrities after the de-identification is applied while it recognise it fairly well before the transformation\n\nI have some questions and remarks:\n\n1.) How long are the videos used for evaluation a), what is the exact study protocol ?\n\n2.) Are the evaluation networks trained on the same dataset as the loss network? If yes it is not surprising that the generated images can fool the networks as they represent the same data as the loss network and I would like to see the evaluation for networks not trained on the same dataset as the loss network. \n\n3.) The method is optimised to maximise confusion of the identity while preserving low and mid level features. This leads to good de-identification if the set of identities from which to retrieve is densely sampled in the space of low-level features. I.e. if in the set of identities from which to identify a person there exist many people with similar low-level features. However, there are many conceivable scenarios in which the number of possible identities from which to retrieve is far smaller. To de-identify in such scenarios, it is necessary to apply much stronger transformations to the face to obscure the identity of a person. It would be great if this dependency between the strength of the transformation that needs to be applied and the reference set of identities from which to retrieve the identity of a given person could be explicitly discussed in the submission.\n\n4.) The emphasis on performance for video de-identification is somewhat misleading as the method does not seem to include any particular effort to explicitly improve video performance. It is great that the method also seems to work for video, but I cannot see strong evidence that it strongly outperforms pre-existing methods on video performance (they might also just work well out-of-the-box).\n\nNevertheless, I believe the submission addresses an interesting topic and shows non-trivial results. While I have some questions about the evaluation and minor concerns about the presentation I would overall recommend acceptance of the submission.", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}