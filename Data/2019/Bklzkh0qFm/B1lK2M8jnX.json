{"title": "Small incremental extension of existing work", "review": "This work extends Schlichtkrull et al. (2018) by adding attention in two distinct ways: attention between pairs of nodes per relation, and attention between pairs of nodes averaged over all relations. The paper is well written and the equations easy to follow. The results are not strong. And, unfortunately, the model contribution currently is too modest. \n\nInductive task results: Wu et al. (2018) reports that for Tox21 (Duvenauld et al. 2015) is the best-performing approach. We should see the performance on other datasets  (e.g., some of the other datasets in Wu et al. (2018)).\n\nMy introduction suggestion: do not talk about Convolutional neural networks (CNNs). There is a *lot* of work on graph convolutional networks (GCNs). Reading it feels like reading about lattices when the work is about general graphs, and lattices provide no intuition about the proposed solution. \n\n--- After rebuttal ---\n\nStill not convinced of the value of the work to the community. Will keep my score the same.", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}