{"title": "A nice empirical paper with good intuitions and encouraging results", "review": "This paper does not even try to propose yet another \"vacuous\" generalization bounds, but instead empirically convincingly shows an interesting connection between the proposed margin statistics and the generalization gap, which could well be used to provide some \"prescriptive\" insights (per Sanjeev Arora) towards understanding generalization in deep neural nets.\n\nI have no major complaints but for a few questions regarding clarifications,\n1. From Eq.(5), such distances are defined for only one out of the many possible pairs of labels. So when forming the so-called \"margin signature\", how exactly do you compose it from all such pair-wise distances? Do you pool all the distances together before computing the statistics, or do you aggregate individual statistics from pair-wise distances? And how do you select which pairs to include or exclude? Are you assuming \"i\" is always the ground-truth label class for $x_k$ here?\n\n2. In Eq.(3), the way you define the distance (that flipping i and j would change the sign of the distance) is implying that {i, j} should not be viewed as an unordered pair, in which case a better notation might be (i, j) (i.e. replacing sets \"{}\" with tuples \"()\" to signal that order matters).\n\nAnd why do you \"only consider distances with positive sign\"? I can understand doing this for when neither i nor j corresponds to the ground-truth label of x, because you really can't tell which score should be higher. But when i happens to be the ground-truth label, wouldn't a positive distance and a negative distance be meaningful different and therefore it should only be beneficial to include both of them in the margin samples?\n\nAnd a minor typo: In Eq.(4), $\\bar{x}_k$ should have been $\\bar{x}^l$?", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}