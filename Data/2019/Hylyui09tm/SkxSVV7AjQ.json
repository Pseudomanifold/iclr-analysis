{"title": "Review of EMI", "review": "This paper introduces actions as a co-predictor of next-states and the predicted (from current and next state) in the context of (model-based) RL. In addition they incorporate the idea of using a JSD-based objective do prediction (as the Deep InfoMax paper), which is novel to RL. The enforce a linear structure between current / next states and actions with an additional sparse nonlinear term computed from both current states and actions. From this, they are able to quantify the amount of novelty in the representation space as a measure of exploration, which can be used as an intrinsic reward.\n\nI found the paper to be very well-written and easy to understand. The prediction part is similar to that used in CPC structurally, except they include the action in two different prediction tasks and they have some built-in intrinsic rewards, which is good.\n\nI had some issues with the motivations of some of the loss functions. \n- The JSD-based objective makes sense, but I don't think it's correct to call it an \"approximation\" to the KL (this is only true where the log-ratio of the joint and the product of marginals is small). Rather, it would be better to describe this choice as simply using a different measure between the joint and marginals.\n- It seems like the best motivation for having linear relations is you can do multiple predictions using the same state / action encodings.\n- For measuring exploration (11) couldn't one just use the predictor models T? How does the output of T (perhaps correctly normalized with the marginals) correlate with (11)?\n\nOther notes:\nPage 2:\nFigure 1 is awfully confusing. Could this be clarified a little bit? I\u2019m not sure what the small dots or their colors are supposed to represent.\n\nCould diversity also be added by adding a prior to the state representations (as is done in Deep InfoMax)?\n\nWhy were the vision experiments stopped at 500 x 100k (500 million) frames?  I can\u2019t validate the SOTA claims, but it seems like the model is still improving: are there\u2019s further experiments?\n\nAn ablation study would be nice comparing the different hyper parameters (intrinsic rewards, diversity, etc).", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}