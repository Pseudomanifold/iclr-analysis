{"title": "More appropriate for quantum computing literature", "review": "Review of \"Neural Network Cost Landscapes as Quantum States\"\n\nPaper summary:\n\nThe paper proposes a new algorithm \"quantum amplitude amplification\"\nfor training and model selection in binary neural networks. (in which\nboth weights and activations are restricted to the set -1, 1)\n\nSection 2 references related work and gives some motivation, that some\nquantum algorithms scale better (in terms of big-O notation) than\nclassical algorithms.\n\nSection 3 explains the basics of quantum computing (qubits and quantum\ngates).\n\nSection 4 explains the proposed method. There are two toy\nproblems. The binary neural network has 8 weight parameters. There are\nhelpful Figures 1-2 which explain the network structure and the\nquantum circuit.\n\nSection 5 explains the results of using the proposed method in a\nquantum computer simulator (not an actual quantum computer). On the\ntwo toy problems the paper observes quadratic speedups with respect to\na brute force search.\n\nComments:\n\nA strong point is that the paper is very well-written and easy to\nunderstand. \n\nHowever there are several weak points which should be addressed before\npublication. Major weak points are (1) only (noiseless?) toy data sets\nare used, (2) some terms in the paper are unclear/undefined, and (3)\nresults are unconvincing.\n\nIt is not clear that this article should be published in the machine\nlearning literature. One of the hallmarks of machine learning is a\nfocus on algorithms for real data sets / problems. In contrast the\nfocus of this paper is quantum computations on toy data /\nproblems. Maybe this paper would be better suited for publication in\nthe quantum computation literature?\n\nThe toy problems are explained in section 4.2. Is there any noise or\nare these noiseless simulations? How does your model/algo perform as a\nfunction of the noise level? How many data points did you simulate\nfrom the model? (e.g. what is the number of observations in the training set?)\n\nThe paper uses the terms \"cost landscape\" and \"meta-cost landscape\"\nwithout explicitly defining them. Equations should be added to clarify\nthese terms.\n\nResults could be made more convincing by\n1. using a real quantum computer.\n2. using real data rather than toy data.\n3. adding error bars or confidence intervals to Figures 4-5.\n4. using a more appropriate baseline -- why not try the algorithms mentioned in section 2.1?\n\nFigure 3 could be clarified by providing ticks and labels on the x\naxes.\n\n", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}