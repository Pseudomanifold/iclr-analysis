{"title": "This paper presents a VAE model that jointly models images and their labels.", "review": "\n\nThis paper presents a VAE model that jointly models images and their labels. Specifically, the following the VAE framework, the proposed model encodes an image into a latent variable, whose prior is conditioned on the labels of the image, and the latent variable is used to reconstruct the image. The paper also presents a variant which also reconstructs the labels \n\n\nMy comments are as follows:\n\n1. About the significance and originality, although to my knowledge, there seems to be no the exact match in the existing approaches of the idea of incorporating labels into the prior of the latent variable of VAE, the idea seems a little bit trivial and less of technical depth. Moreover, in terms of performance, it seems that the proposed model is not significantly better than the previous models. Therefore, my major concern of this paper goes to the significance.\n\n2. In terms of experiments, I am not convinced that using 20D of PSE VS 10D of CVAE is a fair comparison, although the CVAE will use another 10 dimensions to encode 10 labels with one-hot form. Moreover, using the same settings for all the models in comparison may not be perfect because different models may have different best settings. It would be better if the validation set is used to tune the settings a little bit. \n\n3. Does the proposed model use the word embeddings of the labels? It could be better to report both results of word embeddings and one-hot encoding of the labels, to see if word embeddings help. ", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}