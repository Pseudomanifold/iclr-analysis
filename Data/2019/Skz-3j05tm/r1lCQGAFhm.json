{"title": "Good performance but less clear novelty", "review": "The paper proposes a Graph Convolutional Network-based encoder-decoder model with sequential attention for goal-oriented dialogue systems, with the purpose of exploiting the graph structures in KB and sentences in conversation. The model consists of three encoders for a query, dialogue history, and KB, respectively, and a decoder with a sequential attention mechanism. The proposed model attains state-of-the-art performance on the modified DSTC2 dataset of (Bordes et al., 2017). For the experiments with graphs constructed from word co-occurrence matrix, code-mixed versions of modified DSTC2 released by (Banerjee et al., 2018) are used.\n\nPros and Cons\n(+) SOTA performance on the DSTC2 dataset.\n(+) Without dependency parser when it is not possible\n(-) Limited novelty\n(-) Limited convincing the advantage of GCN itself\n\nDetailed comments\nThe paper incorporates the graph structures in sentences and KB to make richer representations of conversation and achieves a state-of-the-art performance on the DSTC2 dataset. The paper is clearly written, and the results seem promising. However, as the paper combines existing mechanisms to design a model for dialog, the novelty seems to be relatively weak.\nIn particular, I felt that some experimental results are required to verify some of the arguments put forward by the authors. We listed two issues as below.\n\n1. Effects of GCN\nThe authors show that RNN-GCN-SeA can make state-of-the-art performance, but not how much GCN makes effects on improving the performance on the dialog task. \nI think the authors need to compare the results of RNN-GCN-SeA with a model without GCN (i.e. RNN-SeA) in order to show that exploiting the structural information of dependency and contextual graphs do play an important role.\nThe random graph experiments (Table 3) show the effect of good structure in GCN, but I felt that it is not enough to demonstrate an improvement by GCNs. \n\n2. Comparative Experiments\nI think that some experiments, which is reported in the previous papers (including Mem2Seq), would make the author\u2019s experimental argument strong.\n- Entity F1 score for the modified DSTC2 dataset\n- Results on bAbI dialog dataset (task1~5 and its OOV variants) and In-Car Assistant dataset\n\nMinor issues\n1. Authors described that Mem2Seq is one of the state-of-the-art models in this field, including in the abstract. However, Mem2Seq does not outperform seq2seq model in all experiments. From what point of view is this model state-of-the-art? \n2. Recent studies have focused on copy mechanism in task-oriented dialog systems. Could you explain how the copy mechanism could be incorporated into the proposed model? I am also interested in the comparative results between seq2seq + attn + copy (per-resp-acc of 47.3) and its entity F1 measure (Eric and Manning, 2017; Madotto et al. 2018).\n\n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}