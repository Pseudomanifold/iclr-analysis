{"title": "Review for \"Neural Belief Representations\"", "review": "# Review for \"Neural Belief Representations\"\n\n\n\nThe authors argue in the favor of belief representations for partial observable Markov decision processes. The central argument is that uncertainty needs to be represented to make optimal decision making. For that aim, three belief representations based on sufficient statistics of the future are evaluated and compared in a set of disective studies. Those studies find that predicting the future results in uncertainty being represented in the state representations, although they differ in quality.\n\nI found the paper hard to follow for various reasons. \n\n- NCE is reviewd, while CPC is not. I would have found a review of CPC as well to help my understanding, especially to draw the line between CPC and CPC|Action.\n- In 2.1., $b_t$ is defined as a probability, while it is the output of a neural network later. This is formally incompatible, and I found  the connection not well explained. From my understanding, $b_t$ is a vector that represents the sufficient statistics if learning works. The probability interpretation is thus stretched.\n- The architecture description (starting from the second paragraph on page 4) feels cluttered. It was clearly written as a caption to Figure 1 and hence should be placed as such. Still, stand alone texts are important and in my humble opinion should be augmented with equations instead of drawings. While the latter can help understanding, it lacks precision and makes reproduction hard.\n- The MLP to predict the ground truth is not sufficiently described in the main text. I think it needs to go there, as it is quite central to the evaluation.\n\nSince the manuscript is half a page under the limit, such improvements would have been feasible.\n\nApart from the quality of the manuscipt, I like the fact that a disective study was done in such a way. \n\nHowever, I would have liked to see more comparisons, e.g. in $(x, y, \\theta)$\u00a0environments it is also possible to obtain quite good approximations of the true posterior via particle filtering. Also, other more straightforward approaches such as MDN-RNNs can represent multiple maxima in the probability landscape; this would have enabled to examine the benefit of conditioning on actions in a different context.\n\nRight now, it is unclear what the paper is about. On the one hand, it does a focused disective study with well controlled experiments, which would be a good fit if many different models were considered. On the other hand, it advertsises CPC|Action; but then it falls short in evaluating the method in more challenging environments.\n\nTo sum it up, I feel that the paper needs to be clearer in writing and in experimental structure. The currently tested hypothesis, \"does CPC|Action perform better than CPC and FP in a set of well controlled toy environments\" is, imho, not of broad enough interest.", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}