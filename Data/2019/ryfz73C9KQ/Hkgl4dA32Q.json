{"title": "Good paper, some details missing or unclear", "review": "** Summary **\nThe authors evaluate three different representation learning algorithms for partially observable environments. In particular, they investigate how well the learned representation encodes the true belief distribution, including its uncertainty. \nThey propose an extension to a previous algorithm and evaluate all three algorithms on a range of tasks.\n\n** Clarity **\nThe paper is well written and overall easy to follow.\n\n** Quality **\nThe paper evaluates the described algorithms on a sufficiently large set of tasks. There is no theoretical analysis.\n\n** Originality & Significance **\nWhile the authors propose a novel extension to an existing algorithm, I believe the value of this work lies in the detailed empirical analysis.\n\n** Missing Citations **\n\nI believe two recent papers (this year's ICML) should be mentioned in the related work section as they propose two representation learning algorithms for POMDPs that, as far as I can tell, are not yet mentioned in the paper but quite relevant to the discussed topic. [1] Because it also uses PSRs and [2] because it explicitly learns a belief state. It would be interesting to see how [2] compares in terms of performance to FP and CPC(|Action).\n\n[1] Hefny, A., Marinho, Z., Sun, W., Srinivasa, S. & Gordon, G.. (2018). Recurrent Predictive State Policy Networks. Proceedings of the 35th International Conference on Machine Learning, in PMLR 80:1949-1958\n\n[2] Igl, M., Zintgraf, L., Le, T.A., Wood, F. & Whiteson, S.. (2018). Deep Variational Reinforcement Learning for POMDPs. Proceedings of the 35th International Conference on Machine Learning, in PMLR 80:2117-2126\n\n** Question **\n\nI have several questions where I'm not sure I understand the paper correctly:\n\n1.) Why can FP only predict the mean? For example, one could use a PixelCNN as decoder, which would allow to learn an entire distribution, not just the mean over images.\n2.) The problem that CPC and CPC|Action is unable to predict objects if they don't influence the future trajectory doesn't seem surprising to me because whether an image is a positive or negative example can usually be determined by the background, the object is not necessary to do so. In other words, this is a problem of how the negative samples are chosen: If they were constructed using a simulator that shows the same background but without the objects, the belief would need to start encoding the presence of objects. Is this correct or am I missing something?\n3.) Am I correct in thinking that CPC(|Action) would not be applicable to properly estimate the belief distribution in the presence of noise, i.e. for example when estimation the exact location based on sensors with Gaussian noise?\n\n** Overall **\n\n* Pros:\n- Extensive, interesting evaluation\n- Novel CPC|Action algorithm\n\n* Cons:\n- No theoretical analysis/justification for claims\n- There are several subtleties that I am not sure are sufficiently discussed in the paper (see my questions above)", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}