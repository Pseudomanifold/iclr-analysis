{"title": "New approach to quantizing activations, SotA/competitive on several real image problems", "review": "Quality:\nThe work is well done. Experiments cover a range of problems and a range of quantization resolutions. Related work section in, particular, I thought was very nicely done. Empirical results are strong. \n\nIn section 2.2, it bothers me that the amount of bias introduced by using the local grid approximation is never really assessed. How much probability mass is left out by truncating the Gumbel-softmax, in practice?\n\nClarity:\nWell presented. I believe I'd be able to implement this, as a practitioner. \n\nOriginality:\nNice to see the concrete approximation having an impact in the quantization space. \n\nSignificance:\nQuantization has obvious practical interest. The regularization aspect is striking (quantization yielded slightly improved test error on CIFAR-10; is that w/in the error bars?). A recent work [https://arxiv.org/abs/1804.05862] links model compressibility to generalization; while this work is more focused on activations, there is no reason that it couldn't be used for weights as well.\n\nNits:\ntop of pg 6 'reduced execution speeds' -> times, or increased exec speeds\n'sparcity' misspelled", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}