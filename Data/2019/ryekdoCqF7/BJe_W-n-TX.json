{"title": "A sequential training of GANs and some theory associated with it", "review": "This paper proposes a method for ensembling GAN\u2019s for capturing diversity in the target space. This done by a convex combination of GAN\u2019s that are sequentially trained by trying to approximate the real distribution by fixing the previous generators. The paper theoretically shows that this approach converges to the optimal theoretical distribution.\n\nComments \n\n1)  What will be the performance of Original GAN and Incremental GAN by finding optimal weighting ($w_i$) parameters for each of them?\n2)  Can you increase the number of parameters of the generator by no of generators used in the incremental GAN\u2019s and compare the performance?\n3) The abstract first line you have written \u2018possibly distribution\u2019 instead of \u2018probability distribution\u2019\n4) Table 1 \u2018Incremental GAN\u2019 doesn\u2019t show consistently improved performance in comparison \u2018Original GAN\u2019. Can you train a few more generators and verify it?", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}