{"title": "Nice paper with exhaustive experiments", "review": "The paper is very well-written and is a nice read. \n\nThe paper presents 1) a new approach of one-shot learning by training meta learning based deformation networks, 2) end-to-end meta learning framework and 3) a new way to synthesize images which boosts the performance a lot. It's a very well written paper with a exhaustive experimentation on various axis: data augmentation strategies (gaussian noise, flipping), comparison with competitive baselines in one-shot learning literature like matching network (Vinyals et al. 2016), ablations on the design of deformation network showcasing what makes this network work well. The ablations offer explanation behind the design choices. The papers also explains the network design and their approach very succinctly.\n\nThe experimentation section is very well done and high-quality. I also appreciated that the experiment setup used in the paper is the standard setup that other SOTA baselines have used which makes it easy to compare the results and contributions of this paper and also keeps the evaluation strategy consistent in literature. Overall the approach demonstrates great results on 5-shot classification learning over previous approaches.\n\nI have following questions to the authors:\n1. what is the training time for end-to-end model compared to previous SOTA baselines?\n2. Can authors link to the design of ResNet-10 model for the sake of clarity even though it might feel obvious?\n3. in Section 6.1 Setup section, authors set epsilon value to 2 for selecting gallery images. Can authors show ablation on epsilon values and why 2 works the best?\n4. Can authors provide intuition into why the strategy proposed doesn't work as well on 1-shot classification? \n\n", "rating": "7: Good paper, accept", "confidence": "1: The reviewer's evaluation is an educated guess"}