{"title": "Clarity and quantification need improvement", "review": "This paper proposes a network architecture inspired by the primate visual cortex. The architecture includes feedforward, feedback, and local recurrent connections, which together implement a predictive coding scheme. Some versions of the network are shown to outperform the similar PredNet and PredRNN architectures on two video prediction tasks: moving MNIST and KTH human actions. Finally, the authors provide neural data from monkeys and argue that their network shows similarities to the biological data.\n\nThe paper contains intriguing ideas about the benefits of sparse and predictive coding, and the direct comparison to biological data potentially broadens the impact of the work. However, major claims are unsubstantiated, and accuracy and clarity need to be improved to make the manuscript acceptable.\n\nMajor concerns:\n1. The authors claim that their architecture is more efficient because it uses sparse coding of residuals. Implementation details and some quantitative arguments, ideally benchmarks, need to be provided to show that their architecture is actually more efficient than PredRNN++ and PredNet.\n\n2. It is unclear whether the PredRNN++ should be compared to the C-C or C-F version of the network. Does the PredRNN++ have access to as many current and future frames as the C-C net? Is this a fair comparison? Please provide a clearer description of the different versions of your network and how they relate to the baseline models. That section in particular has many confusing typos (frame-by-chunk, chunk-by-frame abbreviations mixed up).\n\n3. In Figure 6, the authors claim that more layers lead to \u201cbetter\u201d representations. What does \u201cbetter\u201d mean? It is implied that the networks with more layers actually make the different motions more discriminable. Please quantify this. For example, a linear classifier could be trained on the neural activations. Also, how is this related to the rest of the paper? Do the authors claim that this result is unique to the proposed architecture? In that case, please provide a quantitative comparison to the PredNet or PredRNN++.\n\n4. In Figure 9, the presentation is highly confusing. Plots (c) to (h) are clearly made to look like the monkey data in (b) (nonlinear x-axes?), but show totally different timescales (training epochs vs. milliseconds). Please explain why it makes sense to compare these timescales. Also, what does it mean for a training epoch to have a negative value? \n\nMinor comments:\n1. I don\u2019t understand the \u201ctension\u201d between hierarchical feature representations and residual representations brought up in Section 2. Do the PredNet and PredRNN++ not contain a hierarchy of representations?\n\n2. Figure 1 is not fully annotated and could be clearer. What does the asterisk mean? Why are there multiple arrows between the P\u2019s? What do the small arrows next to the big arrows mean? Please expand the legend. Consider using colors to differentiate between components.\n\n3. I don\u2019t understand Figure 4c. According to the text, this plot shows \u201ceffectiveness as a function of time\u201d, but the x-axis is labeled \u201cLayer Number\u201d. What does \u201ceffectiveness over time\u201d mean? What does the y-label mean (SSIM per day?)? What is \u201ctrunk prediction\u201d (not mentioned anywhere in the text)?\n\n4. For Figure 9, it is pointed out that activity is expected to be lower for E neurons, but is also lower for R and P. This is interesting and also applies to Figure 8, so it would be good to see Figure 8 split up by E/R/P, too. \n\n5. The word \u201cFigure\u201d is missing before figure references.\n\n6. Please proof-read for typography, punctuation and grammar.", "rating": "3: Clear rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}