{"title": "Very interesting approach, but underwhelming results (despite the complexity)", "review": "In this paper, authors focus on the problem of efficiently embedding Knowledge Graphs in low-dimensional embedding spaces, a task where models are commonly evaluated via downstream link prediction and triple classification tasks. The proposed model - Riemannian TransE, based on TransE [Bordes et al. 2013] - maps entities to points in a non-Euclidean space, by minimising a loss based on the geodesic distance in such space. This paper is especially interesting, since extends previous approaches - such as Poincare embeddings - to the multi-relational setting. Results look promising on WN11 and FB13, but authors mention results on the more commonly used WN18 and FB15k are less accurate than those obtained by the baselines (without reporting them). It is worth mentioning that WN18 and FB15k were found to be solvable by very simple baselines (e.g. see [1]). Furthermore, authors do not report any finding on the geometry of the learned spaces.\n\nIntroduction - Wording is a bit weird sometimes, e.g. what does \"evaluating dense matrices or tensors\" mean?\nRelated Work - Likewise, this section was a bit hard to follow. I do not fully get why authors had to use terms like \"planet\", \"launcher\", \"satellite\" etc. for describing mappings between entities and points in a manifold, relations and points in another manifold, and the manifold where the geodesic distances between representations are calculated.\nWhat is the intuition behind this?\nTab. 1 does a great job at summarising existing scoring functions and their space complexity. However, it may be worth noticing that e.g. the inner product used by DistMult is not really a \"dissimilarity\" between two representations (but rather the opposite). Is the number of parameters the same for Riemannian TransE as for the other methods (including the extra \"l\" parameters)? If it isn't the comparison may be slightly unfair.\n\n[1] https://arxiv.org/abs/1707.01476", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}