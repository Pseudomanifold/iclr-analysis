{"title": "Experiments are not convincing", "review": "[Summary]\nPaper \u201cAREA ATTENTION\u201d extends the current attention models from word level to \u201carea level\u201d, i.e., the combination of adjacent words. Specifically, every $r_i$ adjacent words are first merged into a new item; next a key and the value for this item is calculated based on Eqn.(3 or 7) and Eqn. (4), and then the conventional attention models are applied to these new items. The authors work on (char level) NMT and image captioning to verify the algorithm. \n\n[Details]\n1.\tIn the abstract, \u201c\u2026 Using an area of items, instead of a single, we hope attention mechanisms can better capture the nature of the task \u2026\u201d, can you provide an example to show why \u201can area of items\u201d can \u201cbetter capture the nature of the task\u201d? In particular, you need to show why the conventional attention mechanism fails.\n2.\tIn this new proposed framework, how should we define the query for each area including multiple items like words? For example, in Figure 1, what is the query for $n$-item areas where $n=1,2,3$.\n3.\tTwo different kinds of keys are proposed in Eqn. (3) and Eqn. (7). Any comparison between them?\n4.\tI am not convinced by the experimental results.\n(4a) On WMT\u201914 En-to-Fr and En-to-De, we know that \u201ctransformer_big\u201d can achieve better results than the three settings shown in Table 1 & 2. The results of using transformer_big are not reported. Besides, it is not necessary to use the \u201ctiny\u201d setting for En-to-{De, Fr} translation considering the data size.\n(4b) It is widely adopted to use token-level neural machine translation. It is not convincing to work on char-level NMT only. Also, please provide the results using transformer_big setting.\n(4c) There are no BLEU scores for the LSTM setting. Note that comment (4b) and (4c) are also pointed by anonymous readers.\n(4d) It is really strange for me to \u201ctrained on COCO and tested on Flickr\u201d (See the title of Table 4). It is not a common practice in image captioning literature. Even if in (Soricut et al., 2018), the authors report the results of training of COCO and test on COCO (the Table 5). Therefore, the results are not convincing. You should train on COCO and test on COCO too.\ne.\tWhat if we use different area size? I do not find the study in this paper.\n\n[Pros & Cons]\n(+) A new attempt of the attention model that tries to build the attention beyond unigrams.\n(-) Experiments are not convincing.\n(-) The motivation is not strong.\n", "rating": "5: Marginally below acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}