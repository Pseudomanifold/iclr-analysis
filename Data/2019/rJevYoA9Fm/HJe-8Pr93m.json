{"title": "This is an interesting work with huge potential.", "review": "The paper is dedicated to computation of singular values of convolutional layers. While singular values of convolutional layers represent sufficient interest for researchers, huge computational complexity made it difficult to investigate their properties in the case of layers of deep neural networks. Using the fact that operator matrix of the convolutional layer has a special form (i.e. can be represented as block-matrix, which blocks are doubly block circulant matrices) the authors proposed a more efficient method of computation of singular values. I really enjoyed reading this paper and I think that it opens a lot of interesting applications. As one of the possible applications the authors proposed a regularization method based on bounding of singular values.\n\nThe paper from my point of view has two main drawbacks:\n\n1.  Diversity of experiments. While the paper has strong theoretical component, the part dedicated to experiments is not broad enough. It would be interesting to see regularization on other architectures and other datasets.\n\n2.The system of references. I would recommend to add not only references to the sources, but also to the theorem numbers or the chapters. For example, I would recommend to replace \u2018Poposition 9 ((Lefkimmiatis et al., 2013))\u2019 with \u2018Poposition 9 ((Lefkimmiatis et al., 2013, Proposition 1))\u2019. In pure math papers, it is a standard rule to add such additional information since many papers contain a lot of theorems and it significantly simplifies reading and understanding the paper.\n\nDespite these disadvantages this is a great work with huge potential.\n", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}