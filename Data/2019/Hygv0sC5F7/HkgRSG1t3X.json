{"title": "Importance of ReLU networks and max-margin used in this paper are unclear.", "review": "Recently, the implicit bias where gradient descent converges the max-margin classifier was shown for linear models without an explicit regularization.\nThis paper tries to extend this result to ReLU network, which is more challenging because of the non-convexity.\nMoreover, a similar property of stochastic gradient descent is also discussed.\n\nThe implicit bias is a key property to ensure the superior performance of over-parameterized models, hence this line of research is also important.\nHowever, I think there are several concerns as summarized below.\n\n1. I'm not sure about the significance of the ReLU model (P) considered in the paper.\nIndeed, the problem (P) is challenging, but an obtained model is linear defined by $w$.\nTherefore, an advantage of this model over linear models is unclear.\n\nMoreover, since the max-margin in this paper is defined by using part of dataset and it is different from the conventional max-margin, the generalization guarantees are not ensured by the margin theory.\nTherefore, I cannot figure out the importance of an implicit bias in this setting (, which ensures the convergence to this modified max-margin solution).\nIn addition, the definition of the max-margin seems to be incorrect: argmin max -> argmax min.\n\n2. Proposition 1 (variance bound) gives a bound on the sum of norms of stochastic gradients.\nHowever, I think this bound is obvious because stochastic gradients of the ReLU model (P) are uniformly bounded by the ReLU activation.\nCombining this boundedness and decreasing learning rates, the bound in Proposition 1 can be obtained immediately.\nMoreover, the validity of an assumption on $w_t$ made in the proposition should be discussed.\n\n3. Lemma F.2 is key to show the main theorem, but I wonder whether this lemma is correct.\nI think the third equation in the proof seems to be incorrect.\n", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}