{"title": "Hard to understand and weak methodological contribution", "review": "General comment\n==============\nThe authors describe an attention mechanism for training with images of different sizes. The paper is hard to understand due to major grammatical errors and unclear descriptions. Methods for training with images of different sizes have been proposed before, e.g. spatial pyramid networks. I also have concerns about their evaluation. Overall, I believe that the paper is not ready to be submitted to a conference or journal.\n\nMajor comments\n=============\n1. Methods for training with images already exists, e.g. spatial pyramid pooling (http://arxiv.org/abs/1406.4729) or fully-convolutional networks (https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf). These are not cited in the paper and not included as baselines in their evaluation.\n\n2. The attention mechanisms looks similar to classificat soft-attention (https://arxiv.org/abs/1502.), which is not cited in the paper.\n\n3. The paper contains major spelling and grammatical errors, making it hard to understand important aspects.\n\n4. I can not see a clear improvement of their method over ResNet and DenseNet when the same number of model parameters is about the same. Without making sure that the number of model parameters is about the same, it is unclear if the performance gain is due the increased number of model parameters or the methodology.", "rating": "2: Strong rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}