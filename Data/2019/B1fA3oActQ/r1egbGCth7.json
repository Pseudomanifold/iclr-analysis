{"title": "Review of \"GraphSeq2Seq: Graph-Sequence-to-Sequence for Neural Machine Translation\"", "review": "This paper proposes a method for combining the Graph2Seq and Seq2Seq models into a unified model that captures the benefits of both.  The paper thoroughly describes in series of experiments that demonstrate that the authors' proposed method outperforms several of the other NMT methods on a few translation tasks.\n\nI like the synthesis of methods that the authors' present.  It is a logical and practical implementation that seems to provide solid benefits over the existing state of the art.  I think that many NMT researchers will find this work interesting.\n\nTable 4 begs the question, \"How does one choose the number of highway layers?\"  I presume that the results in that table are from the test data set.  Using the hold out data set, which number gives the best value?\n\nThe paper's readability suffers from poor grammar in some places.  This fact may discourage some readers.\n\nThe authors should fix the missing parentheses in Eqns. (6)-(9).", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}