{"title": "The paper introduces methods for reducing the computational cost of CNN implementations by exploiting analogies between ResNets and differential equations. The form and organization should be revised? The technical content is not developed enough.", "review": "The paper introduces methods for reducing the computational cost of CNN implementations. These new parameterizations of CNN like architectures limit the coupling between the parameters in order to achieve this reduction. The inspiration for these new parametrization comes from analogies between the functional form of ResNet modules and numerical schemes for solving reaction diffusion PDEs.  Experiments are performed on image classification benchmarks (CIFAR, STL).\n\nBoth the organization and the technical writing of the paper are poor.  Notations are often confusing, the technical part is not detailed nor motivated enough. There is almost nothing on the related  work.\n\nConcerning the content, the paper builds on the PDE inspired NNs topic, focusing on CNNs and on a specific form of PDE, reaction-diffusion equations.  This is an interesting topic with recent publications. \nBefore developing the PDE aspect, the authors present a first method decoupling the classical convolution into a series of two operations. This decomposition is used later, but is not directly related to the main topic of the paper. This is very close to ref (Howard 2017) and the difference with their method should be highlighted.\n\nThe main equation providing the link with reaction diffusion equation is eq. (8).  The interpretation provided here is not satisfactory and this should be motivated and formulated in more details. From what I understand, the analogy with reaction simply comes because the second term in eq. (8) is a function of all the input variables and the one with diffusion comes from the fact that convolutions perform a local linear spatial operation so that a convolution could probably be interpreted as a differential operator. Is there an analogy with the Laplacian used in R&D equations? Even if one could interpret a convolution as a differential operator, there should be terms of different orders there. Said otherwise, this expression may have the potential to represent a reaction-diffusion equation, but also other functional components and there is no reason why it should be a reaction-diffusion form.\nConsidering the stability argument in eq. (11), a part of the Jacobian is missing, the one relative to the second term, could you explain?\nThe circulant method has already been used in CNNs by some authors together with a FFT implementation, what is new here? (see some ref. below).\nThen the performance of the proposed methods are close to the MobileNet reference baseline , but the best two methods seem to be this baseline and the closely related method denoted LinearMix in the table. The PDE inspired algorithms are usually below these two methods. Could you comment on that? \nIn fig. 1, you did not compare neither with mobileNet nor with a FFT implementation of a ResNet. Why?\nFinally, one of the arguments advocated in the paper is the importance of classical stability results for PDEs, but this not developed.\n\nPro : the topic is timely and some of the arguments might lead to  interesting developments.\nCons : both the form and the technical content need to be revised. The technical part is not developed enough.\n\nAdditional references\nYu Cheng, Felix X. Yu, Rog\u00e9rio Schmidt  Feris, Sanjiv Kumar, Alok N. Choudhary,Shih-Fu Chang, Exploration of Parameter Redundancy in Deep Networks with Circulant Projections2015 IEEE International Conference On Computer Vision (ICCV)2015\nCaiwen Ding, , Siyu Liao, , Yanzhi Wang , Zhe Li , Ning Liu , Youwei Zhuo , Chao Wang , Xuehai Qian , Yu Bai , Geng Yuan , Xiaolong Ma , Yipeng Zhang , Jian Tang , Qinru Qiu , Xue Lin , Bo Yuan, CirCNN: Accelerating and Compressing Deep Neural Networks Using Block-Circulant Weight Matrices \n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}