{"title": "This paper proposes an approach that uses GAN framework to generate audio.", "review": "This paper proposes an approach that uses GAN framework to generate audio through modeling log magnitudes and instantaneous frequencies with sufficient frequency resolution in the spectral domain. Experiments on NSynth dataset show that it gives better results then WaveNet. The most successful deep generative models are WaveNET,  Parallel WaveNet and Tacotran that are applied to speech synthesis, the method should be tested for speech synthesis and compared with WaveNet, Parallel WaveNet as well as Tacotran.\n\nFor WaveNet, the inputs are text features, but for Tacotran, the inputs are mel-spectrogram. Here the inputs are log magnitudes and instantaneous frequencies. So the idea is not that much new.\n\nGAN has been used in speech synthesis, see \nStatistical Parametric Speech Synthesis Incorporating Generative Adversarial Networks\nIEEE/ACM Transactions on Audio, Speech, and Language Processing ( Volume: 26 , Issue: 1 , Jan. 2018 )\n\nSo for this work, GAN's application to sound generation is not new.", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}