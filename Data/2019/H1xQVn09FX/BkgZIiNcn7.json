{"title": "Exciting work", "review": "This is an exciting paper with a simple idea for better representing audio data so that convolutional models such as generative adversarial networks can be applied. The authors demonstrate the reliability of their method on a large dataset of acoustic instruments and report human evaluation metrics. I expect their proposed method of preprocessing audio to become standard practice.\n\nWhy didn't you train a WaveNet on the high-resolution instantaneous frequency representations? In addition to conditioning on the notes, this seems like it would be the right fair comparison. \n\nI'm still not clear on unrolled phase which is central to this work. If you can, spend more time explaining this in detail, maybe with examples / diagrams? In figure 1,  in unrolled phase, why is time in reverse?\n\nSmall comments:\n\n- Figure 1 & 2: label the x-axis as time. Makes it a lot easier to understand.\n\n- I appreciate the plethora of metrics. The inception score you propose is interesting. Very cool that number of statistically-different bins tracks human eval!\n\n- sentence before sec 2.2, and other small grammatical mistakes. Reread every sentence carefully for grammar. \n\n- Figure 5 is low-res. Please fix. All the other figures are beautiful - nice work!", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}