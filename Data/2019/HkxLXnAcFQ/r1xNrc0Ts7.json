{"title": "thought-provoking observations and nice comparative experiments", "review": "There are a few things I like about the paper. \n\nFirstly, it makes interesting observations about the evaluation of the few-shot learning approaches, e.g. the underestimated baselines, and compares multiple methods in the same conditions. In fact, one of the reasons for accepting this paper would be to get a unified and, hopefully, well-written implementation of those methods. \n\nSecondly, I like the domain shift experiments, but I have the following question. The description of the CUB  says that there is an overlap between CUB and ImageNet.  Is there an overlap between CUB and mini-ImageNet? If so, then domain shift experiments might be too optimistic or even then it is not a big deal?\n\nOne thing I don\u2019t like is that, in my opinion,  the paper includes much redundant information which could go to the appendix in order to not weary the reader. For instance, everything related to Table 1. There is also some overlap between Section 2 and 3.3, while MAML, for instance, is still not well explained. Also, tables with too many numbers are difficult to read, e.g. Table 4.  \n\n---- Other notes -----\n\nMany of the few-shot learning papers use Omniglot, so I think it would be a valuable addition to the appendix. Moreover, there exists a cross-domain scenario with Omniglot-> MNIST which I would also like to see in the appendix.    \n\nIn the Matching Nets paper, there is a good baseline classifier based on k-NNs. Do you know how does that one compares to Baseline and Baseline++ models if used with the same architecture for the feature extractor?\n\nThe conclusion from the network depth experiments is that \u201cgaps among different methods diminish as the backbone gets deeper\u201d. However, in a 5-shot mini-ImageNet case, this is not what the plot shows. Quite the opposite: the gap increased. Did I misunderstand something? Could you please comment on that?\n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}