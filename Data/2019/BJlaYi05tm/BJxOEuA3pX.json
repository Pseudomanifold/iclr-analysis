{"title": "interesting idea but result is not significant", "review": "This paper considers the problem of computing preimages of convolutional network outputs. The main technology is a change of basis: expressing an arrangement of d generic hyperplanes in \\R^d in the basis givens by their rays (section 3). The paper focuses on arrangements coming from circulant matrices (section 4), and found that the expression of such arrangements in this basis is regular, and for a particular example in \\R^3, showed that they could completely understand the ReLu map (section 5). \n\nThe problem is definitely interesting, and very difficult. However, the contribution is minimal. Firstly, the reduction to circulant matrices is a huge step and needs serious justification. The paper justified its restriction to circulant network via this claim: (Section 4):\n\\begin{quote}\nWe will exploit the fact that convolutional\nmatrices are in most respects asymptotically equivalent to those of circulant matrices where each new row is a one element cyclic shift of the previous.\n\\end{quote}\nThis needs to be made precise to be useful. In what respect? What does asymptotically equivalent mean? Without a serious justification here, analyzing circulant matrix is too narrow a scope. \n\nNest codes: the punchline seems to be that the network contracts data, which is not new. The results are from the analysis of a *single* example in 3 variables - how far does this extend? \n\nIn short, this paper has very little concrete mathematical or computational contribution. \n\n", "rating": "2: Strong rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}