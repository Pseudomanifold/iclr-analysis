{"title": "A well-written paper with limited implication.", "review": "The paper focuses on the stability prediction task on the ShapeStacks dataset. Specifically, the paper creates a new extension to the dataset, and it proposes the use of \"Neural Stethoscopes\" framework to analyze deep neural nets' physical reasoning of local stability v.s. global stability. It is shown in the paper neural nets tend to be misled by local stability when the task is to predict global stability. Then the paper utilizes the proposed framework to de-bias the misleading correlation to achieve a state-of-the-art on the dataset.\n\nThe paper is very well-written and easy to follow. The main idea is simple and the experiments are detailed. Specifically on the task of stability prediction, it is quite interesting to know that neural nets can be misled by visual cues (local stability).\n\nHowever, my concern is that the paper focuses only on a very specific application domain,  and an improvement over the niche dataset with much more supervision (from the extension) is not surprising at all. In the mean time, the notion of \"Neural Stethoscopes\" could be much more  generally applied. Without applications in other domains, it is not immediately clear what the paper's implication is.", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}