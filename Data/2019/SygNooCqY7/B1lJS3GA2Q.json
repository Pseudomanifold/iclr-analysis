{"title": "Fundamental questions regarding the premises of this paper seem to be unanswered.", "review": "In this work, a new method for (adaptively) choosing the noise distribution in a noise-tempered generative adversarial network is proposed. Noise tempering in training GANs has been around for a while. The main argument in those existing work (and also in this paper) is that GAN training gets stuck when gradient vanishes due to non-intersecting support of the real and generated distributions. Hypothetically, if such phenomenon is happening, then adding noise to the samples ensures that the support overlap and hence gradient vanishing is expected to be prevented. Typical scenarios of adding noise has been studied, for example adding a noise with variance vanishing with training iterations. This ensures that later in the training, if the generator is close to the real data, the error from having noisy samples do not propagate to the generator training. \n\nThis paper starts off from this assumption, asking the question of why we need to reduce the noise. This suggests training with non-vanishing noise. Two heuristic reasonings in support of such approach are (i) in existing approach of vanishing noise, it is not clear how to schedule the reduction of noise variance, leading to inefficiency or non-convergence, and (ii) minimizing noisy divergence can also achieve convergence to the true distribution, as long as the noise is not degenerate. In the latter the non-degeneracy can be achieved by using multiple noise distributions. \n\nThe main contribution of this paper is that a neural network based adaptive noise generator is proposed. During the training, the noise (from a family of noise distributions) that makes the real and generated distributions as similar as possible is chosen, while constrained to having a bounded variance. The only evidence that this improves the training is via numerical experiments run by the authors (with no (anonymized) reproducible implementation references, e.g.~github). The FID and IS scores on several datasets are presented, which suggest that NTGAN achieves better scores. \n\nIn table 3, specific architectural and hyper-parameter choices have been made for competing baselines. For example, for SNGAN, the authors of SNGAN report IS score of 8.22 on CIFAR-10 with ResNET and 7.58 with standard CNN. If the settings are fair, then these improves upon the reported IS of NTGAN. Given that no code is available, how does one interpret the resulting table of scores? How do you ensure fairness in different choices made for different architectures?\n\nThe proposed approach of minimizing the loss over the noise with regularizer for the variance is surprising, as the theory in Lemma 1 seems to suggest an alternative (but more natural) approach. That is maximize the loss over the noise with perhaps regularizer that restricts the choice of no-noise or small variance. Can the authors elaborate on that choice?  \n\nThe metric of IS and FID score is too coarse to measure the subtle improvements that are made by the proposed approach. Given that the paper is motivated by the paths the gradients are taking during the training, it seems that analysis of the gradients (with and without the noise) is in order. Such thorough analyses will settle several myths regarding gradient vanishing, such as does gradient vanishing happen in the training of typical GANs, and does noise adding mitigate it. This is particularly interesting, as if WGAN is used with Wasserstein distance, there should be no gradient vanishing due to non-overlapping support. Checking these conjectures numerically is an important task, and is particularly critical for this paper. \n", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}