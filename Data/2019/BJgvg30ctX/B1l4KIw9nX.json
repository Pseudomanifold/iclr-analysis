{"title": "Theoretically grounded regularizer that penalizes confident predictions, experimental section needs to be improved", "review": "\nThe authors propose a regularizer placed on the final linear layer of invertible networks that penalizes confident predictions, leading to better generalization. The algorithm is theoretically grounded and even though SOTA networks do not meet some theoretical requirements in practice, it seems to be effective.\n\nThe ideas presented are interesting, but the paper is confusing at times and some motivations seem hand-wavy (see below).\n\nEven though penalizing overly confident predictions is an important topic, it has been attacked by various approaches in the past. It is not clear how the proposed method empirically compares to other approaches from the literature. On the theoretical side, proposition 2.1 and its proof are the main contribution. This very interesting observation could potentially be very useful in many tasks and shows once again why invertible neural networks are an important class of deep networks.\n\nMain concerns:\n\nThe authors do not compare their method to other approaches from the literature with similar goals, such as [1]. Therefore, it is hard to judge the performance of the proposed regularizer.\n\nThe authors claim that their InvNet is approximately invertible but there is no guarantee for this, making empirical conclusions unclear. The experiments would be more conclusive if a network that is fully invertible by construction is used. Such networks exist and perform on par with ResNets [2], so there is no reason not to use them. This would remove the need for analysis or discussion of this matter, as this issue clutters the main contribution and makes the claims rather fuzzy right now.\n\nMinor\n\n- Why are citations displayed in blue? This does not seem to be ICLR formatting standard.\n\n[1] Pereyra et al., \"Regularizing neural networks by penalizing confident output distributions.\"\n[2] Jacobsen et al., \"i-RevNet: Deep Invertible Networks\"", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}