{"title": "The comparison study needs some more detail, the RtF part is not significant enough.", "review": "This paper points out a important issue in current continual learning literature: Due to the different settings and different evaluation protocols of each method, comparison between methods are usually not fair, and lead to distinct conclusions.\nThe paper is in general easy to understand except a few drawbacks listed in the cons.\n\nPros:\n1. This paper investigates an important problem, aka, how does the methods compare to each other with the same evaluation protocol.\n2. Experiments are performed on the previous methods, which could be used as a baseline for future works in this field.\n3. Proposes to combine discriminative model with generative model to save computation when using generative model to store rehearsal examples.\n\nCons:\n1. Details of each experiments are missing. \nDifferent methods are evaluated under the \"incremental task learning\", \"incremental domain learning\",  \"incremental class learning\" settings. However, to my knowledge, some of the methods will not work under all of the three settings, as the author also suggest that XdG only works with task id. However, I think there are a few more. For example, the LwF methods has multiple sets of output neurons, which implicitly assumes the task id is known. It is not described in the paper how to evaluate it under \"incremental domain learning\", aka, how to decide which set of output to use if task id is not available during testing. Another example, the results in table 3 and 4 indicates that EWC with task id is better than without. However, original EWC does not take task id during testing, it is not described how to introduce dependency on the task id for EWC.\n2. Using the term feedback connection is misleading to the reader since the described method is just using an encoder/decoder structure. In my opinion this is different from feedback connection in which higher layer is an input for lower layers. Autoencoder or encoder/decoder structure is more appropriate.\n3. There is some contribution in the RtF part, namely the saved computation compared to DGR. However, subjectively, I think this contribution is not very significant. The same thing can be achieved with DGR by sharing the network between the discriminative model and the discriminator in GAN. In my opinion this is more a design bonus in using generative replay than a major methodology innovation.\n\nConclusion:\nThe first part that compares different methods is worth publishing given more details are provided. I'm more than happy to give a higher score if the authors are able to provide more details and the details are reasonable.", "rating": "6: Marginally above acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}