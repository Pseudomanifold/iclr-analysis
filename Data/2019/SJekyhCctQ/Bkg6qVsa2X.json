{"title": "Innovative perturbation-based learning strategy leads to very impressive performance in adversarial detection", "review": "This paper proposes a method for the detection of adversarial examples via what the authors term \"neural fingerprinting\" (NeuralFP). Essentially, a reference collection of perturbations are applied to the training data so as to learn the effects on the classification decision. The premise here is that on average, normal examples from a common class would have similar changes in the classification decision when reference perturbations are applied, whereas adversarial examples (particularly those off the local submanifold) may have a markedly different set of changes from what was expected for the targeted class. These reference perturbations as well as the anticipated output perturbations together form the \"fingerprints\".\n\nTo measure the difference between observed outputs and fingerprints, the average (squared?) Euclidean distance is used. Given a fixed set of input fingerprints (presumably chosen so as to provide coverage of the range of possible perturbation directions), the authors use the distance formula as a regression loss (\"fingerprint loss\") to train the choice of output fingerprints. Although the authors do not explicitly state it this way, this secondary training objective encourages a K-Means style clustering of output perturbations where the output fingerprints serve as cluster representatives. \n\nThis learning formulation is to my mind is both very innovative and extremely effective, as demonstrated by the authors' experimental results. Their experiments show superlative performance (near perfect detection!) against essentially the full range of state-of-the-art attacks. They give careful attention to the mode of attack, and show excellent performance even for adaptive white-box attacks, in which existing attack methods are given the opportunity to minimize the fingerprint loss.\n\nThe presentation of the paper is excellent - clear, well-motivated, and detailed, with careful attention given to experimental concerns such as the choice of perturbation directions (the recommendation is to choose them at random), and the number of fingerprints to pick.\n\nOverall, the reported results are so good, and the approach so convincing, that one wonders what the weaknesses of the approach might be (if any). Questions that do come to mind are:\n* Can an adversarial strategy can be developed that could execute a successful attack while minimizing the fingerprint loss. \n* Another issue is whether the NeuralFP would work on more challenging data sets where the classes are highly fragmented - at what rate would the benefits of NeuralFP fade as the classification performance degrades? \n* What happens to performance if the perturbation directions are chosen so as to better conform with the local sub-manifolds... would fewer perturbations be required? (It would seem that reducing the number of perturbations needed could have a significant effect on training time.)\n\nOverall, this is a very strong and important result, fully deserving of acceptance.\n\nP.S. Two sets of typos that need attention:\n* In Equation 3, the Euclidean norm is taken. In Equation 5, the squared Euclidean norm is taken. Presumably, one of these is a typo. Which?\n* In the definition of delta-min and delta-max in the first paragraph of Section 2.2, y-hat should be w-hat.\n\n", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}