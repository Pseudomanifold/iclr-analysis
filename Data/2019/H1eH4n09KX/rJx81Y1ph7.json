{"title": "Official review", "review": "\nThe paper presents a model to perform audio super resolution. The proposed model trains a neural network to produce a high-resolution audio sample given a low resolution input. It uses three losses: sample reconstructon, adversarialy loss and feature matching on a representation learned on an unsupervised way.\n\nFrom a technical perspective, I do not find the proposed approach very novel. It uses architectures following closely what has been done for Image supre-resolution. I am not aware of an effective use of GANs in the audio processing domain. This would be a good point for the paper. However, the evidence presented does not seem very convincing in my view. While this is an audio processing paper, it lacks domain insights (even the terminology feels borrowed from the image domain). Again, most of the modeling decisions seem to follow what has been done for images. The empirical results seem good, but the generated audio does not match the quality of the state-of-the-art.\n\nThe presentation of the paper is correct. It would be good to list or summarize the contributions of this work.\n\nRecent works have shown the amazing power of auto-regressive generative models (WaveNet)  in producing audio signals. This is, as far as I know, the state-of-the-art in audio generation. The authors should motivate why the proposed model is better or worth studying in light of those approaches. In particular, a recent work [A] has shown very high quality results in the problem of speech conversion (which seems harder than bandwidth extension). It would seem to me that applying such models to the bandwith extension task should also lead to very high quality results as well. What is the advantage of the proposed approach? Would a WaveNet decoder also be improved by including these auxiliary losses?\n\nWhile the audio samples seem to be good, they are also a bit noisy even compared with the baseline. This is not the case in the samples generated by [A] (which is of course a different problem). \n\nThe qualitative results are evaluated using PESQ. While this is a good proxy it is much better to perform blind tests with listeners. That would certainly improve the paper. \n\nFeature spaces are used in super resolution to provide a space in which the an L2 loss is perceptually more relevant. There are many such representations for audio signals. Specifically the magnitude of time-frequency representations (like spectrograms) or more sophisticated features such as scattering coefficients. In my view, the paper would be much stronger if these features would be evaluated as alternative to the features provided by the proposed autoencoder. \n\nOne of the motivations for defining the loss in the feature space is the lack (or difficulty to train) auxiliary classifiers on large amounts of data.  However, speech recognition models using neural networks are quite common. It would be good to also test features obtained from an off-the-shelf speech recognition system. How would this compare to the proposed model?\n\nThe L2 \"pixel\" loss seems a bit strange in my view. Particularly in audio processing, the recovered high frequency components can be synthesized with an arbitrary phase. This means that imposing an exact match seems like a constraint as the phase cannot be predicted from the low resolution signal (which is what a GAN loss could achieve). \n\nThe paper should present ablations on the use of the different losses. In particular, one of the main contributions is the inclusion of the loss measured in the learned feature space. The authors mention that not including it leads to audible artifacts. I think that more studies should be presented (including quantitative evaluations and audio samples).\n\nHow where the hyper parameters chosen? is there a lot of sensitivity to their values?\n\n\n[A] van den Oord, Aaron, and Oriol Vinyals. \"Neural discrete representation learning.\" Advances in Neural Information Processing Systems. 2017.\n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}