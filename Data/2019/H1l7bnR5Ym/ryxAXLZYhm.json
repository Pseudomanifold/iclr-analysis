{"title": "Stripping the priors from Bayesian GANs", "review": "Summary\n=========\nThe paper extends Bayesian GANs by altering the generator and discriminator parameter likelihood distributions and their respective priors. \nThe authors further propose an SGHMC algorithm to collect samples of the resulting posterior distributions on each parameter set and evaluate their approach on both a synthetic and the CIFAR-10 data set. \nThey claim superiority of their method, reporting a higher distance to mode centers of generated data points and better generator space coverage for the synthetic data set and better inception scores for the real world data for their method.\n\nReview\n=========\nAs an overall comment, I found the language poor, at times misleading.\nThe authors should have their manuscript proof-read for grammar and vocabulary.\nExamples: \n- amazing superiority (page 1, 3rd paragraph)\n- Accutally... (page 1, end of 3rd paragraph)\n- the total mixture of generated data distribution (page 3, mid of 3.1)\n- Similarity we define (page 3, end of 3.1)\n- etc.\nOver the whole manuscript, determiners are missing.\n\nThe authors start out with a general introduction to GANs and Bayesian GANs in particular, \narguing that it is an open research question whether the generator converges to the true data generating distribution in Bayesian GANs.\nI do not agree here. The Bayesian GAN defines a posterior distribution for the generator that\nis proportional to the likelihood that the discriminator assigns to generated samples.\nThe better the generator, the higher the likelihood that the discriminator assign to these samples.\nIn the case of a perfect generator, here the discriminator is equally unable to distinguish real and generated samples and consequently degenerates to a constant function.\nUsing the same symmetry argument as the authors, one can show that this is the case for Bayesian GANs.\n\nWhile defining the likelihood functions, the iterator variable t is used without introduction.\n\nFurther, I a confused by their argument of incompatibility.\nFirst, they derive a Gibbs style update scheme based on single samples for generator and discriminator parameters using\nposteriors in which the noise has been explicitly marginalized out by utilizing a Monte Carlo estimate.\nSecond, the used posteriors are conditional distributions with non-identical conditioning sets.\nI doubt that the argument still holds under this setting.\n\nWith respect to the remaining difference between the proposed approach and Bayesian GAN,\nI'd like the authors elaborate where exactly the difference between expectation of objective value\nand objective value of expectation is.\nSince the original GAN objectives used for crafting the likelihoods are deterministic functions,\nrandomness is introduced by the distributions over the generator and discriminator parameters.\nI would have guessed that expectations propagate into the objective functions.\n\nIt is, however, interesting to analyze the proposed inference algorithm, especially the introduced posterior distributions.\nFor the discriminator, this correspond simply to the likelihood function.\nFor the generator, the likelihood is combined with some prior for which no closed form solution exists.\nIn fact, this prior changes between iterations of the inference algorithm.\nThe resulting gradient of the posterior decomposes into the gradient of the current objective and the sum over all previous gradients.\nWhile this is not a prior in the Bayesian sense (i.e. in the sense of an actual prior belief), it would be interesting to have a closer look at the effect this has on the sampling method.\nMy educated guess is, that this conceptually adds up to the momentum term in SGHMC and thus slows down the exploration of the parameter space and results in better coverage.\n\nThe experiments are inspired by the ones done in the original Bayesian GAN publication.\nI liked the developed method to measure coverage of the generator space although I find the\nterm of hit error misleading.\nGiven that the probabilistic methods all achieve a hit rate of 1, a lower hit error actually points to worse coverage.\nI was surprised to see that hit error and coverage are only not consistently negatively correlated.\nAdding statistics over several runs of the models (e.g. 10) would strengthen the claim of superior performance.", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}