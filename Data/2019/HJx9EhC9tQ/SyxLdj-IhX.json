{"title": "Interesting paper; some assumptions should be stated more clearly", "review": "edit:  the authors nicely revised the submission, I think it is a very good paper. I increased my rating.\n\n-----\n\nThis paper presents a method that learns to reproduce 'block towers' from a given image. A perception model, a physics engine model, and a rendering engine are first trained together on pairs of images.\nThe perception model predicts a representation of the scene decomposed into objects;  the physics engine predicts the object representation of a scene from an initial object representation; the rendering engine predicts an image given an object representation.\n\nEach training pair of images is made of the first image of a sequence when introducing an object into a scene, and of the last image of the sequence, after simulating the object's motion with a physics engine. The 3 parts of the pipeline (perception, physics, rendering) are trained together on this data.\n\nTo validate the learned pipeline, it is used to recreate scenes from reference images, by trying to introduce objects in an empty scene until the given scene can be reproduced. It outperforms a related pipeline that lacks a scene representation based on objects.\n\nThis is a very interesting paper, with new ideas:\n- The object-based scene representation makes a lot of sense, compared to the abstract representation used in recent work. \n- The training procedure, based on observing the result of an action, is interesting as the examples are easy to collect (except for the fact that the ground truth segmentation of the images is used as input, see below).\n\nHowever, there are several things that are swept 'under the carpet' in my opinion, and this should be fixed if the paper is accepted.\n\n* the input images are given in the form of a set of images, one image corresponding to the object segmentation. This is mentioned only once (briefly) in the middle of the paragraph for Section 2.1, while this should be mentioned in the introduction, as this makes the perception part easier. There is actually a comment in the discussion section and the authors promised to clarify this aspect, which should indeed be more detailed. For example, do the segments correspond to the full objects, or only the visible parts?\n\n* The training procedure is explained only in Section 4.1. Before reaching this part, the method remained very mysterious to me. The text in Section 4.1 should be moved much earlier in the paper, probably between current sections 2.3 and 2.4, and briefly explained in the introduction as well.\nThis training procedure is in fact fully supervised - which is fine with me: Supervision makes learning 'safer'. What is nice here is that the training examples can be collected easily - even if the system was not running in a simulation.\n\n* if I understand correctly the planning procedure, it proceeds as follows:\n- sampling 'actions' that introduce 1 object at a time (?)\n- for each sampled action, predicting the scene representation after the action is performed, by simulating it with the learned pipeline, \n- keeping the action that generates a scene representation close to the scene representation computed for the goal image of the scene.\n- performing the selected action in a simulator, and iterate until the number of performed actions is the same as the number of objects (which is assumed to be known).\n\n-> how do you compare the scene representation of the goal image and the predicted one before the scene is complete? Don't you need some robust distance instead of the MSE?\n-> are the actions really sampled randomly?  How many actions do you need to sample for the examples given in the paper?\n\nI also have one question about the rendering engine:  Why using the weighted average of the object images? Why not using the intensity of the object with the smallest predicted depth?  It should generate sharper images. Does using the weighted average make the convergence easier?\n", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}