{"title": "This paper presents a meta algorithm to improve the robustness of learning methods under noisy labels.", "review": "This paper presents a meta algorithm to improve the robustness of learning methods under noisy labels. The idea is to squeeze out the negative effects of noisy labels actively. The paper trains deep neural networks by stochastic gradient descent on \u201cfitting\u201d labels; while trains deep neural networks by scaled stochastic gradient ascent on \u201cnot-fitting\u201d labels. Experimental results show the improvement on robustness. \n\nThe good things of the paper are clear. \n1.\tTechnical sound with reasonable idea\n2.\tProblem is well motivated\n3.\tPaper is general well written.\n\nSome comments\n1.\tThe idea using instance selection is not new. The novelty could be improved. If the paper could make more insight from either theoretical or application value, would be more interesting.\n2.\tExperiments are too standard. More divers and various data sets would be more convincing. \n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}