{"title": "Empirical Paper on Evaluating Generalization Properties with Regularized / Non-Regularized DQN", "review": "This is an empirical study on the ability for DQNs trained with/without regularization to perform well on variants of the same environment (e.g. increasing difficulty of a game). The paper is well written, the experimental methodology is clear & sound, and the significance is around improved sample efficiency via warm starting from a regularized DQN to fine tune. The error bounds for the regularized models results seem uncomfortably large in some cases. Overall it looks like a good methodological paper that can inform others on taking regularization more seriously when training DQNs. Evaluating on a modified ALE environment is great, but it would have been better to see this having similar impact in real life applications.", "rating": "5: Marginally below acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}