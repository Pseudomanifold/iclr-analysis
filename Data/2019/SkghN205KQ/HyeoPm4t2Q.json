{"title": "Useful extension of prior weakly-supervised SPEN work", "review": "Summary:\nThis paper discusses a method to train SPENs when strong supervision is not provided. Instead, training feedback comes in the form of a scalar-valued scoring function for a provided input as well as a prediction. The approach taken here is similar to that described in [1] in that score-violating pairs are found using some procedure, which are then used to update the parameters of the model. The primary difference here is that a random search procedure is used to find score violations rather than the test-time inference procedure; this is justified by noting that the gradient descent procedure may become stuck in flat areas of the optimization surface and thus not encounter high-reward areas. Experiments are run on multilabel classification, citation field extraction, and shape parsing tasks to demonstrate the validity of this approach.\n\nComments:\nOverall, this paper is very nicely written and presents its ideas very clearly. The base approach is the same as presented in [1], but the changes to the learning procedure are adequately justified (and the experiments corroborate this). Furthermore, everything is explained in sufficient detail to be easy to follow. The main detail that I didn\u2019t notice anywhere was a sentence or two describing the random search procedure used - adding this would further clarify your approach.\n\nThe tasks chosen to evaluate these methods are diverse and indicate that this approach is broadly useful in situations where strong supervision may be hard to come by. I think it would have been interesting to see how the model performs in a semi-supervised task (i.e. where some small fraction of the data has labels), but perhaps this is better suited for future work. The one question I have regarding your results is the following: you include the average reward for the citation-field extraction task in your results table, but don\u2019t seem to comment on this anywhere. Are there any conclusions that you think these results imply?\n\nThis paper is an excellent addition to the field of structured prediction, and thus I think it should be accepted.\n\n[1] Rooshenas, A., Kamath, A., & McCallum, A. (2018). Training Structured Prediction Energy Networks with Indirect Supervision. NAACL HLT 2018\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}