{"title": "An interesting application of RL, but scientifically sloppy", "review": "Starting from the hypothesis that humans have evolved basic autonomic visceral responses that influence decision making in a meaningful way and that these are at work in driving a car, the authors propose to use such signals within the RL framework. This is accomplished by augmenting the RL reward function with a model learned directly from human nervous system responses. This leads to a \nconvex combination of extrinsic rewards and visceral responses, with the goal to maximize extrinsic rewards and minimizing the physiological arousal response. The authors first show that they can train a CNN to predict systolic peaks from the pulse waveform based on the input images. The output of this network is then used with parametrically altered weightings in combination with the task related reward to evaluate performance on different driving tasks. The authors show that for different weightings performance on a number of driving tasks performance as measured by the collected extrinsic rewards is better.\n\nOverall, this is an interesting application of RL. It is OK to be inspired by biology, neuroscience, or psychology, but further reaching claims or interpretations of results in these fields need to be chosen carefully. The discussion of neuroscience and psychology are only partially convincing, e.g. there is extensive evidence that autonomic responses are highly dependent on cognition and not just decisions dependent on visceral, autonomic responses of the SNS. Currently, the manuscript is rather loosely switching between inspirations, imprecise claims, and metaphorical implementations with relation to neuroscience. The authors are encouraged to relate their work to some of the multi-criteria and structural credit assignment literature in RL, given the convex combination of rewards.  It may also be important to relate this work to imitation learning, given that the physiological measurements certainly also reflects states and actions by the human agents. While one indication for the reasons of higher extrinsic rewards with the augmented system is mentioned by the authors, namely that the autonomic signal is continuous and while the extrinsic rewards are sparse is convincing, it is not at all clear, why the augmented system performs better as shown in figure 5. \n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}