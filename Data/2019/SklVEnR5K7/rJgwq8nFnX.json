{"title": "Interesting approach in its simplicity with flaws in evaluation", "review": "This work shows that adding a simple blurring into max pooling layers can address issues of image classification instability under small image shifts. In general this work presents a simple and easy to implement solution to a common problem of CNNs and even though it lacks more thorough theoretical analysis of this problem from the signal processing perspective (such as minimal size of the blurring kernel for fulfilling the Nyquist-Shannon sampling theorem), it seems to provide ample empirical evidence.\n\nPros:\n+ The introduction and motivation is really well written and Figure 3 provides a clear visualisation main max pooling operator issues.\n+ The proposed method is really simple and shows promising results on the CIFAR dataset. With random shifts, authors had to tackle cropping with circular shifts. As it can cause artifacts in the data, authors also provide baseline performances on the original data (used for both training and testing).\n+ Authors provide a thorough evaluation, ranging from comparing hidden representations to defining consistency metrics of the classified classes.\n\nThis work is lacking in the experimental section due to some missing details and few inconsistencies. I believe the most of my concerns can be relatively easily fixed/clarified in an update of this submission.\n\nMajor issues, which if fixed would improve the rating:\n- It is not correct to average test accuracy and test consistency as both measures are different quantities, especially when using them for ranking. The difference between accuracy of different methods are considerably smaller than differences in the classification consistency. \n- It is not clear how many shifts are used for computing the \"Random Test Accuracy\" and the \"Classification Accuracy\". Also whether the random shifts are kept constant between evaluated networks and evaluation metrics.\n- Authors do not address the question what is the correct order of operations for the blurring. E.g. would the method empirically work if blurring was applied before max pooling? Do the operations commute?\n- The selection of the filters is rather arbitrary, especially regarding the 1D FIR filters. The separability of these filters should be discussed.\n- I believe authors should address how this work differs to [1], as it also tests different windowing functions for pooling operators, even though in different tasks.\n\nMinor issues, which would be nice to fix however which do not influence my rating:\n* Section 3.1 - And L-Layer deep *CNN*, H_l x W x C_l -> H_l x W_l x C_l\n* Section 3.1. Last paragraph - I would not agree with the statement that in CNNs the shift invariance must necessarily emerge upon shift equivariance. If anything, this may hold only for the last layer of a network without fully connected layers and with average pooling of the classifier output (ResNet/GoogleNet like networks).\n* Explicitly provide the network architecture as [Simonyan14] does not test on CIFAR and cannot use Batch normalisation.\n* It would be useful to add citation for the selected FIR filters.\n* The flow of section 4.2. can be improved to help readability. The three metrics should be first motivated before their introduction. Metric 2. paragraph - the metric is defined below, not above. \n* It would be interesting to see what would be the performance if the blurring filters were trained as well (given some sensible initialisation).\n* One future direction would be to verify that this approach generalises to larger networks as well. It might be worth to discuss this in the conclusions.\n\n[1] Scherer, Dominik, Andreas M\u00fcller, and Sven Behnke. \"Evaluation of pooling operations in convolutional architectures for object recognition.\" Artificial Neural Networks\u2013ICANN 2010. Springer, Berlin, Heidelberg, 2010. 92-101.", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}