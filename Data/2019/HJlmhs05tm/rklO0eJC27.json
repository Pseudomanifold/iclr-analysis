{"title": "There are some unclear issues, regarding correctness and significance", "review": "It is well known that energy-based model training requires sampling from the current model.\nThis paper aims to develop an energy-based generative model with a generator that produces approximate samples.\nFor this purpose, this paper combines a number of existing techniques, including sampling in latent space, using a GAN-like technique to maximize the entropy of the generator distribution.\nEvaluation experiments are conducted on toy 2D data, unsupervised anomaly detection, image generation.\n\nThe proposed method is interesting, but there are some unclear issues, which hurts the quality of this paper.\n\n1. Correctness\n\nThe justification of adding a gradient norm regularizer in Eq. (3) for turning a GAN discriminator into an energy function is not clear.\n\nSampling in latent space and then converting to data space samples to approximate the sampling from p_theta is operationally possible. There are three distributions - the generator distribution p_G, the distribution p_comp implicitly defined by the latent-space energy obtained by composing the generator and the data-space energy, and the energy-based model p_E.\np_G is trained to approximate p_E, since we minimize KL(p_G||p_E). Does latent space sampling necessarily imply that p_comp leads to be closer to p_E ?\n\n2. Significance\n\nIn my view, the paper is an extension of Kim&Bengio 2016.\nTwo extensions -  providing a new manner to calculate the entropy term, and using sampling in latent space. In this regard, Section 3 is unnecessarily obscure.\n\nThe results of image generation in Table 2 on CIFAR-10 are worse than WGAN-GP, which is now in fact only moderately performed GANs. In a concurrent ICLR submission - \"Learning Neural Random Fields with Inclusive Auxiliary Generators\", energy-based models trained with their method are shown to significantly outperform WGAN-GP.\n", "rating": "5: Marginally below acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}