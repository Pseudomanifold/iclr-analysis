{"title": "Claims of being first not completely justified", "review": "Overview:\n\nThis paper proposed an approach for zero-shot phoneme recognition, where it is possible to recognise phonemes in a target language which has never been seen before. Rather than just training a phoneme recogniser directly on background data and then applying it to unseen data, phonetic features are first predicted, allowing phonemes not in the source language set to be predicted.\n\nMain strengths:\n\nThe paper's main strength lies in that this is a very unexplored area that could assist in the development of speech technology where it is currently not possible. The proposed model (Section 2) has also not been considered in prior work.\n\nMain weaknesses:\n\nThe paper's main weakness is in some of its claims and that it misses some very relevant literature. Detailed comments together with a minimal list of references are given below (but I would encourage the authors to also read a bit more broadly). But in short I do not think it is that easy to claim that this is the first paper to do zero-shot learning on speech; many of the zero-resource studies where unlabelled audio is used could be seen as doing some for of zero-shot matching. Specifically [5] is able to predict unseen phoneme targets.  Multilingual bottleneck features can be applied to languages that have never been seen before [2], and the output of phoneme recognisers trained on one language have long been applied to get output on another unseen language. The first one-shot learning speech paper [4] (to my knowledge) is also not mentioned at all. The approach in the paper also still relies on some text data from the target language; if this then can be described as \"zero-shot\" learning, then I think many of these previous studies c also make this claim.\n\nOverall feedback:\n\nThere is definitely value in this work, but it should be much better situated within the broader literature. Below I give some editorial suggestions and also outline some suggestions for further experiments.\n\nDetailed comments, suggestions and questions:\n\n- Abstract: It would be useful to have some details of the \"baseline model\" here already, especially since it is such a new task.\n- Introduction: \"... but they can hardly predict phones or words directly due to their unsupervised nature.\" This is a strong statement that maybe requires more justification. On the one hand, the statement is true, and the high word error rates in e.g. [3] can be cited. On the other hand, it has been shown that at the phone-distinction level, these models perform quite well and sometimes outperform supervised models [1]. Since this paper also considers phone error rate as a metric, I think care should be taken with such statements.\n- Introduction: \"While zero-shot learning has attracted a lot of attention in *the* computer vision community, this setup has hardly been studied in speech recognition research especially in acoustic modeling.\" Definitely look at some of the studies mentioned below, and also [4] specifically.\n- \"However, we note that our model can be combined with a well-resourced language model to recognize words.\" How would this be done, since I think this is actually quite a challenging task.\n- Section 2: \"... useful the original ESZSL architecture ...\" -> \"... useful in the original ESZSL architecture ...\"\n- Section 2.2: I assume the small text corpus is at the phone level (and not characters directly)? This should be clarified, and it could raise the question of whether this approach is truly \"zero-shot\".\n- Section 3.2: \"We used EESEN framework ...\" -> \"We used the EESEN framework ...\"\n- Section 4: You could look at the recent work in [2], which uses multilingual bottleneck features trained on 10 languages and applied to multiple unseen languages. It would be interesting to also train your approach on multiple languages instead of only English.\n\nMissing references:\n\n1. M. Heck, S. Sakti, and S. Nakamura, \"Feature Optimized DPGMM Clustering for Unsupervised Subword Modeling: A Contribution to Zerospeech 2017,\" in Proc. ASRU, 2017.\n2. E. Hermann and S. J. Goldwater, \"Multilingual bottleneck features for subword modeling in zero-resource languages,\" in Proc. Interspeech, 2018.\n3. H. Kamper, K. Livescu, and S. Goldwater, An embedded segmental k-means model for unsupervised segmentation and clustering of speech,\" in Proc. ASRU, 2017.\n4. B. M. Lake, C.-Y. Lee, J. R. Glass, and J. B. Tenenbaum, \"One-shot learning of generative speech concepts,\" in Proc. CogSci, 2014.\n5. O. Scharenborg, F. Ciannella, S. Palaskar, A. Black, F. Metze, L. Ondel, and M. Hasegawa-Johnson, \"Building an ASR system for a low-resource language through the adaptation of a high-resource language asr system: Preliminary results,\"in Proc. ICNLSSP, 2017.\n\nEdit: Based on the rebuttal I've changed my rating from 4 to 5.", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}