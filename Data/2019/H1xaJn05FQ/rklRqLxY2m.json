{"title": "Review", "review": "This paper proposes training generative models with Wasserstein auto-encoders. It uses the sliced-Wasserstein distance to measure the dissimilarity between p_z and q_z.\n\nStrengths:\n1.    This paper is easy to read. \n2.    Concepts are introduced clearly. \n\nMy major comments are the following:\n1.  The innovation is a bit on the incremental level, especially given the results from WAE (Tolstikhin, ICLR18). The training objective is the same as Eq(4) in the WAE paper. The only difference is that the dissimilarity measure between p_z and q_z used in this paper is the sliced- Wasserstein distance, while WAE used GAN/MMD-based penalties. The advantage of using sliced-Wasserstein distance is not clear to me either.  \n\n2. The empirical results are fairly weak.  The authors may consider reporting the sample qualities (e.g. FID) for all the methods. \n\n3. The results of WAE-MMD are not reported.\n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}