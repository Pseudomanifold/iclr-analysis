{"title": "The paper proposes a new auto-encoder model, but possibly contains errors in math and the experiments are not convincing enough.", "review": "The authors propose a new autoencoding algorithm for the unsupervised generative modeling which they call Sliced Wasserstein Autoencoders (SWAE). SWAE minimizes a reconstruction cost (measured with respect to the non-negative cost function c(x,x') defined for pairs of input images x, x'), regularized by a penalty measuring a discrepancy between the prior distribution over the latent space qz and the push-forward pz of the unknown data distribution through the deterministic encoder. The authors present an extensive theoretical argument supporting the choice of this objective and a number of empirical results performed on MNIST, LSUN bedrooms, and Celeba. \n\nEven though this paper raises several interesting questions, I have several major issues with it:\n****\n**** 1. Claim around Equation 3 is not proved.\n****\nAll the sections before 2.3 are providing a rather detailed theoretical argument meant to support the choice of the SWAE objective appearing in Eq. 14 of Section 2.3. Here I wand to point out to a mathematical inaccuracy in the authors' discussions, which may render the whole argument questionable. In short, the authors claim around Eq. 3 that \"Eq. 3 is equivalent to Theorem 1 of [1] for deterministic encoder-decoder pairs\" and don't provide any proofs for this nontrivial fact. \n\nThe following is based on some quick derivations I did while reviewing. \n\nRecall that in the current paper Px is the data distribution, Py is the push-forward of Px through the superposition of the encoder \\phi and decoder \\psi (in other words Py is a distribution of \\psi(\\phi(X)) when X is distributed according Px). The authors state that:\n   \\inf_{\\phi, \\psi} Wc(Px, Py)\n    is equivalent to\n   (* ) \\inf_{\\phi, \\psi} E_{X \\sim Px}[ c(X, \\psi(\\phi(X))) ].\nIn other words, the authors state that using Theorem 1 of [1] they are able to show that minimizing a c-optimal transport distance between Px and Py (which is parametrized by \\psi and \\phi) is *equivalent* to an unconstrained optimization problem appearing on the r.h.s. of Equation 3. \n\nNow, the Theorem 1 of [1] referenced by authors states that if Pz is any prior distribution over the latent space and \\psi * Pz is its push-forward through the deterministic decoder \\psi, then the optimal transport between Px and the resulting latent variable model \\psi * Pz can be equivalently written as:\n   (**) Wc(Px, \\psi * Pz) = \\inf_{f such that f * Px = Pz} E_{X \\sim Px}[ c(X, \\psi(f(X))) ].\nImportantly, note how the right hand side of (**) contains a constrained optimization over an auxiliary (encoder) function f, which does not appear at all in the left hand side. If the authors were to apply (**) directly, they would arrive at the following statement:\n   \\inf_{\\phi, \\psi} Wc(Px, Py)\n    is equivalent to\n   (*** ) \\inf_{\\phi, \\psi} \\inf_{f such that f * Px = \\phi * Px} E_{X \\sim Px}[ c(X, \\psi(f(X))) ].\nFinally, comparing (*) stated by the authors and (***) obtained above, we see that (*) is obtained by selecting one particular function f = \\phi from the set {f such that f * Px = \\phi * Px}. Meanwhile, this set in general may contain multiple other functions f and as a result this only shows that (*) >= (***) (as we replace \\inf_f with one particular choice of f). However, in this case, I think it is indeed possible to show that (*) = (***). Imagine (***) has a global minimum at (\\psi_0,\\phi_0, f_0), that is the global optimum of (***) equals E_{X \\sim Px}[ c(X, \\psi_0(f_0(X))) ]. The same value can be achieved by (*) by setting \\phi = f_0. QED. \n\nOnce again, these are my preliminary derivations and they need to be checked. But it looks like the claim of the authors is indeed true. \n\n****\n**** 2. Empirical evidence is not convincing. ****\n****\nThe main topic of the paper is the unsupervised generative modeling, and the authors claim certain improvements in this field compared to the previous literature. Even though there are no ultimate evaluation metrics available in the field, recently the researchers started supporting their methods with several metrics, including FID scores. By now for most of the widely used datasets the state of art FID scores are well known. In all the experiments the authors provide pictures and interpolations (last row of Fig. 3, Fig. 5) without numbers. I would say nowadays presenting pictures is not enough (being too subjective) and at least some objective numbers (preferably FID) capturing the quality of generated samples should be reported. The authors go into detailed measurements of discrepancy between the aggregate posterior pz and the prior qz, but it is not clear how this affects the actual sample generation. Finally, it is not clear why the authors compare only to WAE-GAN and did not consider WAE-MMD, which is free of adversarial training (in contrast to WAE-GAN) and thus has a stable training and does not involve extra computations of updating the discriminator (as noted by authors on page 10).\n\n[1] Bousquet et al., 2017.", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}