{"title": "minor generalization of AdaGrad style methods", "review": "The paper presents a generalization of the Adagrad type methods using a min-max formulation and then presents two alternate algorithms to solve this formulation. \n\nIt is unclear to me that much extra generalization has been achieved over the original AdaGrad paper. That paper simply presents the choice of hyperparameters as an optimal solution to a proximal primal dual formulation. The formulation presented here appears to be another form of the proximal mapping formulation, and so it is unclear what the advance here is. The AdaGrad paper used a particular Bregman divergence, and different divergences yield slightly different methods, as is observed here by the authors when they use different divergence measures.\n\nThe Bregman divergences do make sense from a primal pual proximal formulation point of view, but why do you use a discrepancy function in your min-max formulation that comes from the \\phi - divergence family? Why not consider an L_p normalization of the discrepancy? \n\nThe difference between formulations (5) and (6) is not clearly specified. Did you mean to drop the constraints that \\beta \\in \\cal{B}_t ? Otherwise, why is (6) , which looks to be a re-write of (5), unconstrained and hence separable?\n\nThe authors claim that the method is free of parameter choices, but the initial \\beta_0 seems to be a crucial parameter here since it forms both a target and a lower bound for subsequent \\beta_t's. How is this parameter chosen and what effect does it have on convergence? From the results (Figs in Sec 5), this choice does significantly impact the final test loss obtained. \n    \nI could not find a proof for Thm 6 in the appendix. Did I over look it or is there a typo?", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}