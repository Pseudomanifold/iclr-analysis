{"title": "An interesting paper but can still be improved.", "review": "This paper proposes a new soft negative log-likelihood loss formulation for multi-class classification problems. The new loss is built upon the taxonomy graph of labels, which is provided as external knowledge, and this loss provides better semantic generalization ability compared to a regular N-way classifier and yields more accurate and meaningful super-class predictions.\n\nThis paper is well-written. The main ideas and claims are clearly expressed. The main benefits of the new loss are caused by the extra information contained by the taxonomy of labels, and this idea is well-known and popular in the literature. Based on this reason, I think the main contribution of this paper is the discussion on two novel learning settings, which related to the super-classes. However, the formulation of the new soft NLL loss and the SG measurement involves lots of concepts designed based on experiences, so it\u2019s hard to say whether these are the optimal choices. So, I suggest the authors discuss more on these designs.\nAnother thing I concern about is the source of label taxonomy. How to efficiently generate the taxonomy? What if the taxonomy is not perfect and contains noises? Will these significantly affect the models\u2019 performance? I think it\u2019s better to take these problems into consideration. \nIn conclusion, I think this is an interesting paper but can still be improved.", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}