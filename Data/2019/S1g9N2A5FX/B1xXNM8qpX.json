{"title": "Interpretable Continual Learning", "review": "Authors propose an incremental continual learning framework which is based on saliency maps on the learned tasks(i.e., explanations) with the ultimate goal of learning new tasks, while avoiding catastrophic forgetting. To this end, authors employ an attention mechanism based on average saliency masks computed on the predictions of the earlier task. In addition, a new metric, Flexible Saliency Metric (FSM) is proposed to evaluate the generated saliency maps. Authors employ three public, well-known datasets to evaluate the performance of their proposed framework.\n\nThe paper is well written and easy to follow. The methodology is sound and the results demonstrate that the proposed framework outperforms very recent conditional learning approaches. Nevertheless I have some major concerns with the methodology, proposed evaluation metric and experiments. Please find below my comments.\n\n- Technical novelty is rather limited. Contribution is incremental with respect to previous works on CL, as they use the variational CL (VCL) framework of Nguyen at al, 2018 and the weight of evidence (WE), as used in Zintgraf et al., 2017, to compute the saliency maps. From these saliency maps, a mask is computed to focus the attention in subsequent tasks, by averaging the explanations. This, however, limits the applicability of the proposed framework to \u2018similar\u2019 images (as pointed out by the authors). Another limitation of this technique is that explanations on learned tasks should correspond, spatially, to meaningful/discriminative areas for new tasks. Otherwise, the use of explanations on this CL approach would not work.\n- According to the authors, one of the limitations of known metrics to evaluate CL approaches is that \u2018the area of the saliency regions should be all connected, wasting opportunity to identify salient but possibly non-connected areas, such as the two eyes of an animal\u2019. Nevertheless, I do not see how this can be alleviated in the proposed FSM. The first term of eq (8), i.e., log(d_sal) will be large in the case of, for example, the two eyes of an animal, favouring again for connected saliency regions. How d_sal is computed? Is it a dense matrix between all pair of points?  \n- Being the FSM one of the main contributions of this work, experiments to assess its usability are insufficient. Authors should correlate the values obtained across the different CL frameworks with FSM to the actual performance in terms of precision/accuracy. Results demonstrate that the proposed ICL approach achieves the lowest values, in terms of FSM, but any interpretation can be done if it is not correlated with well established evaluation metrics.\n- Furthermore, it would be interesting to see how this method performs in more complex datasets, such as ImageNet, where tasks within the continual learning process may differ a lot. \n- I also feel the literature on CL is scarce and it does not motivate the choices of the manuscript. Authors should include a more detailed literature on this problem. \n\nMinor comments\n\n- In page 3, which is the difference between benchmarks and medical data, as datasets? Public medical data are also benchmarks.\n- How the z value in eq (6) is found? An ablation study to see the impact on the final results would be interesting.\n- In page 5, when describing the limitations of current methods for saliency map evaluation (\u2018It remains tricky how to identify,\u2026.,etc),what does etc mean? Please be more concise on the limitations. ", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}