{"title": "Exciting task! Not sure about model results", "review": "This paper presents CoDraw, a grounded and goal-driven dialogue environment for collaborative drawing. The authors argue convincingly that an interactive and grounded evaluation environment helps us better measure how well NLG/NLU agents actually understand and use their language \u2014 rather than evaluating against arbitrary ground-truth examples of what humans say, we can evaluate the objective end-to-end performance of a system in a well-specified nonlinguistic task. They collect a novel dataset in this grounded and goal-driven communication paradigm, define a success metric for the collaborative drawing task, and present models for maximizing that metric.\n\nThis is a very interesting task and the dataset/models are a very useful contribution to the community. I have just a few comments below:\n\n1. Results:\n1a. I\u2019m not sure how impressed I should be by these results. The human\u2013human similarity score is pretty far above those of the best models, even though MTurkers are not optimized (and likely not as motivated as an NN) to solve this task. You might be able to convince me more if you had a stronger baseline \u2014 e.g. a bag-of-words Drawer model which works off of the average of the word embeddings in a scripted Teller input. Have you tried baselines like these?\n1b. Please provide variance measures on your results (within model configuration, across scene examples). Are the machine\u2013machine pairs consistently performing well together? Are the humans? Depending on those variance numbers you might also consider doing a statistical test to argue that the auxiliary loss function and and RL fine-tuning offer certain improvement over the Scene2seq base model.\n\n2. Framing: there is a lot of work in collaborative / multi-agent dialogue models which you have missed \u2014 see refs below to start. You should link to this literature (mostly in NLP) and contrast your task/model with theirs.\n\nReferences\nVogel & Jurafsky (2010). Learning to follow navigational directions.\nHe et al. (2017). Learning Symmetric Collaborative Dialogue Agents with Dynamic Knowledge Graph Embeddings.\nFried et al. (2018). Unified pragmatic models for generating and following instructions.\nFried et al. (2018). Speaker-follower models for vision-and-language navigation.\nLazaridou et al. (2016). The red one!: On learning to refer to things based on their discriminative properties.\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}