{"title": "An artificial task for modeling and evaluation of goal-oriented dialogs", "review": "The paper proposes a game of collaborative drawing where a teller is\nto communicate a picture to a drawer via natural language.  The picture\nallows only a small number of components and a fixed and limited set\nof detailed variations of such components.\n\nPros:\n\nThe work contributed a dataset where the task has relatively objective\ncriteria for success.  The dataset itself is a valuable contribution\nto the community interested in the subject.   It may be useful for\npurposes beyond those it was designed for.\n\nThe task is interesting and its visual nature allows for easy inspection\nof the reasons for successes or failures.  It provides reasonable grounding\nfor the dialog.  By restricting the scope of variations through the options\nand parameters, some detailed aspects of the conversation could be explored\nwith carefully controlled experiments.\n\nThe authors identified the need for and proposed a \"crosstalk\" protocol\nthat they believe can prevent leakage via common training data and\nthe development of non-language, shared codebooks that defeat the purpose\nof focusing on the natural language dialog.\n\nThe set up allows for pairing of human and human, machine and machine,\nand human and machine for the two roles, which enables comparison to\nhuman performance baselines in several perspectives.\n\nThe figures give useful examples that are of great help to the readers.\n\nCons.:\n\nDespite the restriction of the task context to creating a picture with\nseverely limited components, the scenario of the dialogs still has many\ndetails to keep track of, and many important facets are missing in the\ndescriptions, especially on the data.\n\nThere is no analysis of the errors.  The presentation of\nexperimental results stops at the summary metrics, leaving many\ndoubts on why they are as such.\n\nThe work feels somewhat pre-mature in its exploration of the models\nand the conclusions to warrant publication.  At times it feels like the\nauthors do not understand enough why the algorithms behave as they do.\nHowever if this is considered as a dataset description paper and\nthe right expectation is set in the openings, it may still be acceptable.\n\nThe completed work warrants a longer report when more solid conclusions\ncan be drawn about the model behavior.\n\nThe writing is not organized enough and it takes many back-and-forth rounds\nof checking during reading to find out about certain details that are given\nlong after their first references in other contexts.  Some examples are\nincluded in the followings.\n\nMisc.\n\nSection 3.2, datasets of 9993 dialogs:\nAre they done by humans?   Later it is understood from further descriptions.\nIt is useful to be more explicit at the first mention of this data collection effort.\nThe way they relate to the 10020 scenes is mentioned as \"one per scene\", with a footnote on some being removed.\nDoes it mean that no scene is described by two different people?  Does this\nlimit the usefulness of the data in understanding inter-personal differences?\n\nLater in the descriptions (e.g. 4.1 on baseline methods) the notion of\ntraining set is mentioned, but up to then there is no mentioning of how\ntraining and testing (novel scenes) data are created.\nIt is also not clear what training data include: scenes only?\nDialogs associated with specific scenes?  Drawer actions?\n\nSection 4.1, what is a drawer action?  How many possibilities are there?\nFrom the description of \"rule-based nearest-neighbor drawer\" they seem to be\ncorresponding to \"teller utterance\".\nHowever it is not clear where they come from.  What is an example of a drawer action?\nAre the draw actions represented using the feature vectors discussed in the later sections?\n\nSection 5.1, the need for the crosstalk protocol is an interesting observation,\nhowever based on the description here, a reader may not be able to understand\nthe problem.  What do you mean by \"only limited generalization has taken place\"?  Any examples?\n\nSection 5, near the end: the description of the dataset splits is too cryptic.\nWhat are being split?  How is val used in this context?\n\nAll in all the data preparation and partitioning descriptions need substantial clarification.\n\nSection 6:  Besides reporting averaged similarity scores, it will be useful to report some error analysis.\nWhat are the very good or very bad cases?  Why did that happen?\nAre the bad scenes constructed by humans the same as those bad scenes\nconstructed by machines?  Do humans and machines tend to make different errors?\n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}