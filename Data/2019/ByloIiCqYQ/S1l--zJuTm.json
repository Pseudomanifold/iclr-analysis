{"title": "Using deep neural networks to learn embeddings for binary software vulnerability detection; unclear about its contribution for ML community", "review": "This paper proposes a variational autoencoder-based architecture for binary code embedding. For evaluation, they construct a dataset by compiling source code in the NDSS18 dataset. They evaluate their approaches against several neural network baselines, and demonstrate that their learned embeddings are more effective at distinguishing between vulnerable and non-vulnerable binary code.\n\nThe application of deep representation learning for (binary) vulnerability detection is  a promising direction in general. Meanwhile, the authors did a quite comprehensive comparison with neural network baselines for embedding representation. However, I have several questions and concerns about the paper:\n\n- The contributions of this paper are unclear to me. The authors claim that a main contribution is their dataset. I agree that this is a contribution, but since this dataset is built upon an existing dataset with source code, and the dataset construction techniques themselves are not novel, especially for machine learning community, I do not see a significant contribution in this part.\n\n- The proposed approach is new, but the technical novelty is marginal. I think this model design is not specific to the binary vulnerability detection, but should also be applicable to other vulnerability detection settings, e.g., the original NDSS18 dataset. It would be great if the proposed approach also performs better on other vulnerability detection tasks than the baselines.\n\n- What would be the performance of using hand-designed features on the same benchmark? If the proposed approach learns better embeddings, any intuition on what additional information is captured by the learned embeddings?\n\nMinor suggestions: The paper needs an editing pass to fix some typos. Also, the authors seem to setup the paper template in a wrong way, and may need to consider fixing it.", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}