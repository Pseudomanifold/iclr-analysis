{"title": "Review of \"Analysing Mathematical Reasoning Abilities of Neural Models\"", "review": "This paper develops a framework for evaluating the ability of neural models on answering free-form mathematical problems. The contributions are i) a publicly available dataset, and ii) an evaluation of two existing model families, recurrent networks and the Transformer. \n\nI think that this paper makes a good contribution by establishing a benchmark and providing some preliminary results. I am biased because I once did exactly the same thing as this paper, although at a much smaller scale; I am thus happy to see such a public dataset. The paper is a reasonable dataset/analysis paper. Whether to accept it or not depends on what standard ICLR has towards such papers (ones that do not propose a new model/new theory).\n\nI think that the dataset generation process is well-thought-out. There are a large variety of modules, and trying to not generate either trivial or impossible problems is a plus in my opinion. The results and discussions in the main part of the paper are too light in my opinion; the average model accuracy across modules is not an interesting metric at all, although it does show that the Transformer performs better than recurrent networks. I think the authors should move a portion of the big bar plot (too low resolution, btw) into the main text and discuss it thoroughly. Details on how to generate the dataset, however, can be moved into the appendix. I am also not entirely satisfied by using accuracy as the only metric; how about using something like beam search to build a \"soft\", secondary metric?\n\nOne other thing I want to see is a test set with multiple different difficulty levels. The authors try to do this with composition, which is good, but I am not sure whether that captures the real important thing - the ability to generalize, say learning to factorise single-variable polynomials and test it on factorising polynomials with multiple variables? And what about the transfer between these tasks (e.g., if a network learns to solve equations with both x and y and also factorise a polynomial with x, can it generalize to the unseen case of factorising a polynomial with both x and y)? Also, is there an option for \"unsolvable\"? For example, the answer being a special \"this is impossible\" character for \"factorise x^2 - 5\" (if your training set does not use \\sqrt, of course).", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}