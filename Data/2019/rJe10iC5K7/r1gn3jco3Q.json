{"title": "Interesting idea", "review": "The paper describes a method, which learns the hierarchical decomposition of moving objects into parts without supervision, based on prediction of the future. A deep neural network is structured into a sequence of encoders and decoders: the input image is decomposed into objects by a trained head, then motion is estimated from predicted convolutional kernels whose model is trained on optical flow; the latent motion output is encoded into separated motion fields for each object and then composed into a global model with a trainable structured matrix which encodes the part hierarchy. The latent space is stochastic similar to VAEs and trained with similar losses.\n\nStrengths:\n\nThe idea is interesting and nicely executed. I particularly appreciated the predicted kernels, and the trainable structure matrix. Although the field of hierarchical motion segmentation is well studied, up to my knowledge this method seems to be the first of its kind based on a fully end-to-end trainable method where the motion estimators, the decomposition and the motion decoders are learned jointly.\n\nThe method is evaluated on different datasets including fully synthetic ones with synthetic shapes or based on MNIST; very simple moving humans taken from ATARI games, and realistic humans from two different pose datasets. The motion decomposition is certainly not as good as the definition and the output of a state of the art human pose detector; however, given that the decomposition is discovered, the structure looks pretty good.\n\nWeaknesses\n\nI have two issues with the paper. First of all, although the related work section is rich, the methods based on hierarchical motion decompositions are rarer, although the field is quite large. Below are a couple of references:\n\nMihir Jain, Jan Van Gemert, Herve\u0301 Je\u0301gou, Patrick Bouthemy, and Cees GM Snoek. Action localization with tubelets from motion. CVPR, 2014.\n\nChenliang Xu and Jason J Corso. Evaluation of super-voxel methods for early video processing. CVPR, 2012.\n\nJue Wang, Bo Thiesson, Yingqing Xu, and Michael Cohen. Image and video segmentation by anisotropic kernel mean shift. ECCV, 2004 \n\nChenliang Xu, Caiming Xiong, and Jason J Corso. Streaming hierarchical video segmentation. ECCV 2012.\n\nMatthias Grundmann, Vivek Kwatra, Mei Han, and Irfan Essa. Efficient hierarchical graph-based video segmentation. CVPR, 2010.\n\nPeter Ochs, Jitendra Malik, and Thomas Brox. Segmentation of moving objects by long term video analysis. IEEE PAMI, 2014.\n\nDiscovering motion hierarchies via tree-structured coding of trajectories\nJuan-Manuel P\u00e9rez-R\u00faa, Tomas Crivelli, Patrick P\u00e9rez, Patrick Bouthemy, BMVC 2016.\n\nSamuel J Gershman, Joshua B Tenenbaum, and Frank Ja\u0308kel. Discovering hierarchical motion structure. Vision Research, 2015.\n\nSecondly, the presentation is not perfect. The paper is densely written with lots of information thrown rapidly at the reader. Readers familiar with similar work can understand the paper (I needed a second pass). But many parts could be better formulated and presented.\n\nI understood the equations, but I needed to ignore certain thinks in order to understand them. One of them is the superscript in the motion matrices M, which does not make sense to me. \u201cg\u201d seems to indicate \u201cglobal\u201d and \u201cl\u201d local, but then again a local parent matrix gets index \u201cg\u201d, and this index seems to switch whether the same node is seen as the current node or the parent of its child. \n\nFigure 3 is useful, but it is hard to make the connection with the notation. Symbols like z, M etc. should be included in the figure.\n\nThe three lines after equations 2 and 3 should be rewritten. They are understandable but clumsy. Also, we can guess where the binary constraints come from, but they should be introduced nevertheless.\n\nIn essence, the paper is understandable with more efforts than there should be necessary.\n\n\nOther remarks:\n\nThe loss L_struct is L_2, I don\u2019t see how it can favor sparsity. This should be checked and discussed.\n\nA symbolic representation is mentioned in the introduction section. I am not sure that this notion is completely undisputed in science, it should at least not be presented as a fact.\n\nThe ATARI dataset seems to be smallish (a single video and 5000 frames only).\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}