{"title": "Official Review", "review": "==== Review Summary ====\n\nThe paper demonstrates an interesting and potentially useful idea.  But much of it is poorely explained, and experimental results are not strongly convincing.  The only numerical evaluations are on a simple dataset that the authors made themselves.  The most interesting claim - that this network can learn unsupervised hierarchical object segmentation based on unlabelled video data -  is not well supported by the paper.  \n\n==== Paper Summary ====\n\nThis paper presents a deep neural network which learns object Segmentation, Structure, and Dynamics from unlabelled video.  The idea is quite useful, as it is a step towards learning models that can \"discover\" the concept of objects in a visual scene without any supervision.  \n\nThe central contributions of this paper are:\n(1) To show how one can use coherent motion (the fact that different parts of an object move together) to learn unsupervised object segmentation.\n(2) To show how once can learn the relation between objects (e.g. \"arm\" is part of \"body\") by observing relative motion between segments.\n\n==== General Feedback ====\n\nThe paper would benefit a lot from better explanations and being better tied together (see \"Details\" below for examples).   Figure captions would benefit from much better explanations and integration with the text - each figure caption should at least describe what the figure is intended to demonstrate.  Variables such as ($\\mathcal M$, $\\mathcal S$, $\\mathcal I$, $\\mathcal L$) should be indicated in figures .  \n\nMany things would benefit from being defined precisely with Equations.  For example I have no idea how the \"soft\" structural descriptor S is computed.  Is it (A) a parameter that is shared across data points and learned?  or (B) is it computed per-frame from the network?  And after it is calculated, how are the S_{ik} values (which fall between 0 and 1) used to combine the motion maps?  \n\n==== Scientific Questions ===\n\nI'm confused as to what the latent variables z \"mean\".  It seems strange that there is a 1-d latent variable representing the motion of each part.  Translation of a segment within an image is 2D.  3D if you include planar rotation, then there's scaling motion and out-of-plane rotations, so it seems an odd design choice that motion should be squeezed into a 1D representation.\n\nI find it difficult to assess the quality of the \"next frame predictions\".  There's lots other literature on next-frame prediction to compare against (e.g. https://arxiv.org/abs/1605.08104).  At least you could compare to a naive baseline of simply shifting pixels based on the optical flow.  \n\nI'm confused about how you are learning the \"estimated flow\".  My impression is that the input flow is calculated between the last 2 frames $\\hat M = flow(I_{t-1}, I_t)$.  And that the \"estimated\" flow is an estimate of $flow(I_{t}, I_{t+1})$.  But in Section 4.3 you seem to indicate that the \"estimated\" flow is just trained to \"reconstruct\" the input flow.... In that case why not just feed the input flow directly into the Image Decoder?  What I guess you're doing is trying to Predict the next flow ($flow(I_{t}, I_{t+1})$) but if you're doing this neither Figure 3 nor Section 4.2 indicates this, hence my confusion.  \n\n==== Details ====\n\nFigure 3: \n----\nThe \"shapes\" example is odd, because it's not obvious that there's a structural hierarchy linking the shapes.  Maybe a \"torso/left arm/right arm\" would be better for illustrative purposes?\nIt would be helpful to put the variable names ($\\mathcal M_k$, etc) on the figure.\nShould add a second arrow coming into the (f) the Structural descriptor from a leaf-variable $p_k$\nAlso it would be helpful to indicate where the losses are evaluated.\n\"Next Frame\" should probably be \"Reconstruction\" (though \"Prediction\" might be a more accurate word).\n---\n\nSection 4.2:\nNotational point, it seems k can be from 1 to d.  But in Section 3 you say it can be from 1 to \"n\". Maybe it would be clearer to change both (\"n\" and \"d\") to \"K\" to emphasize that \"k\" is an index which goes up to \"K\".  (edit... now after reading 5.1: Latent Representation, I understand.  If there are n parts in the dataset you use d>n dimensions and the network learns to \"drop\" the extra ones... it would help to clarify that here).\nStructural Descriptor: You say \"in practice, we relax the binary constraints\"... Yet this is important.. should write down the equation and say how the \"soft\" version of [i \\in S] calculated.\nSection 4.3\n\"elbo\" seems like the wrong name for this loss, as it's not an Evidence Lower BOund.  The elbo would be the sum of this loss and the first component of L_{recon}.  It is a regularizing term, so you could call it L_reg.\nIt's not obvious that sparse local motion maps mean a heirarchical tree structure, but I see how it could help.  I suggest that without evidence for this loss you soften the claim to \"this is intended to help encourage the model to learn a heirarchical tree structure\"\nFigure 4: \nIt appears that each row indicates a different video in the dataset, but then in 4f you still have two rows but they appear to correspond to different algorithms... a vertical separator here might help show that the rows in 4f do not correspond to the rows in 4a-e.\n\"Next Frame\" here appears to refer to ground truth, but in Figure 3 \"Next Frame\" appears to be the prediction (which you call reconstruction). \nSection 5.1\n\nFuture Prediction: No explanation either here or in Figure 4 of what it actually shows.  (What would a failure look like?)\nHierarchical structure... You binarize... how?\nFigure 9:\nWhat does this show?  The figure does not obviously demonstrate anything.  Maybe compare to ground-truth future frames?\nSection 5.3:\nFuture Prediction: These images are from the test set, right?  If so, that is worth mentioning. \nObject Segmentation (\"in several different dimensions\"  -> \"corresponding to the active latent dimensions?\")\nObject Segmentation: Visually, it looks nice, but I have now idea how good this segmentation is.  You compare verbally to R-NEM and PSD, but there're no numbers.\nHuman Studies... The line \"For those whose predicted tree structures are not consistent with ours, they all agree with our results and believe ours are more reasonable than others\" .. brings to mind an image of a room full of tortured experimental subjects not being allowed to leave until they sign a confession that their own tree structures were foolish mistakes and your tree structures are far superior.... So probably it should be removed because it sounds shady. \n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}