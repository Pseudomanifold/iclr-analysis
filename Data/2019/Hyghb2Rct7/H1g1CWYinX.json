{"title": "First review", "review": "This paper introduces the use of sequential information (state-action pairs) for enhancing imitation learning, and using recurrent networks (LSTM) in that process.  The authors motivate this by pointing out that while the state information, if Markovian, should contain all information necessary for decision making, with incomplete learners redundant information in the sequential state-action information leading to the current state can be helpful, citing some concrete examples. \nAfter describing a number of variants of this idea, in the context of IRL, BC, etc., the authors conduct a systematic empirical evaluation to assess the effectiveness of the proposal, over the baselines, using a number of RL benchmark problems. \nThe results are favorable and convincingly show that the proposed sequential enhancement can bring significant improvement in terms of attained rewards, convergence speed and stability in many of the tested cases. \nOne suggestion I have is that it would be interesting to investigate into the question of how the addition of sequential information adds value is related to the validity of Markovian assumption in each of the problem being considered. \nIt is a good empirical paper demonstrating the practical use of an idea that is simple but reasonable, and in a way that is substantiated using proper cutting edge framework and baselines. \n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}