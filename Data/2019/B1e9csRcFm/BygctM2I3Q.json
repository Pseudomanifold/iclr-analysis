{"title": "The paper needs more clarification on the implication from the theoretical results as well as empirical results", "review": "The main contribution of this paper is that it shows both theoretically and empirically that in linear graph embeddings, the generalization error is bounded by the norms of the embedding vectors rather than the dimension of the embedding vectors. \n\nThe list of my concerns or cons of this paper is:\n\n- For the main theorem, i.e., Theorem 1, \na.) why is it intuitive that the size of the training dataset required for learning a norm constrained graph embedding is O(C|A|_2). This is not that intuitive to me. Later, the authors argue that graphs are usually sparse and average node degree is usually smaller than the embedding size, thus it is easily overfitting the training data. However, I would say, in practice, the positive training pairs are not restricted to 1-hop neighbors, but could also be 2 or more hops, in that case, it won't easily overfit. \nb.) the main result from the theorem is that the error gap of norm constrained embeddings scales as O(d^-0.5(lnn)0.5), but I did not see how this is related to the norms of the embedding vectors and how is this evidenced in the empirical studies? It might be better to show a plot of error gap vs. d and/or n. \nc.) how is this analysis related to the later claim that \\lambda_r controls the model capacity of linear graph embedding?\n\n- The linear graph embedding framework considered in this paper assumes that each node only has one set of embeddings, but in practice, one node usually has two sets of embeddings as context node or a center node. How would this affect the whole analysis and claims?\n\n- How would the claims or analysis in this paper be generalized to non-linear graph embedding frameworks?\n\n- For the experiments, \na.) In Figure 3, the y label of (b) is missing, and the Average L2 norm of (c) cannot reflect the Generalization performance \nb.) In Figure 4(a), why after overfitting, we can still observe that the test accuracy increases?\nc.) In Figure 5, why the test precision first increases and then decrease with more regularization?", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}