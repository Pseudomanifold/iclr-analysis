{"title": "Interesting paper about a useful optimization shortcut, but too brief experiments", "review": "(I have reviewed an earlier version of this paper before for another venue.)\n\nDescription:\n\nThis paper proposes a method to identify, from a manifold embedding solution, data points that may be stuck in a bad local minimum. The idea is to temporarily allow such points an extra embedding dimension, and evaluate how much the point would like to move away from its current position along that dimension. Examples are shown for Stochastic Neighbor Embedding (SNE), t-distributed SNE, and Elastic Embedding. Moreover, the paper proposes to temporarily provide such points the extra dimension during optimization, so that regularization makes the extra dimensions vanish at the end.\n\nThe identification of pressured points is demonstrated for COIL-20 and MNIST data; for the same data sets it is demonstrated that the optimization with temporary extra dimensions for pressured points speeds up convergence for the methods.\n\nEvaluation:\n\nBetter optimization and avoiding local minima are important topics in dimensionality reduction, hence the paper addresses an important issue. The paper is well written, and methodologically it seems sound, although it seems the analyses are somewhat specific to the particular dimensionality reduction methods considered, and was is not clear enough if the same can be done for any method (or if not for any method, for which types of cost functions?).\n\nThe concept of pressure seems to me to be related to computing the contributions of individual data items in decomposable (or approximately decomposable) objective functions. Decomposition of neighbor embedding cost functions to individual point contributions is used in evaluation frameworks like CheckViz of Lespinats and Aupetit (2011) to identify local areas in dimensionality reduction that contain distortion: such decomposition simply takes advantage of the fact that neighbor embedding cost functions are typically sums over pairwise terms, although it may not take into account roles of the data items in normalization terms of distributions.\nAs a difference to evaluation frameworks like CheckViz of Lespinats and Aupetit (2011), authors state that some cost functions are not easily decomposed, and that large objective function alone does not indicate being stuck in a local minimum. However,\n- The examples of SNE/t-SNE objective functions seem a bit weak, though - aren't they composed of a sum of pairwise terms, where each pairwise term is complicated but is still mostly dominated by corresponding pairwise distance?\n- It is unclear how often, in neighbor embedding applications, the optimized solution would involve a pairwise term that has a high cost but is *not* be stuck in a local minimum. In methods such as SNE, a local objective function value directly denotes difference from gold standard neighborhoods, which are achievable in a high enough dimensional space assuming the original neighborhoods arise from high-dim. coordinates; thus any point having a nonzero local cost should have \"pressure\" to improve.\n- Authors mention that a point could be \"on its way\" to a local minimum: ok, but this should primarily happen during optimization, not at the end of it? (if so, clarify).\n- No experimental comparisons to other methods (like CheckViz) are done.\n\n\nFor the demonstration of identifying pressured points for embedding quality analysis, it is somewhat unclear how strong conclusions can be drawn, since there is no gold standard and no comparison to any other way of identifying badly optimized points. Authors do describe the findings, but it is unclear whether this method yields better identification than e.g. CheckViz or similar approaches.\n\nFor the optimization experiments, two data sets is a too small amount, and differences in the final output quality are not visually very strong; however, the speed advantage does seem notable and useful.\n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}