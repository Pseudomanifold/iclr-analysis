{"title": "Review", "review": "The paper proposes simple modifications to GAN architecture for unsupervised conditional image generation. The authors achieve this by making the distribution of noise z dependent on variable y that can depend on the label distribution when available. This involves learning to predict the input noise z as well as y from the generated image. The qualitative results shown for unsupervised conditional image generations using the approach are convincing. \n\nPros:\n\t- The paper is well written and easy to follow.\n\t- The simple modification to the noise distribution leads to good results on unsupervised conditional image generation.\n\t- Minimizes loss terms exactly instead of lower bound as is commonly done in other similar unsupervised approaches.\n\t- Theoretical justifications for the approach are convincing.\n\nCons:\n\t- The paper can be strengthened by including ablation studies on the loss term for the z reconstruction.\n\t- How will InfoGAN and VEEGAN compare with similar loss terms for the z reconstruction added to their objective?\n\t- It will be useful to show FID and other similar scores to better evaluate the learned generative model. Including mode counting, experiments will strengthen the paper.\n\t- ACGAN can suffer from the issue of generating images where it is easy to infer y [1]. This leads to mode collapse within each category/class. Will the proposed approach suffer from similar issues?\n\n[1] Shu, Rui, Hung Bui, and Stefano Ermon. \"AC-GAN Learns a Biased Distribution.\"", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}