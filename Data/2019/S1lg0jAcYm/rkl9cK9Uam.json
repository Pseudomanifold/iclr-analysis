{"title": "An interesting paper with the potential to inspire many possible extensions, but overly complicated presentation (addressed in review).", "review": "In this paper the authors propose a new variance-reduction technique to use when computing an expected loss gradient where the expectation is with respect to independent binary random variables, e.g. for training VAEs with a discrete latent space. The paper is interesting, highly relevant, simple to implement, suggests many possible extensions, and shows good results on the experiments performed. However the exposition leaves a lot to be desired.\n\nMajor comments:\n\nThe authors devote several pages of fairly dense mathematics to deriving the ARM estimate in section 2 (up to section 2.5). However I found it relatively easy to derive (15) directly, using elementary results such as the law of total expectation and a single 1-dimensional integral, in about 10 lines of equations. As the authors note, deriving (4) from (15) requires an extra line or two. In my opinion it would greatly improve the clarity of the paper to use a more direct and straightforward derivation (perhaps with the interesting historical account of how the authors first derived this result given in an appendix). I could understand the more lengthy derivation being helpful if it gave insight into the source of variance reduction, but I don't see this personally, and the current discussion of variance reduction does not refer to the derivation of (15) at all.\n\nThe analysis of variance in section 2.6 leaves a lot to be desired. The central claim of the paper is that this method reduces variance, so it is an important section! Firstly, the variance of ARM vs AR is interesting, but the variance of ARM vs REINFORCE seems also highly relevant. Secondly, it seems like it would be very informative to look at the ratio of stdev to the mean for the ARM gradient estimate, since the true gradient is multiplied by sigmoid(phi) sigmoid(-phi) and so is very small if the probability of z = 1 is close to 0 or 1, exactly in the same regime where ARM has an advantage in variance reduction over AR. For example, it may be that learning in this regime is very difficult due to the weak gradient even if the estimate is extremely low variance. Thirdly and somewhat relatedly, in this same regime (z = 1 close to 0 or 1) the ARM gradient estimate is very often 0, meaning no learning takes place, so it seems a bit strange to argue that the new method is fantastic in the regime where it's almost always not learning! Of course, not learning is better than adding lots of spurious variance as reinforce would, but perhaps this could be made clearer. Finally, the theoretical analysis involving correlation gives very little insight and is extremely hand-wavy. A short worked example in the 1D or 2D case explicitly computing the variance of REINFORCE, AR and ARM seems like it would be highly informative.\n\nMinor comments:\n\nIn the introduction, \"*approximately* maximizing the marginal likelihood\" might be more accurate, since as given in (28) the exact marginal likelihood is not optimized in practice, and the exact marginal likelihood is not of the form (1) but is rather the logarithm of something of the form (1).\n\nI wasn't clear why \"equal in distribution\" was used a few things for things that are simply equal, such as just above (5).\n\nIn section 2.3, I don't see any real reason the estimates in (9) and (11) \"could be highly positively correlated\", other than an argument along the lines of the simple one given in section 2.6 that they're often equal and so zero.\n\nAs an aside, in section 3.1, it is great not to assume conditional independence of the binary latent variables across layers, but assuming conditional independence within each layer is still very restrictive. It is reasonable for the generative distribution to have this property, since the resulting net can still be essentially \"universal\" by stacking enough layers, but assuming this factorization in the variational distribution is highly restrictive with hard-to-reason-about consequences for the learned generative model. I realize this is a commonly used assumption and the authors are interested in the variance reduction properties of their approach rather than the training itself, but I just mention that it would be great to see extensions of the current work that can cope tractably with correlated latent variables within each layer.\n\nIn section 3.2, according to my understanding of standard terminology, \"maximum likelihood inference\" is a misnomer and would normally be \"maximum likelihood estimation\", since maximum likelihood is a method for estimating parameters whereas inference is about inferring latent variable values given parameters.\n\nIn section 4, it would be great to see some plots of explicit variance estimates of the different methods, given the overall goal of the paper (unless I just missed this?), even though figure 1 gives some insight into the variance characteristics.\n\nIn section 4.2, the expression log 1/K \\sum_k Bernoulli... differs in the placement of log from Jang et al (2017). Which is the standard convention for this task?", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}