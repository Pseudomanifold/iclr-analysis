{"title": "Limited technical novelty", "review": "This paper proposes a spatio-temporal 3D translator for the unsupervised image-to-image translation task and a new CT-to-MRI volumetric images translation dataset for evaluation. Results on different datasets show the proposed 3D translator model outperforms per-frame translation model.\n\nPros:\n* The proposed 3D translator can utilize the spatio-temporal information to keep the translation results consistent across time. Both color and shape information are preserved well. \n* Extensive evaluation are done on different datasets and the evaluation protocols are designed well. The paper is easy to follow.\n\nCons:\n* The unsupervised video-to-video translation task has been tested by previous per-frame translation model, e.g. CycleGAN and UNIT. Results can be found on their Github project page. Therefore, unsupervised video-to-video translation is not a new task as clarified in the paper, although this paper is one of the pioneers in this task. \n* The proposed 3D translator extend the CycleGAN framework to video-to-video translation task with 3D convolution in a straightforward way. The technical novelty of the paper is limited for ICLR.  I think the authors are working on the right direction, but lots of improvement should be done.\n* As to Table 4, I am confused about the the per-frame pixel accuracy results. Does the 3D method get lower accuracy than 2D method?\n* As to the GTA segmentation->video experiments, the 3D translator seems cause more artifacts than the 2D method (page 11,12). Also, the title of the figure on page 11 should both be \u201cGTA segmentation->video\u201d\n\nOverall, the technical innovation of this paper is limited and the results are not good enough. I vote for rejection.", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}