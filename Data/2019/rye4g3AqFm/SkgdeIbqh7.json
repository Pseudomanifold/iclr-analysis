{"title": "Interesting perspective but most relevant experiments are on very tiny networks", "review": "This paper propose an interesting perspective to explain the generalization behaviors of large over-parameterized neural networks by saying that the parameter-function map in neural networks are biased towards \"simple\" functions, and through a PAC-Bayes argument, the generalization behavior will be good if the target concept is also \"simple\". I like the perspective of view that combines the \"complexity\" of both the algorithm bias and the target concept in the view of generalization. However, the implementation and presentation of the paper could be improved.\n\nFirst of all, the paper is a bit difficult to follow as some important information is either missing or only available in the appendix. For example, in Section 2, to measure the properties of the parameter-function mapping, a simple boolean neural network is explored. However, it is not clear how the sampling procedure is carried out. There is also a 'training set of 64 examples', and it not obvious to the reader how this training set is used in this sample of neural network parameters.\n\nFollowing that, the paper uses Gaussian Process and Expectation-Propagation to approximately compute P(U). But the description is brief and vague (to non-expert in GP or EP). As one of the main contribution stated in the introduction, it would be better if more details are included.\n\nMoreover, the generalization bound is derived with the assumption that the learning algorithm uniformly sample from the set of all hypothesis that is consistent with a given training set. It is unlikely that this is what SGD is doing. But explicit experiments to verify how close is the real-world behavior to the hypothetical behavior would be helpful.\n\nThe experiment in section 6 that verify the 'complexity' of 'high-probability' functions in the given prior is very interesting. It would be good if some kind of measurements more directly on the real world tasks could be done, which will better support the argument made in the paper.\n", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}