{"title": "Official review for GENERATING MULTIPLE OBJECTS AT SPATIALLY DISTINCT LOCATIONS", "review": "This paper proposed a model to generate location-controllable images built upon GANs. The experiments are conducted on several datasets. Although this  problem seems interesting, here are several concerns I have:\n\n1.Novelty: the overall framework is still conditional GAN framework. The multiple -generators-discriminators structure has been used in many other works (see the references). The global-local design is not new. Finally, compared with Reed et al. [2016], the novelty is limit. \n\n2.Motivation: I still can not tell why the proposed method is better than ones with scene layout. For me, the cost of collecting annotated data is almost the same. \n\n3. The experimental results are week.  For such a task, it is difficult to find a good metric. Thus the qualitative comparison is important. I think the author should follow standard rule to do some design for user study instead of cherry pick some examples. Besides, it should include more baselines instead of StackGAN. \n\nReferences: \na. Xi et al. Pedestrian-Synthesis-GAN: Generating Pedestrian Data in Real Scene and Beyond\nb. Yixiao et al. FD-GAN: Pose-guided Feature Distilling GAN for Robust Person Re-identification\n\nRevision:\nThanks for the work of the authors' and all the reviewers. I spent sometime reading the rebuttal as well as the revised paper. It addressed most of my concern. I would like to change my rating from 5 to 6. ", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}