{"title": "missing important related works, careless writing and insufficient evaluation", "review": "This paper introduces a generalization of convolution operations to manifold-valued data using  the computation of the weighted Frechet mean (wFM). Without applying any non-linear units and pooling layers, the paper proposes to merely stack suching generalized convolutional layers to construct a deep network for the data residing on Riemannian manifolds. The evaluations on video classification and reconstruction tasks show the advantages of the introduced network over some baselines. \n\nThe paper\u2019s major contribution is using wFM to generalize the traditional convolution for manifold-valued data.  Accordingly, the critical technical contribution is to estimate the wFM. The paper suggests a inductive/recursive way for the wFM approximation. To the best of my knowledge, there already exist some inductive/recursive wFM estimation methods like [1,2]. Unfortunately, the authors seem to overlook them and do not discuss them at all. Accordingly, I think the paper missed some important related works for sufficient study.\n\n[1] Y. Lim and M. Pa \u0301lfia. Weighted inductive means .LAA, 453:59\u201383, 2014.\n[2] Hesamoddin Salehian et al., An efficient recursive estimator of the Fre \u0301chet mean on a hypersphere with applications to Medical Image Analysis, Mathematical Foundations of Computational Anatomy. 2015.\n\nDue to the inconsistent fonts, chaotic layout it is really hard for the readers to follow the content of the paper. I feel like the paper seems to be completed in the last minute. This brings another critic problem, it is not easy to reimplement the wFM layers, which is the core contribution of the paper. For instance, the paper claims that they used intrinsic Riemannian metric when using wFM to convolve the manifold-valued data. I guess it is involved in \\Gamma_X^Y (Eq.2) which is explained as the shortest curve from X to Y. Anyway it fails to describe what kind of intrinsic metric they used for the specific manifold-valued data like SPD matrices and linear subspace. In addition, is it \\Gamma_{M_{n-1}}^{X_n} rather than \\Gamma_{M_{n-1}}^{X_M} for Eq.(2)? \n\nAnother problem is the evaluations are far from sufficient. For video classification, the paper only uses the moving MNIST, which is not a challenging dataset while there are plenty of large scale video datasets. In addition, the paper is expected to compare SOTA video classification methods. To learn the advantage of the proposed network over some related manifold networks like Huang et al., 2016, Huang & Van Gool 2017, it is necessary to evaluate them in the experiments.  For video reconstruction, using 1000 frame color sample of video is also not sufficient to study the effectiveness of the proposed ManifoldNet. Furthemore, it is also expected to compare more SOTA auto-encoder based reconstruction models like VAE [3], AAE [4]  and WAE [5].\n\n[3] Kingma et al., Auto-encoding variational bayes, 2013\n[4] Makhzani et al., Adversarial autoencoders, 2015\n[5] Wasserstein auto-encoders, 2017\n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}