{"title": "More intuitions and insights are required to understand the proposed method", "review": "This paper presents a new meta-learning framework that learns data-dependent latent space and performs fast adaptation in the latent space. To this end, an encoder that maps data to latent codes and a decoder that maps latent codes to parameters are also learned. Experimental results demonstrate its effectiveness for few-shot learning.\n\nInterestingly, the initialization for adaptation is task-dependent, which is different from conventional MAML-like methods. Furthermore, the results on multimodal few-shot regression seems to show that it works well for multimodal task distribution, which is important for generalization of meta-learning. However, there are quite a few questions that are less clear and require more discussions and insights. \n\n1. Since this work relies heavily on an encoding process and a decoding process, more details and discussions on the design and requirement of the encoder and decoder are necessary. Particularly, the inclusion of a relation network in the encoding process seems ad hoc. More explanations may be helpful. \n\n2. It is less clear why this method can deal with multimodal task distribution as shown in the regression experiment. Is it related to the data-dependent model initialization?\n\n3. It applies meta-learning in a learned latent space, which seems quite related to a recent work, Deep Meta-Learning: Learning to Learn in the Concept Space, Arxiv 2018, where meta-learning is performed in a learned concept space. A discussion on its difference to this prior work seems necessary. ", "rating": "6: Marginally above acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}