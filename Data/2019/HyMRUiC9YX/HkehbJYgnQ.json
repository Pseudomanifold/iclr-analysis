{"title": "Enhancing the Transferability of Adversarial Examples with Smoothed Gradient Attacks", "review": "Summary. The authors empirically investigate the influence of the architecture and the capacity of an NN-model on the transferability of adversarial examples. They also study the influence of the smoothness. From the obtained results, they propose the smoothed gradient attack showing improvements on the transferability of adversarial examples.\n\nPros.  \n* Robustness of neural nets is a challenging problem of interest for ICLR\n* The paper is well written\n* The experimental study is convincing\n* The experimental results for the smoothed gradient attacks are promising\n\nCons.\n* The results of the experimental study are somehow expected\n* the idea of smoothing gradients is not new\n\nEvaluation.\nThe experimental study of the transferability of adversarial examples is well designed. Experimental protocol is convincing. The smoothed gradient attacks improve many previously proposed attacks. Therefore, my opinion is rather positive. But, as a non expert in the field, I am not completely convinced by the novelty of the approach.\n\nSome details.\nTypos: That l8 abstract; systems l9 intro; and l2 related work; directly evaluation l2 Section4, must has l-10 p4; \n* the choice \\sigma = 15 in Section 6.2 should be justified by the following study\n* \\sigma is not given in Figure 3(a)", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}