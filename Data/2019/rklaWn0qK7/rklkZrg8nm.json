{"title": "Interesting, well-written paper", "review": "==Summary==\nThis paper is well-executed and interesting. It does a good job of bridging the gap between distinct bodies of literature, and is very in touch with modern ML ideas. \n\nI like this paper and advocate that it is accepted. However, I expect that it would have higher impact if it appeared in the numerical PDE community. I encourage you to consider this conference paper to be an early version of a more comprehensive piece of work to be released to that community.\n\nMy main critique is that the paper needs to do a better job of discussing prior work on data-driven methods for improving PDE solvers.\n==Major comments==\n* You need to spend considerably more space discussing the related work on using ML to improve PDE solvers. Most readers will be unfamiliar with this. You should explain what they do and how they are qualitatively different than your approach. \n\n* You do a good job 3.3 of motivating for what H is doing. However, you could do a better job of motivating the overall setup of (6). Is this a common formulation? If so, where else is it used?\n* I\u2019m surprised that you didn\u2019t impose some sort of symmetry conditions on the convolutions in H, such as that they are invariant to flips of the kernel. This is true, for example, for the linearized Poisson operator. \n\n==Minor comments==\n\n* Valid iterators converge to a valid solution. However, can\u2019t there be multiple candidate solutions? How would you construct a method that would be able to find all possible solutions?\n\n* In (9), why do you randomize the value of k? Wouldn\u2019t you want to learn a different H depending on what computation budget you knew you were going to use downstream when you deploy the solver? \n\n* In future work it may make sense to learn a different H_i for each step i of the iterative solver. \n\n* When introducing iterative solvers, you leave it as an afterthought that b will be enforced by clamping values at the end of each iteration. This seems like a pretty important design decision. Are there alternatives that guarantee that u satisfies b always, rather than updating u in such a way that it violates G and then clamping it back? Along these lines, it might be useful to pose (2) with additional terms in the linear system to reflect G. \n", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}