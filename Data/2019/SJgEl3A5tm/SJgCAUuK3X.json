{"title": "Physical adversarial attack on object detectors is interesting.", "review": "This is an interesting paper targeting adversarial learning for interfering car detection. The approach is to learn camouflage patterns, which will be rendered as a texture on 3D car models in urban and mountain scenes, that minimizes car detection scores by Mask R-CNN and YOLOv3-SPP.\n\nDifferent from image-based adversarial learning, this paper examines whether 3D car textures can degrade car detection quality of recent neural network object detectors. This aspect is important because the learned patterns can be used in the painting of real-world cars to avoid automatic car detection in a parking lot or on a highway.\n\nThe experimental results show that the car detection performance significantly drops by learned vehicle camouflages.\n\n Major comments:\n\n- It is not clear how learned camouflage patters are different in two scenes. Ideally, we should find one single camouflage patter that can deceive the two or more object detection systems in any scenes.\n\nMinor comments:\n\n- In abstract, it is not good that you evaluated your study as \"interesting\". I recommend another word choice.\n", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}