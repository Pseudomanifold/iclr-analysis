{"title": "Interesting approach for removing bias while learning sentence representation", "review": "This paper presents a method for removing bias of a textual entailment model through an adversarial training objective. While existing textual entailment datasets such as SNLI have been crucial for driving research on natural language inference and universal sentence representations, recent work showed that models only processing the hypothesis can achieve 67% accuracy, indicating that such models heavily exploit biases in the dataset. To mitigate these biases, the authors propose to let the model predict the label both from the premise-hypothesis representation and the hypothesis-only representation. On the backward pass, the sign of the gradient going into the hypothesis-only representation is flipped, making that representation invariant to biases that would otherwise allow for predicting the entailment label from the hypothesis only. The paper is written very clearly and the analysis of the methods is thorough. The method itself is a fairly simple trick and one could argue that, overall, this is incremental work. However, in my view learning less biased sentence representations is very relevant to the community and this paper is executed well. Particularly the improvements on the variety of downstream task compared to InferSent are impressive. I would be interested in hearing whether the authors have suggestions for applying similar techniques to entailment models that do not build up a specific premise and hypothesis representation (e.g. attention-based methods proposed for SNLI).", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}