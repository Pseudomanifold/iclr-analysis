{"title": "Interesting ideas that need further refinement", "review": "Summary:\n\nThis paper proposes maximizing the \u201creflective likelihood,\u201d which the authors define as: E_x E_y [log q(y|x) - \\alpha log q(y)] where the expectations are taken over the data, q is the classifier, and \\alpha is a weight on the log q(y) term.  The paper derives the reflective likelihood for classification models and unsupervised latent variable models.  Choices for \\alpha are also discussed, and connections are made to ranking losses.  Results show superior F1 and perplexity in MNIST classification and 20NewsGroups modeling.\n\nPros:\n\nI like how the paper frames the reflective likelihood as a ranking loss.  It does seem like subtracting off the marginal probability of y from the conditional likelihood should indeed \u2018focus\u2019 the model on the dependent relationship y|x.  Can this be further formalized?  I would be very interested in seeing a derivation of this kind.    \n\nI like that the authors test under class imbalance and report F1 metrics in the experiments as it does seem the proposed method operates through better calibration.\n\nCons:\n\nMy biggest issue with the paper is that I find much of the discussion lacks rigor.  I followed the argument through to Equation 3, but then I became confused when the discussion turned to \u2018dependence paths\u2019: \u201cwe want our learning procedure to follow the dependence path\u2014the subspace in \u0398 for which inputs and outputs are dependent. However this dependence path is unknown to us; there is nothing in Eq. 1 that guides learning to follow this dependence path instead of following Eq. 3\u2014the independence path\u201d (p 3).  What are these dependence paths?  Can they be defined mathematically in a way that is more direct than switching around the KLD directions in Equations 1-3?  Surely any conditional model x-->y has a \u2018dependence path\u2019 flowing from y to x, so it seems the paper is trying to make some stronger statement about the conditional structure?\n\nMoving on to the proposed reflective likelihood in Equation 4, I could see some connections to Equations 1-3, but I\u2019m not sure how exactly that final form was settled upon.  There seems to be a connection to maximum entropy methods?  That is,   E_x E_y [log q(y|x) - \\alpha log q(y)] = E_x E_y [log q(y|x)] + \\alpha E_y [ -log q(y)] \\approx E_x E_y [log q(y|x)] + \\alpha H[y], if we assume q(y) approximates the empirical distribution of y well.  Thus, the objective can be thought of as maximizing the traditional log model probability plus an estimate of the entropy.  As there is a long history of maximum entropy methods / classifiers, I\u2019m surprised there were no mentions or references to this literature.  Also, I believe there might be some connections to Bayesian loss calibration / risk by viewing \\alpha as a utility function (which is easy to do when it is defined to be data dependent).  I\u2019m less sure about this connection though; see Cobb et al. (2018) (https://arxiv.org/abs/1805.03901) and its citations for references.   \n\nThe data sets used in the experiments are also somewhat dissatisfying as MNIST and 20NewsGroups are fairly easy to get high-performing models for.  I would have liked to have seen more direct analysis / simulation of what we expect from the reflective likelihood.  As I mentioned above, I suspect its really providing gains through better calibration---which the authors may recognize as F1 scores are reported and class imbalance tested---but the word \u2018calibration\u2019 is never mentioned.  More direction comparison against calibration methods such as Platt scaling would be make the experiments have better focus.  It would be great to show that this method provides good calibration directly during optimization and doesn\u2019t need the post-hoc calibration steps that most methods require. \n\nEvaluation:  While the paper has some interesting ideas, they are not well defined, making the paper unready for publication.  Discussion of the connections to calibration and maximum entropy seems like a large piece missing from the paper\u2019s argument.  ", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}