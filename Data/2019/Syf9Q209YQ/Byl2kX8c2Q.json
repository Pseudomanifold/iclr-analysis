{"title": "Interesting Approach with Good Results", "review": "Review for MANIFOLD REGULARIZATION WITH GANS FOR SEMISUPERVISED LEARNING\nSummary:\nThe paper proposed to incorporate a manifold regularization penalty to the GAN to adapt to semi-supervised learning. They approximate this penalty empirically by calculating stochastic finite differences of the generator\u2019s latent variables. \nThe paper does a good job of motivating the additional regularization penalty and their approximation to it with a series of experiments and intuitive explanations. The experiment results are very through and overall promising. The paper is presented in a clear manner with only minor issues. \nNovelty/Significance:\nThe authors\u2019 add a manifold regularization penalty to GAN discriminator\u2019s loss function. While this is a simple and seemingly obvious approach, it had to be done by someone. Thus while I don\u2019t think their algorithm is super novel, it is significant and thus novel enough. Additionally, the authors\u2019 use of gradients of the generator as an approximation for the manifold penalty is a clever.\nQuestions/Clarity:\nIt would be helpful to note in the description of Table 3 what is better (higher/lower). Also Table 3 seems to have standard deviations missing in Supervised DCGANs and Improved GAN for 4000 labels. And is there an explanation on why there isn\u2019t an improvement in the FID score of SVHN for 1000 labels?\nWhat is the first line of Table 4? Is it supposed to be combined with the second? If not, then it is missing results. And is the Pi model missing results or can it not be run on too few labels? If it can\u2019t be run, it would be helpful to state this.\nOn page 11, \u201cin Figure A2\u201d the first word needs to be capitalized. \nIn Figure A1, why is there a dark point at one point in the inner circle? What makes the gradient super high there?\nWhat are the differences of the 6 pictures in Figure A7? Iterations?\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}