{"title": "Insufficient clarity", "review": "REVISION: thanks for the clarification. I have slightly increased my rating (to 4).\n\nThis paper tackles a very interesting subject but lacks sufficient clarity of presentation to allow me to do a proper review.\n\nFirst, there are many sentences which are not well-formed or are ambiguous (in pretty much all the sections). Then there are terms which are introduced without being first clearly explained or defined. Finally, there are issues with the mathematical clarity as well, with many notations which are used without being explained or defined. Sometimes one can figure out the missing information later (e.g., fig 1 talks about mutual information objectives without stating if we want to maximize or minimize it, but later in the text we figure that out) but it makes reading very difficult.\n\nWhat is a 'transformed one' (on page 2)\nWhat is a 'geometric intrinsic reward'?\nWhere are the intrinsic rewards defined?\nWhat is a 'non-parametric classifier'? A neural net? an kernel SVM?\n\nThere are also some mathematical problems:\n- if f (page 3) has a discrete output, then it will probably lose information, so it cannot be inverted (contrary to the stated assumption that f(x)!=f(y) for x!=y)\n- what are the differences between the different Q functions being defined? do the correspond to different action spaces? What is Q_task? What is pi_meta?\n- in eqn 2, I do not think that the log q_c term maximizes the mutual information between actions and (G(t),G(t+1)), i.e. it would be missing an entropy term\n- what is Z_c in eqn 2?\n\n", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}