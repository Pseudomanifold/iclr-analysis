{"title": "Needs refinement", "review": "This paper introduces and details a new research framework for reinforcement learning called Dopamine. The authors give a brief description of the framework, built upon Tensorflow, and reproduce some recent results on the ALE framework. \n\nPros:\n1. Nice execution and they managed to successfully reproduce recent deep RL results, which can be challenging at times.\n\nCons:\n1. Given that this is a paper describing a new framework, I expected a lot more in terms of comparing it to existing frameworks like OpenAI Gym, RLLab, RLLib, etc. along different dimensions.  In short, why should I use this framework? Unfortunately, the current version of the paper does not provide me information to make this choice. Other than the framework, the paper does not present any new tasks/results/algorithms, so it is not clear what the contribution is.\n\n\nOther comments:\n1. The paragraphs in sections 2.1 and 2.2 (algorithmic research, architecture research, etc.) seem to say pretty much the same things. They could be combined, and the DQN can be used as a running example to make the points clear.\n2. The authors mention tests to ensure reliability and reproducibility. Can you provide more details? Do these tests account for semantic bugs common while implementing RL algorithms?", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}