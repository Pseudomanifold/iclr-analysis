{"title": "classifier-agnostic method for object localization", "review": "This paper proposes a classifier-agnostic method for saliency map extraction. In order to address the dependence of saliency map extraction on the classifier, the authors propose to learn a saliency mapping by considering all possible classifiers (i.e., a certain classifier structure w.r.t. the space of all its parameters). The goal is to find the relevant features in the data that work with all possible classifiers. The proposed framework is formulated as a min-max game between two players: a mask m corresponding to the saliency mapping, and a function f sampled from a set of classifiers with the same structure but different parameters. The mapping m is optimized to maximize the masked-out classification error (such that m captures all relevant features whose removal can maximally confuse the classifier), while f is optimized to minimize the mask-out classification error.\n\nThe idea of how to formulate the classifier set and how to sample from the set is interesting. However, I have some concerns regarding the overall model:\n\n1) It seems not quite convincing to me why the model should involve an adversarial game. In particular, why f should be optimized to minimize the masked-out classification error? I understand that by doing this, f has an opposite goal with m so as to force m to capture as many relevant features as possible. However, I do not think f has a natural motivation to minimize the maxed-out error. In my opinion, it seems more convincing if f is optimized to minimize the masked-in classification error, but not necessarily the masked-out one. I think this also explains why the model works better by adding the classification loss over original images in Eq. (8). Would it be more natural if we optimize both f and m to minimize the masked-in classification error? And it would easier to train compared with the min-max model. Maybe some more explanation on the motivation of such an adversarial game can be helpful.\n\n2) I was curious whether the alternating optimization of m and f would cause the cumulation of errors? I mean, if in some iteration m just captures irrelevant features, f will still be optimized to accomodate to such a bad mapping. Would such kind of error accumulate during training?\n\n3) In Algorithm 1, after \\theta_m is learned, how is m is determined?", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}