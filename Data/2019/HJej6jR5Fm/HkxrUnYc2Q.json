{"title": "Unclear presentations, limited novelty.", "review": "Summary:\nThis paper proposed a few-shot learning approach for interactive segmentation. Given a set of user-annotated points, the proposed model learns to generate dense segmentation masks of objects. To incorporate the point-wise annotation, the guidance network is introduced. The proposed idea is applied to guided image segmentation, semantic segmentation, and video segmentation.\n\nClarity:\nOverall, the presentation of the paper can be significantly improved. First of all, it is not clear what the problem setting of this paper is, as it seems to have two sets of training data of fully-annotated images (for training) and the combined set of point-wise annotated images and unannotated images (guidance images T in the first equation); It is not clear whether authors generate the second dataset out of the first one, or they have separate datasets for these two. Also, it is not clear how the authors incorporate the unannotated images for training. \n\nThe descriptions on model architecture are also not quite clear, as it involves two components (g and f) but start discussing with g without providing a clear overview of the combined model (I would suggest changing the order of Section 4.1 and Section 4.2 to make it clearer). The loss functions are introduced in the last part of the method, which makes it also very difficult to understand. \n\nOriginality and significance:\nThe technical contribution of the paper is very limited. I do not see many novel contributions in terms of both network architecture and learning perspective.\n\nExperiment:\nOverall, I am not quite convinced with the experiment results. The method is compared against only a few (not popular) interactive segmentation methods, although there exist many recent works addressing the same task (e.g. Xu et al. 2016). \n\nThe experiment settings are also not clearly presented. For instance, what is the dataset used for the evaluation of the first paragraph in section 5.1? How do you split the Pascal VOC data to exclusive sets? How do you sample point-wise annotation from dense mask labels? How does the sampling procedure affect the performance? \n\nThe performance of the guided semantic segmentation is also quite low, limiting the practical usefulness of the method. Finally, the paper does not present qualitative results, which are essential to understanding the performance of the segmentation system. \n\nMinor comments:\n1. There are a lot of grammar issues. Please revise your draft.\n2. Please revise the notations in equations. For instance, \n    T = {{(x_1, L_1),...} \\cup {\\bar{x}_1,...}\n    L_s = {(p_j,l_j):j\\in{1,...,P}, l\\in{1,...,K}\\cup{\\emptyset}}\n    Also, in the next equation, j\\in\\bar{x}_q} -> p_ j\\in\\bar{x}_q} (j is an index of pixel)\n", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}