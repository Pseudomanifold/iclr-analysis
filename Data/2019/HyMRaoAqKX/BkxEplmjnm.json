{"title": "Increasing the expressiveness of decoder by an implicit decoder looks interesting, and it enables the decompositions of high-level abstract information from low one.", "review": "The paper proposed an implicit auto-encoder, featuring both the encoder and decoder constituted by implicit distributions. Adversary training is used train the models, similar to the technique used in the AVB model. The main difference with AVB is the use of an implicit decoder, which endows the model with the ability to disentangle the data into high-level abstract representation and local representation. Although sharing some similarities, the extension of using implicit decoder is interesting, and leading to some interesting results. \n\nMy main concern on this paper is the lack of any quantitive results to compare with other similar models. We only see the model can do some task, but cannot assess how well it did comparing to other models.", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}