{"title": "Interesting ideas, but needs a few more justifications for certain modeling choices over others", "review": "Summary:\nThis paper effectively learns a variant of a Deep Value Network (Gygli et al 2017), a model consisting of an energy network that assigns scores to input-output tuples that is trained to mimic a task-specific loss. The primary differences between the model presented in this work (titled LDRSP) and DVNs are twofold: first, the initial label prediction used at test time for inference is the output of a model rather than being initialized to all zeros. Second, a GAN-inspired loss is used to train both the scoring function and the initial prediction estimator. This new setup is compared against a variety of recent structured prediction methods on the tasks of multilabel classification, semantic segmentation, and 3-class face segmentation.\n\nComments:\nI think the ideas presented in this paper are interesting, but I think their presentation could be a bit clearer. As mentioned in the summary, what you\u2019re presenting is still more or less a deep-value network with some additions - however, you don\u2019t refer to it as such in the body of the paper anywhere I saw. The first addition is the use of a learned model to produce the initial prediction; this is a natural extension to Deep Value Networks, and on its own is somewhat incremental in nature. I do not think you adequately explained why you chose to use a GAN-like loss to learn these models. Another baseline that would have helped justify its use would be to train your G model to predict structured outputs in the standard way (max-margin or cross-entropy loss) and then train your energy function in the DVN way. \n\nThe experimental settings are somewhat small in scope but follow the precedent set by previous structured prediction papers, which is fine. You make appropriate comparisons against previous structured prediction models as well as against different types of GAN-like losses. But, as I mentioned before, I think you needed to have more comparisons against different ways of training these networks that do not follow a GAN-inspired framework. \n\nOverall, I like the new ideas in this paper but I think a few more experimental settings are required before they should be published.\n\n=== after rebuttal ===\n\nI appreciate the response, but I still think further analysis of the model is needed to understand where the gains in performance are coming from. The claim is that this is due to the adversarial loss used, but without further ablations I feel this is too strong a claim to be making given the current evidence.\n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}