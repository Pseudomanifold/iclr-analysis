{"title": "Results are interesting but lack of novelty in the methodology", "review": "I didn\u2019t worked in the field of structure elucidation from NMR spectroscopy so I might missed something. This paper utilized Siamese neural networks (Bromley 1993) and contrastive loss (Hadsell et al 2006) to learn a latent representation from the NMR spectra, which can be used for similarity search and the most similar compounds will be able to shad some light for the structures of the unknown natural product. The experiments showed significant improvement (AUC under precision-recall curve) over competitors. \n\nMy main concern is the lack of novelty in the methodology. The formulation is the same as Hadsell et al 2006 and the only change is an coefficient added to a loss term which kept to be fixed without explanation. As a result, I don\u2019t feel this is enough to make it publishable at ICLR.  \n\nSome detailed comments below:\n1. In eq(3), why P = 1.5? Some intuition or explanation?\n2. I spent some time understanding the evaluation method in Section 4.2 and still not very sure I understand it. What is the formulae to compute your Tanimoto scores? Is this the same as PubChem Tanimoto scores which depends on fingerprints?\n3. There is a formatting issue for the prediction and recall formulae.\n4. I know in the computational mass spectrometry community there was an recent paper, \u201cCritical Assessment of Small Molecule Identification 2016: automated methods\u201c where the winners were predicting the molecular fingerprints which directly shad the lights on the compound structures and can also be used for similarity searching, is this an option here for NMR data?", "rating": "3: Clear rejection", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}