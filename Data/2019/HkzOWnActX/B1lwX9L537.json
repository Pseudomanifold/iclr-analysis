{"title": "Official review", "review": "\nMuMoMAML: Model-Agnostic Meta-Learning for Multimodal Task Distributions\n\nThis paper proposed multi-modal MAML, which alleviates the single initialization limitation of MAML by modulating task prior with MAML. Below are some comments.\n\nPros:\n1. Overall, the paper is clear written. \n2. By using modulation, there is no need to explicitly control/know the number of modes in advance.\n3. The multi-MAML baseline is good for an ablation study, though it is only on a synthetic regression task.\n4. MUMOMAML combines the strength of both gradient-based and model-based meta-learners.\n\nCons.\n1. The novelty of the paper seems to be the combinations of MAML and FiLM, which seems a bit limited.\n2. I wonder whether the proposed method is mostly useful when there is a clear mode difference as in the synthetic regression/RL tasks of the paper. Moreover, the paper only shows tasks with only two-three modes, what happen when there is a large number of modes?\n3. What's the results on the mini-Imagenet? The Omniglot seems to be saturated already.\n4. Why tau is not updated in the inner loop of Algorithm 1?\n\nMinor:\n1. page 4, 'in to' -> 'into'\n2. In page 5, in 'based on the input data samples and then\ninfers the parameter to modulate the prior model', what does the `input data samples' refers to? Is it the training data of a meta-learning task?\n3. Do you stop gradient to the learner in MUMOMAML?", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}