{"title": "Layer-wise conditioning via task-embedding for meta-learning", "review": "Strengths:\n+ The paper identifies a valid limitation of the MAML algorithm: With a limited number of gradient descent steps from a single initialization, there is a limit to the ability of a fixed-size neural network to adapt to tasks sampled from a diverse dataset.\n+ The tSNE plots show some preliminary interesting structure for the simple regression and RL tasks, but not for the classification task.\n\nWeaknesses:\n- The motivation of uncovering latent modes of a task distribution does not align with the proposed method. The algorithm computes a continuous representation of the data from a task (which is fixed during gradient-based fast adaptation). The mode identity, on the other hand, should be a discrete variable.  Such a discrete variable is never explicitly computed in the proposed method.\n- The technical writing is unclear and jargon is often used without definition. Importantly, one of the central motivators of the paper, \"task modulation\", is never given a precise definition.\n- The standard few-shot classification task (Omniglot) does not clearly consist of a task distribution that is multimodal, so the method is not well-motivated in this setting.\n- Experimental conclusions are weak.\n\nMajor comments:\n- The paper neglects to discuss how the proposed method could be used in the context of other methods for \"gradient-based meta-learning\" such as Ravi & Larochelle (2016). I believe the attention-based modulation and the FiLM modulation could be easily adapted to that setting. Why was this not discussed or evaluated?\n- Conditioning has been used in the context of few-shot learning before, but this is not discussed (https://arxiv.org/abs/1805.10123, https://arxiv.org/abs/1806.07528).\n- The paper often confounds task representation with neural network parameter values. For example, Figure 1 depicts the adaptation of parameter values with gradients (\\nabla L), yet the caption describes \"task modes.\" More careful writing would disentangle these two components.\n- The motivation for the particular form of the task embedding computation is not given. What were the other options? Why not, for example, an order-invariant function instead of a bidirectional GRU?\n- In all of the experiments, there is no appropriate baseline that keeps the parameter dimensionality constant, so it is unclear whether the (marginal) improvement in performance is due to added expressivity by adding more parameters rather than an algorithmic improvement. I suggest an ensembling baseline with an appropriate number of ensemble members.\n- There is no evaluation on a standard benchmark for few-shot classification (miniImageNet), and the Omniglot improvement is small.\n- The reinforcement learning comparison at some point compares MUMOMAML with modulation applied (therefore with access to task-specific data) to MAML with no adaptation (and therefore no access to task-specific data). This is not entirely fair.\n- tSNE results can be misleading (e.g., see https://distill.pub/2016/misread-tsne/), and the task delineation is not extremely clean. I would be more convinced if a clustering algorithm were applied.\n\nMinor comments:\n- The paper needs to be checked over for English grammar and style.\n- everywhere: The \"prior\" referred to in this paper is not a prior in the Bayesian sense. I suggest a more careful use of terminology.\n- abstract: \"augment existing gradient-based meta-learners\" You augment a specific variant of gradient-based meta-learning, MAML.\n- pg. 1: \"carve on a snowboard\" don't know what this means\n- The terminology of \"task distribution\" and \"modes\" thereof is used without introduction in the introduction section. The terminology \"model-based meta-learning/adaptation\" and \"gradient-based meta-learning/adaptation\" is also used without introduction here. This makes the introduction unnecessarily opaque. Consider the reader who is not familiar with meta-learning papers; they would have a very hard time parsing, for example, the phrase \"...this not only requires additional identity information about the modes, which is not always available or is ambiguous when the modes are not clearly disjoint...\" (pg. 1).\n- Further, the terminology \"model-based\" seems non-standard, and is aliased with the term model-based reinforcement learning (which specifically refers to the set of RL algorithms that make use of a \"model\" of transition dynamics). Since the paper tackles a reinforcement learning benchmark, this may lead to some confusion.\n- pg. 3; \"our model does not maintain an internal state\" Is the task representation/embedding not an internal state?\n- pg. 3: \"relevant but vaguely related skills\" this is imprecise\n- pg. 3: The episodic training setup, which is standard to meta-learning setups, could be much better described. The MAML algorithm could be given better intuition.\n- everywhere: \"task specific\" -> task-specific\n- Algorithm 1: \"infer\" is a misuse of terminology that usually refers to an operation in latent variable probabilistic modelling. Since the computation of \\tau is purely feedforward, I recommend writing \"compute.\"\n- \\tau should be used in some places where v is used instead", "rating": "3: Clear rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}