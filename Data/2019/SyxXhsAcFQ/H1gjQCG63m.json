{"title": "Difficult to read, insufficient evaluation", "review": "This paper proposes autoencoder architectures based on Cohen-Welling bases for learning rotation-equivariant image representations. The models are evaluated by reconstruction error and classification in the space of the resulting basis on rotated-MNIST, showing performance improvements with small numbers of parameters and samples.\n\nI found most of this submission difficult to read and digest. I did not understand much of the exposition. I\u2019ll freely admit I haven\u2019t followed this line of work closely, and have little background in group theory, but I doubt I\u2019m much of an outlier among the ICLR audience in that regard. The \u201cPreliminaries\u201d section is very dense and provides little hand-holding for the reader in the form of context, intuition, or motivation for each definition and remark it enumerates. I can't tell how much of the section is connected to the proposed models. (For comparison, I skimmed the prior work that this submission primarily builds upon (Cohen & Welling, 2014) and found it relatively unintimidating. It gently introduces each concept in terms that most readers familiar with common machine learning conventions would be comfortable with. It's possible to follow the overall argument and get the \"gist\" of the paper without understanding every detail.)\n\nAll that being said, I don\u2019t doubt this paper makes some interesting and important contributions -- I just don\u2019t understand what they are.\n\nHere are some specific comments and questions, mostly on the proposed approaches and experiments:\n\n* What actually is the \u201ctensor (product) nonlinearity\u201d? Given that this is in the title and is repeatedly emphasized in the text, I expected that it would be presented much more prominently. But after reading the entire paper I\u2019m still not 100% sure what \u201ctensor nonlinearity\u201d refers to.\n\n* Experiments: all models are described in long-form prose. It\u2019s very difficult to read and follow. This could be made much clearer with an algorithm box or similar.\n\n* The motivation for the \u201cCoupled Autoencoder\u201d model isn\u2019t clear. What, intuitively, is to be gained from reconstructing a high-resolution image from a low-resolution basis and vice versa? The empirical gains are marginal.\n\n* Experiments: the structure of the section is hard to follow. (1) and (2) are descriptions of two different models to do the same thing (autoencoding); then (3) (bootstrapping) is another step done on top of (1), and finally (4) is a classifier, trained on top of (1) or (2). This could benefit from restructuring.\n\n* There are long lists of integer multiplicities a_i and b_i: these seem to come out of nowhere, with no explanation of how or why they were chosen -- just that they result in \u201clearn[ing] a really sharp W_28\u201d. Why not learn them?\n\n* How are the models optimized? (Which optimizer, hyperparameters, etc.?)\n\n* The baseline methods should also be run on the smaller numbers of examples (500 or 12K) that the proposed approach is run on.\n\n* A planar CNN baseline should be considered for the autoencoder experiments.\n\n* Validating on MNIST alone (rotated, spherical, or otherwise) isn\u2019t good enough in 2018. The conclusions section mentions testing the models with deeper nets on CIFAR, but the results are not reported -- only hinting that it doesn\u2019t work well. This doesn\u2019t inspire much confidence.\n\n* Why are Spherical CNNs (Cohen et al., 2018) a good baseline for this dataset? The MNIST-rot data is not spherical.\n\n* Table 1: The method labels (Ours, 28/14 Tensor, and 28/14 Scale) are not very clear (though they are described in the text)\n\n* Table 1: Why not include the classification results for the standard AE? (They are in the Fig. 6 plot, but not the table.)\n\n* Conclusions: \u201cWe believe our classifiers built from bases learnt in a CAE architecture should be robust to noise\u201d -- Why? No reasons are given for this belief.\n\n* There are many typos and grammatical errors and odd/inconsistent formatting (e.g., underlined subsection headers) throughout the paper that should be revised.", "rating": "3: Clear rejection", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}