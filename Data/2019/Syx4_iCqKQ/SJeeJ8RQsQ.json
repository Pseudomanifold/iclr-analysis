{"title": "An interesting paper, but still need to improve", "review": "This paper unifies both classification and regression task based on the polar prototype network. For classification, the prototypes for all classes are chosen in advance based on a max-margin principle, while the embedding of all instances is then optimized to have small cosine distance to assigned prototypes. For the regression, the output value is interpolated between the two prototypes. Experiments on classification, regression, and combined tasks show the method can achieve good results.\n\nThe idea of using the prototype and the polar system is interesting, and the whole paper is well-written. However, there are still some problems and questions about this paper.\n1. There are two problems with using the max-margin prototypes. First, to maximize the smallest distance between two prototypes, the authors use MC or evolutionary algorithms to do the optimization, which may be time-consuming, and it may be extremely difficult when the prototype space is high dimension. Second, the previous approach indeed obtains discriminative prototypes, but we lose the **class correlation**. In the extreme case, it is equal distance between all prototypes, but some similar classes will have a smaller prototype distance than others. For example, the prototype distance between \"cat\" and \"dog\" should not be the same as that between \"car1\" and \"car2\". The semantic consideration in the paper can solve this problem to some extent, but there needs more evidence.\n\nUsing the pre-defined prototype is also considered in the paper \"M. Perrot et al. Regressive Virtual Metric Learning. NIPS15\". \n\n2. For the unified output space\nOne main contribution is that based on the polar system, the method unifies both classification and regression tasks in the same space. We can also do this in basic embedding algorithms. In the embedding space, a method can do both classification and regression with the nearest neighbor rule (based on majority voting and average respectively). The authors should compare with such kinds of methods in the experiments.\n\n3. Experiments\nFrom the experiments, using semantic cannot improve a lot for the classification task. The authors can try more datasets to validate is this the common scenario. The reviewer strongly suggests the authors should compare with more methods. For example, in some papers the prototypes are learned simultaneously (Snell et al. Prototypical networks for few-shot learning. NIPS17; Wen et al. A discriminative feature learning approach\nfor deep face recognition. ECCV16); while in other cases, there are no prototypes as we optimize the triplet/contrastive loss directly. First, the authors can compare classification performance with these approaches; besides, some visualization results can also show the used prototypes or embeddings. \nThe main advantage of the method is not stressed clearly in the experiments part. The authors can clarify it in later versions.\n\nThe final rating depends on the authors' response.", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}