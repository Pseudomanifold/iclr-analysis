{"title": "promising work, further tests needed", "review": "This is an interesting paper in which the authors propose a shallow neural network, the architecture of which was optimized to maximize brain score, and show that it outperforms other shallow networks at imagenet classification. The goal of this paper \u2014 allowing brain data to improve our neural nets \u2014 is great. The paper is well written (except for a comment on clarity right below), and presents an interesting take on solving this problem. \n\nIt is a little unclear how the authors made CORnet optimize brain score: \u201cHowever, note that CORnet-S was developed using Brain-Score as a guiding benchmark and although it was never directly used in model search or optimization, testing CORnet-S on Brain-Score is not a completely independent test.\u201d Making these steps clearer is crucial for evaluating better what the model means. In the discussion \u201cWe have tested hundreds of architectures before finding CORnet-S circuitry and thus it is possible that the proposed circuits could have a strong relation to biological implementations.\u201d implies that the authors trained models with different architectures until the brain score was maximized after training. A hundred(s) times of training on 2760 + 2400 datapoints are probably plenty to overfit the brainscore datasets. The brain score is probably compromised after this, and it would be hard to make claims about the results on the brain modeling side. The author acknowledge this limitation, but perhaps a better thing is to add an additional dataset, perhaps one from different animal recordings, or from human fMRI? \n\nArguably, the goal of the paper is to obtain a model that overpowers other simpler models, and not necessarily to make claims about the brain. The interesting part of the paper is that the shallow model does work better than other shallow models. The authors mention that brain score helps CORnet be better at generalizing to other datasets. Including these results would definitely strengthen the claim since both brain score and imagenet have been trained on hundreds of times so far. \n\nAnother way to show that brain score helps is to show it generalizes above or differently from optimizing other models. What would have happened if the authors stuck to a simple, shallow model and instead of optimizing brain score optimized performance (hundreds of times) on some selected image dataset (this selection dataset is separate from imagenet, but the actual training is done on imagenet) and then tested performance on imagenet? Is the effect due to the brain or to the independent testing on another dataset?\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}