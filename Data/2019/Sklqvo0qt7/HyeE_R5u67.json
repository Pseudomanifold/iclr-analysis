{"title": "Incremental results using known analysis tools", "review": "This paper provides a new generalization bound for two layer neural network with regularization. The main analysis tool is to bound the Rademacher complexity of the network (due to regularization). While the work achieves a bound that is superior than a previous work, I personally find the work less inspiring and somewhat incremental. I have three main concerns of the result/work:\n\n1. The analysis is on a very shallow network. It is not clear how this result shed insight on understanding the success of *deep* neural network.\n\n2. The work is restricted to analyzing a NN with explicit regularization. As the authors noted themselves, such a paradigm is less popular in practice now.\n\n3. The analysis tool - bounding Rademacher complexity - is very standard", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}