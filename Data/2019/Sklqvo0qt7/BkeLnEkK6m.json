{"title": "Interesting ideas but unclear how they contribute to a better understanding of generalization of neural networks", "review": "The authors consider the notion of path norm for two layer ReLu network, and derive a generalization bound for a path-norm regularized estimator under a regression model.\n\nI apologize for the cursory review, as I have only been asked to review this paper two days ago. I have two main concerns about this paper: it is not clear to me how the distinction between \u201ca priori\u201d and \u201ca posteriori\u201d estimates enables a better understanding of the problem of generalization, and it is not clear to me how this paper contributes to a better understanding of generalization for neural networks.\n\nA priori v. a posteriori:\n\nThe authors attempt to distinguish \u201ca priori\u201d and \u201ca posteriori\u201d bounds by whether they depend on the true or estimated regression function. However, note that \u201ca priori bounds\u201d are significantly different from the common meaning of a \u201cgeneralization bound\u201d, which is most often understood to obtain a model-free bound of the generalization error. I found the reference to (Dziugaite and Roy, 2017) particularly confusing, as I am not sure how a PAC-Bayesian approach corresponds to an \u201ca priori\u201d approach.\n\nAdditionally, it seems that the theorems in the paper are phrased in the realizable case (i.e. where the true data-generating distribution is part of the model class). I believe that this is a poor model in the context of neural networks, which are often used to approximate complex models. Indeed, the authors claim that: \u201cif the path-norm is suitably penalized during training, we should be able to control the generalization gap without harming approximation accuracy\u201d which is true in the realizable case. However, the authors\u2019 experiment (table 2) show that the training (and testing!) performance tends to decrease when regularization is applied. In particular, I fail to see any evidence that \n\nThe problem of generalization in neural networks:\n\nMy other concern is that the present results fail to contribute to a broader understanding of neural network generalization. Indeed, as the authors mention in the conclusion, strong regularizers are rarely used in practice, and do not seem to particularly affect the generalization properties of neural networks [see Zhang et al. 2017]. Instead, recent efforts in the community have attempted to explain the generalization of neural networks by identifying some distinguished and favorable property of the trained network: see e.g. [Arora et al. 2018, figure 2]. This can then be observed empirically on large networks, and a basic counterfactual can be established by measuring them on networks trained on random data or at initialization. On the other hand, while it is clear that bounding the capacity of the estimator (e.g. through a norm constraint in this case) yields favorable generalization properties, it is not clear to me how relevant these are to larger networks.\n\nMinor comments:\n1. Please include references for definitions (e.g. path-norm), and theorem headers when appropriate\n2. The condition in Assumption 2 is often referred to as a \u201csub-gaussian tail / sub-gaussian noise\u201d, rather than \u201cexponentially decaying tail\u201d (as in this particular instance, the tail decays as the exponential of a square).\n3. After Lemma 2, in the derivation for L(\\theta), the second equality sign should be an inequality. The last \\hat{L}_{B_n}(\\theta) should simply be L_{B_n}(\\theta).\n4. In table, the display is somewhat confusing: for accuracy, higher is better, whereas for \\norm{\\theta}_p / \\sqrt{n}, lower is better. Consider expressing the accuracy as error instead.\n", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}