{"title": "well-written paper with good empirical results", "review": "This paper addresses black-box classifier attacks in the \u201chard-label\u201d setting, meaning that the only information the attacker has access to is single top-1 label predictions. Relative to even the standard black-box setting where the attacker has access to the per-class logits or probabilities, this setting is difficult as it makes the optimization landscape non-smooth. The proposed approach reformulates the optimization problem such that the outer-loop optimizes the direction using approximate gradients, and the inner-loop estimates the distance to the nearest attack in a given direction. The results show that the proposed approach successfully finds both untargeted and targeted adversarial examples for classifiers of various image datasets (including ImageNet), usually with substantially better query-efficiency and better final results (lower distance and/or higher success rate) than competing methods.\n\n=====================================\n\nPros:\n\nVery well-written and readable paper with good background and context for those (like me) who don\u2019t closely follow the literature on adversarial attacks. Figs. 1-3 are nice visual aids for understanding the problem and optimization landscape.\n\nNovel formulation and approach that appears to be well-motivated from the literature on randomized gradient-free search methods. Novel theoretical analysis in Appendix that generalizes prior work to approximations (although, see notes below).\n\nGood empirical results showing that the method is capable of query-efficiently finding attacks of classifiers on real-world datasets including ImageNet. Also shows that the model needn\u2019t be differentiable to be subject to such attacks by demonstrating the approach on a decision-tree based classifier. Appears to compare to and usually outperform appropriate baselines from prior work (though I\u2019m not very familiar with the literature here).\n\n=====================================\n\nCons/questions/suggestions/nitpicks:\n\nEq 4-5: why \\texttt argmin? Inconsistent with other min/maxes.\n\nEq 4-5: Though I understood the intention, I think the equations are incorrect as written: argmin_{\\lambda} { F(\\lambda) } of a binary-valued function F would produce the set of all \\lambdas that make F=0, rather than the smallest \\lambda that makes F=1. I think it should be something like:\n\nmin_{\\lambda>0} {\\lambda}\ns.t. f(x_0+\\lambda \\theta/||\\theta||) != y_0\n\nSec 3.1: why call the first search \u201cfine-grained\u201d? Isn\u2019t the binary search more fine-grained? I\u2019d suggest changing it to \u201ccoarse-grained\u201d unless I\u2019m misunderstanding something.\n\nAlgorithm 2: it would be nice if this included all the tricks described as \u201cimplementation details\u201d in the paragraph right before Sec. 4 -- e.g. averaging over multiple sampled directions u_t and line search to choose the step size \\eta. These seem important and not necessarily obvious to me.\n\nAlgorithm 2: it could be interesting to show how performance varies with number of sampled directions per step u_t.\n\nSec: 4.1.2: why might your algorithm perform worse than boundary-attack on targeted attacks for CIFAR classifiers? Would like to have seen at least a hypothesis on this.\n\nSec 6.3 Theorem 1: I think the theorem statement is a bit imprecise. There is an abuse of big-O notation here -- O(f(n)) is a set, not a quantity, so statements such as \\epsilon ~ O(...) and \\beta <= O(...) and \u201cat most O(...)\u201d are not well-defined (though common in informal settings) and the latter two are redundant given the meaning of O as an upper bound. The original theorem from [Nesterov & Spokoiny 2017] that this Theorem 1 would generalize doesn\u2019t rely on big-O notation -- I think following the same conventions here might improve the theorem and proof.\n\n=====================================\n\nOverall, this is a good paper with nice exposition, addressing a challenging but practically useful problem setting and proposing a novel and well-motivated approach with strong empirical results.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}