{"title": "An interesting extension of the 'learning to communicate' work using targeted messages and multiple rounds of communication. ", "review": "The authors propose a new architecture for learning communication protocols. In this architecture each message consists of a key and a value. When receiving the message the listener produces an attention key that is used to selectively attend to some messages more than other using soft attention. This differs from the typical 'broadcasting' protocols learned in literature. \n\nQuestions / Comments: \n- Eqn (4) looks like a vanilla RNN. Did you experience any issues around exploding or vanishing gradients when doing multiple rounds of communication? Why not use a gated architecture here? \n- \"Centralized Critic\" section: This equation is from the COMA paper, ie. a centralised critic with policy gradients rather than DDPG. What did you use for the variance reduction baseline to estimate the advantage? Also, did you try conditioning the critic on the central state rather than the concat of observations? Formally this is required for the algorithm to be convergent. \n- How many independent seeds are the results averaged over? \n- The attention mechanism seems to provide very little value across all experiments: \n-- 84.9% vs 82.7% \n-- 89.5% vs 89.6% \n-- 64.3% vs 68.9% \nDid you check if any of these numbers are significant? This is my single biggest concern with the paper. Currently it's unclear whether attention is required at all in the settings presented. It would be good to see eg. the TarMAC 2-stage on the traffic junction (97.1%) ablated without attention.", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}