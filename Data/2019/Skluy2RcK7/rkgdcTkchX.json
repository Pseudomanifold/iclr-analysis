{"title": "Poorly written with unclear contributions", "review": "This is a paper with scattered potentially interesting ideas. But the execution is limited and the writing poor with critical details lacking.  A major limitation of the paper is that it is not clear what contribution it makes. Some of the analyses are indeed interesting but 1) these analyses are mostly descriptive and 2) they are limited to one particular (outdated) architecture. How would batch norm or residual connections or any of the developments that have happened since AlexNet affect these results?\n\nAs a side note, the references/comparisons between AlexNet and recurrent nets (see abstract, etc) are misleading. This is based on the claim that Bowers et al (2014) qualitatively different results but this is for entirely different domains (words). Indeed what could have made potentially the work more relevant would have been to show some kind of benchmarking between AlexNet and alternative architectures (possibly RNNs). As such the current study does not contribute much except for comparing different semi-arbitrary measures of selectivity for one specific (outdated) network architecture trained on a particular problem (ILSVRC).\n\n****\nMinor points:\n\nThe study is limited to correctly classified images as stated on page 3. This seems like a major confound in a study aimed at understanding the visual representations learned. It seems to me that the conclusions of the paper could be heavily biased because of this (when computing any measure based on inter and intraclass responses).\n\nIn general, this is a relatively poorly written paper which would be hard to reproduce. For instance, the image generation for activating units (assuming it is novel) could be interesting but it is not even described with sufficient details so as to reproduce the results.", "rating": "3: Clear rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}