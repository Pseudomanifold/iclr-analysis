{"title": "decent novelty but motivations and approaches not convincing enough", "review": "To solve the problem fo \u201cpreserving relative positions of nodes\u201d, the paper applied the capsule network to the graph node embedding task and proposed the model named \u201cCapsG\u201d. The CapsG construct two capsule layers and utilize the dynamic routing between capsules to iteratively update the target node representation in a random walk. The experimental results on datasets with node features and without node features both seem promising. I think the idea of the model is interesting, but I have some concerns about the motivation and the soundness of the model.\n\n1. I am not convinced of the motivation of \u201cpreserving the relative positions of nodes\u201d. The authors claimed in the Introduction that the CNN has the problem of preserving the relative positions, and the problem of GCN based models are just because they used \u201cthe variant of CNNs\u201d. To me the GNNs, even the GCN based models have very different mechanisms from CNNs, this simple inference is not convincing at all. I would like to see more detailed example or explanation about how GCNs encounter this problem. In fact, many graph node embedding models, such as Deepwalk, node2vec or GAT seem not to have this problem to me.\n\n2. I enjoyed the section \u201cComparing CapsG with related works\u201d, but after reading that section I had a strong feeling that using capsule layers may not be necessary in this model, or at least not a very natural selection. One question is about the definition of the capsule layers. The approach used the capsule layers for each random walk, where the capsules in the first capsule layer are just single nodes. It is essentially just an extension to the node aggregation mechanism by using multi-hop node information. Another question is about \u201cW_i\u201d in Eq. (1). It is an important parameter which defines the transformation for each capsule. And it is one of the major differences from other models such as GAT. However, The index of capsules are randomly decided and different indices will result in different output vectors, which seems to conflict with the motivation of position invariance.\n\n3. For experiments, I think it is better to demonstrate the advantages by adding two results: the ablation model using the same \u201cW_i\u201d for different capsules in Eq. (1); the running time of CapsG. As it samples a number of random walks for each node, and update target node representation in each random walk with many iterations, I am curious whether it slows down compared to other GNNs.", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}