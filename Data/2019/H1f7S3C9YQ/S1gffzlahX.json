{"title": "Nice approach for automatically discovering synonymous entities", "review": "The paper presents a neural network model (SYNONYMNET) for automatically discovering synonymous entities from a large free-text corpus with minimal human annotation. The solution is fairly natural in the form of a siamese network, a class of neural network architectures that contain two or more identical subnetworks, which are an obvious approach for such a task, even though this task's SotA does not cover such architectures. even though the abstract consists the word novel, the chosen architecture is not a novel one but attached to this task, it can be considered as if.\n\n# Paper discussion:\n\nThe introduction and the related work are well explained and the article is well structured. The authors mark very well the utility of automatically discovering synonyms.\n\nSection 2 presents the SynonymNet, mainly the bi-LSTM applied on the contexts and the bilateral matching with leaky unit and the context aggregation for each entity, along with training objectives and the inference phase.\n\nThe novelty does not consist in the model since the model derives basically from a siamese network, but more in the approach, mainly the bilateral matching: one input is a context for an entity, the other input is a context for the synonym entity, and the output is the consensus information from multiple pieces of contexts via a bilateral matching schema with leaky unit (highest matched score with its counterpart as the relative informativeness score) and the context aggregation. The inference phase is a natural step afterward. Also, the usage of the leaky unit is clearly stated.\n\nSection 3 presents the experimental phase, which is correct. The choice of LSTMs is understandable but other experiments could have been done in order to make clearer why it has been chosen. Regarding also the word embeddings choice, other experiments could have been completed (word2vec and GloVe have been competing with many other embeddings recently).\n\nOne noticed misspelling: GolVe (Pennington et al., 2014) ", "rating": "7: Good paper, accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}