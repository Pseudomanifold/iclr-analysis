{"title": "A neural architecture and analysis of predicting satisfiability with minimal supervision", "review": "The paper describes a general neural  network architecture for predicting satisfiability. Specifically, the contributions include an encoding for SAT problems, and predicting SAT using a message passing method, where the embeddings for literals and clauses are iteratively changed until convergence.\n\nThe paper seems significant considering that it brings together SAT solving and neural network architectures. The paper is very clearly written and quite precise about its contributions. The analysis especially figures 3,4, and 7 seems to give a nice intuitive ideas as to what the neural network is trying to do. However, one weakness is that the problems are run on a specific type of SAT problem the authors have created. Of course, the authors make it clear that the objective is not really to create a. State-of-the-art solver but rather to understand what a neural network trying to do SAT solving is capable of doing. On this front, I think the paper succeeds in doing this. One thing that was a little confusing is that why should all the literals turn to SAT (turn red) to prove SAT (as it is shown in figure 3). Is it that the neural network does not realize that it has found a SAT solution with a smaller subset of SAT literals. In other words, is it not capable of taking advantage of the problem structure.\n\nIn general though, this seemed to be an interesting paper though its practical implications are quite hard to know either in the SAT community or in the neural network community.", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}