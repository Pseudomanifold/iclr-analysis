{"title": "need more in-depth analysis", "review": "[Summary]\n\nThis paper presents an interesting idea that to append the agent's action space with the expert's most frequent action pairs, by which the agent can perform better exploration as to achieve the same performance in a shorter time. The authors show performance gain by comparing their method with two baselines - Dagger and InfoGAIL.\n\n\n[Stengths]\n\nThe proposed method is simple yet effective, and I really like the analogy to mini-moves in sports as per the motivation section.\n\n\n[Concerns]\n\n- How to choose the number and length of the action sequences?\nThe authors empirically add the same number of expert's action sequences as the basic ones and select the length k as 2. However, no ablation studies are performed to demonstrate the sensitivity of the selected hyperparameters. Although the authors claim that \"we limit the size of meta-actions k to 2 because large action spaces may lead to poor convergence\", a more systematic evaluation is needed. How will the performance change if we add more and longer action sequences? When will the performance reach a plateau? How does it vary between different environments?\n\n- Analysis of the selected action sequences.\nIt might be better to add more analysis of the selected action sequences. What are the most frequent action pairs? How does it differ from game to game? What if the action pairs are selected in a random fashion?\n\n- Justification of the motivation\nThe major motivation of the method is to release the burden of memory overheads. However, no quantitative evaluations are provided as to justify the claim. Considering that the input images are resized to 84x84, storing them should not be particularly expensive.\n\n- The choice of baseline.\nInfoGAIL (Li et al., 2017) is proposed to identify the latent structures in the expert's demonstration, hence it is not clear to me how it suits the tasks in the paper. The paper also lacks details describing how they implemented the baselines, e.g. beta in Dagger and the length of the latent vector in InfoGAIL.\n\n- The authors only show experiments in Atari games, where the action space is discrete. It would be interesting to see if the idea can generalize to continuous action space. Is it possible to cluster the expert action sequences and form some basis for the agent to select?\n\n- Typos\n{LRR, RLR/RRL} --> {LRR, RLR, RRL}\nsclability --> scalability\nwe don't need train a ... --> we don't need to train a ...\nAtmost --> At most\n\n\n[Recommendation]\n\nThe idea presents in the paper is simple yet seemingly effective. However, the paper lacks a proper evaluation of the proposed method, and I don't think this paper is ready with the current set of experiments. I will decide my final rating based on the authors' response to the above concerns.", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}