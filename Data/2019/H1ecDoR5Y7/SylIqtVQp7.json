{"title": "rigorous math with heavy machinery but not well motivated", "review": "Based on a dynamic system perspective, this paper characterizes the convergence of gradient penalized Wasserstein GAN. The analytic framework is similar to the one used in Nagarajan & Kolter but requires very heavy machinery to handle measure valued differentiation. Overall the math seems solid but I have a few questions about the motivation and assumption. \n\n1. To my limited knowledge, it seems that the two-time-scale framework [1] handles both batch and stochastic settings well also from a dynamic system perspective. I am wondering why not follow their path since under their framework adding a gradient penalty does not introduce all the technical difficulty in this paper. \n\n2. The main theorem characterizes the stability or convergence but does not characterize the advantage of gradient penalty. Does it make the system more stable? At least more technical discussion around the theorem is needed. \n\n3. Besides the technicality of handling the support of the measure, what is new beyond the analysis of Nagarajan & Kolter?\n\n[1] GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium\nby Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, Sepp Hochreiter\n\nI may be missing something and would like to see the author's response. \n\n=== after rebuttal ===\n\nI have carefully read the authors' response. I appreciate the explanation. After reading [1] in detail, my conclusion is still that [1] seems to be a stronger framework than the current one and easily extends to the setting with gradient penalty. Compared with Nagarajan and Kolter, the contribution of this paper seems to be minor, although technically involved. I have checked the updated pdf but haven't found the authors' rigorous \"more stable\" argument.", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}