{"title": "Interesting empirical study with some flaws", "review": "This paper empirically explores heuristics commonly used in deep learning: learning rate restarts, warmup and distillation. The authors utilize two recently proposed tools for neural network analysis: mode connectivity (MC) finding a low loss pathway between two given points in the space of DNN parameters and CCA measuring the correlation of  DNN layer activations. Conducting a set of experiments and analyzing the results the authors refine the intuition behind the considered heuristics and dynamics of corresponding training procedures. \n\nStrengths:\n\n+ The authors conduct experiments ensuring robustness of MC framework.\n+ In the chosen settings the experimental methodology of the paper sounds reasonable. I find the idea of DNN analysis from both perspectives of weight space and activations important.\n+ Paper is well-written and organized clearly. All the used methods and experiments are adequately described.\n+ The authors draw connections between obtained results and hypotheses introduced in prior work.\n\nWeaknesses:\n\n- There is a possible flaw in the choice of experimental settings. Authors mention Batch Normalization (BN) among heuristics widely used in deep learning. It is known that properties of both loss surface and activations are different between DNN architectures which include BN layers and those which do not. To emphasize generality of obtained results, it would be beneficial to conduct experiments for both types of DNN architectures as at the moment the majority of the results are presented for VGG architecture which typically does not include BN. Impact of other architecture modifications (e.g. skip connections) might be considered as well.\n\n- I find the significance of the results unclear. Although the particular insights of the learning procedures are revealed there is not enough attention paid to their value for possible improvements of the procedures and their applications. There is only one idea proposed by the authors based on the experimental results \u2013 fixing the deeper layers during the warmup phase, but the practical implications of this idea are not discussed.\n\nOther comments:\n\n* The scale used in Figure 3 and similar figures in the appendix is not easily comprehensible. I recommend to comment further on the scale or possibly adjust it.\n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}