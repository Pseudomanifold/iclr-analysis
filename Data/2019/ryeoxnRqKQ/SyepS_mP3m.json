{"title": "Good evaluation but important prior work was missed which substantially reduces novelty and makes a major rewrite necessary", "review": "In this work the authors use a score-based adversarial attack (based on the natural evolution strategy (NES)) to successfully attack a multitude of defended networks, with success rates rivalling the best gradient-based attacks.\n\nAs confirmed by the authors in a detailed and very open response to a question of mine, the attack introduced here is actually equivalent to [1]. While the attack itself is not novel (which will require a major revision of the manuscript), the authors point out the following contributions over [1]:\n\n* Attack experiments here go way beyond Ilyas et al. in terms of Lp metrics, different defense models, different datasets and transferability.\n* Different motivation/derivation of NES.\n* Concept of adversarial distributions.\n* Regression network for good initialization.\n* Introduction of accuracy-iterations plots.\n\nMy main concerns are as follows:\n* The review of the prior literature, in particular on score-based and decision-based defences (the latter of which are not even mentioned), is very limited and is framed wrongly. In particular, the statement \u201cHowever, existing black-box attacks are weaker than their white-box counterparts\u201d is simply not true: as an example, the most prominent decision-based attack [2] rivals white-box attacks on vanilla DNNs as well as defended networks [3].\n* The concept of adversarial distributions is not new but is common in the literature of real-world adversarials that are robust to transformations and perturbations (like gaussian noise), check for example [4]. In [4] the concept of _Expectation Over Transformation (EOT)_ is introduced, which is basically the generalised concept of the expectation over gaussian perturbations introduced in this work.\n* While I like the idea of accuracy-iterations plots, the idea is not new, see e.g. the accuracy-iterations plot in [2] (sample-based, Figure 6), the loss-iterations plot in [5] or the accuracy-distortion plots in [3]. However, I agree that these type of visualisation or metric is not as widespread as it should be.\n\nHence, in summary the main contribution of the paper is the application of NES against different defence models, datasets and Lp metrics as well as the use of a regression network for initialisation. Along this second point it would be great if the authors would be able to demonstrate substantial gains in the accuracy-query metric. In any case, in the light of previous literature a major revision of the manuscript will be necessary.\n\n[1] Ilyas et al. (2018) \u201cBlack-box Adversarial Attacks with Limited Queries and Information\u201d (https://arxiv.org/abs/1804.08598) \n[2] Brendel et al. (2018) \u201cDecision-Based Adversarial Attacks: Reliable Attacks Against Black-Box Machine Learning Models\u201d (https://arxiv.org/abs/1712.04248)\n[3] Schott et al. (2018) \u201cTowards the first adversarially robust neural network model on MNIST\u201d (https://arxiv.org/abs/1805.09190)\n[4] Athalye et al. (2017) \u201cSynthesizing Robust Adversarial Examples\u201d (https://arxiv.org/pdf/1707.07397.pdf)\n[5] Madry et al. {2017) \u201cTowards Deep Learning Models Resistant to Adversarial Attacks\u201d (https://arxiv.org/pdf/1706.06083.pdf)", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}