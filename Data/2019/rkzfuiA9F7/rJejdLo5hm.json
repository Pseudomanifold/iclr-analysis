{"title": "Some experiments are missing. ", "review": "This paper proposes a Projective Subspace Network (PSN) for few-shot learning. The PSN represents each support set of classes as a subspace obtained by SVD. Then the method calculates distances between a query and classes by the projection error to the subspace. Instead of using the prototype of the class center, the subspace representation is more robust to outliers. Though the contribution seems to be incremental, it is a reasonable improvement upon Matching Networks and Prototypical Networks.\n\nPros. \n+ The proposed subspace method is simple and reasonable\n+ The performance is better than some related works on few-shot learning. \n\nCos. \n- The authors claimed that subspace representation is more robust to noise within each class samples. However, this is not supported by experiments. The authors evaluated the distractor classes. However, this is not the case when the outlier existed within each class samples. \n\n- For semi-supervised few-shot learning, the authors proposed a fake class with zero means. The effect of this fake class is not evaluated. \n\n- The dimensionality of subspace (n) seems to be not written.\n\n- The sensitivity analysis of the dimensionality of subspace is missing. For subspace methods, it is essential to evaluate the performance w.r.t the dimension. \n\n- Descriptions in the related work section should be improved. It is unclear how the proposed method is related to K-means, K-modes, and K-prototype. Also, the authors wrote that works (Chan et. 2015, Sun et al. 2017) use PCA or SVD to reduce the dimensionality of feature representation in neural networks. However, both methods do not perform dimensional reduction. PCANet (Chan et al . 2015) obtains convolutional filters by applying PCA to input images or feature maps. SVDNet (Sun et al. 2017) applies SVD for obtaining decorrelated weights in a neural network. \n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}