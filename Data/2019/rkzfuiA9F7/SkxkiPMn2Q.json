{"title": "Interesting extension to embedding-based approaches to few-shot learning but results are a bit disappointing", "review": "This paper considers the problem of few-shot learning and proposes a new embedding-based approach. In contrast to previous work (such as Matching Networks and Prototypical Networks) where distance is computed in pure embedding space, this work proposes computing a low-dimensional subspace to represent a class and using the distance from an embedded query point to this subspace. The low-dimensional subspace for a class is computed by running truncated Singular Value Decomposition on the normalized embeddings of all points in the support set for that class and using the top n left singular vectors as the basis for the class's subspace. The authors also propose an extension to their model to the semi-supervised few-shot learning setting by incorporating masked-mean computation and zero-mean cluster for distractor items (both ideas borrowed from Renn 2017 for prototypical networks). Experiments are conducted on Mini-Imagenet in the few-shot learning setting and on Mini-Imagenet and Tiered-ImageNet in the semi-supervised few-shot learning setting.\n\nPros:\n- Proposed idea is novel and proposes an interesting change to existing embedding-based few-shot learning techniques.\n\nCons:\n- Performance benefit is a bit disappointing; Mini-Imagenet few-shot performance improvement relative to Prototypical-Nets is minimal (barely 1% for 5way-5shot and 20way-5shot case). For semi-supervised experiments, there is bigger improvement for Mini-Imagenet (4% for both without distractors and with distractors) but less so for Tiered-ImageNet (close to 0% for without distractors and with distractors).\n\nRemarks:\n- The paper seems to be missing what the dimensionality of the subspace is for the experiments? Was this picked using validation set performance?\n- In first paragraph of page 2, it seems too strong to say \"...this makes our paper unparalleled to previous studies\"; maybe change to \"...this make our proposed model novel relative to previous work\"\n- Is there previous work that has involved back-propagating through SVD? It would be useful to mention these as references.\n- In Figure 1, it is visually shown how outliers can negatively impact Matching-Networks and Prototypical-Networks but not visually shown how PSN is resistant to them?\n- The claim is made that the proposed method is more robust to outliers. Is there more of a justification that can be given for this? Either in terms of some intuition or an experiment that can be run? For example, can it be shown that outliers cause the prototype of a class to move a lot (in terms of distance from original prototype without outliers) whereas the original subspace compared to subspace with outliers is less different by measuring this on Mini-Imagenet?\n- Typo on page 5: \"in what follwos\" => \"in what follows\"\n- In Discussion, paper states, \"Moreover, the Prototypical Network makes use of the class mean and can be easily incorporated in our testbed\": what does this mean exactly?", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}