{"title": "good paper, accept", "review": "This paper formulates the black-box adversarial attack as a gradient estimation\nproblem, and provide some theoretical analysis to show the optimality of an\nexisting gradient estimation method (Neural Evolution Strategies) for black-box\nattacks.\n\nThis paper also proposes two additional methods to reduce the number of queries\nin black-box attack, by exploiting the spacial and temporal correlations in\ngradients. They consider these techniques as priors to gradients, and a bandit\noptimization based method is proposed to update these priors. \n\nThe ideas used in this paper are not entirely new. For example, the main\ngradient estimation method is the same as NES (Ilyas et al. 2017);\ndata-dependent priors using spatially local similarities was used in Chen et\nal. 2017.  But I have no concern with this and the nice thing of this paper is \nto put these tricks under an unified theoretical framework, which I really \nappreciate.\n\nExperiments on black-box attacks to Inception-v3 model show that the proposed\nbandit based attack can significantly reduces the number of queries (2-4 times\nfewer) when compared with NES. \n\nOverall, the paper is well written and ideas are well presented.\nI have a few concerns:\n\n1) In Figure 2, the authors show that there are strong correlations between the\ngradients of current and previous steps. Such correlation heavily depends on\nthe selection of step size.  Imagine that the step size is sufficiently large,\nsuch that when we arrive at a new point for the next iteration, the\noptimization landscape is sufficiently changed and the new gradient is vastly\ndifferent than the previous one. On the other hand, when using a very small\nstep-size close to 0, gradients between consecutive steps will be almost the\nsame. By changing step-size I can show any degree of correlation.  I am not\nsure if the improvement of Bandit_T comes from a specific selection of\nstep-size. More empirical evidence on this need to be shown - for example, run\nBandit_T and NES with different step sizes and observe the number of queries\nrequired.\n\n2) This paper did not compare with many other recent works which claim to\nreduce query numbers significantly in black-box attack. For example, [1]\nproposes \"random feature grouping\" and use PCA for reducing queries, and [2]\nuses a good gradient estimator with autoencoder. I believe the proposed method\ncan beat them, but the authors should include at least one more baseline to \nconvince the readers that the proposed method is indeed a state-of-the-art.\n\n3) Additionally, the results in this paper are only shown on a single model\n(Inception-v3), and it is hard to compare the results directly with many other\nrecent works. I suggest adding at least two more models for comparison (most\nblack-box attack papers also include MNIST and CIFAR, which should be easy to\nadd quickly). These numbers can be put in appendix.\n\nOverall, this is a great paper, offering good insights on black-box adversarial\nattack and provide some interesting theoretical analysis. However currently it\nis still missing some important experimental results as mentioned above, and\nnot ready to be published as a high quality conference paper. I conditionally\naccept this paper as long as sufficient experiments can be added during the\ndiscussion period.\n\n\n[1] Exploring the Space of Black-box Attacks on Deep Neural Networks, by Arjun\nNitin Bhagoji, Warren He, Bo Li and Dawn Song, https://arxiv.org/abs/1712.09491\n(conference version accepted by ECCV 2018)\n\n[2] AutoZOOM: Autoencoder-based Zeroth Order Optimization Method for Attacking\nBlack-box Neural Networks, by Chun-Chen Tu, Paishun Ting, Pin-Yu Chen, Sijia\nLiu, Huan Zhang, Jinfeng Yi, Cho-Jui Hsieh, Shin-Ming Cheng,\nhttps://arxiv.org/abs/1805.11770\n\n==========================================\n\nAfter discussing with the authors, they provided better evidence to support the conclusions in this paper, and fixed bugs in experiments. The paper looks much better than before. Thus I increased my rating.", "rating": "7: Good paper, accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}