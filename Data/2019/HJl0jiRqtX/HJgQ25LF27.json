{"title": "A nice application model but some unclear points", "review": "The paper proposes Partial VAE to handle missing data and a variable-wise active learning method. The model combines Partial VAE with the acquisition function to design an intelligent information acquisition system. The paper nicely combines the missing value problem with an active learning strategy to in an acquisition pipeline and demonstrate the effectiveness on several datasets.\n\nI have following comments/questions:\n\n1.  Does p(x_i | z) include parameters? How do these parameters be trained?\n\n2. Does sample from p(x_i | x_o) follow by sampling z from q(z|x_o) then sample x_i from p(x_i | z)? How to sample from p(x_\\phi | x_i, x_o) in Eq (7)?\n\n3. In Eq (9), it uses q(z_i|x_o), q(z_i | x_i, x_o),  q(z_i | x_i, x_o, x_\\phi) while in Eq (4) it only shows how to learn q(z|x_o). Does it need to learn multiple partial inference networks for all combination of i and \\phi ?\n\n4. The comparison with similar algorithms seems to be weak in the experiment section. RAND is random feature selection, and SING is global feature selection by using the proposed method. These comparison methods cannot provide enough information on how well the proposed methods performs. There are plenty of works in the area of \u201cactive feature acquisition\u201d and also many works in feature selection dated back to Lasso which should be considered as comparison targets.\n\n5. In the \u201cpersonalized\u201d implementation of EDDI on each data instances, is the model trained independently for each data point or share some parameters across different data? If so, what are the shared parameters?", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}