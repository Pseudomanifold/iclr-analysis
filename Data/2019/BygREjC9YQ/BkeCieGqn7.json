{"title": "Promising novel research, high practical relevance", "review": "* Description\n\nThe paper considers the following random process on the parameters z (modeled as Gaussians):\n- shrink z towards zero and add Gaussian i.i.d. noise to it.\n- update the parameters to the posterior w.r.t. a batch, where the likelihood is approximated as a diagonal multivariate normal distribution.\nThis results in a Kalman filter like updates. There have been related methods proposed performing Bayesian learning in the form of assumed density filtering, considered as separate learning algorithms. At the same time methods such as RMSprop and Adam were previously derived from completely different considerations. The work can derive these methods in the Bayesian framework with certain additional assumptions / simplifications. It allows to naturally explain tracking the gradient statistics as uncertainties and the normalization of the gradient in the existing methods as the update of the mean parameters in the Kalman filter taking into account these uncertainties. \nThe experiments on MNIST show that derived more Bayesian variants of RMSprop and Adam can improve generalization in terms of test likelihood and test error. \n\n* Assessment\n\nThe provided derivation of Bayes like learning algorithms is relatively simple and could be very useful in practice and in further improvement of the learning methods. The approximations used are not completely clear. The clarification of the idea of a separate optimization problem per variable is necessary. The provided experiments, if there is nothing subtle, are clearly done and would be sufficient.\nThere are some open questions such as: does the method in fact learn useful variances of the parameters, i.e. really performs an approximate Bayesian learning? Overall if find it a promising novel research direction of high practical relevance.\n\n* Clarity\n\nIntro:\nWhy is the unnumbered equation on page 1 is called a \u201cBayesian optimization problem\u201d? There is so many sings called Bayesian that one cannot be sure what it means. In the context of the paper it should be a Bayesian learning problem, but I do not see a posterior distribution over the parameters. Overall, I did not get the point of the discussion in the introduction and Figure 1 altogether. Everything it says to me is that global minimize coordinates are dependent through the objective. I do not see what the unnumbered equation on page 1 has to do with Bayesian inference and how the correlation of parameters in the posterior distribution is related to the dependencies in the minimizer. Could authors please seriously consider clarifying this section?\nIn what follows the paper keeps a factorize approximation to the posterior of parameters of a NN in the form of a Gaussian distribution per coordinate. It thus does not in any way avoid making this restrictive assumption.\n\nResults:\nSorry, I am not familiar with the background behind (6). Which value of z is assumed in the conditional expectation, is it conditioning on \u201cz = \\mu_{prior}\u201d? How come the approximation to the variance of the data likelihood does not depend on the data? If we make this approximation, how much it is still relevant to the Bayesian learning?\n\nWhat are the overheads of the proposed methods? I expect they scale as easily to large problems as SGD?\n\n* Experiments\n\nFrom Figure 2 it seems that BRMSprop and BAdam can achieve relatively good results for large range of eta in 10^-5 to 10^-2 and it seems from the trend that even smaller eta would work. Does it mean they do not need in fact tuning of the learning rate? \nThe experiment uses 50 epochs, do the compared methods reach the convergence? Could the authors consider an experiment running best setting of parameters per method with twice as many epochs?\nSome artificial toy experiments could be of interest. For example, consider a classification problem with a 1D Gaussian data distribution in each class and the logistic regression model with 2 parameters. Does the method approximate the posterior distribution?\n\n* Related work\n\nThe approach to Bayesian learning taken in the paper needs to be better discussed. I think it is from the family of methods known as \u201cassumed density filtering\u201d, occurring in:\nGhosh et al. \u201cAssumed Density Filtering Methods for Scalable Learning of Bayesian Neural Networks\u201d\nwith earlier works well described in \nMinka T. \u201cExpectation propagation for approximate Bayesian inference\u201d. \nIn particular equation (5) of the submission is well known.\nThe work  Khan et al. 2018 \u201cFast and scalable Bayesian deep learning by weight-perturbation in Adam\u201d also derives Bayesian learning algorithms in the forms closely similar to RMSprop and Adam and interprets the running statistics as uncertainties. However it takes the variational Bayesian learning approach, which means the reverse KL divergence is used somewhere. Could the authors discuss conceptual similarities and differences to this work?\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}