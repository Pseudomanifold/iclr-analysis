{"title": " ", "review": "The Paper is written rather well and addresses relevant research questions.\nIn summary the authors propose a  simple and intuitive method to improve the defense on adversarial attacks by combining random permutations and using a 2d DFT. The experiments with regards to robustness to adversarial attacks I find convincing, however the overall performance is not very good (such as the accuracy on Cifar10). \n\nMy main points of critique are:\n\n1. The test accuracy on Cifar10 seems to be quite low,  due to the permutation of the inputs. This \nmakes me question  how favorable the trade-off between robustness vs performance is. \n\n2. The authors state \"We believe that better results on clean images automatically translate to better results on adversarial examples\"\n\nI am not sure if this is true.   One counter argument is  that better results on clean images can be obtained by memorizing more structure of the data (see [1]). But if more memorizing (as opposed to generalization) happens, the classifier is more easily fooled (the decision boundary is more complicated and exploitable).\n\n\n\n[1] Zhang, C., Bengio, S., Hardt, M., Recht, B., & Vinyals, O. (2016). Understanding deep learning requires rethinking generalization. arXiv preprint arXiv:1611.03530.", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}