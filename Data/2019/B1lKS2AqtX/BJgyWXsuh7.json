{"title": "well-written, well-experimented paper with limited novelty", "review": "The paper proposes a spatiotemporal modeling of videos based on two currently available spatiotemporal modeling paradigms: RNNs and 3D convolutions. The main idea of this paper is to get the best world of both in a unified way. The method first encodes a sequence of frames using 3D-conv to capture short-term motion patterns, passes it to a specific type of LSTM (E3D-LSTM) which accepts spatiotemporal feature maps as input. E3D-LSTM captures long-term dependencies using an attention mechanism. Finally, there are 3D-conv based decoders which receive the output of E3D-LSTM and generate future frames. The message of the paper, I believe, is that 3D-conv and RNNs can be integrated to perform short and long predictions. They show in the experiments how the model can remember far past for reasoning and prediction.\nThe nice point of the method is that it is heavily investigated through experiments. It's evaluated on two datasets, with ablation studies on both. Moreover, the paper is well-written and clear. technically, the paper seems correct.\nHowever, my only big concern is about the limited novelty of the method. E3D-LSTM is the core of the novelty, which is basically an LSTM with extra gate, and attention mechanism.  \n\nother comments:\n- As the method by essence is a spatiotemporal learning model, why the method is not evaluated on full-length videos of the something-something dataset for classical action classification task, in order to compare it with the full architecture of I3D, or S3D?\n\n- While the paper discusses self-supervised learning, I would suggest showing its benefit on online action recognition task. One without frame-prediction loss and one with. \n\n- the something-something dataset has 174 classes, how was the process of selecting 41 classes out of it?", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}