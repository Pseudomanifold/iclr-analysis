{"title": "Interesting paper, possibly some confusion on some causal modelling (especially Section 2.1)", "review": "The paper introduces a new intrinsic reward for MARL, representing the causal influence of an agent\u2019s action on another agent counterfactually. The authors show this causal influence reward is related to maximising the mutual information between the agents\u2019 actions. The behaviour of agents using this reward is tested in a set of social dilemmas, where it leads to increased cooperation and communication protocols, especially if given an explicit communication channel. As opposed to related work, the authors also equip the agents with an internal Model of Other Agents that predicts the actions of other agents and simulates counterfactuals. This allows the method to run in a decentralized fashion and without access to other agents\u2019 reward functions.\n\nThe paper proposes a very interesting approach. I\u2019m not a MARL expert, so I focused more on the the causal aspects. The paper seems generally well-organized and well-written, although I\u2019m a bit confused about the some of the causal modelling decisions and assumptions. This confusion and  some potential errors, which I describe in detail below, are the reason for my borderline decision, despite liking the paper otherwise. \n \nFirst, I\u2019m a bit confused about the utility of the Section 2.1 model (Figure 1), mostly because of the temporal and multiple agents aspects that seem to be dealt with (\u201cmore\u201d) correctly in the MOA model. Specifically in Figure 1, one would need to assume that there is only one agent A influencing agent B at the same time (and agent B does not influence anything else). For example, there is no other agent C which actions also influence agent B, and no agent D that is influenced by agent B, otherwise the backdoor-criterion would not work, unless you add also the action of agent C to the conditioning set (or its state). Importantly, adding the actions of all agents, also a potential agent D that is downstream of B would be incorrect. So in this model there is some kind of same time interaction and there seems to be the need for a causal graph that is known a priori. These problems should disappear if one assumes that only the time t-1 actions can influence the time t actions, as in the MOA model. I assume the idea of the Figure 1 model was to show a relationship with mutual information, but for me specifically it was quite confusing. \n\nI was much less confused by the MOA causal graph represented in Figure 4, although I suspect there are quite some interactions missing (for example s_t^A causes u_t^A similarly to the green background? s_t causes s_{t+1} (which btw in this case should probably be split in two nodes, one s_{t+1} and one s_{t+1}^B?). Possibly one could also add the previous time step for agent B (with u_{t+1}^B influenced by u_t^B I would assume?). As far as I can see there is no need to condition on a_t^B in this case to see the influence of a_t^A on a_{t+1}^B, u_t^A and s_t^A should be enough?\n\nMinor details:\nIs there possibly a log missing in Eq. 2?\n", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}