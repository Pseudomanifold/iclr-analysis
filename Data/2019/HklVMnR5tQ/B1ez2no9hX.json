{"title": "Nice work, but claims are bit much", "review": "Summary:\nThe authors propose IMV-LSTM, which can handle multi-variate time series data in a manner that enables accurate forecasting, and interpretation (importance of variables across time, and importance of each variable). The authors use one LSTM per variable, and propose two implementations: IMV-Full explicitly tries to capture the interaction between the variables before mixing the LSTM hidden layers with attention. IMV-Tensor uses separate LSTMs for each variable that remain separate, and mixes the hidden layers of the LSTMs using attention. The propose model outperforms popular interpretable models on three different datasets, and the experiments regarding the variable importance is convincing.\n\nPros:\n- The paper is clearly written, easy to understand.\n- IMV-LSTM outperforms many baselines including popular interpretable models on three different datasets, and the interpretation part is not super rigorous, but convincing enough.\n- Multi-variate time-series data are very common, therefore an interpretable, accurate models such as IMV-LSTM have a big practical impact.\n- I like the idea of using the important variables to train another model for testing how accurately the models can choose important variables\n\nIssues:\n- In the introduction: claim that attention mechanism can unveil the effect of variable to the target is tricky, potentially dangerous: Attention is attention. It is no causal, let alone correlation. Coefficients in logistic regression are correlated with the prediction target. Variables with high attention has \"some relationship\" with the prediction target. \n- The methodological novelty of IMV-LSTM is limited. Using attention mechanism on RNN to provide interpretation has been explored quite often. This paper is not so different from other works [1,2,3]\n- Claim that this is the first work to derive temporal-level & variable-level importance is not convincing: The importance calculation of this paper boils down to averaging the attention values. This can be easily done in the previous works [1,2,3], or any model that uses attention on each input channel and on the temporal axis.\n- Can't follow Eq.10. How is this justified?\n\n\n[1] Choi, E., Bahadori, M.T., Sun, J., Kulas, J., Schuetz, A. and Stewart, W., 2016. Retain: An interpretable predictive model for healthcare using reverse time attention mechanism. In Advances in Neural Information Processing Systems (pp. 3504-3512).\n[2] Zhang, J., Kowsari, K., Harrison, J.H., Lobo, J.M. and Barnes, L.E., 2018. Patient2Vec: A Personalized Interpretable Deep Representation of the Longitudinal Electronic Health Record. IEEE Access.\n[3] Xu, Y., Biswal, S., Deshpande, S.R., Maher, K.O. and Sun, J., 2018, July. RAIM: Recurrent Attentive and Intensive Model of Multimodal Patient Monitoring Data. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (pp. 2565-2573). ACM.\n", "rating": "6: Marginally above acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}