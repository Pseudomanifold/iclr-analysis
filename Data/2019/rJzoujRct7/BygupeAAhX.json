{"title": "promising performance, left more mysteries than observations", "review": "The authors propose a model that learns to play the China Competitive Poker game. The model uses CNN to predict the actions, and is trained from actual human game records. The model is shown to beat the current best AI and human amateur players.\n\nThe performance is certainly strong (if it were true). But given the double-blinded policy, there is literally no way to verify the correctness of the performance---in other words, the paper is currently not reproducible at all. So the following comments are based on the trust-worthiness of the paper.\n\n(1) immature writing: The writing lacks formality and looks like a final project report. For instance, the super-short Section 2 is rather unprofessional---it is hard to believe that the related works can be described within two paragraphs anyway. Even as someone who understands the game of China Competitive Poker, I find it very hard to follow Section 3. There is a big room for improving the English writing.\n\n(2) ill-illustrated specialty of the model: In particular, it is not clear why the model should be superior than other modeling choices. For instance, what role does the neighboring connections of CNNs play? What are the cons and pros of choosing CNNs? Are there strong motivations to design the model this way? \n\n(3) many unanswered mysteries: why does the model trained with human records readily super-human? Note that this is controversial to common imitation learning where the typical performance is bound by the human-level performance. Even though authors claimed in the response that there are \"many professional records\"---but how many is many? Did the authors analyze the records and separate the professional versus amateur ones?", "rating": "2: Strong rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}