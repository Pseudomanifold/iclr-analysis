{"title": "Spreading vectors for similarity search", "review": "The authors propose a method to adapt the data to the quantizer, instead of having to work with a difficult to optimize discretization function. The contribution is interesting.\n\nAdditional comments and suggestions:\n\n- in the related work overview it would be good to also check possible connections with optimal transport methods using entropy regularization.\n\n- at some points in the paper, e.g. section 3.3, the authors mention Voronoi cells. However, in the related work in section 2 vector quantization and self-organizing maps have not been mentioned.\n\n- more details on the optimization or learning algorithms for eq (3)(4) should be given. The loss function is non-smooth and rather complicated. What are the implications on the learning algorithm when training neural networks? Is it important to have a good initialization or not?\n\n- How reproducible are the results? In Table 1 only one number in each column is shown while eqs (3)(4) are non-convex problems. Is it the best result of several runs or an average that is reported in the Table? \n\n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}