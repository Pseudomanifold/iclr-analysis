{"title": "Interesting idea and promising results", "review": "This paper presents a structural summarization model with a graph-based encoder extended from RNN. Experiments are conducted on three tasks, including generating names for methods, generating descriptions for a function, and generating text summaries for news articles. Experimental results show that the proposed usage of GNN can improve performance by the models without GNN. I think the method is reasonable and results are promising, but I'd like to see more focused evaluation on the semantics captured by the proposed model (compared to the models without GNN).\n\nHere are some questions and suggestions:\n\n- Overall, I think additional evaluation should be done to evaluate on the semantic understanding aspects of the methods. Concretely, the Graph-based encoder has access to semantic information, such as entities. In order to better understand how this helps with the overall improvement, the authors should consider automatic evaluation and human evaluation to measure its contribution. Also from fig. 3, we can see that all methods get the \"utf8 string\" part right, but it's hard to say the proposed method generates better description. \n\n- In the last table in Tab. 1, why the authors don't have results for adding GNN for the pointer-generator model with coverage?\n\n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}