{"title": "Incremental improvement to ASGD approaches at mid-size scaling", "review": "Paper offers an improvement to existing approaches using momentum with SGD for asynchronous training across a distributed worker pool. The key value in the proposal seems to be that it works \"out-of-the-box\" and requires no new parameters to be tuned, while delivering similar final accuracy as other distributed methods.\n\nThe authors begin with an explanation of ASGD training, why it doesn't scale - worker lags that lead to gap in parameter that gradients are computed on (worker parameters) vs parameters applied (master parameters). It also discusses the kind of momentum approaches that are in use today and how it helps and hurts. \n\nThe new proposal in this paper is DANA that builds on Nesterov Momentum to reduce the lag between these two sets of parameters by predicting the parameters that should be used for computing gradients at each worker.\n\nPros:\n- A key issue with most optimization methods is the number of hyperparameters to tune. DANA is \"out-of-the-box\" in that it doesn't introduce any new hyperparameters thus making it easy to scale the training of any model.\n\nCons:\n- The sweetspot for DANA seems to be between 8-24 workers. In practice these days it is pretty easy to run synchronous SGD for these sizes with a setup of 8 GPUs per machine with a few machines. The tuning of learning rate as a hyperparameter is required anyway, and keeping training synchronous doesn't really change that. The only issue is if one often changes number of workers for training, which isn't typical.\n- ASGD is useful for a larger number of workers as it is harder to train with SSGD for those because of the additional synchronization overhead. That is one area though where DANA starts to have worse behavior than other ASGD approaches.\n\nComments:\n- Paper assumes block-random scheduling for simulation, however in practice it is quite common to have a few workers that are consistently slower. How does this kind of bias effect their methods?\n", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}