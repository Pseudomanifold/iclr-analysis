{"title": "In general, a good paper addressing an important issue with distributed deep learning training, i.e., the gradient staleness vs parallel performance (speedup).", "review": "The paper addresses an important problem in distributed training of deep learning models, i.e., the gradient staleness vs the parallel performance. Keeping the gradient up-to-date in distributed training is important in order to achieve a low test error and high accuracy, but that comes at a cost: the overhead of more communication and synchronization. Asynchronous methods to update the gradient have been proposed, but they usually suffer from staleness, i.e., the communication latency between the master and the slaves impacts the accuracy and training time since the accumulated gradient already is \"old\" in relation to the model parameters when distributed to the slaves. \n\nThe paper proposes an approach to estimate the future model parameters at the slaves using Bengio-Nesterov momentum, thus reducing the effects of the communication latency (the gap) between the master and the slaves when collecting and distributing the gradient. The novelty is mainly on the application and implementation side of the spectrum, and not so much theoretical novelty. The contribution is relatively incremental, but important and clear. Reducing training times with maintained accuracy is an important practical problem, and we need all kinds of measures to address that.\n\nThe evaluation seems solid and the results are very promising. The comparison is done with relevant \"competitors\" (e.g., both synchronous and asynchronous approaches for distributed training). However, since the goal of distributed learning is improved execution performance, I would have liked to see more performance numbers. \n\nMinor:\n* Page 7, top paragraph. It's written that Table 2 shows that DANA easily scales to 32 workers. That information is not shown in Table 2... You don'r show any execution time / speedup numbers at all for ImageNet input. \n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}