{"title": "Interesting problem but extremely bad execution", "review": "The paper investigates the problem of universal replies plaguing the Seq2Seq neural generation models. The problem is indeed quite important because for problems with high entropy solutions the seq2seq models have been shown to struggle in past literature. While the authors do pick a good problem, that's where the quality of the paper ends for me. The paper goes on an endless meandering through a lot of meaningless probabilistic arguments.  First of all, factorizing a seq2seq model as done in equation 1 is plain wrong. The model doesn't operate by first selecting a set of words and then ordering them. On top of this wrong factorization, section 2.2 & 2.3 derives a bunch of meaningless lemmas with extremely crude assumptions. For example, for lemma 3, M is supposed to be some universal constant defined to be the frequency of universal replies while all other replies seem to have a frequency of 1. Somehow through this wrong factorization and some probabilistic jugglery, we arrive at section 3 where the takeaway from section 2 is the rather known one that the model promotes universal replies regardless of query. \n\nIn section 3, the authors then introduce the \"max-marginal regularization\" which is a linear combination of log-likelihood and max-margin (where the score is given by log-likelihood) losses. Firstly, the use of word \"marginal\" instead of \"margin\" seems quite wrong to say the least.  Secondly, the stated definition seems to be wrong. In the definition the range of values for \\gamma is not stated. I consider the two mutual exclusive and exhaustive cases (assuming \\gamma not equals 0) below and show that both have issues:\n(a) \\gamma > 0: This seems to imply that when the log-likelihood of ground-truth is already \\gamma better than the log-likelihood of the random negative, the loss comes to life. Strange!\n(b) \\gamma < 0: This is again weird and doesn't seem to be the intended behavior from a max-margin{al} loss. \nI'm assuming the authors swapped y with y^{-} in the \"regularization\" part.\nAnyways, the loss/regularization doesn't seem to be novel and should have been compared against pure max-margin methods as well.  \n\nComing to the results section, figure 3 doesn't inspire much confidence in the results. For the first example in figure 3, the baseline outputs seem much better than the proposed model, even if they follow a trend, it's much better than the ungrammatical and incomprehensible sentences generated by the proposed model. Also there seems to be a discrepancy in figure 3 with the baseline output for first query having two \"Where is your location?\" outputs.  The human column of results for Table 3 is calculated over just 100 examples which seems quite low for any meaningful statistical comparison. Moreover, not quite sure why the results used the top-10 results of beam instead of the top-1. \n\nA lot of typos/wrong phrasing/wrong claims and here are some of them:\n(a) Page 1, \"lead to the misrecognition of those common replies as grammatically corrected patterns\"? - No idea what the authors meant.\n(b) Page 1, \"unconsciously preferred\" - I would avoid attaching consciousness before AGI strikes us.\n(c) Page 1, \"Above characters\" -> \"Above characteristics\"\n(d) Page 1, \"most historical\" -> \"most previous\"\n(e) Page 2, \"rest replies\" -> \"rest of the replies\"\n(f) Page 3, \"variational upper bound\" -> Not sure what's variational about the bound\n(g) \"Word Perplexity (PPL) was used to determine the semantic context of phrase-level utterance\"? - No idea what the authors meant.", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}