{"title": "interesting work; more justification can help", "review": "I see the contribution of the paper as two-fold. first is introducing a task of estimating conditional average treatment effect by auxiliary dataset in different environments. second is develop algorithms to accomplish this task both with and without base learner and demonstrate success.\n\nthe causal setting it operates on is classical under strong ignobility and overlap.\n\n\nthe results are very interesting; meta-learning regression weights consistently yield significantly better results without using any base learner (that are often theoretically guaranteed with asymptotic optimality). \n\ncan the authors provide any intuitions? what is special about meta-learning regression weights that lead to much gain? does it get around any drawbacks of the popular base learners?\n\ncausal identification: while the authors operates under strong ignobility and overlap; so the contribution is not really causal here but rather in terms of estimation. I wonder if the authors can leverage these auxiliary information to achieve weaker identification condition. for example conditions like in \"Causal inference using invariant prediction: identification and confidence intervals; Jonas Peters, Peter B\u00fchlmann, Nicolai Meinshausen\"?", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}