{"title": "interesting initiative, ad-hoc model", "review": "The authors define the notion of cost-sensitive robustness, which measures the seriousness of adversarial attack with a cost matrix. The authors then plug the costs of adversarial attack into the objective of optimization to get a model that is (cost-sensitively) robust against adversarial attacks.\n\nThe initiative is novel and interesting. Considering the long history of cost-sensitive learning, the proposed model is rather ad-hoc for two reasons:\n\n(1) It is not clear why the objective should take the form of (3.1). In particular, if using the logistic function as a surrogate for 0-1 loss, shouldn't the sum of cost be in front of \"log\"? If using the probability estimated from the network in a Meta-Cost guided sense, shouldn't the cost be multiplied by the probability estimate (like 1/(1+exp(...))) instead of the exp itself? The mysterious design of (3.1) makes no physical sense to me, or at least other designs used in previous cost-sensitive neural network models like\n\nChung et al., Cost-aware pre-training for multiclass cost-sensitive deep learning, IJCAI 2016\nZhou and Liu, Training cost-sensitive neural networks with methods addressing the class imbalance problem, TKDE 2006 (which is cited by the authors)\n\nare not discussed nor compared.\n\nUpdate: I thank the authors for providing updated information in the Appendix discussing about other alternatives. While I still think it worth comparing with other approaches (as it is still not clear whether Khan's approach is regarded as state-of-the-art for *general* cost-sensitive deep learning), I think the authors have sufficiently justified their choice.\n\n(2) It is not clear why the perturbed example should take the cost-sensitive form, while the original examples shouldn't (as the original examples follow the original loss). Or alternatively, if we optimize the original examples by the cost-sensitive loss, would it naturally achieve some cost-sensitive robustness (as the model would naturally make it harder to make high-cost mistakes)? Those issues are yet to be studied.\n\nUpdate: I thank the authors for providing additional experiments on this part.\n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}