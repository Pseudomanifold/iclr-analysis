{"title": "Promising unification of neural representations with learned logical rules", "review": "\n\nUPDATE: Given the authors' rebuttal and the clear improvements to their paper, I've increased my rating of the work.\n\n=======================\n\nThis paper presents NLProlog, a method that combines logical rules with distributed representations for reasoning on natural language statements. Natural language statements (first converted to logical triples) and templated logical rules are embedded in a vector space using a pretrained sentence encoder. These embedded \"symbols\" can be compared in vector space, and their similarity used in a theorem prover (Prolog) modified to support weak unification. The theorem prover determines the answer to a natural language query by constructing a proof according to its logical rules.\n\nTraining through the non-differentiable theorem prover occurs via an \"evolutionary strategy,\" which enables the model to fine-tune its sentence encoders and learn domain-specific logic rules directly from text. The authors also propose a Gradual Rule Learning (GRL) algorithm that seems necessary for the optimization process to converge on good solutions.\n\nDespite the model's complexity, the paper was fairly clear to me.\n\nAlthough the proposed model is a conglomeration of pre-existing parts, the combination is original to my knowledge. The use of Open Information Extraction to transform natural language statements to logical statements, which amenable to theorem provers, is novel and also circumvents the complicated preprocessing required by previous related works.\n\nThe authors evaluate the proposed approach on subsets of the Wikihop dataset and BABI-1k. NLProlog performs competitively with neural models, similarly augmented with Sent2Vec but lacking explicit logical rules, only on the 'country' subset of Wikihop. It does not compete with or clearly outperform these models in general. As the authors state, it further \"struggles to find meaningful rules for the predicates 'developer' and 'publisher'.\"\n\nNLProlog demonstrates strong performance on a subset of problems labelled unanimously by annotators to require multi-hop reasoning. Unfortunately, this is only done for the \"country\" subset of Wikihop, on which the model was already shown to have the strongest performance. I'd find this more convincing if similar improvements were shown on the other subsets (publisher, developer).\n\nTaking into account also that the BABI subset was used only for ablation, the limited results call into question the significance of the work. It would definitely benefit from more extensive experimental validation. On the other hand, it's very positive to see that NLProlog seems to succeed where the neural models fail, and vice versa, so that the two approaches can be combined in an ensemble to achieve state-of-the-art results. This suggests that the paper's line of research has something to add to the community and should be pursued further. I'd find this result more interesting if an error analysis elucidated some characteristics of the examples that each approach does well/poorly on.\n\nI'd like to see more analysis in general, that answers questions including:\n- How reliable is the Open IE system and how does its performance impact the end task?\n- How well-specified must the a priori rule structures be to achieve good performance? Further, how does the number and structure of the rules (a hyperparameter in this work) affect performance?\n- What is the run-time/complexity of the exhaustive proof search during training?\n- Relatedly, you state that you limit the rule complexity to two body atoms in the rule templates for BABI. Can you estimate what rule complexity is required in the Wikihop tasks?\n\nI would like to recommend this work more confidently because it tackles such an important problem and does so in an interesting, well-conceived way. My reluctance arises from the limited experimental validation and analysis. Given more analysis details and experimental evidence from the authors, I'm happy to raise my recommendation.\n\nPros:\n- the method complements standard deep QA models to achieve state-of-the-art results in an ensemble.\n- unifying neural representations with logical/symbolic formalisms is an important research direction.\n- a code release is planned.\n\nCons:\n- a very complex model, whose details are occasionally unclear; the algorithms in Appendix A are helpful but they are not in the main text.\n- the model expresses only a limited subset of first order logic; dynamically changing world states are not supported (yet).\n- limited experimental validation.\n- it's good to be able to incorporate prior knowledge, but it seems like it's quite necessary to pre-specify rules (in template form).\n\nMinor quibble: Evolutionary learning strategies, such as genetic algorithms, go back a long way. It's strange using only a reference from 2017 to introduce them.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}