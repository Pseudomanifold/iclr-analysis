{"title": "interesting but seems to tackle a too narrow problem", "review": "The paper aims at studying the setting of perturbed rewards in a deep RL setting. Studying the effect of noise in the reward function is interesting. The paper is quite well-written. However the paper studies a rather simple setting, the limitations could be discussed more clearly and there are one or two elements unclear (see below).\n\nThe paper assumes first the interesting case where the generation of the perturbed reward is a function of S*R into the perturbed reward space. But then the confusion matrix does *not* take into account the state, which is justified by \"to let our presentation stay focused (...)\". I believe these elements should at least be clearly discussed. Indeed, in that setting, the theorems given seem to be variations of existing results and it is difficult to understand what is the message behind the theorems.\n\nIn addition, it is assumed that the confusion matrix C is known or estimated from data but it's not clear to me how this can be done in practice.  In equation 4, how do you have access to the predicted true rewards?\n\nAdditional comments:\n- The discount factor can be 0 but can not, in general, be equal to 1. So the equation in paragraph 2.1 \"0 < \u03b3 \u2264 1\" is wrong.\n- The paper mention that \"an underwhelming amount of reinforcement learning studies have focused on the settings with perturbed and noisy rewards\" but there are some works on the subject (e.g., https://arxiv.org/abs/1805.03359) and a discussion about the differences with the related work would be interesting.", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}