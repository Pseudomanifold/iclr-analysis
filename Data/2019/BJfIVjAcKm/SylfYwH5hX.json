{"title": "Well motivated, thorough empirical analysis, well written", "review": "Training for Faster Adversarial Robustness verification via inducing RELU stability\n\n\nAs I am familiar yet not an expert on adversarial training and robustess, my review will focus mainly on the overall soundness of the manuscript. I also only went superficially into the quantitative results.\n\nSummary:\n\nThe authors are interested in the problem of verifying neural networks models trained to be robust against adversarial attacks. The focus is on networks with relu activations and adversarial perturbations within an epsilon l1-ball around each input, and the verification problem consists in proving the network performs as intended for all possible perturbations (infinitely many)\n\nThe review on verification is clear. \nElements that affect verification time are introduced and well explained in main text or appendix from both intuitive and theoretical perspective: l1 penalty, weight pruning, relu stability. These can be summ\\arized as : you want few neurons, and you want them to operate in the same regime for all inputs, both to avoid branching. Relu stability is apparently a new concept and the proposed regularization approximately enforces relu stability.\nThe approximation [itself using the novel improved interval arithmetic] based bounds on unit activations propagated through the network seems not to scale well with depths (more units are mis-labelled as relu unstable, hence wrongly regularized if I understand correctly). The authors acknowledge and document this fact but I would like to hear more discussion on this feature and on the trade-off that still make this approach worthwhile for deeper networks.\n\nThis regularization does not help performance but only paves the way for a faster verification, for this reason the term co-design is used.\n\nThe rest of the manuscript is a thorough empirical analysis of the effect of the penalties/regularizations on the network and ultimately on the verification time, keeping an eye on not deteriorating the performance of the network.\nHow much regularization can be added seems to be indeed an empirical question since networks are \u2018over-parametrized in the first place\u2019 with no clear way to a priori quantify task or model complexity.\n\nThe devil is in the details and in practice implementation seems not straightforward with a complex optimization with varying learning rates and different regularizations applied at different time along the way. But this seems to be the case for most deep learning paper.\n\nThe authors claim and provide evidence to be able to verify network well beyond the scope of what was achievable before due to the obtained speed-ups, which is a notable feature.\n\nOverall, this manuscript is well structured, thorough and pleasant to read, and I recommend it to be accepted for publication at ICLR\n", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}