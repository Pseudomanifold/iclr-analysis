{"title": "A new method for computing Shapely values", "review": "This paper proposes two methods for instance-wise feature importance scoring, which is the task of ranking the importance of each feature in a particular example (in contrast to class-wise or overall feature importance).  The approach uses Shapely values, which are a principled way of measuring the contribution of a feature, and have been previously used in feature importance ranking.\n\nThe difficulty with Shapely values is they are extremely (exponentially) expensive to compute, and the contribution of this paper is to provide two efficient methods of computing approximate Shapely values when there is a known structure (a graph) relating the features to each other.\n\nThe paper first introduces the L(ocal)-Shapely value, which arises by restricting the Shapely value to a neighbourhood of the feature of interest.  The L-Shapely value is still expensive to compute for large neighbourhoods, but can be tractable for small neighbourhoods.\n\nThe second approximation is the C(onnected)-Shapely value, which further restricts the L-Shapely computation to only consider connected subgraphs of local neighbourhoods.  The justification for restricting to connected neighbourhoods is given through a connection to the Myerson value, which is somewhat obscure to me, since I am not familiar with the relevant literature.  Nonetheless, it is clear that for the graphs of interest in this paper (chains and lattices) restricting to connected neighbourhoods is a substantial savings.\n\nI have understood the scores presented in Figures 2 and 3 as follows:\n\nFor each feature of each example, rank the features according to importance, using the plugin estimate for P(Y|X_S) where needed.\nFor each \"percent of features masked\" compute log(P(y_true | x_{S\\top features})) - log(P(y_true | x)) using the plugin estimate, and average these values over the dataset.\n\nBased on this understanding the results are quite good.  The approximate Shapely values do a much better job than their competitors of identifying highly relevant features based on this measure.  The qualitative results are also quite compelling, especially on images where C-Shapely tends to select contiguous regions which is intuitively correct behavior.\n\nComparing the different methods in Figure 4, there is quite some variability in the features selected by using different estimators of Shapley values.  I wonder is there some way to attack the problem of distinguishing when a feature is ranked highly when its (exact) Shapley value is high versus when it is ranked highly as an artifact of the estimator?\n", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}