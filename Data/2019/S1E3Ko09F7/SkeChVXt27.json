{"title": "Novel methods for Shapley value estimation seem theoretically sound, could benefit from slightly more extensive evaluation", "review": "This paper provides new methods for estimating Shapley values for feature importance that include notions of locality and connectedness. The methods proposed here could be very useful for model explainability purposes, specifically in the model-agnostic case.  The results seem promising, and it seems like a reasonable and theoretically sound methodology.  In addition to the theoretical properties of the proposed algorithms, they do show a few quantitative and qualitative improvements over other black-box methods.  They might strengthen their paper with a more thorough quantitative evaluation.\n\nI think the KernelSHAP paper you compare against (Lundberg & Lee 2017) does more quantitative evaluation than what\u2019s presented here, including human judgement comparisons.  Is there a way to compare against KernelSHAP using the same evaluation methods from the original paper?\n\nAlso, you mention throughout the paper that the L-shapley and C-shapley methods can easily complement other sampling/regression-based methods.  It's a little ambiguous to me whether this was actually something you tried in your experiments or not.  Can you please clarify?", "rating": "7: Good paper, accept", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}