{"title": "Interesting, but hard to interpret the technical results.", "review": "This paper presents some results about the information bottleneck view of generalization in deep learning studied in recent work by Tishby et al.\nSpecifically this line of work seeks to understand the dynamics of stochastic gradient descent using information theory. In particular, it quantifies the mutual information between successive layers of a neural network. Minimizing mutual information subject to empirical accuracy intuitively corresponds to compression of the input and removal of superfluous information.\nThis paper further formalizes some of these intuitive ideas. In particular, it gives a variance/generalization bound in terms of mutual information and it proves an asymptotic upper bound on mutual information for the dynamics of SGD.\n\nI think this is an intriguing line of work and this paper makes an meaningful contribution to it. The paper is generally well-written (modulo some typos), but it jumps into the technical details (stochastic calculus!) without giving much intuition to help digest the results or discussion of how they relate to the broader picture. (Although I appreciate the difficulty of working with a page limit.) \n\nTypos, etc.:\np1. \"ereas\" should be \"whereas\"\np2. double comma preceeding \"the weights are fixed realizations\"\np5. extra of in \"needed to represent of the data\"\nThm 1. L(T_m) has not been formally defined when T_m contains a set of representations rather than data points.", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}