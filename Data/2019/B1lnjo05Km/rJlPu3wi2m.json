{"title": "Interesting technique, Lack of Related work", "review": "Authors present a novel regularizer to impose graph structure upon hidden layers of a neural Network. The intuition is that Neural Networks has typically  symmetric computation among different channels in one layer. Due to the lack of order, visually inspecting the hidden representation is not feasible. By adding edges one can impose a structure upon nodes in one layer and add for example a Laplacian regularizer rather than simple L2 norm regularizer to force the activations to follow the imposed structure. \n\nPros: \n\nInteresting idea for bringing some benefits of graphical models into Neural Networks using a regularizer.\n\nExperiments verify that one can successfully improve the intrepretability of hidden representations. Also, they provide examples of use cases for such technique like aligning the capsule dimmensions. \n\nCons:\n\nThe major flaw is the lack of comparison with ``any'' of the related work on interpretability or the prior work on imposing structure upon hidden representations. Also, the manuscripts lacks a clear discussion of where does this work stands in the literature like structured VAEs, graphical models, sum product nets + factor graphs. \n\nAlso, in none of the experiments authors mention how the added regularizer affects the model performance. Whether imposing the grid structure on CNN (last experiment) drops the CNN accuracy or has no effect? Same for the CapsNet.\n\nFurthermore, the feasibility of calculating the Laplacian for larger scale hidden layers or approximating it is not addressed.", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}