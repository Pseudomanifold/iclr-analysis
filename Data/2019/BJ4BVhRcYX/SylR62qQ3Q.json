{"title": "No comparisons and claiming something known make it hard to accept this paper", "review": "This paper claims to have shown some insights about the filters in a neural network. However, it has little contributions that are justifiable to be published and it missed way too many references.\n\nThe visualization of filters is hardly any contribution over [1]. The claim that AM is the best visualization tool is a weird statement given that there are many recent references on visualization, such as [2-4], which the authors all missed.\n\nThe proposed filter pruning is a simplistic approach that bears little technical novelty, and there has been zero comparison against any filter pruning approach/network compression approach, among the cited references and numerous references that the paper didn't cite, e.g. [5-6]. In this form I cannot accept this paper.\n\n[1] D Bau, B Zhou, A Khosla, A Oliva, and A Torralba. Network Dissection: Quantifying the Intepretability of Deep Visual Representations. In CVPR 2017.\n[2] Ramprasaath R. Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam, Devi Parikh Dhruv Batra. Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization. ICCV 2017\n[3] Jianming Zhang, Zhe Lin, Jonathan Brandt, Xiaohui Shen, Stan Sclaroff. Top-down Neural Attention by Excitation Backprop. ECCV 2016\n[4] Ruth Fong and Andrea Vedaldi. Interpretable Explanations of Black Box Algorithms by Meaningful Perturbation. ICCV 2017\n[5] Y. Guo, A. Yao and Y. Chen. Dynamic Network Surgery for Efficient DNNs. NIPS 2016\n[6] T.-J. Yang, Y.-H. Chen, V. Sze. Designing Energy-Efficient Convolutional Neural Networks using Energy-Aware Pruning. CVPR 2017", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}