{"title": "Good insights on magnitude based pruning but needs more empirical results", "review": "This paper proposes a statistical framework for determining parameter importance beyond magnitude based pruning.  The paper derives deep model parameter asymptotic theory to formulate a statistically-grounded pruning criterion which we compare with the magnitude pruning both qualitatively and quantitatively. The paper finds that this criterion to better capture parameter salience, since it takes into consideration the estimation uncertainty. The paper demonstrates the improved results for Lenet in terms of performance and easier post-pruned re-training.\n\nThe paper's take on the commonly used magnitude based pruning if appreciated. However, I am not fully convinced that pruning weights by magnitude close to random judgements in the general case as in the paper abstract. While the points made in Section 2 against magnitude based pruning are sound and relevant, it is unclear making such a strong general claim is wise since weights are commonly regularized. In fact, some previous work on pruning has performed these experiments and found that for common networks with default hyper-parameter configurations, weight based pruning performs better than magnitude based pruning. Li et. Al 2017 in the paper, Figure 4.4 compares random pruning with smallest L1 norm pruning and they find that smallest filter pruning has better accuracy than random filter pruning for all layers. Are there any real networks where such results would apply beyond the toy network in Figure 1?\n\nIn terms of empirical evaluation, results beyond Lenet such as on CIFAR-10 and Imagenet are required to claim Wald pruning is superior over existing methods, and comparison against other pruning methods such as dynamic pruning will make the paper stronger. It is unclear what to make of the 0.8% improvement in the Lenet results, performing extensive evaluation is necessary to show the performance of Wald pruning.\n", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}