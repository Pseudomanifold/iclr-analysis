{"title": "Will not stand up to scrutiny", "review": "This paper proposes using label smoothing and logit squeezing together with Gaussian noise injection at training time as a replacement for adversarial training. The paper builds on the flawed premise that label smoothing and logit squeezing can lead to more robustness - it simply masks the gradients so that the optimization landscape is harder. Also I am unconvinced that simply adding Gaussian noise together with these tricks can lead to any robustness against a worst case adversary - Gaussian noise augmentation is known to not lead to increased robustness (see e.g. [1]) while logit squeezing is also known to not lead to increased robustness (see e.g. [2]). So I cannot fathom why the two combined suddenly start working?\n\nAlso a glance at their experimental evaluation immediately uncovers the flaw that they only used 20 step PGD attack to evaluate the robustness of their model on CIFAR-10. Label smoothing and logit squeezing result in gradient masking and a more difficult terrain to optimize over, so increasing the number of attack steps and doing many random restarts will reveal that their claimed model is not as robust as the authors think.\n\n[1] https://arxiv.org/pdf/1711.08478.pdf\n[2] https://arxiv.org/pdf/1807.10272.pdf", "rating": "2: Strong rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}