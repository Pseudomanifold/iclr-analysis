{"title": "Interesting and well written, but the evaluation is difficult to interpret", "review": "Summary\n-------\nThis paper describes a model for musical timbre transfer which builds on recent developments in domain- and style transfer.\nThe proposed method is designed to be many-to-many, and uses a single pair of encoders and decoders with additional conditioning inputs to select the source and target domains (timbres).\nThe method is evaluated on a collection of individual note-level recordings from 12 instruments, grouped into four families which are used as domains.\nThe method is compared against the UNIT model under a variety of training conditions, and evaluated for within-domain reconstruction and transfer accuracy as measured by maximum mean discrepancy.\nThe proposed model seems to improve on the transfer accuracy, with a slight hit to reconstruction accuracy.\nQualitative investigation demonstrates that the learned representation can approximate several coarse spectral descriptors of the target domains.\n\n\nHigh-level comments\n-------------------\nOverall, this paper is well written, and the various design choices seem well-motivated.\n\nThe empirical comparisons to UNIT are reasonably thorough, though I would have preferred more in-depth evaluation of the MoVE model as well.  Specifically, the authors introduced an extra input (control) to encode the pitch class and octave information during encoding.  I infer that this was necessary to achieve good performance, but it would be instructive to see the results without this additional input, since it does in a sense constitute a form of supervision, and therefore limits the types of training data which can be used.\n\nWhile I understand that quantifying performance in this application is difficult, I do find the results difficult to interpret.  Some of this comes down to incomplete definition of the metrics (see detailed comments below).\nHowever, the more pressing issue is that evaluation is done either sample-wise within-domain (reconstruction), or distribution-wise across domains (transfer). The transfer metrics (MMD and kNN) are opaque to the reader: for instance, in table 1, is a knn score of 43173 qualitatively different than 43180?  What is the criteria for bolding here?  It would be helpful if these scores could be calibrated in some way, e.g., with reference to\nMMD/KNN scores of random partitions of the target domain samples.\n\nSince the authors do additional information here for each sample (notes), it would be possible to pair generated and real examples by instrument and note, rather than (in addition to) unsupervised, feature-space pairing by MMD.  This could provide a slightly stronger version of the comparison in Figure 3, which shows that the overall distribution of spectral centroids is approximated by transfer, but does not demonstrate per-sample correspondence.\n\n\n\nDetailed comments\n-----------------\nAt several points in the manuscript, the authors refer to \"invertible\" representations (e.g., page 4, just after eq. 1), but it seems like what they mean is approximately invertible or decodable.  It would be better if the authors were a little more careful in their use of terminology here.\n\nIn the definition of the RBF kernel (page 4), why is there a summation? \n What does this index? How are the kernel bandwidths defined?\n\nHow exactly are reconstruction errors calculated: using the NSGT magnitude representation, or after resynthesis in the time domain?\n", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}