{"title": "Review", "review": "The paper proposes a method MixFeat for regularizing deep neural networks models, aiming at avoiding overfitting in training. The MixFeat interpolates, based on a careful selected mixing ratio, the hidden states (feature maps) of two randomly selected examples. Unlike MixUp, the MixFeat does not interpolate the labels of the two selected examples and the feature interpolation processes are conducted in the hidden space. Experiments on both Cifar10 and Cifar100 show that the networks with MixFeat improve their predictive accuracy as well as outperform networks with Mixup as regularizer.   \n\nThe paper is well written and easy to follow, and the experimental results on both Cifar10 and Cifar100 show promising results. Nevertheless, the idea of interpolating pairs of latent features for network regularization is not very novel. Additional, the experimental section is a bit weak in its current form. \n\nMain Remarks:\n\n1.\tMixFeat is very similar to Manifold-Mixup (Verma et al., Manifold Mixup: Learning Better Representations by Interpolating Hidden States), where both feature maps and labels of a pair of examples are mixed, so Manifold-Mixup would be a valid comparison baseline to MixFeat. In addition, the proposed method is similar to SMOTE (where features are mixed in the input space). In this sense, performance of SMOTE may be a useful comparison baseline as well.\n2.\tIn the experimental section, the choice of parameter for Mixup seems arbitrary to me and may not be the optimal one. For example, for the Cifar10 and Cifar100 datasets, the original paper highlights that Alpha equals to one is a better choice to obtain better accuracy for ResNet. Also, as highlighted from AdaMixup (Guo et al., MixUp as Locally Linear Out-Of-Manifold Regularization), MixUp is quite sensitive to the choice of Alpha and suboptimal Alpha value easily leads to underfitting. \n3.\tSome claims are not well justified. For example, the authors claim that MixFeat can reduce overfitting even with datasets with small sample size, but did not provide any training cost or errors in Figure6 to support that claim. \n4.\tMixFeat is closely related to MixUp, and I would like to see more experiments with MixUp as baseline in terms of regularization effect. For example, it would be useful to include MixUp in Figures 4 and 6.\n\nMinor remarks: \n\n1.\tWhat were the parameters for MixFeat used for Table 1?\n2.\tIs the proposed method robust to adversarial examples as shown in MixUp and ManiFold-Mixup?\n3.\tHow the incorrect labels are generated in Section 3.2.1 is not very clear to me.\n4.\tSince MixFeat is similar to Mixup, I wonder if MixFeat has the problem of \u201cmanifold intrusion\u201d as suggested in AdaMixUp when generating samples from image pairs?  How sensitive is MixFeat to the parameters Theta and Pi? Would learning mixing policies as suggested by AdaMixUp make sense here?\n\n============after rebuttal============\n\nI really appreciate the authors' rebuttal, which has addressed some of my concerns.\nNevertheless, I agree with the other reviewers about the main weakness of the paper. That is, why the proposed method works and what are its advantages over similar strategies, such as Mixup, AdaMixup and Manifold Mixup, are not clear.", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}