{"title": "Well executed, but not exploring challenging questions", "review": "Summary:\nThe authors propose a benchmark of biologically plausible ANNs on the MNIST dataset with an emphasis on local learning rules (ruling out backpropagation, and enforcing small receptive fields). They find that random projection (RP) networks provide good performance close to backpropagation and outperform other local learning rules based on unsupervised learning.\n\n\n\nEvaluation:\nA well-executed work but with major limitations: it is based mostly on MNIST, analysis of spiking network is limited, and deep biologically plausible learning rules are not investigated.\n\nDetailed comments:\n\nWhile the paper reads well, choosing how to evaluate the contribution for such benchmark paper is a bit difficult, as the novelty is by definition more limited than in papers proposing a new approach.\nIn the following I chose to focus on what information such benchmark may bring to the field for addressing to challenges ahead.\n\n1.\tStrengths\nThe authors made the effort of implementing several biologically plausible learning rules, including Feedback alignment, and sparse coding. In particular, the idea of using local unsupervised learning rules as baselines for learning the hidden layer is a good idea to extend the range of tested algorithms.\n\n2.\t\u201cEasy\u201d dataset\nIt is unclear to me in which way MNIST result can help evaluate the next challenges in the field. While it is good to know that simple algorithms can achieve close to state of the art, I am not sure this is enough for a paper submitted in 2018. Ideally, most of the analysis could be reproduced at least for CIFAR10 (as the authors started to do in table 2).\n\n3.\tLimited architectures\nMost of the analysis is restricted to one single layer. However, biologically plausible algorithms have also been proposed that can in principle apply to multiple layers. In addition to feedback alignment (implemented in the manuscript in the single hidden layer case), you can find relatively simple approaches in the literature, for example\n\u201cBalduzzi, David, Hastagiri Vanchinathan, and Joachim M. Buhmann. Kickback Cuts Backprop's Red-Tape: Biologically Plausible Credit Assignment in Neural Networks. AAAI. 2015.\u201d Given the dominant view that depth is key for learning challenging datasets, not exploring this option at all in a benchmark seems a significant weakness.\n\n4.\tSpiking networks\nWhile the authors seem to emphasize spiking as an important aspect of biological plausibility (by using LIF neurons and STDP). The challenges of such approaches seem to be largely unaddressed and the main take home message is a performance similar to the corresponding rate models. It would be very interesting, for example, to see how many spikes (or spikes per neurons) are need per example to achieve a robust classification.\n\n5.\tOverall objective behind biological plausibility\nExtending the previous point, the results are to some extent limited to accuracy. If one wishes to achieve biological plausibility, more aspect can be taken into consideration. For example:\n-\tDuring test: the average number of activated neurons, the average number of activated synapses. \n-\tDuring training: the overall number of activations needed to train the algorithm.\nIn relation to these consideration, a more concrete discussion about the potential benefits of biological plausibility would be helpful.\n", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}