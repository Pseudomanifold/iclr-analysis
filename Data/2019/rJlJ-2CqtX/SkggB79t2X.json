{"title": "value constrained model-free continuous control", "review": "This paper uses constrained Markov decision processes to solve a multi-objective problem that aims to find the correct trade-off between cost and return in continuous control. The main technique is Lagrangian relaxation and experiments are focus on cart-pole and locomotion task.\n\nComments:\n\n1) How to solve the constrained problem (8) is unclear. It is prefer to provide detailed description or pseudocode for this step.\n\n2) In equation (8), lambda is a trade-off between cost and return. Optimization on lambda reduces burdensome hyperparameter selection, but a new hyperparameter beta is introduced. How do we choose a proper beta, and will the algorithm be sensitive to beta?\n\n3) The paper only conducts comparison experiments with fixed-alpha baselines. The topic is similar to safe reinforcement learning. Including the comparison with safe reinforcement learning algorithms is more convincing.\n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}