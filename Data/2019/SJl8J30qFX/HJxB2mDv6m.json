{"title": "well written with thorough experiments, but limited novelty and scope", "review": "Summary:\nThis paper incorporates Generalized Additive Models (GAMs) with model distillation to provide global explanations of neural nets (fully-connected nets as black-box in the paper). It is well written with detailed experiments of synthetic and real tabular data, and makes some contribution towards the interpretability of black-box models. However, it lacks novelty and is limited to tabular data as presented.\n\nPros:\n- The paper is well written.\n- The experiments are detailed and thorough with both synthetic and real data.\n\nCons:\n- The novelty is limited. The core consists of GAMs well studied in the literature, e.g. Caruana et al 2015. Admittedly, this work also tries to incorporate model distillation to explain black-box models globally. The concept of student models approximating teacher models is not new either. The originality seems incremental in both directions.\n- The scope is limited. The paper only presents applications in tabular data. Also, it would be better to experiment with black-box models beside simple fully-connected nets.\n- The interpretability is not convincing. It is not sufficient to demonstrate the interpretability of the proposed method, or the expressive advantage of feature shapes. It is encouraged to include studies with human subjective to compare against other existing interpretable approaches.\n\nSpecifics:\n- With Figure 3, it is not convincing that the student model actually explains the teacher model, so the paper tries to elaborate more with Table 1. I think Table 1 also needs more details to help, such as the significance of error difference and '-' elements.\n- Many figures are hard to read mostly because of font, color, and overlap.\n", "rating": "6: Marginally above acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}