{"title": "good paper", "review": "This paper is of high quality and clarity. I think it's originality is at least decent. Whether it is significant or not depends on how significant one thinks fully connected neural networks are as these are the models for which this explanation model makes sense.\n\nGood things:\n- It is a very elegant method. It is also very simple (in a good way).\n- The paper is really well written.\n- The experiments are carefully conducted and are indeed showing what the authors describe.\n- I think the method is potentially of practical use.\n\nProblems:\n- I think qualifying this paper as a paper on representation learning is a small stretch. It would be perhaps more suitable to submit it to ICML or NIPS. I think it is close enough though.\n- The font is too small in many figures. It is impossible to read it. \n- I am not sure whether model compression is actually necessary here. How good is the additive model if it is trained as a standalone model straight from the training data in comparison to the neural networks and to the additive model when trained with model compression? If the neural network and the additive model were similar in performance when trained from scratch, I would not see the point in explaining the neural network.\n- Only makes sense to apply this to fully connected networks.", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}