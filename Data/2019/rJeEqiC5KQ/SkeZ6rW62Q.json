{"title": "The paper deals with a significant topic, that of incremental classifier learning, but has a limited novelty and many unclear points", "review": "The paper extends an existing incremental learning method, mainly introducing the latent representations of an autoencoder instead of the original images. It includes a lot of hype in that it simulates the human brain -  because it is based on the iCaRL & Fear Net formulation - and that it fulfils the privacy and legal requirements - because it stores and uses the auto-encoder representations instead of the images.\n\nSpecific comments:\n\n- The title of the paper defines its topic to be context aware advertisement, whereas the main results and all comparisons are made on the CIFAR dataset. Only the last Table (5) provides the performance on the IMDB-CAA dataset, without any detailed analysis of the experiments.\n\n- The results in Table 3 are quite strange: the presented approach starts by outperforming iCaRL method, but then deteriorates very fast wrt size and is much lower than the original method, with no justification on this. Some improvement is shown in size 16.6% without, again, any logical explanation provided.\n\n- Section 4.2 does not provide any detail of the integration resulting in the presented system; Fig.2 does not provide a clear description either.\n\n- Language improvement is required in the experimental sections.\n\n-  ", "rating": "5: Marginally below acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}