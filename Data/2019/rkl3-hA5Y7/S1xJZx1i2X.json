{"title": "Back to the past", "review": "This paper is very interesting as it seems to bring the clock back to Holographic Reduced Representations (HRRs) and their role in Deep Learning. It is an important paper as it is always important to learn from the past. HRRs have been introduced as a form of representation that is invertible. There are two important aspects of this compositional representation: base vectors are generally drawn from a multivariate gaussian distribution and the vector composition operation is the circular convolution. In this paper, it is not clear why random vectors have not been used. It seems that everything is based on the fact that orthonormality is impose with a regularization function. But, how can this regularization function can preserve the properties of the vectors such that when these vectors are composed the properties are preserved.\n\nMoreover, the sentence \"this is computationally infeasible due to the vast number of unique chunks\" is not completely true as HRR have been used to represent trees in \"Distributed Tree Kernels\" by modifying the composition operation in a shuffled circular convolution. ", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}