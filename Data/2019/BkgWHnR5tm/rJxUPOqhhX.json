{"title": "Direct application of ES with NerveNet for fitness evaluation", "review": "[Summary]:\nThis paper tackles the problem of automatic robot design. The most popular approach to doing this has been evolutionary methods which work by evolving morphology of agents in a feed-forward manner using a propagation and mutation rules. This is a non-differentiable process and relies on maintaining a large pool of candidates out of which best ones are chosen with the highest fitness. In robot design for a given task using rewards, training each robot design using RL with rewards is an expensive process and not scalable. This paper uses graph network to train each morphology using RL. Thereby, allowing the controller to share parameters and reuse information across generations. This expedites the score function evaluation improving the time complexity of the evolutionary process.\n\n[Strengths]:\nThis paper shows some promise when graph network-based controllers augmented with evolutionary algorithms. Paper is quite easy to follow.\n\n[Weaknesses and Clarifications]:\n=> Robot design area has been explored extensively in classical work of Sims (1994) etc. using ES. Given that, the novelty of the paper is fairly incremental as it uses NerveNet to evaluate fitness and ES for the main design search.\n=> Environment: The experimental section of the paper can be further improved. The approach is evaluated only in three cases: fish, walker, cheetah. Can it be applied to more complex morphologies? Humanoid etc. maybe?\n=> Baselines: The comparison provided in the paper is weak. At first, it compares to random graph search and ES. But there are better baselines possible. One such example would be to have a network for each body part and share parameters across each body part. This network takes some identifying information (ID, shape etc.) about body part as input. As more body parts are added, more such network modules can be added. How would the given graph network compare to this? This baseline can be thought of a shared parameter graph with no message passing.\n=> The results shown in Figure-4 (Section-4.2) seems unclear to me. As far as I understand, the model starts with hand-engineered design and then finetuned using evolutionary process. However, the original performance of the hand-engineered design is surprisingly bad (see first data point in any plot in Figure-4). Does the controller also start from scratch? If so, why? Also, it is not clear what is the meaning of generations if the graph is fixed, can't it be learned altogether at once?\n\n[Recommendation]:\nI request the authors to address the comments raised above. Overall, this is a reasonable paper but experimental section needs much more attention.", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}