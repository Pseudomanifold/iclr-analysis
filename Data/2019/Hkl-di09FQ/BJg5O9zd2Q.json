{"title": "Interesting experiment results, unfortunately lacking in terms of new insights.", "review": "The paper is easy to read and the presentation is clear, and I really appreciate this.\n\nThe authors address the very important topic of feature extraction and state representation learning. New results in this area are always valuable and welcome. However, my feeling is that the paper falls short in terms of making sufficient new contributions for an ICLR paper. \n\n1. The authors propose to learn a state representation by either training using a combined loss function, or training several representations using multiple loss functions followed by stacking. These are standard and well-known techniques in machine learning. The key contribution one looks for is in terms of new insights on why and when each approach works. The paper fails to provide much insight in this regard. Take this simple scenario: Suppose my input image is actually generated by a linear map plus gaussian noise on the true states. Then I can simply use a PCA as my \"auto encoder\" and happily learn a high quality state representation close to the ground truth. We know why this works. In the real task, the image is a complex non-linear transformation of the true states. What insights do I gain from this work in terms of how I should tackle this?\n\n2. Section 3 states some desirable characteristics in constructing a state representation. These are well-known and fundamental aspects of machine learning -- applicable to almost all models that we want to learn. In this sense, I do not find the section very informative.\n\n3. The empirical results (say, Table 1) seem too noisy to interpret (other than that using the ground truth provides the best performance). It almost seems to suggest that one should simply use random features (as done in the \"extreme learning machine\" approach). Again, not much insight to draw from this.\n\n4. Last comment. Suppose I have a new robotic goal-directed task and my inputs are camera images. Does this work tell me something that I don't already know in terms of learning new feature representation that is highly suitable for my task?\n\n\n\n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}