{"title": "Interesting idea with weaknesses in the formal and empirical parts", "review": "The authors propose a method for learning vector representations for graphs. The problem is relevant to the ICLR community. \n\nThe paper has, however, three major problems:\n\nThe motivation of the paper is somewhat lacking. I agree that learning representations for graphs is a very important research theme. However, the authors miss to motivate their specific approach. They mention the importance of learning on smaller graphs and applying the learned models to larger graphs (i.e., extrapolating better). I would encourage the authors to elaborate on some use cases where this is important. I cannot think of any at the moment. I assume the authors had use cases in combinatorial optimization in mind? Perhaps it might make sense to motivate the use of GNNs to solve vertex cover etc. \n\nI\u2019m not sure about the correctness of some of the theorems. For instance, Theorem 2 states \n\u201cFor any fixed k > 0, there exists a function f(\u00b7) and an input graph instance G such that no k-LOCAL-GATHER algorithm can compute f(G) exactly.\u201d  I\u2019m not claiming that this is a false statement. What I am suspecting at the moment is that the proof might not necessarily be correct. For instance, it is known that what you call 1-LOCAL-GATHER can compute the 1-Weisfeiler-Leman partition of the nodes (sometimes also referred to as the 1-WL node coloring). Now consider the chain graph 1 - 2 - 3 - 4 - 5. Here, the partition that puts together 1-WL indistinguishable nodes are {1, 5}, {2, 4} and {3}. Hence, the 1-WL coloring is able to distinguish say nodes 2 and 3 even their 1-neighborhood looks exactly the same. A similar argument might apply to your example pairs of graphs but I haven\u2019t checked it yet in detail. What is for sure though: what you provide in the appendix is not a proper formal proof of Theorem 2. This has to be fixed. \n\nThe experiments are insufficient. The authors should compare to existing methods on common benchmark problems such as node or graph classification datasets. Comparing to baselines on a new set of task is not enough. Why not compare your method also on existing datasets?\nIf you motivate your method as one that performs well on combinatorial problems (e.g., vertex cover) you should compare to existing deterministic solvers. I assume that these are often much faster at least on smaller graphs. ", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}