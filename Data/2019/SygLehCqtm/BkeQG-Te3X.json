{"title": "Good application paper but evaluation must be strengthened", "review": "General comment\n==============\nThe authors describe two loss functions for learning embeddings of protein amino acids based on i) predicting the global structural similarity of two proteins, and ii) predicting amino acid contacts within proteins. As far as I know, these loss functions are novel and the authors show clear improvements when using the learned embeddings in downstream tasks. The paper is well motivated and mostly clearly written. However, the evaluation must be strengthened and some aspects of it clarified. Provided that the authors address my comments below, I think it is a good ICLR application paper.\n\nMajor comments\n=============\n1. The authors should describe how they optimized hyperparameters such as the learning, lambda (loss section 3.3), or the smoothing factor (section 3.4). These should be optimized on an evaluation set, but the authors only mentioned that they split the dataset into training and holdout (test) set (section 4.1).\n\n2. The way the authors present results in table 1 and table 2 is unclear. Both table 1 and table 2 contain results of the structural similarity tasks but with different baselines. \u2018SSA w/ contact predictions\u2019 is also undefined and can be interpreted as \u2018with\u2019 or \u2018without\u2019 contacts predictions. I therefore strongly recommend to show structural similarity results in table 1 and secondary structure results in table 2 and include in both tables i) \u2018SSA full\u2019, \u2018SSA without contact predictions\u2019, and \u2018SSA without language model\u2019.\n\n3. The authors should compare SSA to the current state-of-the art in structure prediction in addition to baseline models.\n\n4. The authors should evaluate how well their method predicts amino acid contact maps.\n\n5. The authors should describe how they were dealing with variable-length protein sequences. Are sequences truncated and embedded to a fixed length? What is the mean and variance in protein sequence lengths in the considered datasets? The authors should point out that their method is limited to fixed length sequences.\n\n6. The authors should briefly describe the training and inference time on a single GPU and CPU. How much memory is required for training with a certain sequence length, e.g. 400 amino acids per sequence? Does the model fit on a single GPU?\n\n7. The authors should discuss limitations of their method, e.g. that it cannot handle variable length sequences and that the memory scales quadratically by the the sequence length.\n\n8. CRF (SSA) (table 3) includes a biLSTM layer between SSA and the CRF. However, the biLSTM can learn a non-linear projection of embeddings learned by SSA such that it is unclear if improvements are due to the embeddings learned by SSA or the biLSTM+CRF architecture. The authors should therefore train a biLSTM+CRF model on one-hot encoded amino-acids and include it as baseline in table 3.\n\n\nMinor comments\n=============\n9. The way the similarity score s\u2019 is computed (section 3.2.1) should be motivated more clearly. Why do the authors compute the score s\u2019 manually instead of predicting it, e.g. using a model that takes the embeddings z of both proteins as input and predicts a single scalar s\u2019? \n\n10. How does ordinal regression (section 3.2.2) perform compared with a softmax layer? Why do the authors compute s\u2019 and then train logistic regression classifiers on s\u2019 to predict the similarity level, instead of predicting the similarity level directly based on the embeddings z?\n\n11. Why do the authors use a distance threshold of 8A (section 3.3)? Is this common practice in the field?\n\n12. Why do the authors use the not product and the absolute difference as features instead of the embeddings z directly? Which activation function is used to predict contact probabilities (sigmoid, softmax, \u2026)?\n\n13. The authors should reference and describe the results presented in table 1 more clearly.\n\n14. Optional: the authors should analyze if learned embeddings are correlated with amino acid and structural properties such as their size, charge, or solvent accessibility. Do embeddings clusters by certain properties? This can be analyzed, e.g., using a tSNE plot. \n\n15. How does TMalign perform when using the maximum or geometric average instead of the arithmetic average of the two scores (section 4.1)", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}