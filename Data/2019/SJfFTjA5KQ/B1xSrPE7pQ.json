{"title": "Possibly interesting, but unclear exposition and lack of concrete evidence", "review": "This paper attempts to do three things:\n\t1) introduce a generalization / formalism for describing RNN architectures\n\t2) demonstrate how various popular RNN architectures fit within the proposed framework\n\t3) propose a new RNN architecture within the proposed framework that overcomes some limitations in LSTMs\nThe ultimate goal of this work is to develop an architecture that:\n\t1) is better able to model long-term dependencies\n\t2) is stable and efficient to train\n\nSome strengths, concerns, and questions loosely ordered by section:\n\nStable RNNs\n\t- it's not clear to me where equations (2) and (3) come from; what is the motivation? Is it somehow derived from this Runge-Kutta method (I'm not familiar with it)? \n\t- I don't understand what this t^th order time-derivative amounts to in practice. A major claim (in Table 4) is that LSTMs are time-order 2 whereas QUNNs are time-order L and the implication is that this means LSTMs are worse at modeling long term structure than QUNNs ; but how does that actually relate to practical ability to model long-term dependencies? It certainly doesn't seem correct to me to say that LSTMs can only memorize sequences of length 2, so I don't know why we should care about this time-derivative order.\n\t- I thought this section was poorly written. The notation was poorly chosen at times, e.g. the t_k notation and the fact that some $l$ have subscripts and some don't. There were also some severe typos, e.g. I think Claim 1 should be \"L-2-ORNN\". Furthermore, there were crucially omitted definitions: what is reversibility and why should we care? Relatedly, the \"proofs\" are extremely hand-wavy and just cite unexplained methods with no further information.\n\nQUNNs\n\t- The practical difference between QUNNs and LSTMs seems to be that the weights of the QUNN are dynamic within a single forward prop of the network, whereas LSTM weights are fixed given a single run (although the author does admit that the forget gates adds some element of dynamism, but there's no concrete evidence to draw conclusions about differences in practice).\n\t- I don't understand the repeated claim that LSTMs don't depend on the data; aren't the weights learned from data?\n\t\nThere may be something interesting in this paper, but it's not clear to me in its current incarnation and I'm not convinced that an eight-page conference paper is the right venue for such a work. There's a substantial of amount of exposition that needs to be there and is currently missing. I suspect the author knows this, but due to space constraints had to omit a lot of definitions and explanations.\n\nI don't think all papers need experiments, but this paper I think would have greatly benefited from one. Community knowledge of LSTMs has reached a point where they are in practice easy to train and fairly stable (though admittedly with a lot of tricks). It would have been much more convincing to have simple examples where LSTMs fail due to instability and QUNNs succeed. Similarly, regarding long-term dependencies, my sense is that LSTMs are able to model some long-term dependencies. Experimental evidence of the gains offered by QUNNs would have also been very convincing.\n\nNote: It looks like there's some funkiness in the tables on page 8 to fit into the page limit.\n", "rating": "4: Ok but not good enough - rejection", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}