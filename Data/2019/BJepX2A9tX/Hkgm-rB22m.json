{"title": "Okay paper with limited novelty and lacking experimental evidence for main supposed advantages of proposed method", "review": "Disclaimer: I've already reviewed an earlier version of this manuscript for NIPS 2018.\n\n# Summary\n\nIn the context of image classification, the paper proposes a convolutional neural network architecture with rotation-equivariant feature maps that are eventually made rotation-invariant by using the magnitude of the 2D discrete Fourier transform (DFT). Classification experiments are conducted on three different datasets.\n\nThe problem of rotation-invariant image classification addressed by the paper is important, since structures in images may appear at arbitrary orientations in many applications (e.g. microscopy).\n\n\n# Novelty\n\nThe general ideas of the paper are sound, however seem to be of rather minor novelty.\nThe paper claims two main novelties: (1) conic convolutions and (2) using the DFT magnitude for rotation invariant classification in the context of CNNs.\n- While (1) seems novel, the paper doesn't convince me that conic convolutions would be useful in practice. While they are more memory efficient, they achieve this by actually computing fewer features (each conic region is only processed by a particular orientation of a convolution kernel). Hence, they should (theoretically) be less powerful than group convolutions (i.e. G-CNN; the whole image is processed by a particular orientation of a convolution kernel). Furthermore, there are no experiments that demonstrate the advantages of the lower memory footprint of conic convolutions.\n- Novelty (2) is only because it hasn't been used in the context of CNNS, but there is no technical novelty here. Using the DFT magnitude for rotational invariance is an orthogonal contribution that can also be applied to G-CNN, which the paper also evaluates (this is good).\n\n\n# Experiments\n\n- Rotation-equivariant CNNs are expected to perform better than standard CNNs when only limited training data is available. However, this is not thoroughly evaluated in the paper, which only does a very coarse comparison (trained with N=50 or N=100 images). Since this is the main advantage of of CNNs with built-in rotation-equivariance, I expect a more thorough evaluation showing the results for several different training data sizes.\n- The savings in terms of computational and especially storage efficiency of CFNet are not really evaluated, only briefly mentioned in the very short section 3.4. Again, this needs to be expanded since computational/memory efficient is a supposed main advantage of conic convolutions over group convolutions.\n\n- In section 4.2: Why are image rotations used for data augmentation? (The whole point of the compared classification methods (expect for \"CNN\") is to be rotation-invariant.) It would be interesting to show the results with and without image rotation augmentation.\n- G-CNN+DFT is missing for the budding yeast cell classification experiment (section 4.3). As mentioned before, I suspect it would perform well or even better than CFNet. Also, why is Worrall et al. (2017) not compared to in sections 4.2 and 4.3.? (It was the best method in for rotation-MNIST.)\n\n\n# Clarity\n\nAlthough the writing is grammatically well done, I found it difficult to follow the explanation of the proposed method. In particular, the mathematics often add to my confusion instead of clearing it up. Given that the proposed concepts are not actually that complicated, I feel the paper makes heavy use of *mathiness* (\"the use of mathematics that obfuscates or impresses rather than clarifies\" [1]).\n\n[1]: Zachary C. Lipton, Jacob Steinhardt. \"Troubling Trends in Machine Learning Scholarship.\", https://arxiv.org/abs/1807.03341\n\n\n# Missing explanations\n\n- Standard pooling will not preserve rotation-equivariance (RE). While section 3.2 mentions this, it doesn't really explain how pooling is changed to preserve RE. Furthermore, it is also not explained why a deep network based on conic convolutions remains RE after several downsampling and conic convolution layers. I feel there's a problem when the conic regions become tiny after several downsampling operations. Fig. 2 shows that fewer conic regions are used then, limiting the equivariance to 90 degree rotations. This seems like a conceptual limitation.\n- The paper says that the conic convolution layer uses a \"filter size of three pixels\", but fails to mention that this means there are currently strong interpolation artifacts, especially for finer degrees of rotation (the paper only rotates at most 8 times). Section 4 only briefly mentions that this would be alleviated by using steerable filters.", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}