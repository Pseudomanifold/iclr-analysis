{"title": "Nice study of zeroth-order sign SGD", "review": "In this paper, the authors studied zeroth order sign SGD. Sign SGD is commonly used in adversarial example generation. Compared to sign SGD, zeroth-order sign SGD does not require the knowledge of the magnitude of the gradient, which makes it suitable to optimize black-box systems. The authors studied the convergence rate of zeroth-order sign SGD, and showed that under common assumptions, zero-order sign SGD achieves O(sqrt(d/T)) convergence rate, which is slower than sign SGD by a factor of sqrt(d). However, sign SGD requires an unrealisitcally large mini-batch size, which zeroth-order sign SGD does not. The authors demonstrated the performance of zeroth-order sign SGD in numerical experiments.\n\nOverall, this is a well written paper. The convergence property of the zeroth-order sign SGD is sufficiently studied. The proposal seems to be useful in real world tasks.\n\nWeaknesses: \n1) out of curiosity, can we improve the convergence rate of the zeroth-order sign SGD if we assume the mini-batch size is of order O(T)? This could help us better compare zeroth-order sign SGD and sign SGD.\n2) Figure 2 is too small to be legible. Also, it seems that the adversarial examples generated by zeroth-order sign SGD have higher distortion than those found by zeroth-order SGD on CIFAR-10 dataset. Is it true? If so, it would be beneficial to have a qualitative explanation of such behavior.", "rating": "6: Marginally above acceptance threshold", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}