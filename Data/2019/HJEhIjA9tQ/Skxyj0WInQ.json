{"title": "not yet ready to be published", "review": "The paper proposes a novel encoder-based unsupervised representation learning. The network consists an encoder and a discriminator. The encoder learns to generate sample-specific codes, and discriminator tries to assign the generated code to the corresponding sample, given the correct sample and a set of incorrect samples. The method is tested on two relatively small datasets: MNIST and Fashion MNIST. \nThe essence of the method is novel and make sense. The text is short but clear. the method technically sounds. However, the experimental part lacks a quantitative evaluation as well as a comparison to state-of-the-art methods, which makes the assessment of the proposed model difficult. Qualitative results are informative but not enough. Another disappointing point in experiments is that the method is evaluated on two relatively small datasets, with very small latent space (d=2). \nI expected two major experiments: (1) applying the model on a bigger dataset, as mentioned in future works, (2) consider this game as a self-supervised representation learning method and use it as an initialization for a supervised task. It gives the opportunity to compare it against others as well.\n\nother points:\n- the paper lacks a comprehensive literature review. the topic is well studied and deserves to cite more than 8 references. \n- some details are missing in the text e.g. fully-connected size, training hyper-parameters, number of incorrect samples fed to discriminator during training, training time, number of parameters.\n- ablation study: which one is a better feature learning network: Encoder or convolutional layers of Discriminator?\n\nIn general, I believe that some significant analyses are missing and it is not possible to accept a paper without having additional insights. ", "rating": "3: Clear rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}