{"title": "Interesting Preliminary Idea but Needs More Work", "review": "The paper presents a new strategy for unsupervised learning. The idea is that a given a random sample, the encoder returns a compressed representation. The decoder then tries to use this representation to pick out the correct sample in the training set.\n\nThe idea is interesting but I have a number of concerns.\n\n(1) I am not convinced that this approach will not degenerate to just learning some sort of hash function. What is encouraging similar images to have similar representations? \n\nFor instance, if the discriminator had access to the encoder function it could just run the encoder on all the samples in the dataset and then pick out the one most similar to the description it has received. (I agree the discriminator doesn't have access to the encoder, but it can learn to mimic it based on a large number of samples)\n\n\n(2) The math could be written a little more rigorously in Section 2.\n\n\n(3) The experiments are not thorough and there is no comparison to existing approaches. \n\n\n\n\n\n", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}