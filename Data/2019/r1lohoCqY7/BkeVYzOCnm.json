{"title": "Interesting topic, somewhat trivial algorithms and somewhat narrow results", "review": "This paper introduces the study of the problem of frequency estimation algorithms with machine learning advice. The problem considered is the standard frequency estimation problem in data streams where the goal is to estimate the frequency of the i-th item up to an additive error, i.e. the |\\tilde f_i - f_i| should be minimized where \\tilde f_i is the estimate of the true frequency f_i.\n\nPros:\n-- Interesting topic of using machine learned advice to speed up frequency estimation is considered\n-- New rigorous bounds are given on the complexity of frequency estimation under Zipfian distribution using machine learned advice\n-- Experiments are given to justify claimed improvements in performance\n\nCons:\n\n-- While the overall claim of the paper in the introduction seems to be to speed up frequency estimation using machine learned advice, results are only given for the Zipfian distribution.\n\n-- The overall error model in this paper, which is borrowed from Roy et al. is quite restrictive as at it assumes that the queries to the frequency estimation data structure are coming from the same distribution as that given by f_i\u2019s themselves. While in some applications this might be natural, this is certainly very restrictive in situations where f_i\u2019s are updated not just by +/-1 increments but through arbitrary +/-Delta updates, as in this case it might be more natural to assume that the distribution of the queries might be proportional to the frequency that the corresponding coordinate is being updated, for example.\n\n-- The algorithm proposed in the paper is very straightforward and just removes heavy hitters using oracle advice and then hashes everything else using the standard CountMin sketch.\n\n-- Since CounMin is closely related to Bloom filters the idea of using machine learning to speed it up appears to be noticeably less novel given that for Bloom filters this has already been done by Mitzenmacher\u201918.\n\n-- The analysis is relatively straightforward and boils down to bucketing the error and integration over the buckets.\n\n\nOther comments:\n-- The machine learned advice is assumed to be flawless at identifying the Heavy Hitters, authors might want to consider incorporating errors in the analysis.\n\n\n\n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}