{"title": "Possibly a good paper but not my area of expertise at all", "review": "The authors propose a novel method of training neural networks for robustness of adversarial attacks based on 2-norm and Lipschitz regularization. Unfortunately I'm not at all familiar with the literature on adversarial attacks so it is difficult for me to judge the quality and significance of this work. The theoretical results look plausible and clearly stated. The experiments show improvements over existing methods but I can't tell whether the right baselines were used. Overall the writing is reasonably clear but not very accessible for someone not already familiar with the area.", "rating": "6: Marginally above acceptance threshold", "confidence": "1: The reviewer's evaluation is an educated guess"}