{"title": "Review", "review": "DOM-Q-NET:\u2028GROUNDED RL ON STRUCTURED LANGUAGE \n\nThis paper presents a somewhat novel graph-based Q-learning method for web navigation benchmark tasks. The authors show that multi-task learning helps in this case and their method is able to learn without BC as previous works have needed. While this work is interesting and to my knowledge somewhat novel. I concerns with one aspect of the evaluation. In some part it was stated that they show the highest success rate for testing on 100 episodes, if this is indeed the maximum success rate, it is unclear if these results are misleading or not. It is possible that there was a lucky seed in those 100 episodes leading to a higher max that is not representative of the algorithm performance. Also, please have the submission proof-read for English style and grammar issues. There are many minor mistakes, some of which are pointed out below. I am rating marginally below due mainly to the potentially misleading results from the comment on using the highest success rate to report results and to a minor extent due to the novelty aspect (though this is an interesting application).\n\n\nComments:\n\n- \u201cEvaluation metric: we plot the moving average of the reward for last 100 episodes, and report the highest success rate for testing on 100 episodes.\u201d \u2014> This is unclear, do you mean you only displayed the maximum success rate out of all 100 episodes? So if the success rates are [0, 100, 0, 0, 0], Figure 2 shows 100% success? If so, this is somewhat misleading and a better metric may have been the average success rate with confidence intervals. Otherwise you may have just gotten a lucky random seed potentially.\n- I would\u2019ve liked to see if this is the only method which benefits from multitask learning or do DOMNETs also benefit. This however, is just a nice to have.\n- I appreciate the inclusion of hyper parameters and commitment to releasing the code in an effort to promote reproducibility! Great job there. \n- I really like the idea of using graph networks with RL, though I\u2019m not sure if it\u2019s novel to this work. Interesting line of work!\n- While this is an interesting application, I\u2019m not sure about the novelty. I suggest spending a bit more time discussing how this work contrasts with methods like Wang et al., or others cited here.\n\nTypos:\n\n\u201cMiniWoB(Shi et al., 2017) benchmark tasks. \u201c \u2014> missing space between citation\n\u201cQ network architecture with graph neural network\u201d \u2014> with a graph neural network\n\"MiniWoB(Shi et al., 2017)\u201d \u2014> MiniWoB (Shi et al., 2017) (missing space)\n\u201cachieved the state\u201d \u2014> achieved state of the art \n\u201c2016; Wang et al., 2018)as main\u201d \u2014> missing space\n\u201cseries of attentions between DOM elements and goal\u201d \u2014> series of attention (modules?) between the DOM elements and the goal (?)\n\u201cconstrained action set\u201d \u2014> constrained action sets\n\u201cIn appendix, we define our criteria for difficulties of different tasks.\u201d \u2014> In the appendix", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}