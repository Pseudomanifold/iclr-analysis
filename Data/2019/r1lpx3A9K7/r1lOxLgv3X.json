{"title": "Novelty and evidence is not yet sufficiently clarified", "review": "This work proposes to defend against adversarial examples by \u201cdenoising\u201d the input image through an autoencoder (a BiGAN trained similar to InfoGAN) before classifying it with a standard CNN. The robustness of the model is evaluated on the L_infinity metric against FGSM and PGD.\n\nMy main criticism is as follows:\n* Novelty: several defences are based on a similar principle and the contributions of this paper are unclear.\n* Insufficient evidence: The evaluation is minimal (only FGSM and PGD, no decision-, transfer- or score-based attacks) and insufficient to support the claims.\n* Gradient masking: There is at least one clear sign of gradient masking in the results (FGSM performing better than PGD).\n\n### Novelty\nThe only prior work against which the paper compares is DefenseGAN. The only advantage over DefenseGAN being stated is performance (because no intermediate optimisation step is used). However, besides DefenseGAN there are several other defences that project the input onto the learned manifold of \u201cnatural\u201d inputs, including (see prior work section in [1] for an up-to-date list):\n\n* Adversarial Perturbation Elimination GAN\n* Robust Manifold Defense\n* PixelDefend (autoregressive probabilistic model)\n* MagNets\n\n### Insufficient evidence\nThe only attacks employed are two gradient-based techniques (FGSM and PGD). It is known that gradient-based techniques may suffer from gradient-masking (see also next point) and that the effectiveness of different attacks various greatly (which is why one should use many different attacks). Hence, a full evaluation of the model should include score-based and decision-based attacks.\n\n### Gradient masking\nIn Figure 5 (b) the FGSM attack performs better than PGD for epsilon = 0.05 (66.4% vs 71.5%). PGD, however, should be strictly more powerful than FGSM if the gradients and the hyperparameters are ok.\n\nGradient masking is the primary reason for why 95% of all proposed defences turned out to be ineffective, and there are good reasons to believe that the same might affect this defence. The robustness evaluation has to be much more thorough and convincing before any substantiated claims about the bidirectional architecture proposed here can be derived. In addition, the difference to prior work has to be made much clearer.\n\n[1] Schott et al. \u201cTowards the first adversarially robust neural network model on MNIST\u201d", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}