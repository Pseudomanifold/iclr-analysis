{"title": "paper review", "review": "The authors propose a new CNN architecture and show results on object and speech recognition. In particular, they propose a multi-scale CNN module that processes feature maps at various scales. They show compelling results on IN and a reduction of compute complexity\n\nPros:\n(+) The paper is well written\n(+) The method is elegant and reproducible\n(+) Results are compelling and experimentation is thorough\nCons:\n(-) Transfer to other visual tasks, beyond IN, is missing\n(-) Memory requirements are not mentioned, besides FLOPs, speed and parameters\n\nOverall, the proposed approach is elegant and clear. The impact of the multi-scale module is evident, in terms of FLOPs and performance. While their approach performs a little worse than NASNet, both in terms of FLOP efficiency and top1-error, it is simpler and easier to train. I'd like for the authors to also discuss memory requirements for training and testing the network. \n\nFinally, various papers have appeared over the recent years showing improvements over baselines on ImageNet. However, most of these papers are not impactful, because they do not show any impact to other visual tasks, such as detection. On the contrary, methods that do transfer get adopted very fast. I would be much more convinced of this approach, if the authors showed similar performance gains (both in terms of complexity and metrics) for COCO detection. \n", "rating": "6: Marginally above acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}