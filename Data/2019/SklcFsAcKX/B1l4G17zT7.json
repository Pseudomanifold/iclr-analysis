{"title": "Interesting but very artificial.", "review": "This paper studies the signal denoting problem. The theoretical results are nice, and supported by numerical experiments. I have the following two major concerns:\n\n(1) Using deep neural network as a prior in signal denoising is definitely an important and also challenging problem, only when the neural network is learnt from data. However, this paper assumes that the weight matrices of the neural network prior are i.i.d. Gaussian ensemble and independent on the signal. This assumption is oversimplified, and makes the theoretical results become quite expected and delicate. One can hardly get any insights of the practical signal denoising.\n\n(2) The paper has a significant overlap with HV:COLT18:\"Global Guarantees for Enforcing Deep Generative Priors by Empirical Risk\". HV:COLT18 consider a RIP-type linear operator, and this paper considers the identity operator, which is actually easier. Dealing with the additive noise is new, but somehow incremental.\n\n~~~~~After Rebuttal~~~~~~\n\nThe rebuttal still cannot justified such a random deep prior well. I keep my rating unchanged.", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}