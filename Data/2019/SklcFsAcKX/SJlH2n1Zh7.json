{"title": "Interesting theoretical result but very far from practical applicability", "review": "The paper studies the standard denoising problem under the assumption that the unknown n-dimensional signal can be written as the output of a known d-layer neural network G mapping k dimensions to n dimensions. The paper specifies an algorithm to perform this denoising and the algorithm is based on a variant of the usual gradient method. Then, under additional assumptions on the neural network G, the paper proves that their algorithm produces a denoised signal that achieves a mean squared accuracy of k/n. Because the input signal has \"effective\" dimensionality k (as it can be written as G(x) for some k-dimensional x), it is nice that it can be recovered at the accuracy k/n by Gradient Descent despite the complicated nature of G. In this respect, the result is quite interesting. However, the underlying assumptions are too strong in my opinion as described below: \n\n1. It is assumed that the Weights of the neural network G are all Gaussian (and also specific Gaussians with mean zero and variances determined by the layer dimensions). This of course is highly impractical. In practice, these network weights are pre-learned (say based on similar datasets) and there is hardly any reason to believe that they will satisfy the Gaussian assumption. \n2. It is assumed that the network is expansive in some sense with an expansivity constant \\epsilon. This \\epsilon then gets into the accuracy bound which basically means that \\epsilon has to be set very small. Unfortunately, this leads to the expansivity condition being quite stringent which will further lead to k being very small (especially if d is large). It is unrealistic to believe that real-world signals will come from a neural network with small k. \n\nGiven that there do not seem to be other such results for the accuracy of neural network denoising, the paper might still be considered interesting despite the above shortcomings. However, I believe that the theoretical result has near-zero relevance to a practical neural network denoiser.\n\nAnother concern is that the paper seems to borrow quite a lot of ideas from the paper \"Global Guarantees for Enforcing Deep Generative Priors by Empirical Risk\" by Hand and Voroninski. It will be good if the authors can explain the essential differences between the present paper and this earlier paper. ", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}