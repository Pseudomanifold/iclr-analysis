{"title": "Interesting direction and open-source platform, but paper falls short of human evaluation", "review": "Summary\n\nThe authors introduce BabyAI, a platform with the aim to study grounded language learning with a human in the loop. The platform includes a *simulated* human expert (bot) that teaches a neural learner. The current domain used in a 2D gridworld and the synthetic instructions require the agent to navigate the world (including unlocking doors) and move objects to specified locations. They also introduce \"Baby Language\" to give instructions to the agent as well as to automatically verify their execution.\n\nThe paper includes a detailed description of the minigrid env with the included tasks and instruction language set. \n\nAuthors trained small and large LSTM models on the tasks on a variety of standard learning approaches, using pure exploration (RL) and imitation from a synthetic bot (IL). They show IL is much more data efficient than RL in this domain as well. Also, a curriculum approach is evaluated (pre-train on task 1-N, then train on task N+1).  \n\nPro\n- Human-in-the-loop research is an exciting direction.\n- The language instruction set is a starting point for high-level human instructions. \n\nCon\n- It is still unclear how to effectively learn with human-in-the-loop. The authors don't actually evaluate \n1) how well the bot imitates a human, or \n2) how an actual human would interact and speed up learning. \nAll experiments are done with standard learning approaches with a synthetic bot. \n- The authors assume that human feedback comes as instructions or demonstrations. These are not the only forms of feedback possible (e.g., preferences). (Does the platform easily support those?)\n\nReproducibility\n- Open-sourcing the platform is a good contribution to the community.\n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}