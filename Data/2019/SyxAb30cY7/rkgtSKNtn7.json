{"title": "Good paper, clear accept", "review": "The paper demonstrates the trade-off between accuracy and robustness of a model. The phenomenon is shown in previous works, but this work interestingly proposes a theoretical model that supports the idea. The proving technique can be particularly beneficial to developing theoretical understanding for the phenomenon. Besides, the authors also visualize the gradients and adversarial examples generated from standard and adversarially trained models, which show that these adversarially trained models are more aligned to human perception.\n\nQuality: good, clarity: good, originality: good, significance: good\n\nPros: \n- The paper is fairly well written and the idea is clearly presented\n- To the best of my knowledge (maye I am wrong), this work is the first one that \nprovides theoretical explanation for the tradeoff between accuracy and robustness\n- The visualization results supports their hypothesis that adversarially trained models \npercepts more like human.\n\nSuggestions:\nIt would be interesting to see what kind of real images can fool the models and see whether the robust model made mistakes more like human.\n", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}