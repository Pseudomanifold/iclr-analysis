{"title": "good paper, interesting findings, should be cautious on over-claiming", "review": "This paper discusses the hypothesis of the existence of intrinsic tradeoffs between clean accuracy and robust accuracy and corresponding implications. Specifically, it is motivated by the tradeoffs between clean accuracy and robust accuracy of adversarially trained network. The authors constructed a toy example and proved that any classifier cannot be both accurate and robust at the same time. They also showed that regular training cannot make soft-margin SVM robust but adversarial training can. At the end of the paper, they show that input gradients of adversarially trained models are more semantically meaningful than regularly trained models.\n\nThe paper is well written and easy to follow. The toy example is novel and provides a concrete example demonstrating robustness-accuracy tradeoff, which was previously speculated. Demonstrating adversarially trained models has more semantically meaningful gradient is interesting and provides insights to the field. It connects robustness and interpretability nicely.\n\nMy main concern is on the overclaiming of applicability of the \"inherent tradeoff\". The paper demonstrated that the \"inherent tradeoff\" could be a reasonable hypothesis for explaining the difficulty of achieving robust models. I think the authors should emphasize this in the paper so that it does not mislead the reader to think that it is the reason.\n\nOn a related note, Theorem 2.2 shows adversarial training can give robust classifier while standard training cannot. Then the paper says \"adversarial training is necessary to achieve non-trivial adversarial accuracy in this setting\". The word \"necessary\" is misleading, here Thm 2.2 showed that adversarial training works, but it doesn't exclude the possibility that robust classifiers can be achieved by other training methods. \n\nminor comments\n- techinques --> techniques\n- more discussion on the visual difference between the gradients from L2 and L_\\infty adversarially trained networks\n- Figure 5 (c): what does \"w Robust Features\" mean? are these values accuracy after perburtation?\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}