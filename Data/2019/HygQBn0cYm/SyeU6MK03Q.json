{"title": "An Ok paper that combines  dropout methods with learning policy using observational data. ", "review": "- Does the paper present substantively new ideas or explore an under explored or highly novel question? \n\nSomewhat, the paper combines two popular existing approaches (Imitation Learning,  Model Based Control and Uncertainty Quantification using Dropout).  The novelty is in  combining pre-existing ideas. \n\n- Does the results substantively advance the state of the art? \n\nNo, the compared methods are not state-of-the-art.\n\n- Will a substantial fraction of the ICLR attendees be interested in reading this paper? \n\nYes. I think that the topics of this paper would be very interesting to ICLR attendees. \n\n-Quality:  \n\nUnclear motivation to penalize prediction uncertainty to make the predicted states stay in the training data.  Also, in some cases references to existing work that includes real robotic systems is out of context at minimum. So yes there are similarities between this paper and existing works  on  learning control for robotics systems using imitation learning, model based control and uncertainty aware cost function. However there is a profound difference in terms of working in simulation and working with a real system for which model and environment uncertainty is a very big issue. There are different challenges in working with a real uncertain system which you will have to actuate,  and working with set of images for making predictions in simulation.   \n\n \n\n-Clarity: \n\nEasy to read. Experimental evaluation is clearly presented. \n\n-Originality: \n\nSimilar uncertainty penalty was used in other paper (Kahn et al. 2017).  Therefore the originality is in some sense reduced.\n\n- Would I send this paper to one of my colleagues to read?\n\nYes I would definitely send this paper to my colleagues. \n\n- General Comment: \n\nDropout can be used to represent the uncertainty/covariance of the neural network model. The epistemic uncertainty, coming from the lack of data, can be gained through Monte Carlo sampling of the dropout-masked model during prediction. However, this type of uncertainty can only decrease by adding more explored data to current data set. Without any addition of data, the  variance reduction, which results  by penalizing the high variance during training, might indicate over-fitting to the current training data. As the penalty forces the model to predict states only in the training dataset, it is unclear how this shows better test-time performance. The output of the policy network will simply be biased towards the training set as a result of the uncertainty cost. More theoretical explanation is needed or perhaps some intuition.  \n\nThis observation is also related to the fact that the model based controller used  is essentially a  risk sensitive controller. \n", "rating": "6: Marginally above acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}