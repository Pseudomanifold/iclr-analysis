{"title": "Accelerated Greedy Sparse Recovery Review", "review": "The paper proposes a greedy-like algorithm for sparse recovery that uses nearest neighbors algorithms to efficiently identify candidates for the support estimates obtained at each iteration of a greedy algorithm. It assumes that the norms of the columns of the matrix A are one to be able to change the project-and-sort step into a nearest neighbors search.\n\nIt is not clear what the value of Fact 1 is, given that none of the sparse recovery algorithms discussed here actually performs ell0 norm minimization. Additionally, it is common in theoretical analysis of sparse recovery to assume that the columns of the matrix A have unit norm. In fact, the RIP implies that the columns of the matrix must have norm within delta of 1. Nonetheless, it would be useful to have a discussion of the effect that having non-unit column norms would have on the proposed approach.\n\nSimilarly, Fact 2 is almost self-evident; I suggest to discard the proof.\n\nThe equivalence of Definition 1 and the statement involving ps and qs needs to be shown more clearly. The statement in Definition 1 is given in terms of distances (ball radiuses), not counts of neighbors.\n\nI suggest swapping the use of CoSaMP and AIHT - the theoretical results of the paper refer to AIHT, so it is not clear why the algorithm itself is relegated to the supplementary material.\n\nIt is not clear how d0 is to be computed to implement Accelerated AIHT.\n\nFor Theorem 1, the authors should comment on when the assumption \"xtilde(t) converges linearly to a k-sparse signal with rate c\".\n\nIn Figures 1 and 2, does \"residual\" refer to the difference between x and xtilde, or b and Axtilde? \n\nMinor comments:\nTypo in page 5 \"\u00bf\"\nGrammar error in page 6 \"characterizing of the difficulty\".", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}