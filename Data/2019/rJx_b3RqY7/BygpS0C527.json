{"title": "Interesting idea, but needs more work", "review": "UPDATE (after author response):\n\nThank you for updating the paper, the revised version looks better and the reviewers addressed some of my concerns. I increased my score.\n\nThere's one point that the reviewers didn't clearly address:  \"It might be worth evaluating the usefulness of the method on higher-dimensional examples where the analytic forms of q(x|z) and q(z) are known, e.g. plot KL between true and estimated distributions as a function of the number of dimensions.\" Please consider adding such an experiment.\n\nThe current experiments show that the method works better on low-dimensional datasets, but the method does not seem to be clearly better on more challenging higher dimensional datasets.  I agree with Reviewer1 that \"Perhaps more ambitious applications would really show off the power of the model and make it standout from the existing crowd.\" Showing that the method outperforms other methods would definitely strengthen the paper.\n\nSection 5.4: I meant error bars in the numbers in the text, e.g. 13 +/- 5.\n\n---------\n\nThe paper proposes a new loss for training deep latent variable models. The novelty seems a bit limited, and the proposed method does not consistently seem to outperform existing methods in the experiments. I'd encourage the authors to add more experiments (see below for suggestions) and resubmit to a different venue.\n\nSection 4:\n- q(z) seems to be undefined. Is it the aggregated posterior?\n- How is equation (1) related to ELBO that is used for training VAEs?\n\nSome relevant references are missing: I\u2019d love to see a discussion of how this loss relates to other VAE-GAN hybrids.\n\nVEEGAN: Reducing mode collapse in GANs using implicit variational learning\nhttps://arxiv.org/pdf/1705.07761.pdf\n\nDistribution Matching in Variational Inference\nhttps://arxiv.org/pdf/1802.06847.pdf\n\n\nSection 5.1:\n- The quantitative comparison measures MSE in pixel space and inception score, neither of which are particularly good measures for measuring the quality of how well the conditionals match. I\u2019d encourage the authors to consider other metrics such as log-likelihood.\n\n- It might be worth evaluating the usefulness of the method on higher-dimensional examples where the analytic forms of q(x|z) and q(z) are known, e.g. plot KL between true and estimated distributions as a function of the number of dimensions.\n\nSection 5.4: \n- The error bars seem quite high. Is there a reason why the method cannot reliably reduce mode collapse?\n\nMinor issues:\n- CIFAT-10 -> CIFAR-10\n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}