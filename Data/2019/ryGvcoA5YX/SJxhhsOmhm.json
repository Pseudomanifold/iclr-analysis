{"title": "Interesting ideas and results. Needs improvement in writing, formalization and possibly more ablation studies.", "review": "This paper proposes a Dynamic Parameter Generator (DPG) that given a test input modifies the parameters of a classification model. They also propose to regularize the training using a Data Generator (DG) to slow down catastrophic forgetting. DG is used to constrain the training that the internal representations of data generated by DG does not rapidly change. DG removes the need for storage of data or labels.\n\nPositives:\n- Both ideas of DPG and DG are novel in preventing catastrophic forgetting.\n- DG is novel because it does not require storage of data and does not depend on labels.\n- Experimental results are significantly better than the previous state-of-the-art.\n\nSuggestions and clarification requests:\n- Figures are very small and equations are cramped because of reduced spacing.\n- There are some vague explanations in the intro that could be reduced. It would be nice to first introduce concrete math then give the intuitions. That saves some space.\n- It would nice to compare to the recent Progress & compress [1]. Unfortunately, they have not provided results on benchmark MNIST tasks.\n- This work is related to a recently proposed idea in architecture search [2] that learns to predict the weights of a network given its architecture.\n- Can you clarify whether you have used DG at test time?\n- Can you report results without using DG? It is not clear whether DPG is accountable for preventing the catastrophic forgetting or the sluggishness enforced by DG.\n- Questions 1 and 2 need more formalization if the authors want to clearly prove a statement.\n- As the answer to Question 1 suggests, have you explored enforcing a Lipschitz constraint?\n- The answer to Question 2 is interesting. Could you rewrite it more formally? It seems like you can argue that DG\u2019s objective encourages the employment of unused parameters which is important in tackling catastrophic forgetting.\n- Can you elaborate on how much forgetting happens for DG?\n- It seems that in figure 3.f and 3.c the MA method is unable to reach the best possible performance on the last task. Can you also report the table of accuracies on the last task?\n\n[1] Schwarz, Jonathan, et al. \"Progress & Compress: A scalable framework for continual learning.\" arXiv preprint arXiv:1805.06370 (2018).\n[2] Brock, Andrew, et al. \"SMASH: one-shot model architecture search through hypernetworks.\" arXiv preprint arXiv:1708.05344 (2017).", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}