{"title": "paper needs major revision to improve clarity and empirical validation", "review": "This paper proposes a method for continual learning. The model has three components: a) a data generator to be used at training time to replay past examples, b) a parameter generator that takes the input observation to produce parameters for c) the actual classifier. The authors demonstrate the method on simple datasets with a stream of 2 or 3 tasks.\n\nStrenghts:\n- the combination of components is novel\n- the method does not rely on task descriptors neither at training nor test time\nWeaknesses:\n- the paper needs a major rewrite to improve fluency and to better organize and describe the proposed approach\n- the empirical validation is weak.\n\nRelevance\nLearning in a continual setting is certainly very relevant for this venue.\n\nNovelty\nWhile each component is by itself not very novel (replay methods for continual learning have already been used, networks predicting parameters have also become a fairly common approach in meta-learning literature), the proposed combination is novel in this sub-field.\n\nClarity\nClarity is very poor and definitely does not meet the acceptance bar for this conference. I believe that the authors would need to make a major revision to address this issue. While ICLR allows authors to revise papers, I think the revision needed to fix this draft goes beyond the acceptable limit, as reviewers would then need to make a whole new revision.\nFirst, fluency is very poor. There are lots of grammatical errors (see first sentence of introduction \"neural networks suffers..\"),  a plethora of un-necessary acronyms which force the reader to go back and forth to figure out what they refer to (MA, DG, DPG, DPG&S, ...), and several sentences are not well formed (e.g., read first sentence of introduction).\nSecond, some statements are contradictory; e.g., the authors define \"basic unit\" as \"simple MLP with one hidden layer\", but then say it \"is an activation function plus a matrix transformation\"..\nThird, graphics and formulas are too small and not legible.\nFourth, the organization of the paper is poor, it is very wordy yet vague. For instance, the authors should precisely describe how the data generator is trained in sec. 2.3. The authors should provide an algorithm summarizing how the different components interplay both at training and test time. At present, I am making educated guesses about how this system works.\nFor instance, how are real and generated examples interleaved? how is forgetting prevented in the data generator?   \n\nReferences to prior work\nWhile there are lots of references in sec. 4, they are not sufficiently well described - see third paragraph of sec. 4 where the authors cite almost 20 papers by simply saying they are \"some other approaches\". \nAlso, I did not find mention to methods predicting parameters in the meta-learning community but also others like:\nDenil et al. \"Predicting network parameters in deep learning\" NIPS 2013\n \nEmpirical validation\nThe empirical evaluation does show an advantage of the proposed approach on some simple streams composed by up to three tasks. However, a) the tasks are really simple because of the small number of tasks considered and b) the baselines are weak. For instance, EWC is now a bit out-dated as there are variants that work a bit better, like:\nChaundry et al. \"Riemannian Walk ...\" ECCV 2018\nand there are other methods like \"Progress and Compress\" Schwartz ICML 2018 the authors could have compared against.\nBesides, the authors do not mention anything about memory and time cost both at training and test time, possibly including the time to cross validate all the hyper-parameters of this method.\nOverall, I am left with the sense that the proposed approach will be hard to scale to many more tasks and more realistic images (for which we do not quite know how to train efficiently and well generators).\n\nOther comments\nI did not find the formalization in eq. 9 very useful. The first and last term in that equation can be very big and there is no sense of how lose this bound is.\nAlso, it is not clear whether there is a general principle to partition the set of parameters (to determine which ones should be shared).", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}