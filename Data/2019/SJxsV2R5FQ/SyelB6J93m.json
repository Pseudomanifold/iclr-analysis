{"title": "L EARNING SPARSE RELATIONAL TRANSITION MODELS", "review": "\nSUMMARY:\nThis work is about learning state-transition models in complex domains represented as sets of objects, their properties, ``\"deictic\" reference functions between sets of objects, and possible actions (or action templates). A parametric model for the actions is assumed, and these parameters act on a neural net that learns the transition model (probabilistic rule) from the current state to the next one.  It is basically this nonlinear transition model implemented by a network which makes this work different from previous models described in the literature. The relational transition model proposed is sparse, based on the assumption that actions have only ``local effects on related objects. The prediction model itself is basically a Gaussian distribution whose mean and variances are represented by neural nets. For jointly learning multiple rules, a clustering strategy is presented which assigns experience samples to transition rules. The method is applied to simulated data in the context of predicting pushing stacks of blocks on a cluttered table top.\n\nEVALUATION: \nThe type of problems addressed in this paper is challenging and highly relevant for solving problems in the ``real'' world. Although the method proposed is in some sense a direct generalization of the work in [Pasula et al.], it still contains many novel and interesting aspects.Any single part of the model (like the use of Gaussians parametrized by functions implemented via neural nets) is somehow ``standard in deep latent variable models, but in complex real-world rule-learning problems the whole system presented  defines  certainly a big improvement over the state-of-the-art, which in my opinion has the potential to indeed advance this field of research.     \n ", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}