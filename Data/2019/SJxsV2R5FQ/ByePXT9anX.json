{"title": "Learning sparse relational transition models", "review": "In the manuscript \"Learning sparse relational transition models\", the authors combine neural nets with relational models, using ideas from linguistics. They apply this to learning the representations of the space in which a simulated robot operates in a reinforcement learning ML paradigm. This work is of interest to the AI community and ICLR is a good venue for this work.\n\nThe authors apply their model in particular to a problem in which the simulated robot must rearrange objects in space, and they achieve reasonable accuracy.\n\nMajor points:\n\n- Organisationally, I thought that the authors could have gotten to the loss function sooner, as much of the development of the theory is lacking in motivation until specific tasks are defined.\n\n- The application domain seemed to lose some of the power of the linguistic analysis they were doing to develop the representation through \"properties\" and \"action templates\". These definitions were quite general, but it was unclear if more than a few (with few parameters) were used in the actual application, and so it's unclear that so much generality was required by the application.\n\n- The authors could have compared with more modern deep learning techniques for reinforcement learning such as DeepMimic (Peng et al 2018).\n\nMinor points:\n- Typesetting periods \"Pasula et al. and\" -> \"Pasula et al.\\ and\"\n\n- Page 2: \"value of a note\" -> \"value of a node\"\n\n- 3.1 was hard to follow.", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}