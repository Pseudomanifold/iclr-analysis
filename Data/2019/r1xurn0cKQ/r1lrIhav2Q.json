{"title": "Interesting idea, but many flaws.  ", "review": "This paper presents an interesting idea by formulating the problem of zero-shot learning in a meta-learning framework.  Specifically, the proposed model consists of two components: the task module and the correction module, where the former module learns to map the text description of a class to the sample mean and the latter one updates the predictions for unseen classes.   \n\nThe presentation of this paper is very poor.  Proposed meta-framework has some flaws. And, the experiments are not persuasive enough to demonstrate the significance of the proposed framework.  \n\nThe proposed zero-shot classifier is based on the nearest centroid.   Authors formulate the learning problem as mapping the text description of each class to sample mean of the data of the class.   Within a meat-training instance, the training performance is based on L2 distance between the mapped mean and the sample mean of each class.   This setup is wired.  This because, no matter how many data (x, y pairs) we get, the proposed method only makes the prediction based on the pre-calculated mean.  In other words, the \"number of samples\" in a meta-training dataset becomes the number of unique classes appears in training.    For instance, if we have 10 classes in the $D_\\mathcal{S}$, and10000 samples per class,  the proposed setup will consider the meta training only consist of 10 data points.   \n\nIn addition, the proposed method heavily rely on the feature extractor of the image.  The classification performance could be poor if two the mean of different classes close to each other.    Even they are not, the proposed framework cannot provide sample-level generalization.  \n\nAnother confusion I have is why the training of the task module is not based on a fixed correction module?   \n\nThe experiments also have many problems.  Authors need to clearly state how they construct meta-training, validation and testing instance.   Since the proposed framework is a meta-framework, authors need to report their performance in different meta-train/test splits.  The conventional split of CUB and NAB is only considered as a single split.  How well the proposed framework generalizes to other meta splits?     How well the proposed method performance to a generalized zero-shot setting?  \n\nThere are many typos.  Auhtors definitely need to improve their writing and the layout of the paper. \n\n\n\n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}