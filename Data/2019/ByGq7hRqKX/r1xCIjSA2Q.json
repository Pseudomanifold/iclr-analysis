{"title": "The manuscript is clearly written and  adds to the state of the art in multidomain machine learning.  Recommend as a poster.", "review": "The system is explained thoroughly, and with the help of nice looking graphics the network architecture and its function is clearly described. The paper validates the results against baselines and shows clearly the benefit of double  domain learning. The paper is carefully written and  follows the steps required for good scientific work.\n\nPersonally, I do not find this particularly original, even with the addition of the zero-shot learning component. \n\nAs a side note, the task here does not seem to need a multitask solution. Adding the text input as subtitles to the video gives essentially the same information that is used in the setup. The resulting inclusion of text could utilise the image attention models in a similar manner as the GRU is used in the manuscript for the text. In this case the problem stated in the could be mapped  to a \"DeepMind Atari\" type of RL solution, with text as a natural component, but added as visual clue to the game play. Hence, I am not convinced that the dual attention unit is essential to the performance the system.\n\nIn addition, there are studies (https://arxiv.org/abs/1804.03160) where sound and video are , in unsupervised manner, correlated together. This contains analogous dual attention structure as the manuscript describes, but without reinforcement learning component.\n\nI would recommend this as a poster.\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}