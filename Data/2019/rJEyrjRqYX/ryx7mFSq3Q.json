{"title": "Interesting paper but with incremental contributions", "review": "This manuscript proposes replacing the three gates in the standard LSTM with one gate to reduce the number of parameters and the computation time. The proposed reduce-gate convolutional LSTM is applied in PredNet to predict next frames of a video. \n\nThe main contribution of this paper is proposing an efficient convolutional LSTM. Although the number of the parameters and the training time in the experiments support this statement, the description in the paper is very confusing. \n\n1) In the standard LSTM, the cell state c^{t-1} is not an input for the computation of the three gates and the cell state's candidate. That is, in Eq(15) 2\\kappa and 2n should be \\kappa and n. Compared to Eq(14), it may not show that the standard LSTM has more parameters than rgcLSTM.\n\n2) Eq(5) and Eq(6) are not consistent. If I_g = I_f, the coefficient before \\kappa should be 2; otherwise, the input update shouldn't include c^{t-1}. \n\n3) The intuition of having one gate instead of three is not very clear in the paper. Mixing all the functions, i.e., input, forget, and output filters, does provide freedom for learning but also introduces the learning complexity. Decoupling a complex function into a couple of simpler functions is a common way to narrow down the searching space. This is exactly what the standard LSTM does. The authors may want to provide reasonable arguments to explain intuitively why using one gate is better. \n\nThe model performance comparison in the experiments would be fairer if let the models converge. Perhaps, the standard LSTM is just suffering the gradient-vanishing issue and using ResNet design, for example, might improve the performance. Similarly, the rgcLSTM has fewer parameters as shown in the experiments. A possible explanation for its demonstrated better performance could be that it's less suffering the vanishing gradient. But, this doesn't indicate it's better than the standard LSTM. In summary, experimental results are good to verify the goodness of a model, but the theoretical support or intuitions are more important to understand the benefits that we can gain by making this change to the standard LSTM. This part is not clear from the paper. ", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}