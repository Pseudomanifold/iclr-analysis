{"title": "A new LSTM architecture that demonstrates some improvements over other LSTM modules", "review": "Authors present a new LSTM architecture, i.e. reduced gate convolutional LSTM. Authors use only one trainable gate, i.e. the forget gate which leads to less trainable parameters. They demonstrate the superiority of ti in two datasets, the moving MNIST and KITTI. Their results show that their architecture performs better than others in more accurately predicting next-frame. The paper is clearly written and the evaluation is based on other proposed similar architectures. For the moving MNIST they compared their model against the vanilla convLSTM with three gates and no peephole connections, based on previous work which has shown that it exceeds the accuracy performance of other LSTM based approaches. \nThe results show that the training time is reduced and the standard error alike. The only limitations is that more databases could have been used to demonstrate the enhancement in performance.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}