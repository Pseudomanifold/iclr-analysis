{"title": "official review for \"Improving MMD-GAN Training with Repulsive Loss Function\"", "review": "This paper proposed two techniques to improve MMD GANs: 1) a repulsive loss for MMD loss optimization; 2) a bounded Gaussian RBF kernel instead of original Gaussian kernel. The experimental results on several benchmark shown the effectiveness of the two proposals. The paper is well written and the idea is somehow novel. \n\nDespite the above strong points, here are some of my concerns:\n1.The two proposed solutions seem separated. Do the authors have any clue that they can achieve more improvement when combined together, and why?\n\n2. They are limited to the cases with spectral normalization. Is there any way both trick can be extended to other tricks (like WGAN loss case or GP).\n\n3. Few missed references in this area:\na. On gradient regularizers for MMD GANs\nb. Regularized Kernel and Neural Sobolev Descent: Dynamic MMD Transport\n\nRevision: after reading rebuttal (as well as to other reviewers), I think they addressed my concerns. I would like to keep the original score.  ", "rating": "7: Good paper, accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}