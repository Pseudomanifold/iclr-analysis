{"title": "Refreshingly pedagogical paper; limited experiments despite asking some really interesting questions", "review": "The paper tackles a very interesting problem about representations, especially of the connectionist kind -- how do we know if the learned representations capture the compositional structure present in the inputs, and tries to come up with a systematic framework to answer that question. The framework assumes the presence of an oracle that can give us the true compositional structure. Then the author try to answer some refreshing questions about the dynamics of learning and compositionality while citing some interesting background reading.\n\nHowever, I\u2019m a bit torn about the experiments. On the one hand, I like the pedagogical nature of the experiments. They are small and should be easy to reproduce. On the other hand, all of them seem to be fairly similar kinds of composition with very few attributes (mostly bigrams). So whether the intuitions hold for more complex compositional structures is hard to say.\n\nNevertheless, it\u2019s a well written paper and is a helpful first step towards studying the problem of compositionality in vector representations.\n\n\nMinor points\nPg 3 \u201c_grammar_ for composing meanings *where* licensed by derivations\u201d seems incorrect. \nFigure 5: seems quite noisy to make the linear relationship claim\n\nEDIT: I still think the compositions under consideration are the simpler ones. Still with the new experiments the coverage seems nicer. Given the authors plan to release their source code, I expect there will be an opportunity for the rest of the community to build on these, to test TRE's efficacy on more complex compositions. I updated my scores to reflect the change.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}