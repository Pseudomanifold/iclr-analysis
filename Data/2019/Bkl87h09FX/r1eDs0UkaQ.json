{"title": "Many experiments on a fast-moving field, without clear conclusion", "review": "The work presented in this paper relates to the impact of the dataset on the performance of contextual embedding (namely ELMO in this paper) on many downstream tasks, including GLUE tasks, but also alternative NLP tasks.\n\nThe work is focused on experiments, and draws several conclusions that are interesting, mostly around the amount of gain one can expect and the fact that the choice of the dataset is task-dependent. \n\nOne of the issue is that the authors if seems to believe that ELMO is the best contextual language model. The field is moving so quickly that the experiments might become invalid pretty soon (e.g. see BERT model referenced below).\n\nFinally, the analysis is mostly descriptive and there is few insight by the author about what should be the future work, apart from \"we need a better understanding\".\n\n\nMinor details:\n\nPage 1: \"can yield very strong performance on NLP tasks\" is a very busy way to express the fact that Sentence Encoders work well in practice. \n\nThe field evolves quickly and ELMO has now a competitive models called BERT (arXiv.org\u00a0>\u00a0cs\u00a0> arXiv:1810.04805). I understand that the results of the current papers would hove to be re-run on all these tasks, but I'm afraid the current paper will have a limited impact if it does not use the most effective method at the date of publication...", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}