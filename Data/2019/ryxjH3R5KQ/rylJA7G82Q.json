{"title": "Review", "review": "The authors present an architecture search method where connections are removed with sparse regularization. It produces good network blocks relatively quickly that perform well on CIFAR/ImageNet.\n\nThere are a few grammatical/spelling errors that need ironing out.\n\ne.g. \"In specific\" --> \"Specifically\" in the abstract, \"computational budge\" -> \"budget\" (page 6) etc.\n\nA few (roughly chronological comments).\n\n- Pioneering work is not necessarily equivalent to \"using all the GPUs\"\n\n- There are better words than \"decent\" to describe the performance of DARTS, as it's very similar to the results in this work!\n\n- From figure 2 it's not clear why all non-zero connections in (b) are then equally weighted in (c). Would keeping the non-zero weightings be at all helpful?\n\n-  Why have you chosen the 4 operations at the bottom of page 4? It appears to be a subset of those used in DARTS.\n\n- How do you specifically encode the number of surviving connections? Is it entirely dependent on budget?\n\n- You should add DARTS 1st order to table 1. \n\n- Measuring in GPU days is only meaningful if you use the same GPU make for every experiment. Which did you use?\n\n- The ablation study is good, and the results are impressive.\n\nI propose a marginal acceptance for this paper as it produces impressive results in what appears to be a short amount of search time. However, the implementation details are hazy, and some design choices (which operations, hyperparameters etc.) aren't well justified.\n\n------------\nUPDATE: Score changed based on author resposne\n------------\n", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}