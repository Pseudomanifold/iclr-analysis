{"title": "reinforcement learning approach for hierarchical text classification", "review": "This paper presents an end to end rl approach for hierarchical text classification. The paper proposes a label assignment policy for determining the appropropriate positioning of a document in a hierarchy. It is based on capturing the global hierachical structure during training and prediction phases as against most methods which either exploit the local information or neural net approaches which ignore the hierarchical structure. It is demonstrated the method particularly works well compared to sota methods especially for macro-f1 measure which captures the label weighted performance. The approach seems original, and a detailed experimental analysis is carried out on various datasets. \n\nSome of the concerns that I have regarding this work are :\n - The problem of hierarchical text classification is too specific, and in this regard the impact of the work seems quite limited. \n - The significance is further limited by the scale of the datasets of considered in this paper. The paper needs to evaluate against on much bigger datasets such as LSHTC datasets http://lshtc.iit.demokritos.gr/. For instance, the dataset available under LSHTC3 is in the raw format, and it would be really competitive to evaluate this method against other such as Flat SVM, and HRSVM[4] on this dataset, and those from the challenge.\n- The experimental evaluation seems less convincing such as the results for HRSVM for RCV1 dataset are quite different in this paper, and that given HRSVM paper. It is 81.66/56.56 vs 72.8/38.6 reported in this paper. Given that  81.66/56.56 is not too far from that given by HiLAP, it remains a question if the extra computational complexity, and lack of scalability (?) of the proposed method is really a significant advantage over existing methods.\n - Some of the references related to taxonomy adaptation, such as [3] and reference therein,  which are also based on modifying the given taxonomy for better classification are missing.\n - Comparison with label embedding methods such as [1,2] are missing. For the scale of datasets discussed, where SVM based methods seem to be working well, it is possible that approaches [1,2] which can exploit label correlations can do even better.\n[1] K. Bhatia, H. Jain, P. Kar, M. Varma, and P. Jain, Sparse Local Embeddings for Extreme Multi-label Classification, in NIPS, 2015.\n[2]  H. Yu, P. Jain, P. Kar, and I. Dhillon, Large-scale Multi-label Learning with Missing Labels, in ICML, 2014.\n[3] Learning Taxonomy Adaptation in Large-scale Classification, JMLR 2016.\n[4] Recursive regularization for large-scale classification with hierarchical and graphical dependencies, https://dl.acm.org/citation.cfm?id=2487644", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}