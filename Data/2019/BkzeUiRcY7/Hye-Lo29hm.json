{"title": "An interesting exploration of RL for principle-agent problems", "review": "\nThis paper studies the problem of generating contracts by a principal to incentive agents to optimally accomplish multiagent tasks. The setup of the environment is that the agents have certain skills and preferences for activities, which the principal must learn to act optimally. The paper takes a combined approach of agent modeling to infer agent skills and preferences, and a deep reinforcement learning approach to generate contracts. The evaluation of the approach is fairly thorough.\n\nThe main novel contribution of the paper is to introduce the principal-agent problem to the deep multiagent reinforcement learning literature.\n\nMy concerns are:\n- The paper should perform a literature search on related work from operations research, including especially principal-agent problems, which are not currently surveyed, and perhaps also optimal scheduling problems.\n- How do the problems introduced either map onto real applications or map onto environments studied in existing literature (such as in operations research)?\n- More details should be given on the mind tracker module.\n- Is it necessary to use deep reinforcement learning for contract generation?  If the agent modeling is good, the optimal contracts look like they are probably simple to compute directly in the environments studied.\n\nOverall, the paper is somewhat interesting and relatively technically sound, but the contribution seems marginal. The problems studied seem pulled out a hat, when they could be situated in specific existing literature.\n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}