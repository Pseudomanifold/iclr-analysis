{"title": "Trained multiplicative noise improves robustness to adversarial attacks", "review": "This paper includes multiplicative noise N in training data, such that it trains a model on X\\timesN.  The model then trains on both model parameters theta and on the noise itself in an effort to achieve adversarial robustness\n\nQuality\n- The empirical results appear sound, which suggest that multiplicative trained noise is a sensible approach\n- The writing that leads up to these results is in my opinion problematically vague, as it makes a variety of loose claims and theoretical connections and uses imprecise language.  This results in scientific imprecision, which I detail below in \"clarity\".\n- Some key choices are unsupported.  For example, the choice of fixing noise across batch (as in, there are k noise maps N that are reused across each minibatch) is unclear.  Certainly if you want to train these noise maps, some reuse is required, but the  given sentence \"since we want to learn the noise, we use the same k noise templates across all mini-batches...\" does not explain this critical choice.\n- What does it mean to train a noise map?  I know what it means mechanically, but there is a vague set of explanations that do not leave an empirical or theoretical understanding of why this is a sensible choice.  Connecting this to similarly ill-defined comments on \"excessive linearity\" or \"off manifold\" deepen this issue.\n\nClarity\n- The mechanics of the algorithm are sufficiently clear, but the interpretation is deemed highly vague, such that the result is a rather simple algorithm that is wrapped up with loose and unclear explanations.  Some examples are below:\n- critical terms are introduced without technical explanation.  For example, \"model viability\" is introduced in \\emph{} as the key questoin in the third paragraph of the introduction.  However, after reading this sentence several times, I don't know what this question is trying to ask.  Is it just \"we seek to improve robustness to adversarial attacks\"?  Is \"such out-of-sample data\" meant to point to \"off manifold\" points?  Other terms like \"inculcates\", \"off manifold\", \"inherits\", \"right prediction vs right explanation\", etc. add to this issue.\n- On that point, the term \"off manifold\" is used often but is highly vague.  We all know what this means colloquially, but if you want to make a scientific point about it, there needs to be rigor applied to this definition.\n- The likelihood perspective (section 2.2) is not rigorous.  These distributions are undefined to a problematic extent.  For example, p(Y|X,\\theta) is clear enough, but then what is p(Y|X,A,\\theta)?  I understand A is the adversarial inputs, but what *specifically* is this model?  How *specifically* does A represent the adversarial inputs?  Absent this level of definition and detail on this and other points, the likelihood section is deemed highly vague. \n\nOriginality and Significance\n- At a basic level, this manuscript offers multiplicative and trained noise maps.  That is a meaningful (albeit small) contribution.  The results are rigorous enough to make it interesting in its own right, but the remainder of the choices are justified via vague language rather than rigorous empiricism.  This limits the perceived significance.\n\n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}