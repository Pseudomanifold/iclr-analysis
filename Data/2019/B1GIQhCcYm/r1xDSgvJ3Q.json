{"title": "Nice problem formulation but limited model novelty and comparisons.", "review": "This paper formalizes the problem of unsupervised translation and proposes an augmented GAN framework which uses the mutual information to avoid the degenerate case.\n\nPros:\n* The formulation for the problem of unsupervised translation is insightful.\n* The  paper is well written and easy to follow.\n\nCons:\n* The contribution to the GAN model of this paper is to add the mutual information penalty (MINE, Belghazi et al., 2018) to the GAN loss, which seems incremental. I also wonder if some perceptual losses or latent code regression constraint used in previous works [1,2] can also achieve the same goal.\n* Comparison to \u201cAugmented CycleGAN: Learning Many-to-Many Mappings from Unpaired Data\u201d should be done, since it\u2019s a close related work for unsupervised many-to-many image translation.\n* The visualization results of TI-GAN, TI-GAN+minI, CycleGAN should be listed with the same source input for fair and easy comparison. For example the failure case of figure 8 mentioned in Section 5.2 only appears in Figure 5 (1) not in Figure 5 (2). \n* Minor issues: 1) What does the full name of \u201cTI-GAN\u201d ? 2) Figure 6 is not mentioned in the experiments. 3) What does the \u201cFigure A\u201d mean in Section 4.2 ?\n\n[1] Multimodal Unsupervised Image-to-Image Translation, ECCV\u201918\n[2] Diverse Image-to-Image Translation via Disentangled Representations, ECCV\u201918\n\nOverall, this paper proposes a nice formulation for the problem of unsupervised translation. But the contribution to the GAN model seems incremental and comparisons to other methods are not enough. My initial rating is rejection.\n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}