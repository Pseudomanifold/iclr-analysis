{"title": "Insufficient evidence/experimental validation for the main claims of the paper", "review": "Summary\n\nThis work porposes a approach for one-shot imitation with high accuracy, called \"high fidelity imitation learning\" by the authors. Furthermore, the work addresses the common problem of exploration in imitation learning, which would help to rescue from off-policy states.\n\nReview\n\nIn my opinion, the main claims of this paper are not validated sufficiently in the experiments. I would expect the experiments to be designed specifically to support the claims made, but little evidence is provided:\n\n- The authors claim that the method allows one-shot generalization to an unknown trajectory. To test this hypothesis the authors only provide experiments of generalization towards trajectories of a different demonstrator on the same task of stacking cubes. I would expect experiments with truly different trajectories on a different task than stacking cubes to test the hypothesis of one-shot imitation.\nUntil then I see no evidence for a \"one-shot\" imitation capability of the proposed method.\n\n- That storing the trajectories of early training can act as replacement for exploration as rescue from off-policy states: This is never experimentally validated. This hypothesis could easiliy be validated with an ablation study, were the results of early would not be added to the replay buffer.\n\n- High fidelity imitation: In the caption of Figure 7 the authors note that the unconditional task policy is able to outperform the demonstration videos. Thus the trajectories of the unconditional task policy allow a higher reward then the demonstrations.\nCould the authors please comment on how the method still achieves high fidelity imitation even when the results of the unconditional task policy are added to the replay buffer? In prinicipal these trajectories allow a higher reward than the demonstration trajectories that should be imitated.\n\nMainly due to the missing experimental validation of the claims made I recommend to reject the paper.", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}