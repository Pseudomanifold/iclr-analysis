{"title": "Not enough evidence to conclude much about pooling", "review": "It is often argued that one of the roles of pooling is to increase the stability of neural networks to \ndeformations. This paper presents empirical evidence to contest this assertion, or at least qualify it.\n\nI appreciate empirical studies that question some of the widely accepted dogmas of deep learning. \nFrom this point of view, the present paper is certainly interesting.\n\nUnfortunately, the actual evidence presented is quite weak, and insufficient to draw far reaching \nconclusions. An obvious objection is the authors only consider two datasets, and a very small number of \nmore or less standard pooling methodologies. The effect of pooling is evaluated in terms of cosine \nsimilarlity, which is not necessarily a good proxy for the actual performance of a network.\n\nA more serious issue is that they seem to very readily jump to unwarranted conclusions. For example, \nthe fact that stability to deformations (by which I necessarily mean the specific type of deformations \nthat they consider) tends to decrease in the middle layers of neural networks during training does not \nmean that starting with a neural network with less stability would be better. Maybe some kind of \nspontaneous coarse-to-fine optimization is going on in the network. Similarly, it is obvious that smoother \nfilters are going to lead to more stable representations. However, they might be less good at discriminative \ntasks. Just because smoother filters are more stable does not automatically mean that they are more desirable.\n\nStability to deformations is an important but subtle topic in computer vision. For starters, it is difficult \nto define what kind of deformations one wants to be insensitive to in the first place. A useful model would \nlikely incorporate some notion of deformations at multiple different length scales. \n\nJust showing that one network is better than another wrt some arbitrarily defined simple class of deformations \nwith no reference to actual recognition performance, speed of training, or interpretation of the nature of \nthe deformations and the learned filters is not very convincing. I would particularly like to emphasize the \nlast point. I would really like to understand what pooling actually does, not just at the level of \"if you \nturn it off, then cosine similarity will decrease by this much or that much.\"", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}