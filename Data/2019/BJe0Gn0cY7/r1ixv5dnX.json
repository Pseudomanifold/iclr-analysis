{"title": "Anti-causal encoder/causal decoder", "review": "The paper proposes a method to prevent posterior collapse, which refers to the phenomenon that VAEs with powerful autoregressive decoders tend to ignore the latent code, i.e., the decoder models the data distribution independently of the code. Specifically, the encoder, decoder, and prior distribution families are chosen such that the KL-term in the ELBO is bounded away from 0, meaning that the encoder output cannot perfectly match the prior. Assuming temporal data, the authors employ a 1-step autoregressive (across) prior with an encoder whose codes are independent conditionally on the input. Furthermore, they propose to use a causal decoder together with an anti-causal or non-causal encoder, which translates into a PixelSNAIL/PixelCNN style decoder and an anti-causal version thereof as encoder in the case of image data. The proposed approach is evaluated on CIFAR10, Imagenet 32x32, and the LM1B data set (text).\n\nPros:\n\nThe method obtains state-of-the-art performance in image generation. The paper features extensive ablation experiments and is well-written. Furthermore, it is demonstrated that the code learns an abstract representation by repeatedly sampling form the decoder conditionally on the code.\n\nCons:\n\nOne question that remains is the relative contribution of 1) lower-bounding the KL-term 2) using causal decoder/anti-causal encoder to the overall result. Is the encoder-decoder structure alone enough to prevent posterior collapse? In this context it would also be interesting to see how the encoder-decoder structure performs without \\delta-constraint, but with regularization as in \\beta-VAE.\n\nWhat data set are the ablation experiments performed on? As far as I could see this is not specified.\n\nAlso, I suggest toning down the claims that the proposed method works \"without altering the ELBO training objective\" in the introduction and conclusion. After all, the encoding and decoding distributions are chosen such that the KL term in the ELBO is lower-bounded by \\delta. In other words the authors impose a constraint to the ELBO.\n\nMinor comments:\n- Space missing in the first paragraph of p 5: \\kappaas\n- \"Auxiliary prior\"-paragraph on p 5: marginal posterior -> aggregate posterior?", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}