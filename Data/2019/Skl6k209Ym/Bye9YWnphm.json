{"title": "Sound empirical study", "review": "The authors propose a deep learning method based on image alignment to perform one-shot classification and open-set recognition. The proposed model is an extension of Matching Networks [Vinyals et al., 2016] where a different image embedding is adopted and a pixel-wise alignment step between test and reference image is added to the architecture. \n\nThe work relies on two strong assumptions: (i) to consider each point mapping as independent, and (ii) to consider the correct alignment much more likely than the incorrect ones. The manuscript doesn\u2019t report arguments in favour of these assumptions. The motivation is partially covered by your statement \u201cmarginalizing over all possible matching is intractable\u201d, nevertheless an explanation of why it is reasonable to introduce these assumptions is not clearly stated.\n\nThe self-regularization allows the model to have a performance improvement, and it is considered one of the contribution of this work. Nevertheless the manuscript doesn\u2019t provide a detailed explanation on how the self regularization is designed. For example it is not clear whether the 10% and 20% pixel sampling is applied also during self regularization.\n\nThe model is computationally very expensive and force the use of only 10% of the target image pixels and 20% of the reference images\u2019 pixels. The complexity is intrinsic of the pixel-wise alignment formulation, but in any case this approximation is a relevant approximation that is never justified. The use of hyper column descriptors is an effective workaround to achieve good performance even though this approximation. The discussion is neglecting to argue this aspect.\n\nOne motivation for proposing an alignment-based matching is a better explanation of results. The tacit assumption of the authors is that a classifier driven by a point-wise alignment may improve the interpretation. The random uniformly distributed subsampling of pixels makes the model less interpretable.It may occur for example as shown in figure 3 where the model finds some points that for human interpretation are not relevant and at the same time these points are matched with points that have some semantic meaning.\n", "rating": "6: Marginally above acceptance threshold", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}