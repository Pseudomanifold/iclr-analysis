{"title": "Review for Meta-Learning Probabilistic Inference for Prediction", "review": "This paper presents two different sections:\n1. A generalized framework to describe a range of meta-learning algorithms.\n2. A meta-learning algorithm that allows few shot inference over new tasks without the need for retraining. The important aspect of the algorithm is the context independence assumption between posteriors of different classes for learning weights. This reduces the number of parameters to amortize during meta-training. More importantly, it makes it independent of the number of classes in a task, and effectively doing meta-training across class inference instead of each task. The idea sounds great, but I am skeptical of the justification behind the independence assumption which, as per its justifications sounds contrived and only empirical. \n\nOverall, I feel the paper makes some progress in important aspects of meta-learning.", "rating": "6: Marginally above acceptance threshold", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}