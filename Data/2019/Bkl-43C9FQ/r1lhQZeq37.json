{"title": "Simple and efficient model on spherical data, large scale experiments need more benchmarks", "review": "This article introduces a simple yet efficient method that enables deep learning on spherical data (or 3D mesh projected onto a spherical surface), with much less parameters than the popular approaches, and also a good alternative to the regular correlation based models.\n\nInstead of running patches of spherical filters, the authors takes a weighted linear combination of differential operators applied on the data. The method is shown to be effective on Spherical MNIST, ModelNet, Stanford 2D-3D-S and a climate prediction dataset, reaching competitive/state-of-the-art numbers with much less parameters..\n\nLess parameters is nice, but the argument could be strengthened if the authors could also show impressive results in terms of runtime. Typically number of parameters is not a huge issue for today\u2019s deep networks, but for real-time robotics to be equipped with 3D perception, runtime is a much bigger factor.\n\nI also think that the Stanford 2D-3D-S experiments have some issues:\n\nUNet and FCN-8s are good baselines, but other prior work based on spherical convolution are omitted here. E.g. S2CNN and SphereNet. S2CNN has released their code so it should be benchmarked.\n\nAdditionally, comparison to PointNet++ could be a little unfair. \n\ni) What is the number of points used in PointNet++? The author reported 1000 points for ModelNet which is ok for that dataset but definitely too small for indoor scenes. The original paper used 8192 points for ScanNet indoor scenes.\n\nii) Point-based can have data-augmentation by taking subregions of the panoramic scene, where as sphere-based method can only take a single panoramic image. The state-of-the-art method (PointSIFT) achieves ~70 mIOU on this dataset. PointNet(++) can also achieve 40-50 mIOU. Maybe the difference is at using regular image or panoramic images, but the panoramic image is just a combination of regular images so I wouldn\u2019t expect such a large difference.\n\nIn conclusion, this paper proposes a novel deep learning algorithm to handle spherical data based on differential operators. It uses much less parameters and gets impressive results. However, the large scale experiments has some weaknesses. Therefore I recommend weak accept.\n\n----\nSmall issues / questions:\n\n- Notation lacks clarity. What are x, y in Eqn. 1? The formulation of convolution is not very clear to me, but maybe due to my lack of familiarity in this literature.\n\n- In Figure 1, the terminology of \u201cMeshConv\u201d is first introduced, which should come earlier in the text to improve clarity.\n\n- In the article, the author distinguished their method with S2CNN that their method is not rotation invariant. I don\u2019t understand this part. In the architecture diagram, if average pool is applied across all spherical locations, then why is it not rotation invariant?\n\n===\nAfter rebuttal: \nI thank the authors for addressing the comments in my review. It clarifies the questions I had about on the 2D3DS dataset (panorama vs. 3D points). Overall I feel this is a good model and have solid experiments. Therefore, I raise the score to 7.", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}