{"title": "Timely topic, reasonable approach, and good experimental results", "review": "This paper proposed an adversarial approach to identifying catastrophic failure cases in reinforcement learning. It is a timely topic and may have practical significance. The proposed approach is built on importance sampling for the failure search and function fitting for estimating the failure probabilities. Experiments on two simulated environments show significant gain of the proposed approaches over naive search. \n\nThe reviewer is not familiar with this domain, but the baseline, naive search, seems like straightforward and very weak. Are there any other methods for the same problem in the literature? The authors may consider to contrast to them in the experiments. \n\nWhat is the certainty equivalence approach? A reference would be helpful and improve the presentation quality of the paper.\n\nWhat is exactly the $\\theta_t$ in Section 3.3? What is the dimension of this vector in the experiments? What quantities should be encoded in this vector in practice? \n\nI am still concerned about the fact that the FPP depends on the generalization of the binary classification neural network, although the authors tried to give intuitive examples and discussions. Nonetheless, I understand the difficulty. Could the authors give some conditions under which the approach would fail? Any alternative approaches to the binary neural network? What is a good principle to design the network architecture? \n\nOverall, this paper addresses a practically significant problem and has proposed reasonable approaches. While I still have concerns about the practical performance of the proposed methods, this work along the right track in my opinion.\n\n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}