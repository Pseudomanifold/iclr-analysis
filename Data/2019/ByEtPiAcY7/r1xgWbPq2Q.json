{"title": "Characterizing the Accuracy/Complexity Landscape of Explanations of Deep Networks through Knowledge Extraction", "review": "Overall, this is a interesting paper on an important topic: knowledge extraction from Neural Networks.\nEven though the authors seem propose a novel approach to knowledge extraction, the paper would \ndramatically benefit from two additions:\n- an empirical evaluation on at least two more datasets (as is, the paper uses a single dataset)\n- an illustrative-but-realistic example of how at least one rule is extracted from each layer of the neural network \n\nOther comments:\n- on page 4 (1st paragraph in 3.3), the authors talk about a \"test set\" that, it turns out, it is extracted from the actual training set (1st paragraph of 4.1); the authors should use a more careful terminology\n- from the paper, it seems that the authors tried a single randomly chosen set 1000 random inputs in 4.1; they should most definitely try several such sets\n- Figure 1 should have a legend in the image, rather than as a 2-line caption\n ", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}