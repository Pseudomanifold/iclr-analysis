{"title": "An interesting but tricky method for compositional image generation", "review": "[Overview]\n\nIn this paper, the authors proposed a new method for compositional image generation, called compositional GAN. Given two object images, the proposed model could compose them through spatial transformations into a single image which has a reasonable object layouts. The authors worked on two objects and considered both paired and unpaired training cases. The experimental results shows that the proposed model could learn to compose two objects into a single image with plausible relative layouts.\n\n[Strengths] \n\n1. the authors proposed an interesting method to compose the objects into a single image with meaningful layouts. To achieve this, the authors first used a relative appearance flow network to perform transformation on each object image, and then learns a spatial transformation for each object, through which the file image is generated by putting these two transformed objects into a clean scene.\n\n2. The authors considered both paired training and unpaired training, and also proposed a post-processing method for the image refinement during inference time. In the experiments, the authors presented some generation results on the chair-table and basket-bottle samples.\n\n[Weaknesses]\n\n[1] LR-GAN: Layered Recursive Generative Adversarial Networks for Image Generation. Yang et al.\n[2] ST-GAN: Spatial Transformer Generative Adversarial Networks for Image Compositing. Lin et al.\n[3] Language-Driven Synthesis of 3D Scenes from Scene Databases. Ma et al.\n\n1. The paper did not present and explain the proposed method clearly. The writing is organized poorly and the formulas are sloppy and scattered. The pipeline Fig.1 is hard to follow as well.  \n\n2. The experiments are mainly performed on two composition cases, i.e., chair-table and basket-bottle. Without extensive experiments on various object categories, I can hardly buy this method and admit the contributions of the proposed model.\n\n3. As far as I know, there are a number of work that cope with more complicated and natural images compositions [1][2][3], and these methods do not have the paired supervision, or even do not have the input object images. Also, this proposed method does not take the background into account, which I think is important for a natural image and also challenging due to the contextual constraints. \n\n4. Also, I doubt the generalization ability to other objects. The proposed model needs to be trained specially for each pair of object. Firstly, this is not possible in practice since we usually can not always have the training data for combinational number of object pairs.  I would suggest the authors increase the diversity of the training data and demonstrate the generalization ability of the proposed method. Since the authors used ShapeNet. I think it would be straightforward to use more object categories into account. Moreover, the authors can also use the dataset provided in [2] or [3].\n\n[Summary]\n\nThis paper proposed a method for image generation based on composition. The experiments are performed on two paired object, which demonstrate the effectiveness to some extent. However, I doubt the generalization ability of the proposed method, and the strong assumptions made by the authors for simplicity (no background, strong supervision even in unpaired case) also make it unclear to me regarding the contributions. Overall, I think the authors should perform more experiments to show the generalization ability of the proposed model to more object categories and novel combinations.", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}