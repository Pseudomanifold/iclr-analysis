{"title": "Requested minor clarifications.", "review": "The authors propose a notion of conductance to attribute the deep neural network\u2019s prediction to its hidden units. The conductance is the flow of attribution via the hidden unit(s) in consideration. The paper proposes using conductance to not only evaluate importance of hidden unit to the prediction for a specific input but also over a set of inputs. The strongest part of the analysis of conductance is that conductance naturally couples  the path at the base features with that of the hidden layer.\n\nThe authors position their work well within the existing approaches in the community and generalizes the efficient use of measuring hidden activation wrt to specific input or set of inputs.\n\nThe analysis makes efficient use of mean value theorem in the context of  parametrization of the loss function.\n\nConductance seems to satisfy the completeness of hidden features. Further, it also satisfies the layer-wise conservation principle with the outputs completely redistributed  to the inputs.\n\nIt would be good to see more analysis on the axioms 1 through to 4 for the sake of completeness in the light of partial axiomatization of conductance.\n\nThe authors provide empirical evaluation of conductance over a variety of tasks. It would be good to see some more insight in order to relate to interpretability of the importance of neurons, although there has been no claims made on it as its hard to measure importance without interpretability.\n", "rating": "7: Good paper, accept", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}