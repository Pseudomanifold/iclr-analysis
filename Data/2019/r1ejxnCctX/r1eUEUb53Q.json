{"title": "Interesting approach, but novel contributions seem to be few and poorly justified over Sun et al's work", "review": "The paper proposes a convolutional layer, inspired by optical flow calculation, to calculate the flow between feature maps. Given two feature maps (t, t+1) at layer L in the network, the flow layer calculates the flow between these\ntemporally-consecutive feature maps using TV-L1 optical flow algorithm. The parameters of the flow algorithm are learnt as opposed to being hand selected. This representation does not require pre-computation of flow, and thus is more\ncomputationally efficient compared to approaches that fuse two streams (e.g. 2SCNN). The paper is well-written. The motivation is strong, there is enough experimental evidence in the paper that this works. The idea of calculating the\nshift (i.e the flow) of the feature maps that are optimised for action recognition is interesting. On the other end, I have several reservations/criticisms to the presentation and conclusions of the paper:\n\n1. The paper dismisses other efforts that make similar assumptions as irrelevant in the related work. Sun et al (2018) also only use RGB input, propose a feature representation layer inspired by flow calculations and perform impressively on HMDB outperforming this paper\u2019s results. Dismissing this work in the comparison, and only comparing to Fan et al, seems slightly misleading experimentally. The architectural formulation of Sun et al is slightly different in that flow of features is computed at multiple depths of the RGB network--this seems to be a more expressive approach than the proposed one. I understand that the authors add iterative optimisation, but the contribution in the paper seems to claim similar contribution to Sun et al in proposing the flow layer.\n\n2. The fact that these feature maps are only optimised for the flow (and not to perform recognition separately) seems slightly strange. In the current architecture there\u2019s an assumption that the RGB features are already optimised for the problem, if I understood correctly. I had expected an architecture that optimises the RGB features separately from optimising the flow. It is not clear how the network is trained, is the RGB network first trained and then the flow representation layer? Or is it trained in a single pass backpropagating gradients through the flow layer?\n\n3. I found the structure of the ablation study to be very difficult to follow. Every bold title can be understood solely but is difficult to link to what\u2019s before/after. The usage of a variety of dataset flavours: mini-Kinetics, lowRes-HMDB, HMDB, pre-training, etc makes it difficult to follow the argument.\n\n4. The motivation for flow-of-flow whilst interesting seems to suffer from the same flaw as computing flow-of-flow using TV-L1: the method makes the brightness constancy assumption which will only hold when computing flow between features of constant velocity. The use of an intermediate convolutional layer between the stacked flow layers (flow-conv-flow) achieves\nsuperior results to the flow layer alone, there is no theoretical motivation or explanation for why this would work/solve the brightness-constancy assumption issues in computing flow-of-flow.\n\n5. Flow-of-flow which is pushed from the abstract of the paper as novel, fails to produce valuable results towards the end. Given this is a primary contribution, it is not clear what conclusions to make about this.\n\n6. It has been shown experimentally that calculating flow after the third resNet block produces the best results, but it is not clear why this is the case. The number 3 seems to be magical and little explanation is given.\n\nMinor comments:\n\n1. Fig 1 appears to be missing the additional convolutional layer remapping from 2C' channels back to C channels described in the text\n2. Feature maps are mapped to [0, 255] help numerical stability, but no explanation for why this improves numerical stability is given.\n3. Providing standard deviation metrics for runtime performance in table 9 would give more confidence in the method's superior runtime performance\n4. I Would like to see a study of how changing the number of input channel to the flow layer C' affects performance.\n5. The name MiniKinetics has already been taking and using it to refer to a different subset of the Kinetics dataset is confusing for readers who might mistakenly compare methods based on these results.", "rating": "5: Marginally below acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}