{"title": "Confusing paper, some good ideas", "review": "The paper proposes a new method for anomaly detection using deep learning. It works as follows. \n\nThe method is based on the recent Multiple-Hypotheses predictions (MHP) model, the impact of which is yet unclear/questionable. The idea in MHP is to represent the data using multiple models. Depending on the part of the space where an instance falls, a different model is active. In this paper this is realized using VAEs. The details are unclear (the paper is poorly written and lacks some detailed explainations), but I am assuming that for each hypothesis (ie region of the space) different en- and decoder parameters are learned (sharing the same variational prior??). The authors mention that below this final layer all hypothesis share the same network parameters. An adversarial loss is added to the model (how that is done is not described; the relevant equation (5) uses L_hyp which is not defined) to avoid the mode collapse.\n\nWhat is interesting about the paper:\n- First of all, pushing the the MHP framework towards AD could be relevant by its own right for a very small subcommunity that is interested in this method\n- The idea of using the adv loss for avoiding mode collapse can be useful in other settings; this is def a that I learned from the paper\n- The method might actually work rather well in practice\n\nVotum. As outlined above, the paper makes some rather interesting points, but is not well written and lacks some details. I am not entirely convinced that AD and MHP is a killer combination, but the experimental results are ok, nothing to complain here (except the usual bla: make it larger, more, etc), but honestly they really fine (maybe compare also again against more related work, e.g., Ruff et al ICML 2018).", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}