{"title": "Review", "review": "The paper proposes reference based VAEs, which considers learning semantically meaningful feature with weak supervision. The latent variable contains two parts, one related to the reference set and the other irrelevant. To prevent degenerate solutions, the paper proposed to use reverse KL resulting in a ALICE-style objective. The paper demonstrates interesting empirical results on feature prediction, conditional image generation and image synthesis.\n\nI don\u2019t really see how Equation (5) in symmetric KL prevents learning redundant z (i.e. z contains all information of e). It seems one could have both KL terms near zero but also have p(x|z, e) = p(x|z)? One scenario would be the case where z contains all the information about e (which learns the reference latent features), so we have redundant information in z. In this case, the learned features e are informative but the decoder does not use e anyways. To ensure that z does not contain information about e, one could add an adversarial predictor that tries to predict e from z. Note that this cannot be detected by the feature learning metric because it ignores z for RbVAE during training.\n\nThe experiments on conditional image generation look interesting, but I wonder if the ground truth transformation for MNIST can be simply described as in some linear transformation on the original image. I wonder if the proposed method works on SVHN, where you can use label information as reference supervision. Moreover, I wonder if it is possible to use multiple types of reference images, but fewer images in each type, to reach comparable or even better performance.\n\nMinor points:\n- Why assume that the reference distribution is delta distribution whose support has measure zero, instead of a regular Gaussian?\n- (6), (8), (10) seems over complicated due to the semi-supervised nature of the objective. I wonder if having an additional figure would make things clearer. \n- Maybe it is helpful to cite the ALICE paper (Li et al) for Equation (10).\n- Table 1, maybe add the word \u201crespectively\u201d so it is clearer which metric you use for which dataset.\n- I wonder if it is fair enough to compare feature prediction with VAE and other models since they do not use any \u201cweak supervision\u201d; a fairer baseline could consider learning with the weak supervision labels (containing the information that some images have the same label). The improvement on AffectNet compared to regular VAE does not look amazing given the additional weak supervision.\n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}