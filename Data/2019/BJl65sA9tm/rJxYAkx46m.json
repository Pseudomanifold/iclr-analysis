{"title": "Interesting idea but experimental comparison may not be fair, also sensitivity to lambda parameter is unclear", "review": "Description:\n\nThis paper presents a variant of imitation-based reinforcement learning, when in addition to example trajectories of an expert , example trajectories of non-experts are available.\n\nIn brief, the method is a variant of the GAIL method for adversarial training. In GAIL, the policy is optimized to minimize the ability to discriminate (classify) two classes: trajectories of the expert vs. trajectories from the policy, where the discrimination ability is measured by a neural network discriminator function optimized for maximal discriminative ability. In the proposed  method \"M-GAIL\", the idea is that the discriminator is forced to also discriminate a third class of non-expert demonstrations, but policy optimization is done ignoring the non-expert demonstrations and classifying only the usual two classes with the discriminator.\n\nThe M-GAIL method is compared to GAIL on four control tasks with different amounts of simulated non-expert demonstrations available, and  it outperforms GAIL if the simulated non-expert demonstrations are chosen to be relatively good ones (simulated from a policy having 70% of expert performance).\n\n\nEvaluation:\n\nThe method is described relatively well and the idea of incorporating nonexpert demonstrations seems sound.\n\nIt is not clear to me if the experiment is fair, since M-GAIL learns from more data than GAIL which learns from the expert demonstrations only. It is unclear to me why the experiments did not attempt to supply the nonexpert demonstrations to GAIL too - one could e.g. have naively pooled the nonexpert demonstration into one of GAIL's binary classes, \"expert\" or \"policy\". This is especially concerning since bett\n\nThe method also requires the additional parameter lambda which affects performance in the experiments - it is not clear how to set it in practice, does e.g. cross-validation etc. need to be used? It would be useful to know more about sensitivity to lambda, experiments only consider two values.\n\n\nAdditional comments:\n\nIn the methodological derivation, it was unclear to me why only one parameter lambda is used to control class balance, why not two parameters controlling prevalence of the expert class, policy class, and nonexpert class?\n\nIn proposition 1 the fact that the bias vanishes when lambda=0 seems trivial because eq. 9 reduces to the first term on the right hand side.\n\nIn eq. 5 it's not quite right to call the right-hand side a loglikelihood. Loglikelihoods should be sums over observations of each class (thus emphasizing classes with more data) whereas here each term is an expectation - or do you assume the number of samples corresponding to each expectation term is equal?\n\nClarify the notation d_phi when you introduce it near eq. 3.\n", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}