{"title": "Technically interesting contribution but would need more considerations and evidences", "review": "Summary:\nThe paper presents a novel supervised-learning method for regression using decision trees and neural nets. The core idea is based on a 90s technique called \"regression via classification\" by first apply discretization of target response y by some clustering, and apply any \"classification\" to those discretized values as class labels. Because real-valued y is one-dimensional and ordered, discretization means setting up any thresholds to give N-partitions of training {y_i}s. The proposed method tries to jointly learn these thresholds as well as node splitters of decision trees using neural nets. Because each node splitters are given by neural nets here, probability outputs for binary classification are also available. Regarding these probabilities as probabilistic splitting at each node, response y weighted by the path probabilities to leaves is the final prediction. The learning is in a greedy manner as in standard tree learning because exact joint learning is computationally hard.  Experiments on speaker profiling illustrate the performance improvements against standard nonlinear regression such as SVR and regression trees.\n\nComment:\nThis is a technically very interesting contribution, but several points can be considered more carefully as below.\n\n- To be honest, it would be unconvincing that the approach \"regression via classification (RvC)\" is still valid. The proposed approach is an elaborate extension of this approach, but if we want prediction performance for regression, we would use some ensembles of regression trees such as Random forest, GBDT, ExtraTrees, ... instead of a single CART. Or even we can directly use deep learning based regression. The experiments against CART and SVR would be too naive in the current context of supervised learning. On the other hand, single CARTs are well interpretable and can be a nice tool to get some interpretations of the given data. But the proposed method seems to lose this type of interpretability because of introducing node splitters by neural nets. So the merits of the proposed approach would be somewhat unclear.\n\n- In the context of tree learning, we need to consider two things. \n\nFirst of all, node splitting by general binary splitters are called \"multivariate trees\", but interestingly this does not always bring the good prediction performance on current quite high-dimensional data. So I guess that both optimizing \"threshold for RvC\" and \"nonlinear node splitters\" cannot always bring the prediction performance. Limitations and conditions would need to be clarified more carefully. \n\nSecond of all, probabilistic consideration of decision trees such as eq(4) is almost like so-called \"probabilistic decision trees\" also known as \"hierarchical mixtures of experts (HME)\" in machine learning. See famous widely-cited papers of Jordan & Jacobs 1994 and Bishop & Svensen 2003. This can bring joint learning of probabilistic node splitter (gating networks) and decision functions at leaves (expert networks), and is also known to bring the smoothing effect into discrete and unstable regression trees, and hence the improved prediction performance. So which of probabilistic consideration or RvC contributes to the observed improvement is unclear... \n\n- The target joint optimization of eq (3) is actually optimized by a number of heuristic ways, and it is quite unclear how it is truly optimized. In contrast, HME learning is formulated as a joint optimization (and solved by EM in the case of Jordan & Jacobs, for example).\n\n- The experiments on single datasets of a very specific speaker profiling problem would be somewhat misleading. Probably, for this specific problem, there would be other existing methods. On the other hand, if this is for benchmarking purpose, a regression by neural nets and tree ensemble (random forest or something) can be included as other baselines, and also other types of regression problems can be tested.\n", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}