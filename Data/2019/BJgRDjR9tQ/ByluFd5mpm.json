{"title": "Interesting Connection", "review": "This paper considers the robust estimation problem under Huber\u2019s \\epsilon-contamination model. This problem is a hot topic in theoretical statistics and theoretical computer science community in recent 3 years.  From theoretical statistics community, the main approach is through depth functions. Solving the robust estimation problem can be reduced to solving a min-max problem. While the formulation is clean and can achieve the optimal statistical rate, solving the min-max problem is computationally intractable in general. On the other hand, approaches from TCS community are more involved and sometimes cannot achieve the optimal statistical rate (especially for the general distribution). \n\nThis paper tries to make the approach from theoretical statistical community computationally tractable. This paper builds an interesting connection between f-GAN and depth functions. Importantly, authors show that by carefully choosing the discriminators neural network architecture and constraining the norms of the weight matrices, the generator achieves the optimal rates. This is an interesting theoretical discovery.\n\nMy major question is whether this approach can be used to solve robust estimation problems in more general settings. For example, we want to do robust mean estimation problem and the only assumption on P is it is sub-Gaussian. Is it possible to design a generator-discriminator pair to solve this problem? Theorems in this paper only focus on the Gaussian case. \n\n\nOverall, I like this paper. This paper provides a new angle toward a classical statistical problem. The computational issue has not been resolved yet. However, given recent progress from optimization in deep learning, it is quite possible that the optimization problem in this paper can be solved (approximately). Therefore, I recommend accepting. \n\n\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}