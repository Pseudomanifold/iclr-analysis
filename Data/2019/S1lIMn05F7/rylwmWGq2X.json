{"title": "Robust defensive design using adversarial networks", "review": "The paper proposed a defensive mechanism against adversarial attacks using GANs. The general network structure is very much similar to a standard GANs -- generated perturbations are used as adversarial examples, and a discriminator is used to distinguish between them. The performance on MNIST, SVHN, and CIFAR10 demonstrate the effectiveness of the approach, and in general, the performance is on par with carefully crafted algorithms for such task. \n\npros\n- the presentation of the approach is clean and easy-to-follow.\n- the proposed network structure is simple, but it surprisingly works well in general. \n- descriptions of training details are reasonable, and the experimental results across several datasets are extensive\n\ncons\n- the network structure may not be novel, though the performance is very nice. \n- there are algorithms that are carefully crafted to perform the network defense mechanism, such as Samangouei et al, 2018. However, the method described in this paper, despite simple, works very good. It would be great if authors can provide more insights on why it works well (though not the best, but still reasonable), besides only demonstrating the experimental results.\n- it would also be nice if authors can visualize the behavior of their design by showing some examples using the dataset they are working on, and provide side-to-side comparisons against other approaches.", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}