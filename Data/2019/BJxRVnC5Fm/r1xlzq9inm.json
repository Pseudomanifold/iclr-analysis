{"title": "Interesting and simple method, but needs clarification w.r.t. related methods and results", "review": "This paper proposes a simple improvement to methods for unit pruning. After identifying a unit to remove (selected by the experimenter\u2019s pruning heuristic of choice), the activation of that unit is approximately incorporated into the subsequent unit by \u201cmean replacement\u201d. The mean unit activation (computed on a small subset of the training set) is multiplied by each outgoing weight (or convolutional filter) and added to each corresponding bias instead. Experiments show this method is generally better than the typical method of zero-replacement before fine-tuning, though the advantage is smaller after several epochs of fine-tuning.\n\nWhile I find this paper intriguing and applaud the extensive experimentation and documentation, I have some concerns as well:\n\t1. There are unanswered questions about how this method relates to existing work. It is not clear from the paper how the \u201cmean replacement\u201d method differs from the two most related works (Ye, 2018) and (Morcos, 2018), which propose variations on replacing units with constant values or mean activations, respectively. Also, why does the method in this paper seem to yield good results, while the related method (Morcos, 2018) yields \u201cinferior performance\u201d?\n\t2. The results are stated to only apply to networks \u201cwithout batch normalization\u201d. The reason seems intuitive: any change that can be merely rolled into the bias will be lost after normalization (depending perhaps on the ordering of normalization and the non-linearities). This leaves an annually decreasing fraction of networks to which this method is applicable, given the widespread use of batch norm.\n\t3. Critically, it\u2019s difficult to compare this work against other pruning works given the lack of results reported in terms of final test error and the lack of the ubiquitous \u201cerror vs. %-pruned\u201d plot.\n\t\nOverall, this paper is lacking some clarity, may be limited in originality, may be helpful for some common networks and composable with other pruning methods (significance), but has a good quality evaluation (subject to the clarity issues). I\u2019m rating this paper below the threshold given the limitations, but I\u2019m willing to consider an upgrade to the score if these questions are addressed.\n\nOther notes:\n\t4. What is your definition of a convolutional \u201cpruning unit\u201d? (From context, I\u2019d presume it corresponds to an output activation map.)\n\t5. In Section 3.1:  replace \u201cin practice, people \u2026\u201d with  something like \u201cin practice, it is common to\u201d.\n\t6. In Equation 3, is the absolute value of the pruning penalty used in the evaluation?\n\t7. In the footnote in Section 3.2, how many training samples are needed for a good approximation? How many are used in the experiments?\n\t8. There are a couple typos in Section 3.2: \u201creplacing -the- these units with zeroes\u201d and \u201ceach of these output*s*\u201d.\n\t9. Presumably the \u201c\\Delta Loss after pruning\u201d in Figures 2-6 is validation or test loss, not training loss? Is this the cross-entropy loss? Also, it would be much easier to compare to other papers if test accuracy were reported instead or in addition.\n\t10. In Figure 4, the cost to recover using fine-tuning seems to be only roughly 2% of the original training time. How much time is lost to the process of computing the average unit activation?\n\nUPDATE: I've raised the score slightly to 5 after the rebuttals and revisions.", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}