{"title": "Overall score: 4", "review": "1. Pruning neurons in pre-trained CNNs is a very important issue in deep learning, and there are a number of related works have been investigated in Section 2. However, it is very strange that, I did not see any comparison experiments to these related works in this paper.\n\n2. The presentation of the experiment part is also wired, to report compression rates, speed-up rates, and accuracy might have a more explicit demonstration.\n\n3. ''This is often done by replacing the these units with zeroes\". However, in previous works, we can directly establish a compact network with fewer neurons after pruning some unimportant neurons. Thus, some considerations and motivations in Section 3.2 seem wrong. \n\n4. It seems that the neural network after using the proposed method has the same architecture as that of the original network, but some of it neurons are represented as mean replacement. Therefore, the compression and speed-up rates of the proposed method would be hard to implement in practice.\n\n5. The paper should be further proofread. There are considerable grammar mistakes and unclear sentences.", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}