{"title": "The contribution is incremental due to lack of originality and somewhat narrow scope of the application", "review": "The paper applies multi-armed bandits for choosing the size of the minibatch to be used in each training epoch of a standard CNN. The loss of the bandit is binary: zero if the validation loss decreases and 1 otherwise. In the experiments, the Exp3 bandit algorithm is run with Adam and Adagrad on MNIST, CIFAR-10, and CIFAR-100. The results show that the bandit approach allows to obtain a test error better (although not significantly better) than the test error corresponding to the best minibatch size among those considered by the bandit.\n\nThe idea of viewing the choice of hyperparameters in a learning algorithm as a bandit problem is known and has been explored in different contexts, although the specific application to minibatch size is new as far as I know.\n\nThe paper could have gained strength if bandits had been considered in wider context of parameter/model selection in deep learning.\n\nIt is not clear how results scale with the number and choice of the grid values.\n\nI would have liked to see a more thorough investigation of the impact of the bandit loss on the experiments. It is true that as far as the theory is concerned, any bounded loss is OK. But I practice I would expect that a graduated loss (e.g., signed percentage of change in validation loss), would be more informative.", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}