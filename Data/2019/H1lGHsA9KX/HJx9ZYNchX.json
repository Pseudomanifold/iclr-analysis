{"title": "Well-motivated idea seemingly showing a small improvement in performance, but at little cost and with a potential increase in robustness", "review": "The authors consider the problem of determining the minibatch size for SGD by first fixing a set of candidate sizes, and then learning a distribution over those sizes using a MAB algorithm. A minibatch size is first sampled from the distribution, then one training epoch is performed. A validation error is then computed, and if it is lower than that of the last epoch, the cost of the minibatch is taken to be zero (otherwise one), and the distribution is updated. This is Algorithm 1.\n\nIn Section 4.2, they prove a regret bound, but I don\u2019t think that regret is really the correct notion, here (although it\u2019s very close). This is a subtle point, so I\u2019ll set up some notation. Let w(b_1, ..., b_t) be the result at the tth epoch, if the batch sizes b_1, \u2026, b_t were used at the 1st through tth epochs. Let y(w,b) be 0 if training one epoch starting at w with batch size b would improve the validation error, and 1 otherwise.\n\nThey show (unnumbered inequality on the middle of page 5) that \\sum_t y(w(b_1,...,b_{t-1}),b_t) is close to \\sum_t y(w(b_1,...,b_{t-1}),b^*), where b_t is the batch size that was chosen at time t, and b^* is the best fixed batch size. The key point here is that the comparator (the second sum) starts each epoch at the result that was found by their adaptive algorithm, *not* what would have been found if a batch size of b^* had been used from the beginning.\n\nIn other words, their result does *not* show that their algorithm is close to outperforming a fixed choice of batch size (for that to hold, the comparator would need to be \\sum_t y(w(b^*,...,b^*),b^*)). What they show is similar, but subtly different. They don\u2019t put too much weight on this theoretical result, and in fact don\u2019t even explicitly claim that the comparator in this result is that for a fixed choice of batch size, so really this is a minor issue, but I think that this is something that should be clarified, since it would be easy for a reader to draw an incorrect conclusion.\n\nWith that said, their approach is well-motivated, and their experiments seem to show consistent small improvements in performance. I don\u2019t think the performance improvements are totally conclusive, but one of the most appealing properties of their proposal is that it shouldn\u2019t be much more computationally expensive than using a fixed minibatch size. Furthermore, their approach is potentially more robust, since you can presumably be less careful about choosing the set of candidate minibatch sizes, than you would be for choosing only one. So while the experiments don\u2019t show a big improvement, their proposal has other benefits.", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}