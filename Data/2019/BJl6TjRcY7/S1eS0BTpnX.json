{"title": "The idea is oversimplified, which may limit its applications.", "review": "This paper mainly focuses the imitation of expert policy as well as compression of expert skills via a latent variable model. Overall, I feel this paper is not quite readable, albeit that the prosed methods are simple and straightforward. \n\nAs one major contribution of this paper, the authors introduce a first-order approximation to estimate the action of an expert, where perturbations are considered. However, this linear treatment could yield large errors when the residuals in (1) are still large, which is very common in high-dimensional and highly-nonlinear cases. Specifically, the estimation of \u201cJ\u201d could be hard. In addition, just below (1), the authors mention (1) yields a \u201cstabilized policy\u201d, so what do you mean \u201cstabilized\u201d?\n\nAnother crucial issue lies on the treatment of \u201c\\Delta(s)\u201d, which is often unknown and hard to modeled, Thus, various optimal controllers are introduced so as to obtain robust controllers. Similarly, in (9) it is also difficult to decide what is \u201csuitable perturbation distribution\u201d.\n\nOverall, the linear treatment in (2) and assumption on \u201c\\Delta(s)\u201d in (5) actually oversimplify the imitation learning problem, which may not be applicable in real robot applications.\n\nOthers small comments:\n-Section 2.1 could be moved to supplementary material or appendix, as this part is indeed not a contribution.\n\n- in (5), it should be \u201c-J_{i}^{*}\u201d\n", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}