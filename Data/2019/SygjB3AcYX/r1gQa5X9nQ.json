{"title": "Not sure about the novelty: a slight generalization of [Hein and Maier 2007]", "review": "In classical Label Propagation (LP)-based semi-supervised learning, only the given graph structure and labelled data are taken account (e.g. in citation networks). However, this can be limiting as feature representations for data vertices (given by the matrix X) are not fully exploited. The proposed approach proposes to break this limitation.\n\nThe authors consider LP from a signal processing perspective by showing that it behaves as a low pass filter: It amplifies contributions of small eigenvalues (of the graph Laplacian) and attenuate contributions of large eigenvalues leading to smoother signal.\n\nSuch insight is exploited by replacing the input signal Y by X: Which has the result of smoothing features in X such as data points of the same class would have similar features. Then, a classifier is trained on the labelled data points using the filtered features. This classifier is finally used for classifying unlabelled data points.\n\nThe authors reveal a connection between the proposed approach (GLP) and graph convolutional neural networks (GCN) by showing that the former is a special case of the first, which gives a natural and intuitive explanation to the inner workings of GCNS. \n\nFinally, experiments on 5 datasets have been conducted showing that the proposed approach consistently outperforms recent and classical semi-supervised approaches by a large margin, especially when the number of data points is very small. \n\nThis paper is well motivated and written. However, the novelty is limited as similar ideas have been undertaken by [Hein and Maier 2007] although in different contexts. \n\nAlthough a discussion about [Hein and Maier 2007] has been provided in the related work section, it is not enough to faithfully compare both approaches. The authors should give proper credit to [Hein and Maier 2007] for the original ideas of smoothing the signal X and provide throughput qualitative and quantitative comparisons with [Hein and Maier 2007]:\nAs stated by the authors, this approach is perhaps not directly applicable to citation networks. However, it is applicable to MNIST, and a comparison in this context is necessary. Also, it would be interesting to qualitatively compare the denoising ability of both approaches by showing some example images (on MNIST as provided by [Hein and Maier 2007]).\n\nIn addition, I think this paper would benefit from:\n\n\u2022\tProviding comparisons with recently proposed Gan-based semi-supervised approaches (e.g. Salimans et.al 2016)\n\u2022\tGiving more details about hyper-parameter selection (alpha and k).\n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}