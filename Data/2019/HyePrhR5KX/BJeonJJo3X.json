{"title": "Marked Point Process extension of (Trivedi et al., 2017)", "review": "Overall, the contribution of the paper is somewhat limited [but a little more than my initial assessment, thanks to the rebuttal]. It is essentially an extension of (Trivedi et al. 2017), adding attention to provide self-exciting rates, applied to two types of edges (communication edges and \u201cfriendship\u201d edges). Conditioned on past edges, future edges are assumed independent, which makes the math trivial. The work would be better described as modeling a Marked Point Process with marks k \\in {0,1}.\nOther comments:\n1.\t[addressed] DyRep-No-SP is as good as the proposed approach, maybe because the graph is assumed undirected and the embedding of u can be described by its neighbors (author rebuttal describes as Localized Propagation), as the neighbors themselves use the embedding of u for their own embedding (which means that self-propagation is never \"really off\"). Highly active nodes have a disproportional effect in the embedding, resulting in the better separated embeddings of Figure 4. [after rebuttal: what is the effect of node activity on the embeddings?]\n2.\t[unresolved, comment still misundertood] The Exogenous Drive W_t(t_p \u2013 t_{p\u22121}) should be more personalized. Some nodes are intrinsically more active than others. [after rebuttal: answer \"$W_t(t_p - t_{p-1})$ is personalized as $t_p$ is node specific\", I meant personalized as in Exogenous Drive of people like Alice or Bob]\n3.\t[unresolved] Fig 4 embeddings should be compared against (Trivedi et al. 2017) [after rebuttal: author revision does not make qualitative comparison against Trivedi et al. (2017)]\n\nBesides the limited innovation, the writing needs work. \n4.\t[resolved] Equation 1 defines $g_k(\\bar{t})$ but does not define \\bar{t}. Knowing (Trivedi et al. 2017), I immediately knew what it was, but this is not standard notation and should be defined. \n5.\t[resolved] $g_k$ must be a function of u and v\n6.\t[resolved] \u201c$k$ represent the dynamic process\u201d = >  \u201c$k$ represent the type of edge\u201d . The way it is written $k$ would need to be a stochastic process (it is just a mark, k \\in {0,1})\n7.\t[resolved] Algorithm 1 is impossibly confusing. I read it 8 times and I still cannot tell what it is supposed to do. It contains recursive definitions like $z_i = b + \\lambda_k^{ji}(t)$, where $\\lambda_k^{ji}(t)$ itself is a function of $z_i(t)$. Maybe the z_i(t) and z_i are different variables with the same name?\n8.\t[resolved] The only hint that the graph under consideration is undirected comes from Algorithm 1, A_{uv}(t) = A_{vu}(t) = 1. It is *very* important information for the reader.\nRelated work (to be added to literature):\nDynamic graph embedding: (Yuan et al., 2017) (Ghassen et al., 2017)\nDynamic sub-graph embedding: (Meng et al., 2018)\n\nMinor:\nstate-of-arts => state-of-the-art methods\nlist enumeration \u201c1.)\u201d , \u201c2.)\u201d is strange. Decide either 1) , 2) or 1. , 2. . I have never seen both.\nMAE => mean absolute error (MAE)\n\nYuan, Y., Liang, X., Wang, X., Yeung, D. Y., & Gupta, A., Temporal Dynamic Graph LSTM for Action-Driven Video Object Detection. ICCV, 2017.\nJerfel,  , Mehmet E. Basbug, and Barbara E. Engelhardt. \"Dynamic Collaborative Filtering with Compound Poisson Factorization.\" AISTATS 2017. \nMeng, C., Mouli, S.C., Ribeiro, B. and Neville, J., Subgraph Pattern Neural Networks for High-Order Graph Evolution Prediction. AAAI 2018.\n\n--- --- After rebuttal \n\nAuthors addressed most of my concerns. The paper has merit and would be of interest to the community. I am increasing my score.", "rating": "7: Good paper, accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}