{"title": "Simple Idea, Good Results But Novelty? Detailed Analysis?", "review": "The paper proposes a simple idea to calibrate probabilities outputted by a CNN model to adapt easily to environments where class distributions change with space and time (and are often skewed). The paper shows that such a simple approach is sufficient to get good accuracies without requiring any costly retraining or transfer learning. Thereby proving to give benefits in terms of resource consumption and at the same time giving better results than the state of the art.\n\nHowever, \nA] The proposed calibration doesn't take any CNN specific details into consideration, rather it is a general calibration method which was also proposed in Saerens et. al, 2002 (cited in the paper). It is unclear why the paper specifically talks about CNN.\nB] The proposed Class Skew Detector is a simple method. Change-point detection is a well-studied area. The paper lacks a literature review in this area and a reasoning of why the proposed approach is preferred. Also, an independent analysis of how the class skew detector behaves in the face of rapidly changing class skews versus slow changing class skews is warranted here. Particularly, given that the paper proposes to use this approaches in mobile which may work in both rapid and slow changing class skews.\nC] The Class Skew Detector is dependent on the base model. Thus, it is also likely that the empirical distribution estimated is biased and yet the final accuracies reported are much higher than the base model accuracies. There is something interesting happening here. An analysis of the robustness of the proposed approach in the face of noisy class skew detection could potentially make this paper a stronger work.\nD] The analysis in the paper has largely focused on pre-trained models. However, another analysis that could have been useful here is, varying the quality of the classifier (e.g. classifier trained on skewed training data vs. balanced training data) and measuring how the quality of the classifier correlates with the final performance. Maybe even attempt to answer the question \"which classifiers are likely to work with this approach?\" In fact, this analysis can be either done in a general context of any classifier or just CNN's and identifying whether certain properties of CNN help in getting better performance.\n\nThe paper lacks novelty and at the same time, it is not quite compensating that with a detailed analysis of the work. The problem is interesting and I like the work because the approach is simple and the results look good. I think with a stronger focus on more detailed analysis, this can be a good submission to an applied conference like MobiCom etc.\n\nBy the way, the paper is riddled with several spelling errors - \n\"filed\" -> \"field\", page 1, second paragraph, last line\n\"complimentary\" -> \"complementary\", page 2, section 2, paragraph 1, last line\n\"epoches\" -> \"epochs\", page 2, section 2, transfer learning, second paragraph, second last line\n\"CNNs does not use\" -> \"CNNs do not use\", page 3, section 3, intuition, first paragraph, first line\n\"formular\" -> \"formula\", page 4, above equation 4\nEquation 4 has a typo in the denominator, P_t(i) should be P_t(j), same with Equation 5\n\"obstained\" -> \"obtained\", page 7, second paragraph, first line\n\"adaptation\" is almost everywhere spelled as \"adaption\"", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}