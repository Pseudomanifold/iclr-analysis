{"title": "Review", "review": "The idea proposed in this paper is to improve classification accuracy by making use of the context.\nE.g. on the north pole we will see polar bears but no penguins, on Antartica we have no polar bears but many penguins.\nHence, if we apply our imagenet-like classifier in the wild, we can improve accuracy by taking into account changes in the prior distribution.\n\nThe paper proposes a way to rescale the probabilities to do exactly this and reports improved results on modified versions of \n CIFAR 10 and imagenet with artificial class skew. To achieve this, an additional trick is introduced where the re-scaling is only used when the model is not very certain of its prediction. And additional motivation for this work is that less compute resources are needed if the problem is simplified by utilizing class skew. \n\nThe core idea of the paper is interesting. However, I am not able to understand what exactly is done and I am 100% confident I cannot re-implement it. The authors already improved upon this in our interactions prior to the review deadline. \nAn additional issue is that the paper does not have a good baseline. \nI would not like to dismiss the approach based on its simplicity. An elegant solution is always preferred. However, all the tasks are quite artificial and this limits the \"impact\" of this work. If an \"natural\" application/evaluation where this approach would be possible, it would strengthen the paper greatly. \n\nFor the reasons above I recommend rejection of the manuscript in the current state but I am confident that many of these issues can be resolved easily and if this is done I will update the review.\n\nMissing information\n----------------------------\n- The original manuscript had a lot of information missing, but much of it has since been provided by the authors.\n- In the static class skew experiment, were two passes over the data needed? Or was the Pt(i) pre-set? Would it also be possible to give details about LR, optimizer, LR schedule, batch size, .... for the transfer learning experiments. This would enhance reproducibility. \n- For the imagenet experiments how was Pt(i) set in the if I assume correctly, static setting.\n\nPossible additional baselines:\n-----------------------------------------\n\nWe could make a simpler rescaling by changing the prior distribution and assuming everything else remains constant.\nWhile this is a simplifying assumption, it is very easy to implement and should take only a couple of minutes to run. \nP(i|x)=1/P(X)*P(X|i)*P(i)\nPt(i|x)=P(i|x)*Pt(i)/P(i)\n\nOne could also introduce another baseline where only the most probably classes are considered. Since this approach is clearly sub-optimal since it guarantees some mis-predictions it should serve as a lower bound on the performance that is to be expected. \n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}