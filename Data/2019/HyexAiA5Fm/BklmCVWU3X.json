{"title": "good effort for scalable unbalanced OT, theoretical aspect might be problematic ", "review": "### post rebuttal### authors addressed most of my concerns and greatly improved the manuscript and hence I am increasing my score. \n \nSummary: \n\nThe paper introduces a static formulation for unbalanced optimal transport by learning simultaneously a transport map T and scaling factor xi .\n\nSome theory is given to relate this formulation to unbalanced transport metrics such as Wasserstein Fisher Rao metrics  for e.g. Chizat et al 2018.  \n\nThe paper proposes to  relax the constraint in the proposed static formulation using a divergence.  furthermore using a bound on the divergence , the final discrepancy proposed  is written as a min max problem between the witness function f of the divergence and the transport map T , and scaling factor xi. \n\nAn algorithm is given to find the optimal map T as a generator in GAN and to learn the scaling factor  and the witness function of the divergence with a neural network paramterization , the whole optimized with stochastic gradient. \n\nSmall experimentation on image to image transportation with unbalance in the classes is given and show how the scaling factor behaves wrt to this kind of unbalance. \n\n\nNovelty and  Originality:\n\nThe paper claims that there are no known static formulations known with a scaling factor and a transport map learned simultaneously. We refer the authors to Unbalanced optimal Transport: Geometry and Kantrovich Formulation Chizat et al 2015. In page 19 in this paper Equation 2.33 a similar formulation to Equation 4 in this paper is given. (Note that phi corresponds to T and lambda to xi). This is known as the monge formulation of unbalanced optimal transport. The main difference is that the authors here introduce a stochastic map T and an additional probabilty space Z. Assuming that the mapping is deterministic those two formulations are equivalent. \n\nCorrectness: \n\nThe metric defined in this paper can be written as follow and corresponds to a generalization of the monge formulation in chizat 2015 :\nL(mu,nu)= inf_{T, xi}  int   c_1(x,T_x(z) ) xi(x) lambda(z) dmu(x)  + int c_2(x_i(x)) dmu(x)\n                        \t\t s.t T_# (xi mu)=nu\nIn order to get a kantorovich formulation out of this chizat et al 2015 defines semi couplings and the formulation is given in Equations 3.1 page 20. \n\nThis paper proposes to relax  T_# (xi mu)=nu with D_psi (xi \\mu, \\nu) and hence proposes to use:\n\nL(mu,nu)= inf_{T, xi} int   c_1(x,T_x(z) ) xi(x) lambda(z) dmu(x)  + int c_2(x_i(x)) dmu(x)+  D_psi (xi \\mu, \\nu)\n\nLemma 3.2 of the paper claims that the formulation above corresponds to the Kantrovich formulation of unbalanced transport. I doubt the correctness of this:\n\nInspecting the proof of Lemma 3.2 L \\geq W seems correct to me, but it is unclear what is going on in the proof of the other direction? The existence of T_x is not well supported by rigorous proof or citation? Where does xi come from in the third line of the equalities in the end of page 14? I don\u2019t follow the equalities written at the end of page 14. \n\nAnother concern is the space Z, how does the metric depend on this space? should there be an inf on all Z?\n\nOther comments:\n\n- Appendix A is good wish you baselined your experiments with those algorithms. \n\n- The experiments don\u2019t show any benefit for learning the scaling factor, are there any applications in biology that would make a better case for this method?\n\n- What was the architecture used to model T, xi, and f?\n\n- Improved training dynamics in the appendix, it seems you are ignoring the weighting while optimizing on theta? than how would the weighing be beneficial ?", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}