{"title": "Current work reps capture a surprising amount of structure", "review": "I have no major complaints with this work.  It is well presented and easily understandable. I agree with the claim that the largest gains are largely syntactic, but this leads me to wonder about more tail phenomena.   PP attachment is a classic example of a syntactic decision requiring semantics, but one could also imagine doing a CCG supertagging analysis to see how well the model captures specific long-tail phenomena.  Though a very different task Vaswani et al 16, for example, showed how bi-LSTMs were necessary for certain constructions (presumably current models would perform much better and may capture this information already).\n\nAn important caveat of these results is that the evaluation (by necessity) is occurring in English.  Discourse in a pro-drop language would presumably require longer contexts than many of these approaches currently handle.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}