{"title": "provides a white paper of engineering issues for INT8 inference on CPUs that appears to be companion to existing ones for INT8 for GPU", "review": "This paper reads more like a technical/hardware white paper than a research paper. No real theory is offered, and the results are not really experiments testing hypotheses, but simply reporting the results of their design choices on a various of models.  Thus, it is not clear that this paper is especially suitable for ICLR research track per se.  Furthermore, the calibration method (to find suitable INT8 weights from fp32 ones without further training) appears to be essentially identical to techniques already reported by Nvidia as used by their TensorRT.  The discussion of INT8 for Winograd is something that could have been new and interesting (i.e. this reader has not seen Nvidia discuss this issue previously), but in the end this paper did not offer anything surprising or especially insightful in the brief Section 3.2.2 explaining their approach.  Furthermore, the experiments such as Table 2 do not include Winograd results anyway because that does not give competitive results using INT8, as the authors admit. ", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}