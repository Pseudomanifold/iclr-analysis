{"title": "Compute a GMM in a learned feature space (AE, VAE) and make it class aware by making use of class information or a prediction thereof.", "review": "The authors study the task of sample-based quantitative evaluation applied to GANs. The authors suggest multiple modifications to existing evaluation pipelines: (1) Instead of embedding the samples in the InceptionNet feature space, train a domain-specific encoder. If labeled data is available, add a cross-entropy loss to the encoder training objective so that the class can be predicted. (2) Instead of fitting a single Gaussian in the feature space, fit a GMM instead. This should allow for a more fine-grained \u201cclass-aware\u201d distance between the (empirical) distributions. \n\nPro: \nAttempt to attack a critical issue in generative modeling. Good overview of competing approaches.\nSeveral ablation studies of evaluation measures and the behavior of FID with respect to the representation space.\nThe ideas make sense on a conceptual level, albeit suffering from major practical concerns.\n\nCon:\n- Clarity can be improved (e.g. use of double negatives as in the top of page 3), the same arguments repeated multiple (>3) times (i.e. deficiencies of FID and IS, etc.), Many statements which should be empirically tested are stated as folklore (last paragraph on page 3). In general the paper merits another polishing pass (mode != model, last paragraph in  section 3, \u201cunmatch\u201d, etc.).\n- Why would a VAE capture a good feature space? It is known that the tradeoff between what is stored in the latent space versus the discriminator *completely* depends on the power of the discriminator -- if the discriminator is flexible enough it can just learn the marginal distribution and ignore the latent code. Hence, this subtle issue will likely undermine the entire model comparison.\n- Using the predictive distribution as a soft label for CAFD. Interesting idea, but why would one have access to labels in the first place? Why wouldn't one use a conditional GAN if we already have labels? Secondly, why would the modes necessarily correspond to classes?\n- Stated issues with FID: Why would you expect FID to be resistant to such drastic transformations as blocking out a significant proportion of pixels with \u201cblocks\u201d? This is a *major* change in the underlying distribution. The fact that humans can \u201cfill in\u201d this gap should have nothing to do with the quality of the underlying model. Arguably, you can also hide one eye, the nose and the mouth and still judge the sample as \u201cgood\u201d.\n\nThe ideas presented in this paper are conceptually interesting. However, given the drawbacks discussed above I cannot recommend the acceptance of this work.\n", "rating": "3: Clear rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}