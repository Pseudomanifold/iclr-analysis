{"title": "Good motivation, weak organization, unclear results", "review": "Summary: \nThis paper proposes to reformulate the QA task in SQUAD as a retrieval task, i.e., using question as query and paragraphs as candidate results to be ranked.  Authors makes some modifications to elmo model to create better word embedding for the ranking task. Authors have mentioned and are aware of open domain QA methodologies (e.g., DrQA).\n\nPros:\n- The general idea is interesting, to reformulate any QA task as a ranking task\n\nCons:\n- The methodology and task are not clear. Authors have reformulated QA in SQUAD as as ranking and never compared the results of the proposed model with other QA systems. If authors want to solve a pure ranking problem why they do not compare their methods with other ranking methods/datasets.\n- The novelty: The novelty is not significant. Although modifications to ELMO are interesting. \n- Results: Why authors have not compared their work with DrQA? ", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}