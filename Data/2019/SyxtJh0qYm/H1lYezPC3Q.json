{"title": "interesting paper; missing/weak experiments", "review": "The paper presents a model for learning conditional distribution when arbitrary partitioning the input to observed and masked parts. The idea is to extend the conditional VAE framework such that the posterior is a function of an arbitrary subset of observed variables. Accordingly, reconstruction loss only penalizes the error in the reconstruction of masked (unobserved) variables. The method is compared against 1) classical approaches in missing data imputation on UCI benchmarks; 2) image inpainting against recently proposed GANS for the similar task, as well as; 3) against universal marginalizer, which learns conditional densities using a feedforward / autoregressive architecture.\n\nMy concern about the experimental results on missing data imputation is that strong competition such as Gondra et al\u201917 and Yoon et al\u201918 that report better results on UCI than classical approaches are not included. Could you please comment? See also [1,2] for other autoencoding architectures for this task.\n\nWhile the derivation of the method is principled, it assumes that either the mask is known during the training OR one could efficiently sample a distribution of masks to learn arbitrary conditional densities. Given the exponential number of valid masks in a general setting, one only subsamples a small portion during the training. The question is whether the model can generalize well in this regime? The experimental results in this setting is not very encouraging, suggesting the proposed approach is effective only when the limitted mask patterns are known in advance. \n\n[1] Gondara, Lovedeep, and Ke Wang. \"Multiple imputation using deep denoising autoencoders.\" arXiv preprint arXiv:1705.02737 (2017).\n\n[2] Zhang, Hongbao, Pengtao Xie, and Eric Xing. \"Missing Value Imputation Based on Deep Generative Models.\" arXiv preprint arXiv:1808.01684 (2018).\n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}