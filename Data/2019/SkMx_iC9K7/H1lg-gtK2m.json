{"title": "Approach isn't clear, but seems to lack novelty. Writing could be better. ", "review": "Summary:\nThe authors propose a novel adversarial learning framework consisting of a coarse-to-fine generator and a multiple instance discriminator to generate high-quality sentences without supervision, along with two training mechanisms to make the generator produce higher-quality sentences.\n\nThe coarse-to-fine generator is implemented as a two-stage decoder where the first stage decoder is initialized with a noise vector z and produces an initial sequence by sampling from its distribution at each step. The second stage decoder is able to attend to first stage decoder hidden states when generating its sequence and is initialized with the last hidden state of the first state decoder\n\nTwo training frameworks are defined to help the coarse-to-fine generator learn to produce coherent text. In both frameworks, a multi-instance learner is used as a discriminator and the overall score for the sequence is an average of word-level scores. \n\nIn DelibGAN-I, the first stage decoder is just trained to minimize the negative log likelihood of producing the sampled sequence. I\u2019m not sure I understand how G1 learns to generate coherent text by just maximizing the probability of its samples.\n\nIn DelibGAN-2, the word-level scores from passing the first stage decoder\u2019s output through the discriminator is used to score the sequence. This makes more sense to me w.r.t to why the first stage generator could learn to produce coherent text.\n\nReview:\nThe writing could be clearer. Spacing is consistently an issue in w.r.t. to citations, referencing equations an figures, and using punctuations. Equations are difficult to understand, as well. See Equation 5. I\u2019m confused by how the discriminator score of x_t is computed in equation 5. It seems to be the score of the multi-instance learner when applied to the concatenation of the previous generated tokens and the most recently generated token. This isn\u2019t really a roll-out policy, however, since only a single step is taken in the future. It\u2019s just scoring the next token according to the discriminator. In this case, I\u2019m not sure what the summation over j is supposed to represent. It seems to index different histories when scoring word x_t. The authors should clarify exactly what the scoring procedure is for sequences generated by G2 and make sure that clarification matches what is written in the equation.\n\nBecause deliberation has previous been explored in Xia et al., 2017, the novelty of this work rests on the application of deliberation to GAN training of generative text models, as well as the development of the multi-instance discriminator for assigning word-level scores to the first-stage decoder's actions. However, it\u2019s difficult to know how much of the improvement in performance is due to the modeling improvement because the evaluations are missing key details.\n\nFirst, no information about the model\u2019s hyperparameter setting were provided. Naturally, having two generators would double the number of parameters of the total model. Was an ablation run that looked at doubling the parameters of a single-generator? How powerful are the models being used in this new setup. With powerful models such as the OpenAI GPT being available for generative modeling, how powerful are the base units in this framework?\n\nSecond, I don\u2019t have much intuition for how difficult the tasks being performed are. Because the authors aren\u2019t evaluating on particularly difficult language datasets, they should provide statistics about the datasets w.r.t to vocabulary size, average length, etc.\n\nConsequently, a lot of information that is necessary for evaluating the strengths and weaknesses of this paper are missing from the write-up.\n\nQuestions:\nEquation 2 is slightly confusing. Is the representation of the word at that time step not conditioned on previous and future hidden states?\n\nIs the multi-instance discriminator used in DelibGAN-II or is G2 only scored using the sentence level discriminator score?\n\nSmall:\n-Wang & Wan, 2018a are definitely not the first work to discover that using word-level losses to train models for sentence-level evaluations is suboptimal\n-Please fix issues with spacing. There are issues when citing papers, or referencing equations, or using punctuation.\n-Equation 3 is missing a closing parenthesis on the softmax", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}