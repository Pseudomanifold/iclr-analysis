{"title": "A simple test of CNN and CapsNet's performance on translation", "review": "The authors of this paper compare the robustness of CNN and CapsNet to global translation on the MNIST dataset. Both models were trained on the standard training set of MNIST, and then tested on a set with digits shifting from the upper left corner to the lower right corner. The results of both models were poor. To improve it, the authors add some shifted digits to the training set, and the performances of both models were significantly enhanced. Moreover, the performance of CNN was better than that of CapsNet in the experiments. Generally speaking, the work presented in this paper is clear and straightforward. However, the work is not significant enough to publish as a ICLR paper. Below is my major comments.\n\n1. There are lots of typos and grammatical errors everywhere in the paper. Thus, the manuscript was not well prepared.\n\n2. It is unclear which CapsNet and what settings were used in the experiment.  \n\n3. It is well-known that convolutional networks are good at capturing local patterns from the images, while capsule networks enhance it to consider global configurations of the local patterns, and robust to affine transformation. Obviously, the experiments presented in this manuscript is too simple. Lots of work should be done in the investigation. For example,o on the training set and shifted test set, the authors can enlarge the background and keep the digits in the original size to make it as a local pattern in the image. Will it be detected by CNNs with larger receptive fields for the images? How is it compared with CapsNets? \n\n4. How are both models compared on other (perhaps more complicated and larger) datasets?\n\nIn summary, the work presented here is interesting, but lots of work should be done in order to make it publishable.\n\n", "rating": "3: Clear rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}