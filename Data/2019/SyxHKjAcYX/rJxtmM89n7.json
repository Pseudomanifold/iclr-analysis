{"title": "Interesting idea!", "review": "This paper presents a multilingual NLP model which performs very well on a target language with any leveraging labeled data. The authors evaluated their framework on there different tasks: slot filling, named entity recognition and text classification. Overall, the results look very promising.\n- Strengthens:\n+ The proposed idea is novel.\n+ The results are very good for all three tasks.\n- Weaknesses:\n+ The authors claimed that their model knows what to share. However, they did not provide any evidence proving this hypothesis. Only the experimental results are not enough.\n+ The paper also lacks an analysis to show to some extent what the model learned, e.g. the attention weights or the value of the gate. Is there any correlation between the similarity among languages (source and target) and the attention weights.\n- What are not clear:\n+ It is not clear to me what exactly has been done with the CharCNN embeddings in Section 4.2? How did the authors train the embeddings (only with the source languages or also with the target language)? It seems to me that the proposed model did not work well in this case. ", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}