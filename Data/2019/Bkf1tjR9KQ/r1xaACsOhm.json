{"title": "Interesting but incremental work", "review": "The authors propose a multi-objective neural architecture search based on an evolutionary algorithm. The contradicting objective functions are optimized by ranking the candidates by Pareto-dominance, replace the bottom 50% with new candidates generated by the top 50% candidates through random mutations. The multi-objective function considers classification accuracy and an approximation of the inference speed. The method is compared to MobileNet and Mobile NASNet on ImageNet indicating an improvement with respect to search time.\n\nThe authors admit that their work is incremental and a combination of existing work. Furthermore, they admit that Dong et al. (2018) is the closest related work, however, they do not compare to them in the experimental section. The method by Dong et al. requires only 8 GPU days (Dvolver requires 50) yielding very similar results. Why this has been ignored remains unclear.\n\nThe paper is not self-contained, important methodological aspects of the method are insufficiently described. I recommend at least to formally define the crowding distance. It would be also reasonable to define your objective functions already in Section 3 instead of mentioning them in the caption of Figure 3 and its axis labels.\n\nI think it's fair to call your approach evolutionary but you might want to discuss its relationship to beam search and in this scope discuss [A].\n\nThe comparison in Table 2 is not fair. You use the swift activation function and do not report the corresponding numbers for MobileNet or Mobile NASNet. Ramachandran et al. (2017) report these (75% and 74.2% for NASNet and MobileNet).\nComparing the Dvolver architecture with ReLU activations to MobileNet does not indicate any improvements.\n\nYou mention that most previous approaches are only keeping track of the best solution while you evolve over a population. Maybe this sentence is not well written and something else is meant but now this statement is wrong.\n\n[A] Thomas Elsken, Jan Hendrik Metzen, Frank Hutter: Simple And Efficient Architecture Search for Convolutional Neural Networks. CoRR abs/1711.04528 (2017)", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}