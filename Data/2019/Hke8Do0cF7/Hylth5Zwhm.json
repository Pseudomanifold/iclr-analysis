{"title": "Review", "review": "The paper at hand describes an approach to enable neural networks to take arbitrary structured data (basically any data that is not easily represented as a fixed-dimensional vector) as input. The paper describes how such data can be represented as a set (e.g. a sequence is represented as a set of index + data) and then an auxiliary network called the set aggregating network (SAN)  is used to represent the data in a high dimensional latent space. In addition to the idea, the paper provides a theoretical analysis of the approach which shows that with a sufficiently high dimensional representation the network is able to learn a unique representation for each input example. \n\nGood in this paper: \n - nicely on topic - this is truly about learning representations\n - interesting idea with some (albeit not-surprising) theoretical analysis\n\nNot yet great in this paper: \n - the paper feels a bit premature in multiple ways, to me most importantly the experiments appear to be really rushed. \n  Looking at table 1 - it is really unclear how to read this. The table is hardly explained and it would be good to actually compare the method to the state of the art. I understand that the authors care more about generality here - but it's much easier to build something generic that is very far from the state of the art than to build something that is closer to the state of the art. Also - I feel it would have been interesting to allow for a more direct comparison of the SAN results with the other methods. Similarly, in Table 2 - how far away is this from the state of the art.\n- the variable size image-recognition task seems a bit artificial - I believe that scaling images to a fixed size is a reasonable idea and is well understood and also something that humans can work with. Dealing with variable size images for the purpose of not having a fixed size vector seems artificial and unnecessary - in this case here specifically the images are same size to begin with. By using SAN you loose a lot of the understanding of computer vision research of the last decade (e.g. it's clear that CNNs are a good idea - with SAN - you cannot really do that anymore) - so, I feel this experiment here doesn't add anything. \n\nI feel these comments can probably be addressed by rethinking the experimental evaluation. At this point, I think the paper provides a nice idea with a theoretical analysis - but it doesn't provide enough experimental evidence that this works. \n\nMinor comments: \n - p1: Analogically -> just drop the word\n- p1: citation of Brin & Page -> this seems a bit out of place - yes, it is a method working on graphs, but it is not relevant in the context of the paper - to the best of my knowledge there are no neural networks in this. \n- p2: where Radon - >where the Radon\n- p2: \"One can easily see \" -> I cannot. Please ellaborate", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}