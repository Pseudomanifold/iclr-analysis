{"title": "Good paper, writing and comparison need to be improved", "review": "The paper introduces a new loss function for training a deep neural network which can abstain.\nThe paper was easy to read, and they had thorough experiments and looked at their model performance in different angles (in existence of structured noise, in existence of unstructured noise and open world detection).  However, I think this paper has some issues which are listed below:\n\n\n1)  Although there are very few works regarding abstaining in DNN, I would like to see what the paper offers that is not addressed by the existing literature. Right now, in the experiment, there is no comparison to the previous work, and in the introduction, the difference is not clear. I think having an extra related work section regarding comparison would be useful.\n\n2) The experiment section was thorough, and the authors look at the performance of DAC at different angles; however, as far as I understand one of the significant contributions of the paper is to define abstain class during training instead of post-processing (e.g., abstaining on all examples where the network has low confidence). Therefore, I would like to see a better comparison to a network that has soft-max score cut-off rather than plain DNN. In figure 1-d the comparison is not clear since you did not report the coverage. I think it would be great if you can compare either with related work or tune a softmax-score on a validation set and then compare with your method. \n\n3) There are some typos, misuse of \\citet instead of \\citep spacing between parenthesis; especially in figures, texts overlap, the spacing is not correct, some figures don\u2019t have a caption, etc.\n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}