{"title": "Interesting analysis, but not surprising results", "review": "The authors challenge the CNNs robustness to label noise, but when the label noise is class dependent, more realistic scenario than class independent noise. \nTo analyse the CNNs behavior in such a scenario, they consider the ImageNet 1k dataset, and change some labels to labels that are close according to the ImageNet 1k tree of WordNet. \nThe authors conduct multiple experiment to compare the effect of class dependent and class independent noise on:\n* the model accuracy\n* the robustness to adversarial perturbation \n* the learned representation\n\nThe paper is generally well written and well structured. The analysis is sound and addresses interesting points, giving insightful results. Nevertheless, the overall conclusion is not very surprising. This work  confirms the commonly admitted fact that CNNs learn features that are visually meaningful.   Moreover, there is no significant novelty in the paper. The paper only analyses the CNNs behavior, without suggesting any new algorithm based on the observations. One specific point that seems under-investigated in my sense is the observation about the robustness to adversarial perturbations. The model with the class dependent noisy labels is in average less sensitive to the perturbations, even if this is not significant for the tested noise level. Did the authors test with different noise levels? This calls for a further analysis. It has the potential to give more insights, and probably inspire new methods to improve training robustness.    ", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}