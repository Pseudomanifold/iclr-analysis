{"title": "This paper builds on top introspective learning to bridge the gap between training and test set distributions. Overall, it is an interesting paper showing significant better performance results with and without existing data augmentation.", "review": "This paper proposes to combine the generative capabilities of introspection networks with geometric transformations in order to augment the dataset for training image based classifiers.  The paper is well written and shows promising results on standard datasets, (albeit the SVHN and cifar-10 results are not near STOA).\n\n- There are a few areas where the writing could be more clear: \\omega_t is introduced right after equation 5, but it is unclear what is that parameter. Is it the parameter of a separate f_t(x;\\omega_t) function used to generate the pseudo-negative examples?  Equation 5 is also confusion with f_t conditioned on both \\theta_t and \\omega_t.\n\n- How does the data-argumentation's parameter range compare to the learned \\sigma and g(.), does g(.) learn significantly different/bigger transformations?\n\n- Regarding computation time, how long does it takes to generate the augmented data set using the proposed method? Do you have to keep a series of f_t in-order to transform the pseudo-negative points (equation 12)?\n\n\n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}