{"title": "Unsatisfactory results on a very important topic", "review": "This work aims at addressing the generative model evaluation problem by introducing a new benchmark evaluation suite which hosts a large array of distributions capturing different properties. The authors evaluated different generative models including VAE and various variants of the GANs on the benchmark, but the current presentation leaves the details in the dark.\n\nThe proposed benchmark and the accompanied metrics should provide additional insights about those generative models that are not well known and help drive improvement to model design, similar to [1] and [2]. But the presentation of the work, especially the experiment section, only gives abundant number of results without detailed explanation regarding the pros and cons of the existing models, the efficacy of the proposed metrics, or the reason behind some nice generative properties of GANs that are not able to learn the distribution well.\n\nOther issues:\n- In Section 1, the authors argued that \"we deliberately avoid convolutional networks on images with the aim of decoupling the benefits of various modeling paradigms from domain specific neural architectures\". Then in footnote 4, they mentioned that \"constructed by hand neural generators that well approximate these distributions\" which suggests the importance of the domain specific neural architectures. It would be nicer to see how much the \"specific\" neural architectures help and how different metrics favor different architectures.\n- The authors only used 10K training points and 1K test samples, which seems small especially for multivariate distributions. This could have impacts on the quality of the learned models, especially the neural ones.\n\n[1] M. Zaheer, C.-L. Li, B. Poczos, and R. Salakhutdinov. GAN connoisseur: can GANs learn simple 1D parametric distributions? NIPS Workshop on Deep Learning: Bridging Theory and Practice 2017.\n[2] S. Arora, and Y. Zhang. Do GANs actually learn the distributions? An empirical study. arXiv:1706.08224.\n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}