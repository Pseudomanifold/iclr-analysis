{"title": "Nice idea, nice results, but paper needs work.", "review": "This paper proposed an imitation learning algorithm that achieves competitive results with GAIL, while requiring significantly fewer interactions with the environment.\n\nI like the method proposed in this paper. It seems similar to ideas in this concurrent submission: https://openreview.net/forum?id=B1excoAqKQ\n\nHowever, the paper is a bit difficult to read. The proposed method is made up of several changes compared to the baselines (e.g. using Q-learning without IRL instead of IRL, using off-policy learning, using conditioning to obtain a stochastic policy) but motivation for each component is presented late within the paper. The terminology used to describe these components is a bit confusing. Also some math is presented without intuitive descriptions.\n\nI\u2019d like to see more ablations performed: there are three main changes compared to GAIL, but an ablation is only performed for the stochastic policy. It would be interesting to tease out what is more important, off-policy learning, or bypassing IRL.", "rating": "7: Good paper, accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}