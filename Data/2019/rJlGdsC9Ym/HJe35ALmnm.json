{"title": "Limited experiments, limited justifications, requires additional knowledge", "review": "[The acknowledgment section might be violating the blind review.]\n\nThis paper claims to simplify and improve recently proposed automatic curriculum learning methods. Their experiments in section 4 are very limited to a single setup and most of the simplifications are not well-justified by any new results. Their proposed algorithm in section 5 assumes the presence of addition ordering information about tasks which needs a more thorough comparison to other related works.\n\nSection 4 introduces some simplifications. They \u201crecommend\u201d a few choices by referencing the figures in [2], essentially reiterating the contributions of [2] and presenting no new results. Then they propose modifications to \\eps-greedy with window algorithm of [1] by presenting results on one task. They propose to remove the moving average and essentially reintroducing the naive algorithm of [2].\n\nSection 5 proposes a new algorithm that relies on a additional knowledge of ordering of tasks. It based on a measure called \u201cmastering rate\u201d for a task that it is converted to an \u201cattention\u201d value by incorporating the ordering information. Attention values are propagated in one extra step.\n\nPositives:\nMR algorithm might be good but no compelling experiments are presented.\n\nNegatives:\n- The experiments are limited to one set of tasks introduced by this work. It is not clear if it is a good benchmark for automated curriculum learning. Section 4 does not compare to any method that does not perform any automated curriculum learning.\n- Fig. 6 and 7, the main figures of this paper, show that the baseline gets almost zero reward in most of the experiments. Basically, they are beating a weak baseline without explaining why it has failed. Maybe other algorithms in the previous work would work better in this setting.\n- There is a mistake in analyzing the algorithm of [1]. [1] does not exactly fit in Teacher-Student framework because they use Exp3.S policy that combines Boltzmann exploration with an \\eps-greedy strategy. They also have a hyperparameter \\eta that acts as the temperature of the softmax.\n- There is no ablation study on the importance and effect of each of the last 2 steps of the MR algorithm (Eq. 1, 2, 3). Does one need the ordering?\n- Works such as [3] are also related because of the use of additional ordering information.\n\n\n[1] Graves et al\n[2] Matiisen et al\n[3] Pentina, Anastasia, Viktoriia Sharmanska, and Christoph H. Lampert. \"Curriculum learning of multiple tasks.\" Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2015.", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}