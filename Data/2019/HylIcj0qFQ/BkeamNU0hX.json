{"title": " Interesting results that are well presented, but reads like a lab report with minimal background research, and lacks novelty or significant experimental insight", "review": "Missing references about VC dimension /shattering, Rademacher complexity, etc.\n\nI would like to see more discussion and motivation of using MI to measure capacity (of NNs, or in other contexts). I am not an expert in this area, so I do not know what the appropriate references would be, but only one reference about MI is cited. The paragraph under eqn (1) is helpful, but the relationship between classification accuracy and MI still seems unclear to me.\n\nI also find it is not clear exactly what the MI is measured between - this should be made clearer in the main text, and also in appendix B. Xi and f(theta, Xi) are defined, but nothing else is. It is fairly easy for someone familiar with the notation to guess what the variables refer to, but this should be explicitly stated to avoid confusion and ambiguity. What exactly is Y? The output of the softmax?\n\nAside from the lack of clarity about notation/what symbols represent, I have two main issues with appendix B.\nFirst is the claim \"Note that X and Y are independent as well as Yi and Yj when i neq j\"; I think it should be made clearer that X and Y are independent only in this setting because the experiments are with random data, and it does not seem obvious to me that Yi and Yj are independent. \nSecond, using average accuracy as the probability that the class is the true class seems strange to me for random data. Maybe it's fine and I just haven't wrapped my head around it, or I misunderstood something, but I would like to understand why it makes sense to do this.\n\nIs it standard not to quantize bias values? why does having a large dynamic range mean they shouldn't be quantized?\n\nI find section 3 not very clear. I understand why the loss under perturbation is interesting, but this should be discussed along with what are the results of your experiments. The procedure for doing this should also be cited, unless you came up with it on your own in which case the justification for it should be further discussed.\nI assume you don't do this, but the way the section is worded makes it sound like you train networks with a noisy loss.\n\nIt would be interesting to investigate the claims about parameter-sharing in CNNs (and RNNs) increasing their capacity as measured by MI; e.g. plot MI vs. #times filter is used for different convnet configurations, and #timesteps for RNNs.\n\nQuality: 6/10 The writing is mostly clear to follow, although paragraphs don't always flow well into each other and some sections assume a lot of knowledge. \nClarity: 7/10 Results are clearly presented, although more intuition and context would be helpful, and some sections are not well explained or contextualized\nOriginality: 2/10 The methods are not novel, to my knowledge, and there is little exploration or insight given for the extensive experimental results\nSignificance: 7/10 measuring and reporting results is valuable, and the reported results are interesting\n\nPros:\n - interesting results, good plots\n - overall well structured and explained\n\nCons:\n - plots could use more explanation and interpretation in the captions, and more investigation and insight from the experiments\n - some sections are not clearly worded and I think the objective/interpretation of the experiments would not be clear to someone even a little unfamiliar with the approaches cited\n\n\nSpecific comments/nits (in order reading through paper):\n1. First paragraph of intro is kind of fluff/unnecessary. I would suggest beginning with the 3rd paragraph and work in the second.\n2. It is usually advised in scientific writing not to use phrases like \"it is known\". \"It has been shown by [refs]\" would be better.\n3. \"in the over-parameter region\" -> overparameterized\n4. \"real-models\" -> real models (although this seems like a bit of an odd thing to say to me. What are fake models?? maybe \"empirical study\" would be better)\n5. \"Related work and backgrounds\" remove s\n6. \"capacity ... is related to the learnability of networks\" I don't think this makes it more clear; it just brings up the question about what you mean by learnabilty. Maybe \"how much a network can learn to capture about a dataset\" or something like that. \n7. \"is shown as\" odd phrasing, maybe \"is defined as?\n8. \"classification task (Collins et al)\" -> \"classiification task, as in Collins et al\"\n9. mention what scikit learn uses for hyperparameter tuning / why you use this\n10. Figure 1 would benefit from a bit more explanation in the caption (e.g. memorization performance on/of what; explain what the acronyms mean and what the results tell us)\n11. Some of the hyperparameter specifications here could be put in an appendix if you need space. Some of this information is also not specific to FCDNNs and should go in the preamble before the subsections for each architecture\n12. Figure 2: Why does accuracy go to 1.4? Like Figure 1, caption would benefit from more information and some interpretation. Why do you think the MI levels off/goes up on the right hand side of A?\n13. References about capacity here at the end of 4.1 should go in the background and related work section\n14. \"Result is consistent with theoretical study\" In what ways? How consistent is it? What does the theory say?\n15. Mention if you use truncated bptt in the RNN experiments\n16. Mention what it means for \"all models use full capacity\"\n17. VLSI mentioned without definition\n18. \"RNNs have the tendency of demanding more bits when compared to FCDNNs\" I find this sentence unclear\n19. \"conducting memorization tasks, rather than inferencing with unseen data\" -> saying \"generalization tasks\" would be more accurate; maybe this is being too picky but they can inference with unseen data just fine wihtout requiring more parameter precision; it's only if we care about the generalization performance that they require more parameter precision.", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}