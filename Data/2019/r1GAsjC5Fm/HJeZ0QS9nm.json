{"title": "Good idea, unclear results", "review": "This submission introduces a new method for vision+language navigation which tracks progress on the instruction using a progress monitor and a visual-textual co-grounding module. The method is shown to perform well on a standard benchmark. Ablation tests indicate the importance of each component of the model. Qualitative examples show that the proposed method attends to different parts of the instruction as the agent moves. \n\nHere are some comments/questions:\n- I like the underlying idea behind the method. The manuscript is written well for most parts.\n- The qualitative examples and Figure 2 are really helpful in understanding the reasons behind the improved performance.\n- There is a lot of confusion regarding the use of beam search. It's unclear from the current manuscript which results are with and without beam search. It seems like beam search was added from Ours 1 to Ours 2 in Table 2. It's not clear which rows involve beam search in Table 1. Some concerns about beam width were raised in the comments which I agree with. Please modify the submission to clearly indicate the use of beam search for each result and specify the beam width.\n- The use of beam search seems unrealistic to me as I can not think of any way a navigational model using beam search can be transferred or applied to real-world. I understand that one of the baselines uses beam search, so it's fair for performance comparison purposes, but could you provide any justification of how it might be useful in real-world? If there's no reasonable justification, could you also provide all the results (along with SPL metric) without beam search, including ablation, comparing with only methods without beam search? \n- I do not understand why the OSR in the submission is 0.64 and 0.70 for Speaker-Follower and proposed method and 0.96 and 0.97 in the comments.\n- It seems like the proposed method is tailored for the VLN task. In many real-world scenarios, an agent might be given an instruction which only describes the goal (such as in Chaplot et al. 2017 and Hermann et al. 2017) and not the path to the goal, could the authors provide their thoughts on whether the proposed would work well for such instructions? What would the progress monitor and textual attention distribution learn in such a scenario?\n\nDue to confusion about results and concerns about beam search, I give a rating of 5. I am willing to increase the rating if the authors address the above concerns.", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}