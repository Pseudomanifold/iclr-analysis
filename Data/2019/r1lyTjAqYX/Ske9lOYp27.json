{"title": "Rrecurrent NNs in distributted RL settings as a clear improvement of the feed-forward NN variations in partially observed environments", "review": "This paper investigates the use of recurrent NNs in distributted RL settings as a clear improvement of the feed-forward NN variations in partially observed environments. The authors present \"R2DR\" algorithm as a A+B approach from previous works (actually, R2D2 is an Ape-X-like agent using LTSM), as well as an empirical study of a number of ways for training RNN from replay in terms of the effects of parameter lag (and potential alleviating actions) and sample-afficiency. The results presented show impressive performance in Atari-57 and DMLab-30 benchmarks.\n\nIn summary, this is a very nice paper in which the authors attack a challenging task and empirically confirm that RNN agents generalise far better when scaling up through parallelisation and distributed training allows them to benefit from huge experience. The results obtained in ALE and DMLab improves significantly upon the SOTA works, showing that the trend-line in those benchmarks seem to have been broken. \n\nFurthermore, the paper presents their approach/analyses in a well-structured manner and sufficient clarity to retrace the essential contribution. The background and results are well-contextualised with relevant related work. \n\nMy only major comments are that I\u2019m a bit skeptical about the lack of a more thorough (theoretical) analysis supporting their empirical findings (what gives me food for thought is that LSTM helps that much on even fully observable games such as Ms. Pacman); and the usual caveats regarding evaluation: evaluation conditions aren't well standardized so the different systems (Ape-X, IMPALA, Reactor, Rainbow, AC3 Gorilla, C51, etc.) aren't all comparable. These sort of papers would benefit from a more formal/comprehensive evaluation by means of an explicit enumeration of all the dimensions relevant for their analysis: the data, the knowledge, the software, the hardware, manipulation, computation and, of course, performance, etc. However only some of then are (partially) provided.   \n\n", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}