{"title": "Novel idea, but requires more work.", "review": "This paper presents Generative Adversarial Tree Search (GATS) that simulates trajectories for the Monte-Carlo Tree Search up to a certain depth. The GATS functions as a model that can simulate the dynamics of the system and predict rewards, effectively removing the need for a real simulator in the MCTS search.\n\nThey prove some favourable theoretical properties regarding the bias variance trade-off.  Specifically, they propose the model based model free trade-off which illustrates the trade-off between selecting longer rollouts, which increases the upper performance bound, and getting a more accurate Q estimate, which decreases the upper performance bound.\n\nThey also propose a pseudo count exploration bonus based on the inverse Wasserstein metric as the exploration strategy for GATS.\n \nThey observe that when tree-search rollouts are short, GATS fails to outperform DQN on 4 different games.\n\nQuality:\nIt is unclear to me how you arrive at the result in Equation (9) of Appendix D. You have assumed in the second equation that the optimal action max_a Q(s,a) and max_a \\hat{Q}(s,a) are the same action a. How do you arrive at this conclusion? Since \\hat{Q} is an approximation of Q, why would the action a be the same?\n\nClarity:\nThe paper is fairly well written. There are many grammatical mistakes, but the overall message is more or less conveyed.\n\nOriginality:\nIt is original in the sense that a generative adversarial network is used as the model for doing the tree search. It is disappointing that this model does not yield better performance than the baseline and the theoretical results are questionable. I would like the authors to specifically address the theory in the rebuttal. \n\nSignificance:\n\nWhile I appreciate negative results and there should be more papers like this,  I do think that this paper falls short in a couple of areas that I think the authors need to address. (1) As mentioned in quality, it is unclear to me that the theoretical derivation is correct. (2) The exploration bonus based on the inverse Wasserstein metric would add much value to the paper if it had an accompanying regret analysis (similar to UCB, for example, but adapted to the sequential MDP setting). \n\nIt appears in your transfer experiments that you do indeed train the GDM faster to adapt to the model dynamics, but it doesn\u2019t appear to help your GATS algorithm actually converge to a good level of performance. Perhaps this paper should be re-written as a paper that focuses specifically on learning models that can easily transfer between domains with low sample complexity?\n\nFor the exploration bonus: If the authors added a regret analysis of the exploration count and can derive a bound of the number of times a sub-optimal action is chosen, then this could definitely strengthen the paper. This analysis could provide theoretical grounding and understanding for why their new exploration account makes sense, rather than basing it on empirical findings.", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}