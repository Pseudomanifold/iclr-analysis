{"title": "dense SfM with Deep Learning", "review": "edit: the authors added several experiments (better evaluation of the predicted lambda, comparison with CodeSLAM), which address my concerns. I think the paper is much more convincing now. I am happy to increase my rating to clear accept.\n\nI also agree with the introduction of the Chi vector, and with the use of the term of \"photometric BA\", since it was used before, even if it is unfortunate in my opinion. I thank the authors to replace reprojection by alignment, which is much clearer.\n\n---------------\n\n\nThis paper presents a method for dense Structure-from-Motion using Deep Learning:\nThe input is a set of images; the output is the camera poses and the depth maps for all the images.\nThe approach is inspired by Levenberg-Marquardt optimization (LM): A pipeline extracting image features computes the Jacobian of an error function. This Jacobian is used to update an estimate of the camera poses. As in LM optimization, this update is done based on a factor lambda, weighting a gradient descent step and a Gauss-Newton step. In LM optimization, this lambda evolves with the improvement of the estimate. Here lambda is also predicted using a network based on the feature difference.\n\nIf I understand correctly, what is learned is how to compute image features that provide good updates, how to predict the depth maps from the features, and how to predict lambda.\n\nThe method is compared against DeMoN and other baselines with good results.\n\nI like the fact that the method is based on LM optimization, which is the standard method in 'geometric bundle adjustment', while related works consider Gauss-Newton-like optimization steps. The key was to include a network to predict lambda as well.\n\nHowever, I have several concerns:\n\n* the ablation study designed to compare with a Gauss-Newton-like approach does not seem correct. The image features learned with the proposed method are re-used in an approach using a fixed lambda. If I understand correctly, there are 2 things wrong with that:\n- for GN optimization, lambda should be set to 0 - not a constant value. Several constant values should also have been tried.\n- the image features should be re-trained for the GN framework:  Since the features are learned for the LM iteration, they are adapted to the use of the predicted lambda, but they are not necessarily suitable to GN optimization.\nThus, the advantage of using a LM optimization scheme is not very convincing.\n\nSince the LM-like approach is the main contribution, and the reported experiments do not show an advantage over GN-like approaches (already taken by previous work), this is my main reason for proposing rejection.\n\n* CodeSLAM (best paper at CVPR'18) is referenced but there is no comparison with it, while a comparison on the EuRoC dataset should be possible.\n\nLess critical concerns that still should be taken into account if the paper is accepted:\n\n- the state vector Chi is not defined for the proposed method, only for the standard bundle adjustment approach. If I understand correctly is made of the camera poses.\n\n- the name 'Bundle Adjustment' is actually not adapted to the proposed method.  'Bundle Adjustment' in 'geometric computer vision' comes from the optimization of several rays to intersect at the same 3D point, which is done by minimizing the reprojection errors. Here the objective function is based on image feature differences. I thus find the name misleading. The end of Section 3 also encourages the reader to think that the proposed method is based on the reprojection error. The proposed method is more about dense alignment for multiple images.\n\n\nMore minor points:\n\n1st paragraph:  Marquet -> Marquardt\ntitle of Section 3: revisitED\n1st paragraph of Section 3: audience -> reader\ncaption of Fig 1: extractS\nEq (2) cannot have Delta Chi on the two sides. Typically, the left side should be \\hat{\\Delta \\Chi}\nbefore Eq (3): the 'photometric ..' -> a 'photometric ..'\n1st paragraph of Section 4.3: difficulties -> reason\ntypo in absolute in caption of Fig 4\nEq (6): Is B the same for all scenes?  It would be interesting to visualize it.\nSection 4.5: applies -> apply\n", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}