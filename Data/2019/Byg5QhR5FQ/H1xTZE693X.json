{"title": "Simple interesting neural-net model of logical formulae", "review": "In this paper, the authors provide a new neural-net model of logical formulae. The key feature of the model is that it gathers information about a given formula by traversing its parse tree top-down. One neural net of the model traverses the parse tree of the formula from the root all the down toward the leaves, and generates vectors for the leaves of the tree. Then, another RNN-based neural net collects these generated vectors, and answers a query asked for the formula, such as logical entailment. When experimented with Evans et al.'s data set for logical entailment queries, the authors' model outperforms existing models that encode formulae by traversing their parse trees bottom-up.\n\nI found the idea of traversing a parse tree of a formula top-down and converting it to a vector very interesting. It is also good to know that the idea leads to a competitive model for at least one dataset. \n\nHowever, I am hesitant to be a strong supporter for this paper. I feel that the cons and pros of the model and its design decisions are not fully analyzed or explained in the paper; when reading this paper, I wanted to learn a rule of thumb for deciding when (and why if so) a top-down model of logical formulae works better than a bottom-up model. I understand that what I ask for is very difficult to answer, but experiments with more datasets and different types of queries (such as satisfiability) might have made me happier.\n\nHere are some minor comments.\n\n* Abstract: I couldn't quite understand your point about atoms. According to Figure 1, there is a neural net for each propositional symbol, and this means that your model tracks information about which occurrences of propositional symbols are about the same one. Is your point about the insensitivity of your model to a specific name given to each symbol? \n\n* p1: this future ===> this feature\n\n* p2: these constrains ===> these constraints\n\n* p2: recursively build model ===> recursively built model\n\n* p2: Change the font of R in the codomain of ci.\n\n* p3: p1 at the position of ===> p1 is at the position of\n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}