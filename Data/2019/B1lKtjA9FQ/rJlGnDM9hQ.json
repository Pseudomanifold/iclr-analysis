{"title": "Not convincing enough.", "review": "This paper proposed criteria to measure the capacity of a neural network by injecting perturbation (randomized training data). The paper attempted to show that $l_1$-regularization of the kernel weights is a good measure to control the capacity of a network which contradicts the previous finding by Zhang et al (2017) on regularization which claimed that regularization is neither necessary nor by itself sufficient for controlling generalization error.\n \n\nThe proposed method does not require a held out data to check overfitting, which is an interesting direction to explore. The theoretical analysis is seeming to be correct, however, I don\u2019t have strong expertise in theory, therefore, can not assure the correctness.  The experiments, however, are limited. The experiment was done on cifar-10 and the analysis is based on the early stopping, regularization factor and network depth. \n\nThere is only one dataset that was used for the experiments, more dataset should be explored for robust evaluation. \n\nThe assumptions should be clarified and write clearly. For example, \u201cThus we also expect that accuracy drops if the regularization of the model is increased.\u201d, which accuracy (training?) and what exactly means by increased regularization (value of $\\lambda$)?\n\n", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}