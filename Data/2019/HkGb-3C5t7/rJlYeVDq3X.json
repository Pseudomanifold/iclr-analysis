{"title": "Strong results on benchmark tasks, but problems with clarity of presentation and limited insight about model effectiveness", "review": "The authors tackle the unsupervised domain adaptation problem by extending a previously proposed framework ADDA, as indicated in their title. The main contributions are 1) extending the adversarial discriminator in ADDA to be multiclass (distinguishing between K source classes and 1 \"non-source\" class), and 2) developing a new, MMD-based loss to optimize a representation against the multiclass discriminator. They demonstrate strong adaptation results on a number of standard benchmark visual domain adaptation tasks, indicating that their model is an effective improvement over existing methods.\n\nThe presentation of the method section is a bit confusing or sloppy sometimes. A few examples: near the bottom of page 3 the authors refer to $\\theta_t$, though my understanding is that this should be $\\theta_b$; just before Eq. 3, there is an $h_s$ that should be $h_b$; Eq. 3 needs a $k$ subscript on the log term as well. I also am curious if the authors have an explanation for why, in Eq. 2, one set of logits are divided by the temperature, while the other set remains unmodified\u2014doesn't this mean that the discriminator $D$ is not actually an autoencoder on the source logits, as claimed?\n\nAdditionally, the authors have simultaneously proposed a number of extensions to ADDA, but have not made it clear exactly where their improvements come from. There are a number of alternative instantiations of a similar idea that seem reasonable, and from reading the paper it isn't immediately clear why the authors settled on this particular combination of methods. For example, instead of the MMD-based adversarial objective, it would have been good to see a comparison against an objective similar to that of semi-supervised GANs, i.e. train the shared encoder to maximize the sum of the first K discriminator probabilities. This seems like the most straight-forward multiclass extension to ADDA, and an exploration of how it improves over base ADDA and falls short of the proposed method would provide further intuition.\n\nThere are also a fair number of hyperparameters\u2014in addition to the standard fare, there is also the temperature parameter $T$, the kernel bandwidths $\\sigma_r$, and the dropout parameter $z$. It appears that the authors have optimized these via a hyperparameter search. However, a discussion of how sensitive the model is to these parameters is crucial, since in a truly unsupervised adaptation setting, it isn't possible to hyperparameter tune (no labeled data to evaluate performance with)!\n\nAlthough the authors have demonstrated that their method is effective on standard domain adaptation tasks, the presentation of the method is a bit unclear in a number of ways, and analysis of the components of the proposed method is limited (only one baseline instantiation is explored, as opposed to a more thorough ablation), making it hard to gain a lot of insight from the proposed method.", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}