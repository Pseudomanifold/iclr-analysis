{"title": "An empirical evaluation of a specific genetic algorithm, but without much value add", "review": "This paper looks at a specific implementation of a \"genetic algorithm\" (GA) when applied to learning Atari games.\nUsing a black-box \"random search\" technique, with a few heuristic adaptations, they find performance that is roughly competitive with several other baseline methods for \"Deep RL\".\nMore generally, the authors suggests that we should revisit \"old\" algorithms in Machine Learning and that, when we couple them with larger amounts of computation, their performance may be good.\n\nThere are several things to like about this paper:\n- The authors place a high importance on implementation details + promise to share code. This seems to be a paper that is heavily grounded in the engineering, and I have high confidence the results can be reproduced.\n- The algorithm appears broadly competitive on several Atari games (although Table 1 is admittedly hard to parse).\n- The algorithm is generally simple, and it's good to raise questions of baseline / what are we really accomplishing.\n\nHowever, there are several places where this paper falls down:\n- The writing/introduction is extremely loose... terms are used and introduced without proper definition for many pages. \n    + How would be think about the venn diagram of \"evolutionary strategies\", \"genetic algorithms\", \"deep Q networks\", \"deep RL algorithms\" and \"random search\"... there is clearly a lot of overlap here.\n    + The proposed deep GA has a \"deep Q network\" (or is it a policy... the paper does not make this clear), forms a type of \"evolutionary strategy\" and, at its heart is a type of \"random search\", but is it not also a \"deep RL algorithm\"?\n    + It is not until page 3 that we get a proper definition of the algorithm, and it's hard to keep track of the differences the authors want to highlight compared to the \"baselines\".\n    + What do we gain from the claim \"old algorithms work well\"... gradient descent is also an old algorithm, as are seemingly all of the alternatives? Is age in-of-itself an asset?\n    + Statements like \"compression rate depends on the number of generations, but in practice is always substantial\" are very loose... what does the \"practice\" refer to here, and why?\n\n- There is very little insight/analysis into *how* or *why* this algorithm performs better/worse than the alternatives. I don't feel I understand if/when I should use this algorithm versus another apart from a wall of seemingly random Atari results. In fact, there is a large literature that explains why GAs give up a lot of efficiency due to their \"black box\" nature... what do the authors think of this?\n\n- This paper seems purely focused on results rather than insight, with many hacks/tweaks to get good results... should we believe that GA+novelty search is a general algorithm for AI, or is it just another tool in the arsenal of a research engineer? \n    + In the end, the algorithm doesn't actually seem to outperform state-of-the-art on these Atari baselines... so what are we supposed to take away from this.\n\nOverall, I don't think that this paper provides very much in the way of scientific insight.\nFurther, the results are not even superior to existing algorithms with stronger groundings.\nFor me, this leads it to be a clear reject... even though they probably have code that reliably solved Atari games in a few hours.", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}