{"title": "Interesting exploration, but lacks needed rigor.", "review": "This paper demonstrates that Genetic Algorithms can be used to train deep neural policies for Atari, locomotion, and an image-based maze task. It's interesting that GAs can operate in the very high-dimensional parameter space of DNNs. Results show that on the set of Atari games, GAs perform roughly as well as other ES/DeepRL algorithms.\n\nIn general, it's a bit hard to tell what the contribution of this paper is - as an emperical study of GA's applied to RL problems, the results raise questions:\n\n1) Why only 13 Atari games? Since the algorithm only takes 1-4 hours to run it should only take a few days to collect results on all 57 games?\n\n2) Why not examine a standard GA which includes the crossover operator? Do the results change with crossover?\n\n3) The authors miss relevant related work such as \"A Neuroevolution Approach to General Atari Game Playing\" by Hausknecht et al., which examines how neuroevolution (GA based optimization which modifies network topology in addition to parameters) can be used to learn policies for Atari, also scaling to million-parameter networks. This work already showed that GA-based optimization is highly applicable to Atari games.\n\n4) Is there actual neuroevolution going on? The title seems to imply there so, but from my reading of the paper - it seems to be a straightforward GA (minus crossover) being applied to weight values without changes to network topology.\n\nI think this paper could be strengthened by providing more insight into 1) Given that it's already been shown that random search can be competitive to RL in several Mujoco tasks (see \"Simple random search provides a competitive approach to reinforcement learning\") I think it's important to understand why and in what scenarios GAs are preferable to RL and to ES given similar performance between the various methods. 2) Analysis as to whether Atari games in particular are amenable to gradient-free optimization or if GA's are equally applicable to the full range or RL environments?\n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}