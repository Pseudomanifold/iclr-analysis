{"title": "Hard to evaluate the experimental results.", "review": "The paper addresses both zero-shot and few-shot learning in a unified framework. The key idea is to separate the deep network model into two networks. The first, aimed at learning a feature representation, is trained using standard multi-class but using cosine instead of dot product . The second, is trained using episode-based meta learning. \nThe paper suggests that by training the features in a standard way, the representation is more rich and provides better space for learning the ZS and FS classes. \n\nThe idea is very reasonable, and the experimental evaluations show  large improvement over existing baselines. \n\nMy main concern is that evaluating ZSL and FSL, is often tricky, and one should be careful about the details such that no information is leaked to the unseen classes. The paper is written in a way that makes it hard to evaluate if all the experiments were done in a proper way. Some of gains claimed, like the accuracy improvement for GZSL are very large, reporting by +70% or even +150%(aPY). Sometimes this is a sign that the evaluations are not done in the same way as the baselines, or other issues. More careful analysis is expected to convince that the gains are due to the proposed method. \n\nI would have liked to see (1) more detailed analysis of why the approach works (2) Ablation experiments and more convincing evidence that the improvement is indeed due to the way the representation is trained. (3) Evidence that the feature representation is better. (4) more details about the evaluation procedure. \n\nFor example these can include  (1) repeat the experiments with the same setup, but with a feature representation learned in an episodic way. (2) Evaluate the quality of the representation on another task (3) For the GZSL experiments,  report separately the accuracy on seen and unseen classes. (4) qualitative analysis linking wins and losses to changes in the representation. (5) tuning the size of episodic training to support the claim that small episodes lead to worse representation. \n\nOther comments: \nSome more recent baselines are not included,  e.g. better performance on CUB (57.8%) was reported by \nAtzmon et al, Probabilitis AND-OR Attribute Grouping for Zero-Shot Learning, UAI 2018.  Other improvement by \nZhang and Koniusz. Zero-shot kernel learning. CVPR, 2018.\n\n\nMinor comments :\n-- clarify which classes were used in train, validation, test\n-- Eq 6: L is defined as a function of phi. not used. \n\n\n\n", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}