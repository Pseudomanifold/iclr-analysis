{"title": "Interesting, but there are some unclear issues", "review": "It is well known that optimizing divergences of different directions leads to different learning behaviors - the mode covering behavior of maximum likelihood training and the mode missing behavior of GAN training. This paper makes a good presentation in explaining coverage-driven training and quality-driven training. \nTechinically, this paper make two contributions. First, extend VAEs by using deterministic invertible transformation layers to map samples from the decoder to the image space. Second, use the loss Eq. (8) to train the generator.\n\nHowever, there are some unclear issues.\n\nFirst, the differences between losses may not fully explain the behavior of GANs [I. J. Goodfellow. NIPS 2016 tutorial: Generative adversarial networks. arXiv:1701.00160, 2017], as also seen from some recent studies. For example, using the sum of two divergences [Chen et al., 2018] does not make a significant improvement. \nAlso shown in Table 1, CQ performs better than VAE, but is inferior to GAN.\nUsing the two-term loss Eq. (8) may not be the key for improvement.\n\nOnly after adding the additional flow-based layers, CQF outperforms GAN. Therefore, in Table 1, it would be better to include the result of VAE using the additional flow-based layes for ablation study. \n\nSecond, it is also not clear from the paper that such VAE using the additional flow-based layes is new or not.\n\nThird, the results are not as good as the state-of-the-art. In Table 4, SN-GANs perform the best in three out of four cases.\n\nFourth, the model consists of three networks - encoder, decoder and discriminator. Evaluation about the model's inference capability is necessary in addition to showing its generation capability, since it is equipped with a decoder.\n\nSome typos:\nP5: L_Q(p*)+L_Q(p*) ?\nTable 4: QSF ?", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}