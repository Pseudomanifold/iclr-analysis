{"title": "Potentially Interesting Method but the Paper Needs Polishing", "review": "The paper presents a new Generative Adversarial Network (GAN) for learning a  \ntarget distribution that is defined as the difference between two other \ndistributions. Applications in semi-supervised learning and adversarial training \nare considered in the experimental evaluation and results are presented in \ncomputer vision tasks. \n\nThe paper is not very well written and can be hard to follow. One very important \nissue for me was motivation for defining the target distribution as a difference \nbetween two other distributions. I am not familiar with this area, but reading \nthrough the introduction it was never clear to me why this is a useful scenario, \nin practice. Furthermore, some statements in the introduction felt quite \narbitrary. For example, the authors state that PixelCNN \"does not have a latent \nrepresentation\" in a manner that makes it sound as if that is a bad thing. If \nindeed it is, then why so? It would be very helpful to motivate the setting more \nand to provide a couple of examples of where this method would be useful, in the \nintroduction. Also, regarding the MNIST example in the end of page 1, what is \nthe \"universal set\"? This paragraph also felt a bit arbitrary and unclear.\n\nSome comments about the rest of the paper:\n  - The theoretical results of section 3 are just stated/listed, but are not \n    connected to algorithm 1. Please connect them to the different parts of the \n    algorithm and state in a couple sentences what they imply for the algorithm.\n  - Right after theorem 1, which assumption are you referring to when you say \n    \"the assumption in Theorem 1\"?\n  - The reformulation of section 3.1 is never justified. What led you to use \n    this reformulation and why do you think it is more stable in practice?\n  - You should mention in the caption of table 4, what quantity you are \n    computing.\n\nNote that my evaluation for this paper is based mainly on the way it is written \nas, in its current state, it is hard for me to judge what is novel and what is \nuseful, and what readers are supposed to take in by reading this paper. The main \nquestion that the paper definitely needs to answer, but does not do so currently \n(in my opinion) is:\n\n  When is this method useful to readers? For solving which problems and under \n  what conditions? And also, when is this method bad and should not be used?\n\n== Experiments ==\n\nSection 5.1 is hard to follow and I don't quite get how it connects to the rest.\n\nAlso, in section 5.1.2 you mention that in comparison to Dai et al. (2017) your \nmethod does not need to rely on an additional density estimation network. Even \nif that is true, I cannot see how it is a useful remark given that the method of \nDai et al. seems to always beat your method.\n\n== Style ==\n\nIn figure 1, no labels or legends are provided making it hard to figure out \nwhat's going on at a glance. It would be very helpful to include labels and a \nlegend.\n\nEquation 2 is not written correctly. The equals sign only refers to \"V(G, D)\" \nand not the min-max of that, right? Please make that explicit by first defining \n\"V(G, D)\" alone.", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}