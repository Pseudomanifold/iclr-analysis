{"title": "would like to see the authors spend more time in (a) core contribution and (b) fairer evals.", "review": "This work proposes to use 'non-deterministic oracles' during training seq2seq models for converting natural language queries to SQL counterparts. The authors show better performance on wikisql dataset to 87.1%.\n\n- The authors main contribution is section 4 which i found to be very superficially discussed. \n  (a) I would've liked to see more details on how the set \"O\" is constructed/implemented,\n  (b) How can set O detect some non-trivial invalid continuation actions like \"x >= 10 and x <= 5\", is this outside the scope ?\n  (c) the beam search decoding of correct sqls seems like it can be applied to any seq2seq model, I am not able to see the novelty of this.\n  \n- Evaluation\n  (a) The authors could've presented comparison with other work they cite, including (Zhong et al., 2017) and (Xu et al., 2017). The authors claims for not comparing - such as lowering optimization stability/increases training time does not look valid since the authors do not claim to have better optimization stability/lower training time.\n  (b) The author's trick of adding ANYCOL (and converting to disjunctions) increases the expressive power of the SQL, was this applied to other work as well ?\n  \n  \nFor acceptance, \n- the author's core contribution in defining the non-deterministic oracles, what are the constraints, what is in-scope vs out-of-scope needs to be clearly detailed.\n- the evaluation needs to be (a) better in comparing against more recent work, (b) more fair in including ANYCOL to other work and (c) have a separate metric that discusses how the new contribution of oracles helps lower inconsistent SQL output.\n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}