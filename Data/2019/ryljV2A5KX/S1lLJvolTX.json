{"title": "Elegant approach, well presented, more experimental validation of the core intuition would have been nice", "review": "This work addresses the problem of unsupervised disentangled representation learning, and leverages insights and intuitions about utilizing an information bottleneck (IB) approach to encourage disentangling. In particular, building upon insights of how beta-VAE can be understood (and improved upon) by understanding it in terms of IB, the authors propose to modify GANs to include an IB, so as to leverage similar disentangling benefits. The promise is that this approach could utilise the strengths of the GAN framework over VAEs, such as the often sharper reconstructions and the ease of including discrete latents in addition to continuous ones. \n\nTo implement their proposal in practice, the authors introduce a neat trick to control an upper bound for the additional mutual information term that the new approach -- termed IB-GAN -- requires. This adds just one layer of complexity to the GAN setup via adding a stochastic representation model between the latent representation and the generator, and has elegant limiting cases that recover both the standard GAN and the InfoGAN approach.\n\nThe paper is clearly presented and the intuitive arguments can be readily followed, even though the resulting loss formulation is a bit tricky to justify without expanding upon the underlying motivation. \n\nThe approach is tested on three standard datasets and two different metrics that have previously been used for benchmarking unsupervised disentangling, and the results look convincing enough to demonstrate the improvement over existing GAN approaches. \n\nStill, the experimental section is arguably the weakest part of the paper, as there are now stronger beta-VAE variants as baselines available, so I am taking the numbers for VAE-based methods in the quantitative assessment with a grain of salt. More importantly, though, as the motivation of the work is that introducing an information bottleneck is what creates the success in disentangling, it would have been nice to see this effect more clearly broken out in experiments directly demonstrating the effect of beta and gamma on the degree of disentanglement. \n\nOverall, though, this is an interesting contribution to the rapidly developing subfield of unsupervised disentangling, and I would expect the introduction of IB ideas into GAN setups to drive further advances in representation learning techniques. \n\n===\nUpdate: \nI am happy with the clarifications and the changes to the manuscript, and have increased my rating accordingly from 6 to 7. ", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}