{"title": "Somewhat incremental results and an important point why we can apply RL in this setup remains unclear", "review": "Summary:\nThis paper develops a novel method for predicting organic chemical reactions, in particular, final product prediction from given reactants. Organic molecules consist of covalent bonds, and hence organic reactions can be regarded as an alternating multistep series of bond breaking and bond forming (i.e. qualitative understanding as \"reaction mechanisms\" against quantum chemical calculations). The developed method aims to predict this series of bond changes through a form of reinforcement learning guided with neural networks. In this sense, the setup and formulation seem largely inherited from cited previous papers by Bradshaw et al, 2018 or Kayala & Baldi, 2011 (though they are not used any RL formulation). Organic compounds at each elementary step are represented as molecular graphs, and reactions are thus a series of graph transformations. Each bond change can be considered as \"action\" at that state to form the next states to head for the final product. The method itself seems quite natural: States transitions are shared by an RNN and the hidden states and observations (molecular graphs at each step, and bond changes as actions) are used to learn \"policy\" and \"state transition\" for RL via graph neural networks. Atom pairs to lead the bond change are detected from such graph embeddings and state observations through self-attentive architectures. In addition, masking by additional indicator variables is introduced to avoid redundant training as well as determine the termination of the reaction. Experimental evaluations on a standard large benchmark dataset of USPTO show improved prediction performance compared to previous methods of Jin et al, 2017 and Schwaller et al, 2018.\n\nComment:\n- Given that a chemical reaction can be regarded as a multi-step chain of bond breaking and forming, thus the method part seems a quite natural extension of the past effort but also sounds rather incremental even though the performance gain exists.\n\n- The method part is written clearly but the problem setup seems rather unclear. The most unclear point is how the environment for RL can give any reward to each bond change. How we can know each prediction of a bond change is correct or not? Can it be supervised? Does this mean that the training set of reactions has the correct perfect information of these multi-step bond changes?? How did you construct such curated dataset for USPTO? If this is the case, the motivation to go for RL would be more understandable but this part is not explained at all. (Because it is inherited from previous work of Bradshaw et al 2018 or something?? )\n\n- Why this proposed method has no limitation whereas the previous method by Bradshaw et al, 2018 are limited to \"linear chain topology\" (?). If this method is the direct competitor, what points are important to remove this limitation of the previous method should be clarified more clearly. This method is referred multiple times in the paper, but no direct explanations exist. \n\nPros:\n\t- Nice and solid design of proposed \"graph transformation policy network\"\n\t- Better prediction performance against previous methods\n\nCons:\n\t- Why this extension could break the previous limit (of ELECTRO?) remains unclear\n\t- The descriptions on the problem setup and the data are unclear. Perfectly curated as chemically correct multi-steps of bond changes are given as training set? How we can know each prediction of a bond change is correct or not?\n\t- the proposed architecture is nice but somewhat seems incremental. (heuristic combinations of existing techniques of RL and graph neural nets)\n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}