{"title": "Interesting paper that uses attention for set inputs but needs more ablation study", "review": "The paper proposes several variants of attention-based algorithms for set inputs. Compared with previous approach that processes each instance separately and then pooling, the proposed algorithm models the interactions among the instances within the set and performs better on tasks where such properties are important.\n\nThe experiments seem promising. The paper compares SAB and ISAB to rFF + pooling over multiple different tasks and SAB and ISAB outperform rFF + pooling in many tasks.\n\nOne drawback of the paper which limits its significance is that there are seemingly too many components and it is not clear which components are most important and which are not unnecessary. The authors can conduct some ablation study by removing some components and compare the performance to understand which parts are essential to the improvements.", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}