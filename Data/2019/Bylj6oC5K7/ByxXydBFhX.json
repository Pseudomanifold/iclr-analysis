{"title": "Nice observation and result on CIAFR10. Would like to see how it performs on CIAFR100.", "review": "This paper studies adversarial training of robust classification models. It starts off by analyzing ALP method, and hypothesizes that smaller logits may bring more robustness. Based on this observation, the authors experiment with several logit shrinking method including label smoothing and mixup. The authors further propose a variant loss (Eq. 10) of traditional ALP. Experiments on CIFAR10 demonstrate the observations and the proposed method LRM.\n\n0. My overall evaluation: This paper is well-motivated and the result is good. But it lacks novelty. And more experiments will definitely make it stronger. \n\n1. The Eq. (2) slightly differs from Kannan's ALP paper. They use half clean and half adversarial images in a batch, and here, you use both clean and adversarial images in a batch. Personally I think using both may lead to more robust models. Also, in Table 1, how do you implement ALP? Setting \\alpha = 0? Then this is basically adding one regularization term on top of Madry's loss function.\n\n2. When you expand the square and get Eq. 10, this can also illustrates that: 1) minimize logits 2). minimize a distance measure between clean and adversarial images. Also, when it comes to Eq. 10, some parenthesis typos?\n\n3. For Table 1, I would like to see PGD20 (iterations) + 2 (step size in pixels), PGD100 + 2 and PGD200 + 2. Also, I am interested in seeing CW loss which is based on logit margin. My best guess is that PGD, ALP, LRM may not go down for large iterations, because they all depend on adversarial examples (e.g., PGD7) during training. But I am not sure if the gain will be still there. Also, I think label smoothing may go down significantly.\n\n4. I would like to see results using the \"wide\" model in [madry17] paper for ALP and LRM. I think results from large-capacity models are more convincing.\n\n5. I would like to see results on CIFAR100, which is a harder dataset, 100 classes and 500 images per class. I think CIFAR10 alone is not sufficient for justification nowadays (maybe enough one year ago). It is possible that ALP or logit regularization-based method work only on simple dataset and simple decision boundary (10 classes). Since ImageNet is,  to some extent, computationally impossible for schools, I want to see the justification results on CIFAR100.\n", "rating": "5: Marginally below acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}