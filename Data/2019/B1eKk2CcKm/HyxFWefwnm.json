{"title": "Interesting and potentially useful idea with impact, but some design choices need careful thought before it is useful in practice.", "review": "\nSummary:\nThe paper proposes an unsupervised method to learn a vector representation for short genomic sequences, so-called kmers (like n-grams in natural language processing). The method learns a representation that will result in a good predictor of kmer counts from the kmer sequence itself. The idea is that neighbouring kmers (from the same gene) would have similar counts (same gene expression), and hence would be embedded near to each other. The paper shows some small empirical experiments for 3 tasks: showing similar genes are close, able to distinguish different genes, and able to detect genomic structural variation.\n\nThis is an interesting idea, and would have large impact if done well. However the current approach has multiple weaknesses which leave the proposal less strong that it could be. The paper is written clearly, and while the idea is motivated from word2vec and derivatives, the application to kmers is original.\n\n\nOverall comments:\n- There are two issues conflated in the word scalability:\n  1. computational scalability, where the authors need to run the method on a more realistic dataset and show that the LSTM converges.\n  2. statistical scalability, which I will expand in the next point.\n- The design of finding an embedding that will identify the count given a kmer has several weaknesses, which the paper did not address:\n  1. Two genes could have similar expression, hence similar kmer counts, but different kmers.\n  2. A kmer can appear in multiple genes, and the total count is the sum of all of them.\n  3. Copy number variation (since the paper is interested in cancer) would affect counts\n  4. Two kmers with only one or two differences could be due to SNPs. Should they be near or far?\n  5. Should we learn a representation for each individual, or a representation for the population? Depending on how the sample id (and hence vector v_i) is used, one can get different effects.\n- It seems wasteful that there is no representation learning for each individual, but instead it is just a fixed (arbitrary?) vector in a look up table.\n- The choice of embedding dimension 2 seems to be driven by the fact that the authors wanted to visualize. This is tied up with a weakness that the paper does not measure the quality of the embedding, e.g. using reconstruction error. A good approach is to show that the resulting embedding is useful for some other prediction task (which is usually the reason we want to find an embedding). Reporting mean squared error for Figure 4C would also be helpful.\n\nMinor typos/issues:\n- page 3, Section 3: does j range over k-mers in x_{ij}? You also use it r_j in the first sentence.\n- page 3, Section 3: read length = 100. kmer length = 24. This should be put in the experimental section. Furthermore due to reverse complements, it would be better to have an odd number for k, e.g. 23.\n- page 3,4: using angle brackets to mean a pair is uncommon. Suggest tuple (u,v).\n- page 4: The notation U in the description of the LSTM can be confused with two other things:\nU is the kmer embedding space, and u_{ij} is the embedding vector.\n- page 6: In the text you refer to Figure 3A, I assume you mean Figure 3.\n- page 6, Figure 3: Unclear what the three columns are. I assume similar to Figure 4, they are three individuals.\n- page 6, task 2: It is unclear how the reader can see that the information recovered by kmer2vec is the same information recovered by standard RNA-Seq analysis.\n- page 8, first word: Not sure how Figure 4B shows what the sentence is trying to say.\n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}