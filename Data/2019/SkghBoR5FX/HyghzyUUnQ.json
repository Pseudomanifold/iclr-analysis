{"title": "Need attack results on spatial stream", "review": "This paper proposes an effective attack technique for the widely used optical flow based classification models in white-box and black-box settings. The most interesting result is on the sparsity and frame salience, which could have a lot of applications. But the main idea is to transfer the standard attack techniques from image to video domain. I have some concerns as below. \n\n1. Page 3, \"...while the temporal stream alone achieves 83.7%. Thus, if the motion stream can be fooled, the entire model is compromised.\"\n\nThis statement is not exactly correct. Motion stream is better on UCF101 and HMDB51 dataset, which are two medium scale action recognition dataset. On other large-scale datasets like Sports1M, Kinetics, ActivityNet, etc., motion stream performs much worse than spatial stream. Hence, the motivation of the paper is unclear. Especially for real-world applications, due to real-time requirement, people usually just use the spatial stream. Hence, the current flow attack setting has limited usage. It is very important to show attack results on spatial stream as well. \n\n2. For FlowNet2, authors use gradient of the loss wrt the input images. However, FlowNet2 is a very large network consisting of 5 FlowNets. I am curious what the gradients will look like after the long back-propagation. Can authors comment on this by drawing a figure of magnitude distribution of gradients in the very early layers? \n\n\nDue to limited novelty, I recommend an initial rating of 5. \n\n\n\n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}