{"title": "Fast Gradient Sign Method (FGSM) is extended to the  temporal domain for action recognition attacking, but novelty is limited and experiments are unconvincing", "review": "The paper addresses the problem of adversarial attack for an optical-flow-based action recognition in both the white-box setting (i.e., gradients are available) and the black-box settings (i.e., the gradients cannot be computed by the optical flow algorithm). A video is partitioned into fixed-size temporal intervals, a state-of-the-art deep optical flow estimator is applied on each pair of two consecutive frames within the interval, and perturbations are applied to each frame (or selected frames using saliency cues) within the interval to attack the recognition system using Fast Gradient Sign Method (FGSM). Experiments are carried out on the UCF-101 dataset, in the white-box and black-box settings, and show that the method is able to effectively attack the system.\n\nStrengths:\n- Considering the relatively unexplored problem of attacking action recognition in the temporal domain .\n- Extending the Fast Gradient Sign Method (FGSM) to the temporal domain\n\nWeaknesses:\n - Novelty seems incremental. What appears to be novel is the extension of FGSM from image classification to action recognition (i.e., Sec 3.2) -- specifically, the gradient computation through both the action classifier and the optical flow estimator.  The paper proposes a simple solution that incorporates an existing differential deep optical flow network (FlowNet2.0) into another existing differential action classification model (TwoStream Network). Combining two existing networks seems insufficient for the problem statement as explained next.\n\n- Experiments seem unconvincing. Sec. 5.1 and 5.2 present effectiveness of the proposed attacking approach when using FlowNet2.0 as the optical flow estimator. However, the attacking effectiveness (i.e.,  accuracy drop) may be a consequence of using FlowNet2.0 which is known to be sensitive to additive perturbations.  FlowNet2.0-based action recognition is more sensitive to the perturbations than other methods like TVL1 and Far. \n\n", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}