{"title": "Interesting formulation; lack of mention and comparison to related work, terminology issue, and other flaws", "review": "Pros:\n- Provides illustration and math formulation for the problem of generalization beyond the correlation of labels and correlated but irrelevant attributes. Forming the issue as a domain adaptation problem (or specifically, a special kind of probability shift) is a clever idea.\n\n\nCons:\n- Lacks comparison to existing work. Making features invariant to attributes to improve generalization is not a new idea, cf. :\n(1) Xie, Qizhe, et al. \"Controllable invariance through adversarial feature learning.\" Advances in Neural Information Processing Systems. 2017.\n(2) If you consider the domain difference between various domains to be similar to attribute, then this is also related: Li, Haoliang, et al. \"Domain generalization with adversarial feature learning.\" Proc. IEEE Conf. Comput. Vis. Pattern Recognit.(CVPR). 2018.\n(3) There are other works that, although do not aim at improving generalization, use very similar formulation to decouple attribute from features: e.g. (a) Lample, Guillaume, et al. \"Fader networks: Manipulating images by sliding attributes.\" Advances in Neural Information Processing Systems. 2017.  (b) Mitigating Unwanted Biases with Adversarial Learning (which the authors cite, but do not offer any comparison or differentiation)\nTo improve the paper, these related work should be discussed in related work section, and (if applicable) compared to the proposed method in the experiments, rather than a very brief mention of one of them in Section 3.3 and no comparison.\n\n- Use of the term \"negative transfer\" is problematic. This is a more important shortcoming, but people may disagree with me. As far as I know, this term is used to describe a *source task* being used to help a *different target task* but result in a negative gain in performance (Torrey, Lisa, and Jude Shavlik. \"Transfer learning.\"), which is inherently a multi-task learning setting. However, in this paper it refers to the effect of unrelated features being used in classifier, resulting in a worse generalization. The existence of this issue does not involve a second task at all. If this is not intended, please use another phrase. If the authors think that these are one and the same, I would strongly argue against this proposition.\nAlso, there is no \"negative transfer technique\" as implied by page 2, end of the first paragraph.\n\n- Section 3.2 and 3.3's analysis is somewhat disjoint from the method. The analysis boils down to \"given a different correlation between primary and aux tasks, you can compute the distribution of inputs, which will be different from the source, so let's make the aux task unpredictable to get domain invariance.\" And the method goes on to remove auxiliary task information from the shared feature space. This is disjoint from either eq. (1) picking a target domain closest to source, and Theorem 1 the bound for domain adaptation. One way to improve the paper is to analyze how these analysis are affected by the adversarial training.\n\n- One of the selling points is that the method can adapt to trainable features in deep learning. However, in the experiment, fixed extracted features from pre-trained ResNet is used anyway. If so, a way to improve the paper is to compare to the traditional methods cited in page 2 paragraph 1, by applying them on fixed extracted ResNet features.\n\n", "rating": "2: Strong rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}