{"title": "Interesting results on an important problem, but insufficient analysis and evaluation ", "review": "========== Edit following authors' response  ==========\n\nThank you for your detailed response and updated version. I think the new revision is significantly improved, mainly in more quantitative analyses and details in several places. I have updated my evaluation accordingly. \n\nSee a few more points below.\n\n1. Thank you for clarifying your definition of concepts. I still think that the word \"concept\" has a strong semantic connotation, while the linguistic elements your analyses capture may do other things. The results in appendix E do show that some semantic clusters arise. It's especially interesting to see the blocks in some of the heat maps, where similar \"concepts\" are clustered together (like the sports terms in AG); consider commenting on this. \n\n2. The new quantitative analyses are helpful. One other suggestion that I mentioned before is to connect detected concepts to external resources like WordNet or ConceptNet. That would help show that \"concepts\" are indeed semantic objects. \n \n3. The motivation for replicating as normalizing for length does make sense, although the input would still be unnatural. The comparison to \"one instance\" is helpful, but it's interesting that the differences between it and replication in figure 2 are not large. It would be good to show results that substantiate your assumption that without replication there will be a bias towards lengthy concepts. Does \"one instance\" detect more lengthy concepts than replication? \n\n4. The results on frequency and loss difference in 4.5 are very interesting. There is another angle to consider frequency: words that appear frequently often carry less semantic content (e.g. function words), so one might conjecture that they would require less units. It may be interesting to look at which concepts are detected at each frequency bin.\n\n5. Minor points: section 2.2 still mentions \"regression\" where it should be \"classification\".  \n\n6. A few remaining grammar issues:\n- \"one concept has a less activation value..\" - rephrase \n- end of section 3.3: \"this experiments\" -> \"these experiments\"\n\n\n========== Original review follows ==========\n\nSummary:\n=======\nThis paper analyzes individual units in CNN models for text classification and translation tasks. It defines a measure of sensitivity for a unit and evaluates how sensitive each unit is to \"concepts\" in the input text, where concepts are morphemes, words, and phrases. The analysis shows that some units seem to learn semantic concepts, while others capture linguistic elements that are frequent or relevant for the end task. Layer-wise results show some correspondence between layer depth and linguistic element size.  \n\nThe paper studies an important question that is relatively under-studies in NLP compared to the computer vision community. The motivation for the work is quite convincing.  \nI found some of the results and analysis interesting, but overall felt that the work can be made much stronger by more quantitative evaluations. I am also worried that the notion of \"concept\" is misleading here. See below for this and other comments. I am willing to reconsider my evaluation pending response to the below issues. \n\nMain comments:\n=============\n1. Concepts: \n- morphemes, words, and phrases - are these \"concepts\"? They are indeed \"fundamental building blocks of natural language\" (2.2), but \"concepts\" has a more semantic connotation that I'm not sure these units target at. \n- Some of the results do suggest that units learn concepts, as the analysis in 4.2 shows a \"unit detecting the meaning of certainty in knowledge\" and later units that have similar sentiments. It would be informative to quantify this in some way, for example by matching detected concepts to WordNet synsets, sentiment lexicons, etc., or else tagging and classifying them with various NLP tools. This could also reveal if units learn more syntactic or semantic concepts, and so on. \n2. Generally, many of the analyses in the paper are qualitative and on a small scale. The results will be more convincing with more automatic aggregate measures. \n3. The structure of the paper is confusing. Section3 starts with the approach but then mentions datasets and tasks (3.1). Section 4 is titled experiments, but section 4.1 starts with defining the concept selectivity. I would suggest reorganizing sections 3 and 4, such that section 3 describes all the methods and metrics, while dataset-specific parts are moved to section 4. \n4. section 3.2 should provide more details on the sentence representation and how its obtained in the CNN models. A mathematical derivation and/or figure could be helpful. It is also not clear to me what's the motivation for mean-pooling over the l entries of the vector. \n5. section 3.3: the use of replicated text for \"concept alignment\" is puzzling. This is not a natural input to the model, and I think more justification and motivation \u00e5re needed for this issue, as well as perhaps comparison with other approaches. \n6. I found section 4.4 very interesting. It shows some intuitive results of larger linguistic elements learned at higher layers, but then some results that do not show such a trend. Then, hypothesizing that the middle layers are sufficient AND validating the hypothesis by retraining the model is excellent. It's a very nice demonstration that the analysis can lead to model improvements.  \n7. Figure 2 seems to be almost caused by construction of the different options for S_+. Is it surprising that the replicate set has the highest sensitivity? Is there a better control setup than comparing with a random set? \n8. One concern that I have is the effect of confounding factors like frequency on the results. The papers occasionally attributes importance to concepts (e.g. in 4.2), but I wonder if instead we may be seeing more frequent words. Controlling for the effect of frequency would be useful.   \n\n\nMinor comments:\n==============\n- Section 2.2, first paragraph: regression should be changed to classification\n- The related work is generally relevant, although one could mention a few other papers that analyzed individual neurons in NLP tasks [1, 2]\n- section 4.1: the random set may perhaps be denoted by something more neutral, not S_+ as the replicate and inclusion sets. \n- section 4.3, last paragraph: listing examples showing that units in Europarl focus on key words would be good. \n- Figure 5, y axis label: should this be number of units instead of concepts? \n- Appendix A has several interesting points but there is no reference to them from the main paper. \n\n\nWriting, grammar, etc.:\n======================\n- Introduction: among them - who is them? \n- 2.1: motivated from -> motivated by; In computer vision community -> In the computer vision community\n- 2.1: quantifying characteristics of representations in layer-wise -> rephrase\n- 3.2: dimension of sentence -> dimension of the/a sentence \n- 4.1: to which -> remove \"which\" \n- 4.2: in the several encoding layer -> in several encoding layers \n- 4.3: aliged -> aligned \n- Capitalize titles in references \n- A.2: with following -> with the following; how much candidate -> how much a candidate; consider following -> consider the following \n- A.3: induces similar bias -> induces a bias; such phrase -> such a phrase; on very -> on a very \n- C: where model -> where the model; In consistent -> Consistent; where model -> where the model \n\n\nReferences\n==========\n[1] Qian et al., Analyzing linguistic knowledge in sequential model of sentence\n[2] Shi et al., Why Neural Translations are the Right Length", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}