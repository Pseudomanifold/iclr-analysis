{"title": "Interesting theoretical and practical results but false claims on RNNs", "review": "+ An interesting problem to study on the stability of RNNs\n+ Investigation of spectral normalization to sequential predictions is worthwhile, especially Figure 2\n+ Some theoretical justification of SGD for learning dynamic systems following Hardt et al. (2016b).\n\n- The take-home message of the paper is not clear. First, it defines a  notion of stability based on Lipchitz-continuity and proves SGD can learn it. Then the experiments show such a definition is actually not correct, but rather a data-dependent one. \n- The theory only looks at the instantaneous dynamics from time t to t+1, without unrolling the RNNs over time. Then it is not much different from analyzing feed-forward networks. The theorem on SGD is remotely related to the contribution of the paper. \n- The spectral normalization technique that is actually used in experiments is not new", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}