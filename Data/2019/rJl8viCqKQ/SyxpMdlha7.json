{"title": "Incremental improvements or poor motivation. Writing needs improvement. ", "review": "This paper proposes several improvements to cryptonet proposed in Dowlin et al, 2016. The contributions include: \n1. Better implementation to improve speed and throughput. \n2. Modified architecture (LoLa) to reduce latency. \n3. Using features from a deep network rather than raw input. \nContribution 1 is better engineering with modern libraries and more efficient parallelism. This has limited academic novelty. Contribution 2 seems interesting, but is poorly explained. What is the cause of this improvement? What are some guidelines of latency-bandwidth trade-off in homomorphic deep networks? Contribution 3 seems to eliminate the need for remote classification service itself. Users need classification services because they do not have the computation resources, or do not have enough data to train classifiers successfully. If the users need to generate good representations such that classification becomes linearly separable, then why don\u2019t they just train the last linear layer themselves? Is there any computation or statistical reason to use any remote service?\n\nThe biggest problem with the paper is that it is hard to read and has several writing issues:\n1. It is not self contained. I had to refer to Dowlin et al, 2016 to understand what the authors are referring to. \n2. Notations are used but not defined. For example, I couldn\u2019t find any definition several symbols in section 3.\n3. The narration is too long and detailed: the authors report a laundry list of the things they did, details that should go into the appendix. It\u2019s hard to find what the main contributions are. \n\n\n------------ Response to rebuttals\n\nThe writing of the introduction has been greatly improved. \n\nThe authors suggested a practical scenario of using high level features. I am still somewhat skeptical. To do this the users need to map raw input to good representations. It seems that there are two ways this can work: users and service providers agree on publicly available representations, or the service provider is willing to share everything except the top layer. Both assumptions seem rather restrictive. Nonetheless even with practically useful scenarios, it is standard practice to use good features/representations whenever available, so not really an academic contribution. I am evaluating this paper only by the Lola contribution. \n\nThe presentation of LoLa can still be improved, but I see the main ideas. I think the paper could benefit from additional discussions and experiments. For example, when a practitioner wants to solve a new problem with some design need (e.g. accuracy, latency vs. bandwidth trade-off), what network modules can he choose and how to represent them? I think this type of general discussion can improve the significance and usefulness of the proposed approach. ", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}