{"title": "Decent paper but I have several concerns.", "review": "This paper identifies bias of commercial Face detection API (Microsoft, Google, Face++, IBM) by sending face images generated from AirSim, in which different face attributes (e.g., skin color, age, face orientation, lighting conditions, etc) can be controlled and explored. The paper shows that for darker skin color and old age, the classifier tends to have a higher false negative rate (miss the face more). This is in particular more apparent if Bayesian Optimization is used to explore the parameter space based on the previous detection results to find the failure cases. \n\nThere are several concerns:\n\n1. Bayesian Optimization might itself create a bias in the input data distribution, since it selectively pick some parameter configuration over the others.   \n\n2.  Using simulator might create additional biases. Maybe the faces generated by the simulator using the parameters of skin color of the minority / old age are less realistic than other faces, which lead to higher misclassification rate. In the paper there is no analysis in that aspect. \n\nOverall I feel this is an interesting paper and it may identify important problems in the existing commercial AI system. However,  I am not an expert in this field so I am less confident about the thoroughness of experiments, as well as the fairness of approaches. \n\nMinor issue:\n\nFig. 4 \u201cAge\u201d, skin detection => age. \n", "rating": "6: Marginally above acceptance threshold", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}