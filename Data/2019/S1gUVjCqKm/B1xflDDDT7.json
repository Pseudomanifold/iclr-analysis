{"title": "review", "review": "------------------------------------------\nSummary\n------------------------------------------\nThis paper performs unsupervised classification where the number of classes is unknown. The main idea is to use the CycleGAN framework such that one can reconstruct the original image by first moving to latent space that represents another class (via the connector network), then moving back to the original latent space and going back into image space using a generator. Experiments are conducted on MNIST and CIFAR.\n\n------------------------------------------\nEvaluation\n------------------------------------------\nThe paper tackles an important problem: namely, unsupervised classification (i.e. clustering). I think the use cycle-consistency loss in an auxiliary latent space is quite clever. However, experimental results are lacking. Unsupervised clustering (even when number of classes is not known) is a very well studied problem in machine learning. The authors should compare against at least a few reasonable baselines.\n\n------------------------------------------\nPresentation\n------------------------------------------\nI found the presentation to be somewhat wanting. Section 3 is extremely confusing and in my opinion, not well-motivated. For example, why is self-expressivity important? Why can we assume propositions 3.1 and 3.2?\n\n", "rating": "4: Ok but not good enough - rejection", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}