{"title": "Review", "review": "This paper proposes an autoencoder architecture and training procedure for producing high-quality reconstructions and realistic interpolations. A \"generator\" autoencoder is trained to fool a \"discriminator\" autoencoder. The generator tries to minimize its own reconstruction error and minimize the reconstruction error of the discriminator when fed with interpolated latent vectors of real datapoints. The discriminator autoencoder has three losses, corresponding to minimizing reconstruction error on real datapoints and maximizing reconstruction error on the generator's output on both real datapoints and interpolated outputs. The authors also propose a loss which encourages the distances between real datapoints and their corresponding latent vectors to be similar, as well as a heuristic procedure for stabilizing GAN training. Qualitative results are shown on CelebA.\n\nWhile the results look nice, the paper is not fit for publication in its current form. At a high level, the issues include a lack of convincing experimental verification of the method, a generally contradictory and confusing description of the methods, and frequent factual errors or mischaracterizations. Here I will try to describe many of the issues I found while reading the paper:\n- Experimental results are only given on CelebA which is a dataset with a very strong and easy-to-model structure. The experimental results are completely qualitative. No effort is made to provide a quantitative proof of claims such as \"the reconstructions are less blurry\" or \"the interpolations are higher quality\"; only a few examples are shown. The experiments are not even described in the text, and many of the figures are unreferenced. No ablation studies are done to determine the importance of different loss terms, such as L_dist. No mention is given to how hyperparameters like alpha should be chosen (and in fact, the value given for it \"1^{-4}/2\" is nonsense; 1^{-4} is just 1). No results for a baseline autoencoder (i.e., just optimizing reconstruction loss) are given.\n- At a higher level, no effort is given to argue why interpolation is a useful characteristic to try to encourage. There are no downstream applications proposed or tested. Earlier models, such as VAEGAN, also give reasonable reconstructions and good interpolations. Why is GAIA better? On what problem would I use GAIA and achieve better results apart from making nice-looking interpolations of people's faces?\n- Definitions are often unclear or contradictory. For example, the generator autoencoder is alternatingly treating as taking input X and taking input Z. I believe what is meant is that the generator consists of two networks which compute Z = encoder(X) and X = decoder(Z). Instead, the paper just switches between G(Z) and G(X) wherever convenient. Similarly, the equation for \\delta_Disc is different in Algorithm 1 and in the equation in 2.2. Interpolation, arguably one of the core parts of the model, is described as \"interpolations are Euclidean interpolations between pairs of points in Z, sampled from a Gaussian distribution around the midpoint between Zg1en and Zg2en.\" I assume the mean of this Gaussian is the midpoint; what is its covariance? Etc.\n- All autoencoders are not generative models, and in particular GAIA is not a generative model. There is no generative process. It does not estimate a data distribution. A VAE is a generative model which an autoencoder-like structure, but this does not make all autoencoders generative models.\n- GAIA is described as encouraging \"convex latent distributions\" and a convex set is defined in the text as \"A convex set of points is defined as a set in which the line connecting any pair of points will fall within the rest of the set.\" A convex set is not defined in terms of lines; it's defined in terms of convex combinations of points within the set. In the paper, only lines between points are considered. Claiming that the latent space is \"convex\" in the sense of purple blobs in B is not done - you would need to take a convex combination of multiple latent vectors and decode the results.\n\nThis is an incomplete list of the issues with this paper. The paper would need significant changes before publication.", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}