{"title": "An interesting paper providing learning guarantees for unconstrained size neural network classifiers with explicit (exact) Lipschitz regularization.", "review": "The paper gives convergence guarantees to the true neural network classifier for the networks that are explicitly regularizing the (exact) Lipschitz constant of the network. The bound stated decays as ( log(n)/n )^{1/m}, where n is the number of training points and m is the dimension of the data manifold. Thus the decay rate is pretty slow when the data lies on a high-dimensional manifold. I believe it should also depend on the volume of the data manifold.\n\nComputing the exact Lipschitz constant of the network is intractable. All the theorems apply to minimization problem defined in (1) with the exact Lip(u,X) being regularized, and not to the minimization problem of the lower bound (2). I believe there are also no convergence guarantees how quickly this lower bound on the Lipschitz constant approaches Lip(u,X), unless some assumptions are made on the smoothness of the data manifold (comments and insights would be appreciated). Thus in my opinion the current results have little practical importance. Nevertheless, it\u2019s still interesting to see some ideal-setting guarantees being established.\n\n\nTheorem 2.7: Is m == m_0 (the dimension of the data manifold)? Shouldn\u2019t the bound be 2*C*L_0\u2026.? (assuming lemma 2.9 is correct)\n\nCor 2.8: Where does the volume Vol(M) of the manifold disappear? Is C in equation (6) the same C as in Theorem 2.7? Also, it looks like the bound should bound should have C^2 (assuming theorem 2.7 is correct, and the C\u2019s are the same).\n\n\nIntroduction: I assume u(x,w) is not the last layer map, but a map from the input space to the labels (i.e., the whole neural network function and not just the map from the last hidden layer to the labels). If I am correct, it\u2019s misleading to refer to u(x,w) as the last layer map. And if it is the last layer map, please justify why it is enough to consider the Lipschitz constant of the last layer.\n\nThe term \u201cclean data\u201d is never defined. My guess is that \u201cclean data\u201d refers to the realizable  setting, and \u201cnoisy\u201d to agnostic, where the hypothesis space consist of neural networks of arbitrary size.\n\n\n\u201cOur analysis can avoid the dependence on the weights because we make the assumption that there are enough parameters so that u can perfectly fit the training data. The assumption is justified by Zhang et al. (2016).\u201d\nNote, that the network used in practice achieve zero classification error, as demonstrated by Zhang et al, but I doubt the cross entropy loss (that is usually being minimized) is exactly zero.\n\nRemark 1.4 \u201cwill result in an expected loss..\u201d  (there is also a typo here) should specify that you are talking about empirical error (0-1 loss), since I don\u2019t think the loss function is fixed anywhere earlier in the text.\n\nRemark 2.2 : Just wanted to note, that it is more common to call L(u,\\rho) risk. The gap between L(u,\\rho) and the empirical risk L(u,\\rho_n) is usually called the generalization error (and only in the case of zero empirical risk, L(u,\\rho) is equal to the generalization error). I did check the reference in Goodfellow et al. book, and I see that it is consistent with your definition.\n\nJust below Remark 2.2:\n\u201cWe would also expect the sequence of generalization losses L[u_n ; \\rho] to converge to zero in the case of perfect generalization.\u201d\nOnce again, this is true only in the realizable setting.\n\nCould the authors comment on the connection to Cranko et al. 2018 work?\n\nTypos:\nIn the abstract, no which: \u201c..corrupted labels which we prove convergence to...\u201d\n\u201c...a candidate measure for the Rademacher complexity, which a measure of generalization...\u201d.\n\u201c1-Lipschitz networks with are also important for Wasserstein-GANs\u201d\nSection 2.1 \u201cis it clear that u0, is a solution of \u201c, should be \u201cit is\u201d\n\n\n---------\n[UPDATE]\n\nRegarding the comment \"Our paper resolves the question posed in ICLR Best paper 2017 \"Understanding deep learning requires rethinking generalization\"\", I don't think that analyzing networks with explicit regularization resolves the questions stated in Zhang et al paper. As other reviewers mentioned, there are a number of other papers that formally define quantities that correlate with the generalization error, and are larger for random vs true labels. There are also other papers showing that one can tune some parameters of the optimization algorithm to avoid overfitting on random labels (while it is a modification to the algorithm, it is still similar to explicitly regularizing the Lipschitz constant of the network) (see e.g., Dziugaite et al work on SGLD).\n\nTherefore, the claim in the abstract \"A second result resolves a question posed in Zhang et al. (2016): how can a model distinguish between the case of clean labels, and randomized labels?\" needs to be toned down a bit.\n\nIn my opinion, the work presented in this paper is a valuable contribution to learning theory. The new version of the paper is easy to read. Therefore, I recommend acceptance if the authors change the claim about resolving  the questions posed by Zhang et al.\n\nAnother typo:\n - for convergence, we require that the network also grow(s), ", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}