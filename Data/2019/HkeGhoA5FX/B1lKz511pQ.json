{"title": "excellent application oriented paper; new state-of-the-art results; yet limited novelty", "review": "The authors propose a residual non-local attention net (RNAN) which combines local and non-local blocks to form a deep CNN architecture with application to image restoration.\n\nThe paper has a compact description, provides sufficient details, and including the appendix has an excellent experimental validation.\n\nThe proposed approach provides top results on several image restoration tasks:  image denoising, demosaicing, compression artifacts reduction, and single image super-resolution.\n\nThe main weakness of the paper is the limited novelty, as the proposed design builds upon existing ideas and concepts. However, up to some point all the new ConvNet designs can be seen as incremental developments of the older ones, yet they are needed for the progress of the field.\n\nI would suggest to the authors the inclusion of related works such as:\nTimofte et al., \"NTIRE 2018 Challenge on Single Image Super-Resolution: Methods and Results\", CVPRW 2018\nWang et al., \"A fully progressive approach to single-image super-resolution\", CVPRW 2018\nNote that DIV2K dataset was introduced in:\nAgustsson et al., NTIRE 2017 Challenge on Single Image Super-Resolution: Dataset and Study, CVPRW 2017\n\nalso, the more recent related works:\nBlau et al., \"2018 PIRM Challenge on Perceptual Image Super-resolution\", ECCVW 2018\nZhang et al., \"Image Super-Resolution Using Very Deep Residual Channel Attention Networks\", ECCV 2018\n\nAlso, I would like a response from the authors on the following:\nWhy not using dilated convolutions instead of or complementary with the mask branch or other design choices from this paper?\n", "rating": "7: Good paper, accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}