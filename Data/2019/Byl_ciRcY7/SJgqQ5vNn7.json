{"title": ".", "review": "The submission explores Breiman's dilemma: training margin is not always a good predictor of test error.\n\nIn particular, the authors show that:\n\n- For under-parametrized CNNs, the training prediction margin is a good predictor of the test error.\n- For over-parametrized CNNs, the training prediction margin is not a good predictor of the test error.\n\nThroughout the submission, I suspect that the authors compute the \"functional margin\", that is, the difference between the largest label score and the second largest score, for correctly classified examples. Functional margins ignore the smoothness of the underlying function, a critical factor for generalization. For instance, the function f(x) = 1[x > 0] has large functional margin, but any perturbation around the x-origin would drastically change the prediction. For this reason, I think the authors should consider the \"geometrical margin\" instead, which is unfortunately difficult to compute for general neural networks. Their theory tries to reflect on this issue by using spectrally-normalized bounds, but the practice ignores this issue completely (as far as I can tell).\n\nTherefore, we may be looking at the wrong statistic to predict generalization error. Is Breiman dilemma solved by re-defining margin properly? Geometrical margin can be computed in closed-form for linear classifiers, so perhaps this would be a first step in this investigation.\n\n", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}