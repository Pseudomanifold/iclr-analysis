{"title": "using videos without objects as negative examples to detect objects", "review": "The paper introduces a system that uses positive videos (with the objects of interest in motion) and negative videos (devoid of those objects but the same backgrounds) to detect those objects of interest. The motivation in clear and explanation and flow of the paper are good. The technique will allow building object detectors with less labeling effort.\n\nHowever, the labeling of the first frame in many previous tracking and detection techniques can be compared to collecting a negative video (i.e. the agent needs to make sure that the negative video does not have that or related object in the negative video) and so both these approaches are similar. The current strategy can't by itself detect the absence of the object and hence there is supervision needed there.\n\nOne other important aspect I think was missing was the details of the training and test sets. How many training videos and test videos was this tried on? How different were the test videos? Did the test videos have objects similar to the training videos? Did the test videos have different external condition like lighting etc than the training videos? How similar were the backgrounds in these videos?\n\nPrevious approaches like TLD also used positive and negative samples (though from the same video) and track the object with view and lighting changes. When compared to the baseline, why did the current approach do better than these approaches (since both these methods and using a similar strategy of using positive and negative samples).\n\nHow does the system handle videos with different objects moving in the video with similar physical constraints? When does the system break i.e. what happens if objects are moving too fast, the camera motion or panning is not as expected? How would the manually set weight parameters need to be changed? How reliable are these parameters to new objects, far away objects etc?\n\nHow is variation or slowness being computed reliably without use of optical flow or other techniques? i.e. won't other objects due to camera motion negatively affect this?\n\nIn section 3.3, how do you detect if it has fully converged or close to it for the multiple runs especially since the ground truth is missing?\n\n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}