{"title": "This work extend previous work with multitask linear MDP for discovery of deep hierarchical abstractions from offline setting to a online setting. It lacks clarify in presentation and has limited experiments and anlaysis. ", "review": "pros:\nThe experiment results demonstrate better performance of the proposed method.\nCons: \n1. It does not compare with any existing HRL (with simple adaptation to multitask settings), except for Q learning under different exploration strategies. \n\n2. Also the method is tested only on one type of domain-gridworld, which seems very limited, especially for supporting the claims, including \u201cthe proposed method can uncover a deep hierarchical abstraction of task ensemble in a complete online fashion\u201d and \u201cthe process of learning the hierarchical structure online does not significantly slow learning\u201d\n\n3. There is no implementation details of the proposed in a algorithmic form.\n\n4. There is also no ablation test or discussion of parameters that affect the performance of the experiment results, for example, learning rate, size of the domain. \n\n5. There are a lot of notations used without definition. The paper should be more self-contained by providing accurate definition and citations.\n\nFor example, what are are Interior state,  boundary state, finite exit problem\nIs V(s) computed with based on R_i or R, or both?\nWhat is the control cost refer to? Is it related to R_i or R somehow?\n\n6. Some references are cited wrongly. \nMachado et al (2018) cited is not about HRL. Please double check\nThe references should be updated to reflect the latest information, for example,\nIt might be better to cite the AAAI17 version of the option-critic architectures \nBetween MDPs and Semi-MDP: A framework for Temporal Abstraction in Reinforcement learning should use the 1999 version \n\n \n7. Minor issues:\ntask it is -> task is\nZ^l \\in R^{N\\times N}\n Howver -> however\n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}