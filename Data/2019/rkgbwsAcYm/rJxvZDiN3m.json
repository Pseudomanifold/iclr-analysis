{"title": "The paper proposes a normalization procedure improving transfer learning by considering together the output layers of the source and target deep nets. The contribution is rather limited, the experiments are reasonable but not always complete, the use of language satisfactory but can be improved. ", "review": "This is a reasonable paper based on a simple intuition. The authors have noticed that some of the state of the art methods (they use Li et al - ICML18 as the main reference) are using only some simple normalization for improving the transfer learning and as such they propose preserving the outer layer output of the target network and aligning it with the one of the source network. On top of that they also propose modeling the difference of feature maps considering an attention mechanism obtain through supervised learning. \n\nThe idea in itself is interesting and valuable. However, I have had some difficulty in understanding precisely how the \"behavior\" is really regularized. While I understand what is depicted in Figure 1 I'm not completely sure this really means that the network behavior is regularized rather than simply correlating the two outputs. In the evaluation, the authors present in Figure 4 some qualitative examples but I would have expected to see some quantitative evaluation of this. I would have liked to see experiments on some larger datasets that are commonly used in computer vision (e.g., Caltech 256 is rather old even if it has been used in Li et al.). The quantitative results in Table 1 and 2 indicate some slight improvement but I'm not completely convinced that this is really significant in the end. The results in Figure 4 tend to show that with the attention mechanism there is a central bias and most of the results tend to be concentrated on the center of the image (in this case the result might also be correct but the examples presented are not too eloquent). \n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}