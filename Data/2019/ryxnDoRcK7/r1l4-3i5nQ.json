{"title": "interesting idea", "review": "multi-objective learning is known to regularize estimation and improve optimization. the authors excellently bring this idea to causal inference, in particular learning conditional average treatment effect. I see the main contribution of the paper experimental: the authors demonstrate that their methods achieve good results on different tasks.\n\nthe causal setting it operates under is the classical one: under strong ignorability and overlap. the contribution is in causal estimation, rather than causal identification.\n\nwhile the authors claim the results are all state-of-the art, in several cases, it seems the S-learner is a very competitive and seemingly favorable competitor; in simulation 4,5,6 of fig 3 for example. and fig 6.\n\ncould the authors please clarify in their understanding of the empirical performance? in what scenario/data patterns will the Y-learner often outperform? when does it perform the best compared to its competitors. it could help to give intuitions of why and when the proposal work. it could help future users decide when to use it.", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}