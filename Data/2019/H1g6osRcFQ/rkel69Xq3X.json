{"title": "Novel approach for adapting domain randomization policy for transfer", "review": "This paper presents a novel approach for adapting a policy learned with domain randomization to the target domain. The parameters for domain randomization are explicitly used as input to the network learning the policy. When run in the target domain, CMA-ES is used to search over these domain parameters to find the ones that lead to the policy with the best returns in the target domain.\n\nThis approach is a novel one in the space of domain randomization and sim2real work. The results show that it improves over learning robust policies and over one version of doing an adaptive policy (feedforward network with history input). This approach could\n\nThe paper is well written, clearly explained, has clear results, and also explains and evaluates alternate design choices in the appendix.\n\nPros:\n- Demonstrated transfer across simulated environments\n- Outperforms basic robust and adaptive alternatives\n- Straightforward approach\nCons:\n- Requires explicit domain randomization parameters as input to network. This restricts it from applying to work where the simulator is learned rather than parameterized in this way. \n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}