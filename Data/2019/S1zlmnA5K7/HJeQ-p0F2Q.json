{"title": "How well and why it works at states that are far from any states in the batch?", "review": "This paper studies extrapolation error in off-policy batch reinforcement learning (RL), where the extrapolation error refers to the overestimation of the value for the state-action pairs that are not in the training data.\n\nThe authors propose batch-constrained RL, where the policy is optimize under the constraint that, at each state, only those actions that have been taken in that state in the training data are allowed.  This is then extended to continuous space, where it allows only the state-action pairs that are close to a state-action pair in the training data.  When there is no such action for a given state, the action that is closet to a feasible action at that state is selected.\n\nIt makes intuitive sense that the proposed approach works well as long as we only encounter state-action pairs that are closed to one of the state-action pairs in the batch.  However, I do not expect that this is always the case.  The proposed method is to simply choose the closest action in the batch.  Then why does the proposed approach perform well?  Is it because the experiments are performed under rather deterministic settings?  How often are no state-action pairs found in the neighbor?  Is there any mechanism for recovering from \"not in the batch\"?\n\nThe paper would be much stronger if it study this challenge of \"not in the batch\" more in depth.  Technical contributions in the present paper are rather limited.\n\nA key assumption in the discrete case is that whole episodes are in the batch.  This is rather restricting, because in many applications, it is infeasible to collect a whole episode, and parts of many episodes are collected from many agents.  Although this assumption is stated, it would be nice to emphasize by also stating that the theorems do not hold when this assumption does not hold.  The assumption becomes less important for continuous case, because of approximation.  It might be interesting to study the performance of the proposed approach when the assumption does not hold in the continuous case.\n", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}