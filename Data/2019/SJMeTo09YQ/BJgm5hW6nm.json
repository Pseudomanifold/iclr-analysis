{"title": "A constrained learning of permissable action-state space for speeding up RL ", "review": "The authors introduce an approach for constraining the action-state space of RL algorithms, with the premise to speed up their learning. To this end, two types of constraints are introduced, coupled and embedded into the traditional policy learning for RL. The main idea of using a binary predictors for predictions of permissible actions leading to desired  states is interesting and novel. It is an intuitive approach for constraining the space and the authors showed in their experiments that it leads to significant speed up in learning of two common RL methods (DDQN and DDPG). The approach is also motivated by recent trends in meta-learning (of the binary predictor) and it would be good if the authors relate it to that (also citing some literature on meta learning). \n\nWhile I am in favor of accepting this paper, I think there are several aspects that need be commented on/addressed:\n\n- what would be a simple baseline for constraining the action-state space? One possibility could be to use the learned model to simulate the trajectories and based on that hard code the constraints? Any other ideas, task-specific?\n\n- what is the relation to the model-based RL? In model-based RL we try to learn the transition probabilities from action to states. Could we impose any sparsity constraints on such a model to achieve a similar performance. While the proposed model is more elegant in that it allows the learning of the predictors on the fly, I feel there is a lack of comparisons with approaches that could easily be implemented using heuristics. Please comment. \n\n- could you be more precise about how often the prediction model is updated? What are potential adverse effects if this models keeps overfitting?\n\nThere are also limitations in terms of the number of hyperparameters that need be fine-tuned. I would like that the authors include one paragraph discussing in more detail the limitations of their approach.\n\n", "rating": "7: Good paper, accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}