{"title": "Several technical flaws. Experiments are not representative of federated learning.", "review": "This paper combines distributed optimization algorithm with variational dropout to sparsify the gradients sent to master server from local learners.\n\nMy major concerns are related to technical issues with the algorithm and overly simplified treatment of federated learning. I think almost every section of this paper has problems of varying severeness. I will give comments on every section in the order of its appearance in the paper.\n\nIntroduction:\n\"Federated Learning uses some form of distributed stochastic gradient descent\". Distributed SGD is certainly one of the many approaches to federated learning, but it is hardly suited for the definition of federated learning.\n\n\"Each device then updates the model parameters using the averaged gradients\" - this seems somewhat unconventional to me to be presented in the introduction. More often global server performs the update and sends the parameters back to local learners. The two are equivalent if communication is performed after each iteration, however it is unclear how to implement this scheme if communication frequency needs to be restricted.\n\nWhile model size constraint and communication constraint are important in federated learning, there are multiple other challenges. In particular, data is often unbalanced and non-iid, which is fully ignored by the authors. Privacy and communication frequency are another important aspects of federated learning. Even if authors choose to only address a subset of federated learning challenges, the problem has to be fully described.\n\nPreliminaries:\n\"One popular approximation approach is variational inference, which uses a parametric distribution to approximate the true posterior distribution (Kingma & Welling, 2013).\" While work of Kingma & Welling is certainly important, I do not think it is appropriate as a stand alone citation in the context of the sentence. Variational inference has been studied for over 20 years by many researchers and this should be acknowledged with appropriate references in the general sentence chosen by the authors.\n\n\"In traditional dropout training, either Bernoulli or Gaussian noises are added to the weights\" - dropout is not an additive noise. Weights are multiplied by the corresponding noise variables. This mistake appears at least one more time in the preliminaries section.\n\nEq. 3: I can hardly find it useful to provide equation with several numerical values of unknown origin. Indeed looking at the corresponding reference I could not find an equation with same numbers. Please elaborate or give literature reference with specific equation number.\n\nAlgorithm section:\nEquation for the gradient of $\\alpha$ does not seem to make any sense. It essentially implies that after $\\alpha_{ij}>T$, corresponding $\\alpha_{ij}$ will never be updated again as its gradient is zeroed out. In other words, if the weight is ever masked by dropout, it can never appear again. This issue seems to be confirmed by the later comment \"Second, \u03b8ij is suppressed by large \u03b1ij and it can hardly grow back unless DKL in (1) is removed.\"\n\n\"since \u03b1 is associated with \u03b8 which is synchronized every iteration during SGD, \u03b1 will thus be forced to be almost the same across all the devices\" - I do not see why this is the case. Especially if the authors were to consider imbalanced non-iid partitioning, local \u03b1 can easily diverge from each other. Moreover, if \u03b1 differ across local learners, there is no reason for the average of sparse gradients, computed on the server, to be sparse. This seems to defeat the whole purpose of the proposed method since the communication from server to local devices will be inefficient.\n\nExperiments:\n\"five datasets that fit the federated learning setting\" - datasets considered can hardly be associated with federated learning in my opinion. They can be used to simulate federated learning scenario by partitioning with class and size imbalance. Instead \"Each dataset is randomly and evenly divided into N non-overlapping parts for N devices\", which, as I mentioned earlier, is not representative of federated learning. Moreover I would encourage to consider larger number of devices for the experiments.", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}