{"title": "Well-motived but may have serious issues. EDIT: Serious issues have been fixed.", "review": "This is a well-motived paper that considers bridging the gap\nin discrete-time continuous-state/action optimal control\nby approximating the system dynamics with a convex model class.\nThe convex model class has more representational power than\nlinear model classes while likely being more tractable and\nstable than non-convex model classes.\nThey show empirical results in Mujoco continuous-control\nenvironments and in an HVAC example.\n\nI think this setup is a promising direction but I have\nsignificant concerns with some of the details and claims\nin this work:\n\n1. Proposition 2 is wrong and the proposed input-convex recurrent\n   neural network architecture not input-convex.\n   To fix this, the D1 parameters should also be non-negative.\n   To show why the proposition is wrong, consider the convexity of y2\n   with respect to x1, using g to denote the activation function:\n\n       z1 = g(U x1 + ...)\n       y2 = g(D1 z1 + ...)\n\n   Thus making\n\n       y2 = g(D1 g(U x1 + ...) + ...)\n\n   y2 is *not* necessarily convex with respect to x1 because D1 takes\n   an unrestricted weighted sum of the convex functions g(U x1 + ...)\n\n   With the ICRNN architecture as described in the paper not being\n   input-convex, I do not know how to interpret the empirical findings\n   in Section 4.2 that use this architecture.\n\n2. I think a stronger and more formal argument should be used to show\n   that Equation (5) is a convex optimization problem as claimed.\n   It has arbitrary convex functions on the equality constraints that\n   are composed with each other and then used in the objective.\n   Even with parts of the objective being convex and non-decreasing\n   as the text mentions, it's not clear that this is sufficient when\n   combined with the composed functions in the constraints.\n\n3. I have similar concerns with the convexity of Equation (6).\n   Consider the convexity of x3 with respect to u1, where g is\n   now an input-convex neural network (that is not recurrent):\n\n       x3 = g(g(x1, u1), u2)\n   \n   This composes two convex functions that do *not* have non-decreasing\n   properties and therefore introduces an equality constraint that\n   is not necessarily even convex, almost certainly making the domain\n   of this problem non-convex. I think a similar argument can be\n   used to show why Equation (5) is not convex.\n\nIn addition to these significant concerns, I have a few other\nminor comments.\n\n1. Figure 1 hides too much information. It would be useful to know,\n   for example, that the ICNN portion at the bottom right\n   is solving a control optimization problem with an ICNN as\n   part of the constraints.\n\n2. The theoretical results in Section 3 seem slightly out-of-place within\n   the broader context of this paper but are perhaps of standalone interest.\n   Due to my concerns above I did not go into the details in this portion.\n\n3. I think more information should be added to the last paragraph of\n   Section 1 as it's claimed that the representational power of\n   ICNNs and \"a nice mathematical property\" help improve the\n   computational time of the method, but it's not clear why\n   this is and this connection is not made anywhere else in the paper.\n\n4. What method are you using to solve the control problems in\n   Eq (5) and (6)?\n\n5. The empirical setup and tasks seems identical to [Nagabandi et al.].\n   Figure 3 directly compares to the K=100 case of their method.\n   Why does Fig 6 of [Nagabandi et al.] have significantly higher rewards\n   for their method, even in the K=5 case?\n\n6. In Figure 5, f_NN seems surprisingly bad in the red region of the\n   data on the left side. Is this because the model is not using\n   many parameters? What are the sizes of the networks used?", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}