{"title": "An interesting approach to quantify uncertainty in neural networks", "review": "This paper presents an approach to obtain uncertainty estimates for neural network predictions that has good performance when quantifying predictive uncertainty at points that are outside of the training distribution. The authors show how this is particularly useful in an active learning setting where new data points can be selected based on metrics that rely on accurate uncertainty estimates.\n\nInterestingly, the method works by perturbing all data inputs instead of only the ones at the boundary of the training distribution. Also, there is no need to sample outside of the input distribution in order to have accurate uncertainty estimates in that area.\n\nThe paper is clear and very well written with a good balance between the use of formulas and insights in the text. \n\nThe experimental section starts with a toy 1d active learning task that shows the advantage of good uncertainty estimates when selecting new data points. The authors also present a larger regression task (8 input dimensions and 700k data points in the training set) in which they obtain good performance compared to other models able to quantify epistemic uncertainty. In my opinion, the experiments do a good job at showing the capabilities of the algorithm. If anything, since the authors use the word \"deep\" in the title of the paper I would have expected some experiments on deep networks and a very large dataset.\n", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}