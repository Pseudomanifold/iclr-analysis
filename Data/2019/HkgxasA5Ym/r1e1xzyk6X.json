{"title": "nicely written, but experiments are very limited", "review": "The paper considers the problem of uncertainty estimation of neural networks and proposes to use Bayesian approach with noice contrastive prior.\n\nThe paper is nicely written, but there are several issues which require discussion:\n1. The authors propose to use so-called noise contrastive prior, but the actual implementation boils down to adding Gaussian noise to input points and respective outputs. This seems to be the simplest possible prior in data space (well known for example in Bayesian linear regression). That would be nice if authors can comment on the differences of proposed NCP with standard homoscedastic priors in regression.\n2. The paper title mentions 'RELIABLE UNCERTAINTY ESTIMATES', but in fact the paper doesn't discuss the realibility of obtained uncertainty estimates directly. Experiments only consider active learning, which allows to assess the quality of UE only indirectly. To verify the title one needs to directly compare uncertainty estimates with errors of prediction on preferably vast selection of datasets.\n3. The paper performs experiments basically on two datasets, which is not enough to obtain any reliable conclusions about the performance of the method. I recommend to consider much wider experimental evaluation, which is especially importan for active learning, which requires very accurate experimental evaluation\n4. It is not clear how to choose hyperparameters (noise variances) in practice. The paper performs some sensitivity analysis with resepct to variance selection, but the study is again on one dataset.\n\nFinally, I think that the paper targets important direction of uncertainty estimation for neural networks, but currently it is not mature in terms of results obtained.", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}