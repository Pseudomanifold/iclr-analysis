{"title": "Unclear contribution (did not implement in hardware, cited paper already did similar comparison of architectures)", "review": "The main context for this paper is two recent publications: Giusti et al.\u2019s \"A Machine Learning Approach to Visual Perception of Forest Trails for Mobile Robots\u201d (2016) and Smolyanskiy et al.\u2019s \"Toward Low-Flying Autonomous MAV Trail Navigation using Deep Neural Networks for Environmental Awareness\u201d (2017). \n\nGiusti introduced a dataset of trail images (later called the \u201cIDSIA dataset\u201d) acquired by having a hiker wear three head-mounted cameras. The forward facing image is associated with a label \u201cgo straight\u201d, whereas the two side images are associated with labels for \u201cgo left\u201d and \u201cgo right\u201d. Giusti then trained a convolutional neural network to predict these labels and used the network to guide a \"quadrotor micro aerial vehicle\u201d. \n\nSmolyanskiy improves on Giusti\u2019s work by (1) gathering additional trail image data using three cameras mounted to face forward but with lateral offsets and (2) using this additional data to train a 6 output neural network (\u201cTrailnet\u201d) which predicts both view orientation and lateral offset. In addition, they also combined predicted pose relative to the trail with predictions of localized objects and a depth map for potential obstacles. They compared several neural network architectures for predicting the view angle on the IDSIA data as well as the closed-loop performance of each network in avoiding collisions while operating within a UAV on a previously unseen trail. Though Trailnet did not achieve the highest accuracy (84% vs. the max 92% achieved by ResNet-18), it was the only network that achieved 100% collision avoidance on their UAV test course. \n\nThis paper, \"A CASE STUDY ON OPTIMAL DEEP LEARNING MODEL FOR UAVS\u201d, attempts to evaluate two potentially better convolutional neural networks for UAV trail guidance. They fine tune pertained Inception-Resnet and MobileNet models to predict the IDSIA dataset. These then both achieve better accuracy on the IDSIA test set and were analyzed for inference time and power consumption. These two models are then run through a single simulated path, where both seem to perform adequately across 2 turns in the path. \n\nThis paper has a variety of essential flaws.\n\n1. A large portion of the text is devoted to their hardware and UAV control but they were not able to actually run models on a physical UAV \"due to a hardware bug we were facing with the FCU\u201d. \n2. The paper claims to \"introduce to the best of our knowledge, a very first comparative study of three algorithms in order to find a better motion control of a drone for detecting a trail\u201d. This is a confusing claim since a comparison of neural network architectures is a central part of the evaluation in the Smolyanskiy paper. \n3. The higher accuracy on view orientation does not seem relevant since it was also achieved by Smolyanskiy et al. with networks that they then showed performed worse when combined with object detection, obstacle depth inference and combined controller.\n4. The sentence \"An important goal of our method is to demonstrate the effectiveness of low cost systems for the complex task of flying an autonomous drone\u201d appears to have been plagiarized from \u201cLearning to Fly by Crashing\u201d (2017) which contains \"A important goal of our method is to demonstrate the effectiveness of low cost systems for the complex task of flying in an indoor environment\u201d. ", "rating": "2: Strong rejection", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}