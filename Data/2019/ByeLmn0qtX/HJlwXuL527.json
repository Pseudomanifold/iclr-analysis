{"title": "A preference learning generative model (in deep setting), with somewhat unintuitive setting and weak experimental evaluation", "review": "1) Summary of the paper:\n\nThe paper brings up a relatively new problem of learning a generative model for multiple domains. The domains, D1,...,Dn, may refer to person-specific preferred images, for instance, and they focus on how to build generative models P(x|Di), which represents a set of images preferred by subject i.\n\nThey assumed a specific setup where one can access domain classifiers P(Di|x), but not the samples from P(x|Di). It is a bit odd: actually they worked mostly on a special (relatively new) dataset named \"SCUT-FBP-5500\", which seems to contain labeled samples, (x,D1,...,Dn) -- then, obviously we can access x|Di as well as Di|x. Of course, this type of fully labeled dataset is small-sized.\n\nTheir approach is basically to partition the latent space by the domains D1,...,Dn. They utilize the standard VAE model which is shared across the domains, and introduce domain-specific latent priors P(z|D_i) which are Gaussians. The learning is essentially a combination of the VAE learning and the latent prior learning, where the latter is done by enforcing the generated samples x from each Di to be consistent with the domain classifier P(Di|x). This strategy sounds reasonable enough.\n\nOne issue lies in the latent prior learning (ie, optimization of (3)). Since they need to evaluate P(Di|x), x is limited to the labeled samples, namely those from the (small-sized) SCUT-FBP-5500 dataset only. So although they wrote expectation wrt p(x) in (3), the p(x) cannot be a large dataset like the CelebA dataset as they intended, but p(x) is limited to a small dataset like SCUT-FBP. The large samples from p(x) are only exploited in the VAE learning part.\n\nThe experimental evaluation is weak: evaluated on only one dataset, compared with just standard VAE and StarGAN which are not aimed for the particular problem setup the authors are considering.\n\nAt least, they may be able to compare it with a baseline approach, e.g., using the samples from p(x|D_i) available from the SCUT dataset (small though), one can learn encoder/decoder models for each D_i.\n\n2) Strengths:\n\nRelatively unique problem (but unusual and unintuitive setup) and a reasonable approach.\n\n3) Weak points:\n\n-The writing is sloppy. It doesn't read very well, and difficult to follow. Contains many typos.\n\n-Weak in experimental evaluation and comparison with other (baseline) approaches.\n\n-There appears to exist identity change in many of face image preference examples.  This is unexpected.  I would be more inclined to believe that personal preferences are about appearance (style) features rather than identify.  Yet most examples in Fig.6 indicate the opposite.\n\n- Writing would benefit from laying out intuition beyond both the model and the experimental results.\n", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}