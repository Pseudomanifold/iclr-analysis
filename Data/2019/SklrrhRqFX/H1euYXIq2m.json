{"title": "Comparison with closely related method is necessary", "review": "Summary\nThis paper propose to learning a dynamics model with future prediction in video and using it for reinforcement learning.\nThe dynamics models is a variants of convolution LSTM and it is trained mean squared error in the future frame.\nThe way of using dynamics model for reinforcement learning is similar to Weber et al., 2017, where K step prediction of the dynamics model is uses as an augmented input of the policy.\n\nStrength\nTraining dynamic model to understand physic and using it for reinforcement learning is an interesting problem that worth exploring. This paper tackles this problem and demonstrated experimental setting based on physics games. \n\nWeakness\nThe part for understanding dynamics model is very close to existing convolutional LSTM model (Xingjian et al., 2015), which is a popular baseline in video modelling community and how pretrained dynamics model is used for reinforcement learning is similar to Weber et al., 2017, but this paper does not provide comparison to any of these two baseline. \nSince the difference with these existing method is subtle, clear comparison with these method and difference in characteristic is essential to show the novelty of the paper. \n\nOverall comment\nThis paper address the interesting problem of understanding dynamics for solving reinforcement learning, but the suggested method is not novel and comparison with existing close methods are not performed.", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}