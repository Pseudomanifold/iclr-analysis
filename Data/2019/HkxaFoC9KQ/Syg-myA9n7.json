{"title": "Interesting analysis and evaluation of self-attention + relation network in RL; question about novelty", "review": "This work presents a quantitative and qualitative analysis and evaluation of the self-attention (Vaswani et al., 2017) mechanism combined with relation network (Santoro et al., 2017) in the context of model-free RL. Specifically, they evaluated the proposed relational agent and a control agent on two sets of tasks. The first one \u201cBox-World\u201d is a synthetic environment, which requires the agent to sequential find and use a set of keys in a simple \u201cpixel world\u201d. This simplifies the perceptual aspect and focuses on relational reasoning. The second one is a suite a StarCraft mini-games. The proposed relational agent significantly outperforms the control agent on the \u201cBox-World\u201d tasks and also showed better generalization to unseen tasks. Qualitative analysis of the attention showed some signs of relational reasoning. The result on StarCraft is less significant besides one task \u201cDefeat Zerglings and Banelings\". The analysis and evaluation are solid and interesting. \n\nPresentation: \nThe paper is well written and easy to follow. The main ideas and experiment details are presented clearly (some details in appendix). \n\nOne suggestion is that it would help if there can be some quantitive characteristics for each StarCraft task to help the readers understand the amount of relational reasoning required, for example, the total number of objects in the scene, the number of static and moving objects in the scene, etc. \n\nEvaluation:\nThe evaluation is solid and the qualitative analysis on the \u201cBox-world\u201d tasks is insightful. Two specific comments below:\n\n1. The idea is only compared against a non-relational \"control agent\u201d. It would be interesting to compare with other forms of relation networks, for example, the ones used in (Santoro et al, 2017). This could help evaluate the effectiveness of self-attention for capturing interactions. \n\n2. The difference between relational and control agent is quite significant on the synthetic task but less so on the StarCraft tasks, which poses the question of what kind of real-world tasks requires the relational reasoning, and what type of relational reasoning is already captured by a simple non-relational agent.  \n\nQuestion about novelty:\n\nThis paper claims it presents \u201ca new approach for representing and reasoning\u2026\u201d. However, the idea of transforming feature map into \u201centity vectors\u201d and self-attention mechanism are already introduced and the proposed approach is more like a combination of both. That being said, the analysis and evaluation of these ideas in RL are new and interesting. \n\nOne minor question: since a level will terminate immediately if a distractor box is opened, does the length of the distractor branches still matter? \n\nDespite the question about novelty, I think the analysis in the paper is solid and interesting. So I support the acceptance of this paper. \n\nMissing references: \nIn the conclusion section, several related approaches for complex reasoning are discussed. It might be also worth exploring the branch of work (Reed & Freitas, 2015; Neelakantan et al, 2015; Liang et al, 2016) that learns to perform multi-step reasoning by generating compositional programs over structured data like tables and knowledge graph. \n\nReed, Scott, and Nando De Freitas. \"Neural programmer-interpreters.\" arXiv preprint arXiv:1511.06279 (2015).\nNeelakantan, Arvind, Quoc V. Le, and Ilya Sutskever. \"Neural programmer: Inducing latent programs with gradient descent.\" arXiv preprint arXiv:1511.04834 (2015).\nLiang, C., Berant, J., Le, Q., Forbus, K. D., & Lao, N. (2016). Neural symbolic machines: Learning semantic parsers on freebase with weak supervision. arXiv preprint arXiv:1611.00020.\n\n\nTypo:\npage 1: \"using using sets...\"", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}