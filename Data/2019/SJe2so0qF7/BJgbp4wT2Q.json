{"title": "Privacy preserving data representation", "review": "This paper studies the problem of representing data records with potentially sensitive information about individuals in a privacy-preserving fashion such that they can be later used for training learning models. Informally, it is expected from the transformed output of data record, one should be able to learn about a desired hidden variable, but should not be able to learn anything about a sensitive hidden variable. To that end, the paper proposes a KL divergence based privacy notion, and an algorithmic approach to learn a representation while balancing the utility privacy trade-off.\n\nI am excited about the choice of the problem, but I have reservations about the treatment of privacy in the paper. First, KL divergence is a very weak (average case) notion privacy that can be easily broken. Second, the algorithm that is outlined in the paper gives an empirical way to compute the representation while balancing the utility-privacy trade-off (Eq. 6). However, there is no formal privacy guarantee for the algorithm. It is important to remember that unlike the utility, privacy is a worst-case notion and should formally hold in all occasions.", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}