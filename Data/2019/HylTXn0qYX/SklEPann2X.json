{"title": "Algorithm for testing local optimality in ReLU networks", "review": "Summary:\nThis work proposes a theoretical algorithm for checking local optimality and escaping saddles when training two-layer ReLU networks. The proposed \"checking algorithm\" involves solving convex and non-convex quadratic programs (QP) which can be done in polynomial time. The paper is well organized and technically correct with detailed proofs.\n\nComments:\n1) Applicability issue: the conditions required by the proposed checking algorithm are too ideal, making it difficult to apply in practical applications. For example, the first step of the proposed algorithm is to check whether 0 belongs to the subdifferential. In practice, the iterates may get very close to a stationary point, but arriving to a stationary point might be too time-consuming and unrealistic. If the problem is smooth, then the gradient is expected to be small so that one can easily relax this first order optimality condition by allowing a small gradient. However, since here the problem is nonsmooth, in general the subgradient could be still very large even when the iterate is very close to a stationary point.  Therefore, one would need to relax the ideal conditions in the proposed algorithm to make it more applicable.\n\n2) Another concern is that the efficiency of the proposed method relies too much on the empirical result that the number of flat extreme ray is small. The computational complexities for the test of the local optimality is exponentially depending on the number of flat extreme rays. Thus to guarantee a high efficiency of the proposed test algorithm and to make the main theory sound, it is important to provide a theoretical bound on this number. Without appropriate theoretical guarantees on the upper-bound of this number, it is not persuasive to claim that the proposed theoretical algorithm is of high efficiency.\n \n3) The computational complexity is proportional to the number of training data points which could be huge. Is it possible to have a stochastic version?\n\nTypos:\n1) On page 2, under Section 2, ``$h(t):=$\" should be ``$h(x):=$\"\n\n2) In section 2.1, at the end of the paragraph \"Bisection by boundary data points\": change $b_1$ by $\\delta_1$ in ``$\\Delta_1x_i+b_1$\".\n\n3) On page 4, when defining B_k, change x by x_i. \n\n4) On page 5, above Lemma 1, when defining C_k, N(x_i) is not well defined.", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}