{"title": "Review", "review": "The paper proposes a new way of defining CNNs for omnidirectional images. The method is based on graph convolutional networks, and in contrast to previous work, is applicable to other geometries than spherical ones (e.g. fisheye cameras). Since standard graph CNNs are unable to tell left from right (and up from down, etc.), a key question is how to define anisotropic filters. This is achieved by introducing several directed graphs that have orientation built into the graph structure.\n\nThe paper is fairly well written, and contains some new ideas. However, the method seems ad-hoc, somewhat difficult to implement, and numerically brittle. Moreover, the method is not equivariant to rotations, and no other justification is given for why it makes sense to stack the proposed layers to form a multi-layer network. \n\nThe results are underwhelming. Only experiments with small networks on MNIST variants are presented. A very marginal improvement over SphericalCNNs is demonstrated on spherical MNIST. I'm confused by the dataset used: The authors write that they created their own spherical MNIST dataset, which will be made publicly available as a contribution of the paper. However, although the present paper fails to mention it, Cohen et al. also released such a dataset [1], which raises the question for why a new one is needed and whether this is really a useful contribution or only results in more difficulty comparing results. Also, it is not stated whether the 95.2 result for SphericalCNNs was obtained from the authors' dataset or from [1]. If the latter, the numbers are not comparable.\n\nThe first part of section 3.2 is not very clear. For example, L^l is not defined. L is called the Laplacian matrix, but the Laplacian is not defined. It would be better to make this section more self contained.\n\nIn the related work section, it is stated that Cohen et al. use isotropic filters, but this is not correct. In the first layer they use general oriented spherical filters, and in later layers they use SO(3) filters, which allows anisotropy in every layer. Estevez et al. [2] do use isotropic spherical filters.\n\nIn principle, the method is applicable to different geometries than the spherical one. However, this ability is only demonstrated on artificial distortions of a sphere (fig 3), not practically relevant geometries like those found fisheye lenses.\n\nIn summary, since the approach seems a bit un-principled, does not have nice theoretical properties, and the results are not convincing, I recommend against acceptance of this paper in its current form.\n\n\n[1] https://github.com/jonas-koehler/s2cnn/tree/master/examples/mnist\n[2] Estevez et al. Learning SO(3) Equivariant Representations with Spherical CNNs", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}