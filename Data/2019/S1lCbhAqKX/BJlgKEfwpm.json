{"title": "An approach for content preservation in style transfer", "review": "The paper proposes a method to address the issue of content-preservation, which is usually not explicitly handled in approaches for unsupervised style transfer. The presented technique consists of extracting nouns from the input sentence (where the nouns are selected using POS tags), and encouraging the model to include the same nouns in the generated sentence, using two different losses: 1) one that comes from a language model conditioned on the nouns in the input sentence 2) one that combines the cosine distance between the input and the generated nouns embeddings. The model is evaluated on two different datasets: sentiment transfer and political slant transfer.\n\nThe use of a language model on the generated sentences was already done in \"Unsupervised Text Style Transfer using Language Models as Discriminators\" from Yang et al. (2018). The difference is that now the language model is conditioned on the input nouns, but the impact of this conditioning is not studied in the paper. It is also not totally obvious to me that a language model conditioned on the average of nouns embeddings will be able to exploit this information (unless there are only a couple of words?). Did you try to generate random tuples of 4 or 5 nouns and see what the language model samples when it is conditioned on the average of these nouns embeddings?\n\nAlthough relatively simple, the model combines a lot of different elements (there are 4 different losses), and the impact of each of them is not really clear. It would have been nice to have a more detailed ablation study to see the impact of each loss. In particular, if the language model is conditioned on the content, why is lambda_POS still needed? Similarly, since you also condition the language model on the style, why is the classifier still needed? L_class and L_pos seem redundant with L_lm.\n\nI was initially confused by the title \"Structured content preservation\" and the section title \"POS preservation constraints\". As far as I understand, the POS tags are only used to select the nouns in input and generated sentences, and are otherwise ignored. Similarly, the label \"POS distance\" in Table 1 seems inaccurate, instead I would rather call this \"nouns distance\". Also, I have a concern about this approach for content preservation. The way the loss works is only a \"soft\" way to ensure that the generated nouns are the same, in the sense that if 2 words have a very similar embedding, their cosine distances with any other word will also be very similar. As a result, if \"orange\" and \"apple\" are very close in the embedding space, and \"orange\" is the word in the input sentence, the model penalty for generating \"apple\" as opposed to \"orange\" will be very small. This is typically what happens for people's names that usually have very similar embeddings, this is why I don't find the explanation in 4.2.2 very satisfying.\n\nFew questions:\n1. The equation 8 is very unclear, I cannot understand what d_i is.\n2. You set \u03b7 to 0.5, \u03b1 to 0.2, and \u03b2 to 0.1. How did you find these hyper-parameters? Did you try other configurations? Although these losses have a different nature, it gives the feeling that the L_pos loss (which is the main novelty of the paper) with the coefficient \u03b2 = 0.1 is the least important one.\n3. Could you show some examples of Political Slant Transfer in Appendix?\n4. In Table 2 you selected 100 random sentences from the test set. The original test set of 500 sentences is already quite small. Could you perform the evaluation on the full 500 sentences? The fact of selecting 100 random sentences will make it difficult for other research groups to reproduce and compare similar experiments.\n\nOverall, I find the overall approach quite incremental. Given the previous studies of Hu et al and Yang et al, the novelty boils down to adding a coefficient L_pos, which I don't find particularly convincing, especially given the absence of ablation study.\n\nTypos:\n\"Yep review\" -> \"Yelp reviews\" (3.3)\n\"BLUE score\" -> \"BLEU score\" (4.1.2 and 4.2.2)\n\"infomration\" -> \"information\" (4.1.2)", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}