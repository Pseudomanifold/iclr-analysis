{"title": "A simple but effective improvement for style transfer", "review": "Structured Content Preservation in Style Transfer\n\nThis paper presents a method for style transfer that using an autoencoder. The autoencoder trained to generate a meaning representation of the sentence. A decoder does the style transfer from this meaning representation. The decoder is trained to minimize style transfer loss and content loss. \n\nThe new contribution here is a content loss (referred to as POS loss in the paper), which serves to penalize models that do not retain nouns in the output. \n\nStrengths:\n\n1. The paper addresses an important problem in style transfer, one of balancing content loss versus changing style. \n2. The experiments include a manual evaluation in addition to automatic evaluation. \n3. The evaluations show that the proposed method is effective compared to style transfer methods that don't include this noun-based content loss.\n\nIssues:\n\n1. The manual evaluation seems to have conflated two dimensions of evaluation into a single rating. Specifically, the evaluation question is:  \u201cWhich sentence has an opposite sentiment of the original sentence and at the same time preserves the content of it?\u201d What happens in cases where A preserves the content but does not style transfer and B transfers style but does not preserve content. Which one would the annotators choose? It would be useful to obtain two ratings and combine them instead of using a single one.\n\n2. The idea of enforcing a content loss is well motivated but the approach considered seems rather heuristic. Selecting nouns is a useful start but as the authors point out that not all content words are nouns, and not all nouns are content words always. It would have been useful to consider other categories and quantify their impact in style transfer. \n\n3. It would have been useful to include an ablation where only the noun lm is used but not the training loss. \n\n4. The main gains come from using nouns as the set of content to preserve.  I wonder if there is a simpler baseline that uses the noun-based restriction also. A simple baseline for this idea could be to rescore beams using the same loss function (at test time only). \n\n5. Is there some information on inter-annotator agreement on this task. I suspect the task is straightforward enough that this might not be an issue but it would be useful to know. \n\n6. The difference in BLEU (Human) between the systems is not that large. However, the difference in terms of the manual evaluation is strikingly large. \nThis kind of variance is observed often in language generation tasks. The authors should consider explaining why this difference is so large with a bit more analysis.\n\n7. Why is the paper titled \"structured\"? It was not obvious to me what kind of structure is being inferred or used in this problem. Also, calling the POS distance is confusing as it seems to indicate that there is some POS tag sequence comparison being done here, which is not the case.\n\nOverall this is a focused contribution that presents a simple yet effective empirical advance on style transfer for two types of tasks. \n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}