{"title": "This paper describes the use of reinforcement learning to learn active learning strategies. This paper attempts to increase the scope of the learning of active learning strategies to transfer across very different datasets.", "review": "This paper presents a laudable attempt to generalize the learning of active learning strategies to learn general strategies that apply across many different datasets that have variables of different, not pre-determined, types, and apply the learned active learning strategies to datasets that are different from what they have been learned with. The paper is written quite clearly and is clear in its discussion of what its advance is beyond the current state of the art.\n\nUnfortunately, the motivation of the details of the algorithm and the experiment analysis leave the paper short of what is needed to truly assess the value of this area of work and; therefore, short of what is needed for publication in ICLR. The most notable shortcoming is on page 4, at the bottom, where the actions are described. Among the components of the actions are statistics related to the dataset---the average distance from the chosen point to all the labeled data, and the average distance from the chosen point to all the unlabeled data. The authors do not provide a motivation for the use of these particular statistics. Additionally, the authors did not explore any other statistics. I should think that statistics relevant to the sparsity of the data (e.g., how well they cluster). Additionally, what distance measure is being used? A variety of distance metrics should be explored, such as d-separation for continuous variables and Hamming distance for discrete variables, should be tested, as they intuitively seem likely to affect the results. Additionally, many values are chosen for the experiments without motivation and without testing a variety of values (e.g., 30 for the size of the dataset used to calculate the reward, 1000 RL iterations, and others).\n\nIn the experiments, there needs to be discussion of how much variety there is in the different datasets in terms of their statistical properties that are relevant to active learning, such as how well the data cluster? That would help in understanding why the new algorithm performs as it does relative to the baseline.\n\nOne relatively minor point: The authors state on page 3, \"For example, the probability that the classifier assigns to a datapoint suits this purpose because most classifiers estimate this value.\" This is a bit misleading---only generative classifiers would do this, not discriminative classifiers.\n\nPros:\n1. Very clear writing.\n2. Good motivation for the general problem.\n3. Precise description of algorithm.\n\nCons:\n1. Poor motivation for the particular algorithm implementation---features used in the actions, parameter values chosen.\n2. Lack of experiments with different choices for features and parameter values.\n3. Lack of assessment of the dataset characteristics and how they relate to algorithm performance.", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}