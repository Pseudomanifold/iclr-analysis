{"title": "Very well written paper, interesting idea, unconvincing experimental results", "review": "This paper proposes a novel method to perform meta-learning for stochastic gradient MCMC. They utilize a general family of SDEs that guarantees preservation of the target density with somewhat loose constraint on the drift and diffusion functions (from Ma et al. (2015)). Then, they propose learning these functions on a set of training tasks and evaluating on unseen, different tasks, in a meta-learning fashion.\n\nThis paper is well written and easy to follow. They do a very good job presenting the motivation for their work as well as seminal work in SG-MCMC. The idea is fairly natural, especially in light of recent success of meta-learning and learning optimizers. They do a thorough survey of related work and also do a good job presenting their method in context of very modern work on MCMC and SG-MCMC.\n\nI am not completely convinced by the meta-training objective; both losses seem natural but quite intractable to compute in practice. The use of Stein indicates that the kernel must probably be *very* carefully crafted and given that the whole method relies on this objective, it seems like this could be a breaking point. I am also curious to know how you diagnostic/evaluate the choice of these kernels.\n\nIn terms of evaluation, the experimental results are not the most convincing given that across the board, they are (except in one case) in 4 case within 0.2% of SGHMC and in the two others, within 0.5% and 0.8% respectively. This seems a bit weak, especially considering the compute invested both at training time and for each SG-MCMC step (i.e. getting the outputs from the neural networks vs simply doing HMC). Is there really a case for using the method over SG-HMC? I would have also very much liked to see a run-time evaluation.", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}