{"title": "A heavily engineered approach which achieves good performance in limited settings", "review": "This paper proposes a model-based object-oriented algorithm, SOORL. \nIt assumes access to an object detector which returns a list of objects with their attributes, an interaction function which detects interactions between objects, and a set of high-level macro actions. Using a simplified state representation obtained through the object detector, it performs optimistic MCTS while simultaneously learning transition and reward models. The method is evaluated on two toy domains, PongPrime and miniPitfall, as well as the Atari game Pitfall. It achieves positive rewards on Pitfall, which previous methods have not been able to do. \n\nDespite good experimental results on a notoriously hard Atari game, I believe this work has limited significance due to the high amount of prior knowledge/engineering it requires (the authors note that this is why they only evaluate on one Atari game). I think this would make a good workshop paper, but it's not clear that the contributions are fundamental or generally applicable to other domains. Also, the paper is difficult to follow (see below). \n\nPros:\n- good performance on a difficult Atari game requiring exploration\n- sample efficient method\n\nCons:\n- paper is hard to follow\n- approach is evaluated on few environments\n- heavily engineered approach\n- unclear whether gains are due to algorithm or prior knowledge\n\n\nSpecific Comments:\n\n- Section 3 is hard to follow. The authors say that they are proposing a new optimistic MCTS algorithm to support deep exploration guided by models, but this algorithm is not described or written down explicitly anywhere. Is this the same as Algorithm 3 from Section 5? They say that at each step and optimistic reward bonus is given, but it's unclear which bonus this is (they mention several possibilities) or how it relates to standard MCTS.\nIn Section 3.1, it is unclear what the representation of the environment is. I'm guessing it is not pixels, but it is discrete states? A set of features? \nThe authors say \"we provided the right model class for both experiments\" - what is this model class? \n\n- Concerning the general organization of the paper, it would be clearer to first present the algorithm (i.e. Section 5), go over the different components (model learning, learning macro actions, and planning), and then group all the experiments together in the same section. \nThe first set of experiments in Sections 3.1 and 3.2 can be presented within the experiments section as ablations.  \n\n- Although the performance on Pitfall is good, it's unclear how much gains are due to the algorithm and how much are due to the extra prior knowledge. It would be helpful to include comparisons with other methods which have access to the same prior knowledge, for example with DQN/A3C and  pseudo-count exploration bonuses using the same feature set and macro actions as SOORL uses. \n\n\nMinor:\n- Page 2: \"Since the model...the new model estimates\": should this be part of the previous sentence?\n- Page 5: \"There are reasonable evidence\" -> \"There is reasonable evidence\"\n- Page 5: \". we define a set of...\" -> \". We define a set of...\"\n- Page 8: \"any function approximation methods\" -> \"method\"", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}