{"title": "Interesting direction, but too preliminary", "review": "The submission describes a system for applying machine learning to interactive theorem proving. The paper focuses on two tasks: tactic prediction (e.g. attempting a proof by induction) and position evaluation (the number of  remaining steps required for a proof). Experiments show that a neural model outperforms an SVM on both tasks, using proof states sampled from a proof of the Feit-Thompson theorem as a dataset. It's great to see work on applying neural networks to symbolic reasoning. The paper is clearly written, and provides helpful background on interactive theorem proving.\n\nThe main weakness of the paper is the limited experiments, which only really show that neural methods outperform an SVM (with only a high level description of the features) - and only on the proof of a single theorem. The paper doesn't explore relevant interesting questions, such as whether the model is helpful for guiding humans or machines in making proofs, or perhaps if the approach can be used to find more human-understandable proofs than those found without training on human data. What are the trade-offs in learning from human proofs instead of automated proofs?\n\nOverall, the paper explores an interesting direction, but I think the current experiments are too preliminary for acceptance.\n\n\n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}