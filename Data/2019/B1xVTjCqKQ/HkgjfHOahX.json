{"title": "Review: An interesting approach to data-driven compressed sensing", "review": "\nThis paper proposes a (CNNs) architecture for encoding and decoding images for compressed sensing. \nIn standard compressed sensing (CS), encoding usually is linear and corresponds to multiplying by a fat matrix that is iid gaussian. The decoding is performed with a recovery algorithm that tries to explain the linear measurements but also promotes sparsity. Standard decoding algorithms include Lasso (i.e. l1 regularization and a MSE constraint) \nor iterative algorithms that promote sparsity by construction. \n\nThis paper instead proposes a joint framework to learn a measurement matrix Phi and a decoder which is another CNN in a data-driven way. The proposed architecture is novel and interesting.  \n\nI particularly liked the theoretical motivation of the used MSE loss by maximizing mutual information. \n\nThe use of parallel convolutions is also neat and can significantly accelerate inference, which can be useful for some applications. \n\nThe empirical performance is very good and matches or outperforms previous state of the art reconstruction algorithms D-AMP and Learned D-Amp. \n\nOn comparisons with prior/concurrent work: The paper is essentially a CNN autoencoder architecture but specifically designed for compressed sensing problems. \nThere is vast literature on CNN autoencoders including (Jiang 2017 and Shi 2017) paper cited by the authors. I think it is fine to not compare against those since they divide the images into small blocks and hence have are a fundamentally different approach. This is fine even if block-reconstruction methods outperform this paper, in my opinion: new ideas should be allowed to be published even if they do not beat SOTA, as long as they have clearly novel ideas. It is important however to discuss these differences as the authors have done in page 2.  \n\nSpecific comments: \n\n1. It would be interesting to see a comparison to D-Amp and LDAmp for different number of measurements or for different SNRs (i.e. when y = Phi x+ noise ). I suspect each method will be better for a different regime?\n\n2. The paper: `The Sparse Recovery Autoencoder' (SRA) by Wu et al. https://arxiv.org/abs/1806.10175\nis related in that it learns both the sensing matrix and a decoder and is also focused on compressed sensing, but for non-image data. The authors should discuss the differences in architecture and training. \n\n3. Building on the SRA paper, it is possible that the learned Phi matrix is used but then reconstruction is done with l1-minimization. How does that perform for the matrices learned with DeepSSRR?\n\n4. Why is Figure 1 going from right to left?\n\n\n\n", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}