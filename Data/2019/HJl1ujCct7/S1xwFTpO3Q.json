{"title": "a combination of categorical latent code a Complementary GAN applied to a proprietary manufacturing dataset", "review": "This paper presents a GAN approach adapted for multi-modal distributions of single class data. The generator is trained to generate samples in the low density areas of the data distribution. The discriminator is training to distinguish between generated and real samples and hence is able to discriminate between normal data (=real) and anomalous data (=generated, in low density areas of the normal data). \n\nTo force the model to map the different modes of the data, a categorical latent variable is used that represents the potential distribution modes. Both a one-hot code and a Gaussian mixture model are explored. This is not a novel approach, however, no citations are provided.\n\nTo force the generator to produce samples in the low density areas of the data distribution, a Complementary GAN is used. The authors cite OCAN [zheng18], which in turns cites [Dai, NIPS17]. This approach has the advantage that no threshold needs to be fine-tuned since the discriminator can directly be used for anomaly detection.\n\nConstraints derived from both these goals are included in the loss function, which, in addition, includes terms to encourage diversity and similarity of the generated samples.\n\nThe model is tested on a proprietary dataset of real manufacturing product. The dimension of the data is 280 (after proprietary feature extraction). The authors compare their approach to 9 other anomaly detection methods. The reported performance is the highest. The OCAN method has similar performance. The authors specify that fine-tuning is need for all other methods (except OCAN). Fine-tuning is performed on the same data used for testing, hence providing a marked advantage. However, I do not understand why OCAN is listed in table 1 with both fine-tuning and no fine-tuning (raw). This is not explained and should be clarified. In any case, the combination of Complementary-GAN and the multi-modal latent variable seem to be very effective on this dataset. To understand whether this approach is really superior, other benchmark datasets should be tested.\n\nThe article is technically sound. The citations are generally ok, except for the missing citation related to the use of latent categorical codes for push the model into mapping multiple modes of the data. The math is reasonable, although some notations are a bit hard to follow. The English needs to be improved. There are many grammatical errors and the paper needs to be proof-read. Some errors make it hard to understand the text. In particular the adjective modal is used throughout the paper as a noun instead of 'mode'. There are also several LaTex formatting errors which lead to some gibberish and some of the figures are too small making them unusable when the paper is printed.\n\nOverall, I think the paper is incremental, as it combines two previously published methods. It also lacks generality as only one (proprietary) dataset is used. English needs to be proof-read and formatting errors fixed.\n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}