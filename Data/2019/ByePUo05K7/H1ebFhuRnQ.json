{"title": "Shape-bias or shortcut-bias and catastrophic forgetting?", "review": "The paper seeks to establish via a series of well-designed experiments that CNNs trained for image classification differ in a fundamental way from human vision \u2013 they don\u2019t encode shape-bias like human vision. Towards this goal, the authors modified the training data with \u2018shortcut\u2019 features to be functions of the category label using single diagnostic pixels and their placements, noise masks (salt and pepper, additive) and their parameters and demonstrate that image categorization CNNs learn whatever statistical features are there in the data most relevant to the learning task.\n\nInvestigation of the properties of neural architectures like CNNs and using the understanding thus developed to create better neural architectures, learning algorithms and training paradigms are good directions for the community and from that perspective, the direction explored in the paper is of great relevance and interest to the community. \n\nThe paper presents careful experimentation to establish that image categorization CNNs learn the statistical features most relevant to the learning task. And, it seems to satisfactorily demonstrate this. It shows that such features could be single pixels, noise masks and even parameters of stochastic distributions which randomly produce these features, as long as the parameters are predictive of the image category. The experiments are well designed and they demonstrate this point quite well. They also demonstrate the well-known problem of catastrophic forgetting.\n\nNonetheless, there are significant drawbacks in the presented work:\n\n1.\tThe experiments don't seem to effectively demonstrate the main claim of the paper that categorization CNNs do not have inductive shape bias (encode shape information). (Let\u2019s make this claim more concrete: categorization CNNs when trained via supervised learning with paired training data of {(image, category_label)} do not have inductive shape bias.)\n\nThe best way to demonstrate this would have been to subject a trained image-categorization CNN to test data with object shapes in a way that the appearance information couldn\u2019t be used to predict the object label. The paper doesn\u2019t do this. None of the experiments logically imply that with an unaltered training regime, a trained network would not be predictive of the category label if shapes corresponding to that category are presented. \n\n2.\tDue to the surprising results (especially the intensity of observed effects), we tried to reproduce some results from the paper in our lab and faced difficulties in doing so:\n\na.\tWe tried to replicate Figure 4(a) 'nopix' and 'same' cases on a standard setting (VGG-12-BN on CIFAR-10). The results deviated significantly (33%-72% margin) on \u2018nopix\u2019 case from the results reported in the paper on a much stronger setting (1/3072 pixels vs 1/50176 as in the paper). Please let me know any crucial settings (see below) that we might have missed.\n\nDetails: We used the vgg-cifar10 repository by chengyangfu. The only additions was fixing the pixel values while sending in the data. The code is anonymized and hosted here: https://file.io/qiziAK. The pixel values in CIFAR-10 using the pytorch dataloader are between [-0.45, 0.45] theoretically, typically much smaller. We set the (0,0) RGB pixels categorically spacing it uniformly from [-0.25, 0.25), [-0.025, 0.025), [-0.0025, 0.0025) as a simple experiment. The third case did not suffer any decrease in the nopix case or any increase in the pix at all. The first case showed significant deviations from the claimed results with the no-pix resulting in ~43% accuracy which is 33% off vis-\u00e0-vis the results in the paper. The \u2018same\u2019 setting didn\u2019t achieve 100% either though it got close - achieving 98.4%. \n\nSummary: The paper presents an important line of investigation to understand the properties of CNNs. However, it fails to effectively demonstrate its main claim. Further, we had difficulties in reproducing the results. As it stands, the submission is not of publishable quality.\n\nI encourage the authors to do more careful experimentation to demonstrate their main claim and perhaps work on strategies to encourage CNNs to learn more meaningful features, including \u2018shape\u2019-features and submit to a future conference.\n\nRevision: Updated my rating to acknowledge that the reproducibility issue is addressed.", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}