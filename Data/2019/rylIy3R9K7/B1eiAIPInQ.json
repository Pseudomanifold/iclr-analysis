{"title": "Interesting Analysis GANs' Learning Dynamics in a Limited Setting", "review": "This paper analyses the learning dynamics of GANs by formulating the problem as a primal-dual optimisation problem. This formulation assumes a limited class of models -- Wasserstein GANs with discriminators using linear combinations of base functions. Although this setting is limited, it advanced our understanding of a central problem related to GANs, and provides intuition for more general cases. The paper further shows the same analysis can be applied to multi-task learning and distributed learning.\n\nPros:\n\n* The paper is well written and well motivated\n* The theoretical analysis is solid and provide intuition for more complex problems\n\nCons:\n\n* The primal-dual formulation assumes Wasserstein GANs using linear discriminator. This simplification is understandable, but it would be helpful to at least comment on more general cases.\n\n* Experiments are limited: only results from GANs with LQG setting were presented. Since the assumption of linear discriminator (in basis) is already strong, it would be helpful to show the experimental results from this more general setting.\n\n* The results on multi-task learning were interesting, but the advantage of optimising the mixing weights was unclear compared with the even mixture baseline. This weakens the analysis of the learning dynamics, since learning the mixing did not seem to be important.\n\nIt would also be helpful to comment on recently proposed stabilising methods. For example, would spectral normalisation bring learning dynamics closer to the assumed model?", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}