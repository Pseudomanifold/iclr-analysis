{"title": "Weak reject: Incremental work and insufficient experiments.  ", "review": "This paper proposes new heuristics to prune and compactify neural networks. The heuristics try to consider 1) filter weight and gradient normalization by their size, 2) saliency normalization across layers, 3) saliency accumulation across batch. The author claims that these can address problems previous studies had and experimental results show that the proposed method achieve higher compression ration with less loss of accuracy.\n\nThis paper discusses how to determine the importance of filters. As cited in the paper, there have been various attempts to tackle the same problem and the paper contributes to the series of efforts. The paper introduces a new way to compute such importance values based on their observations. The method is tested on a few dataset and a various models and compared with some previous studies. I like the simple but yet effective method, however, I think it is not good enough for ICLR. \n\n1. What is effective is not very clear.\n\nThe paper pointed out issues of previous studies and proposed the new method based on the observations. However, only the final method is compared with other work and it did not examine which part of the method was essential. The paper needs more detailed analyses on the proposed method. For example, the readers would want to know if the normalization in Eq. (2) is really important or not. The readers would be also interested in a visualization like Fig. 2 without saliency normalization. \n\n2. The numbers of previous studies come only from their papers.\n\nIt is very difficult to know if the proposed method is actually better than the previous methods if the numbers just come from their papers. We want to compare the ideas, but not numbers. The essential ideas of other papers need to be abstracted and tested in the paper by itself. It relates to the first item above. \"Baseline\" should be a baseline method but not models without pruning.\n\nNumbers from other papers are still useful to show that the numbers in the paper are good in an absolute manner.\n\n3. Weak theoretical reasoning\n\nEq. (1) in the paper is not actually used for optimization while some previous methods do. If the proposed method is better than other methods which directly optimizes the loss, should we think that the formulation itself is bad? \n\nThe paper discusses imbalanced pruned pruning results. It needs to show that it is actually bad.\n\n* minor things\n\n** Table 1: Should the first row of \"Wen et al. (2016)\" have \"5-19\" and \"1-5\" or \"4-19\" and \"1-4\" for \"Filters\" and \"Channels\", respectively?\n\n** I'd recommend another proofreading.", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}