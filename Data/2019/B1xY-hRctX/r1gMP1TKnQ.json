{"title": "interesting directions but unclear novelty and some claims that are too strong", "review": "The paper introduces Neural Logic Machines, a particular way to combine neural networks and first order but finite logic. \n\nThe paper is very well written and structured. However, there are also some downsides.\n\nFirst of all, Section 2.1 is rather simple from a logical perspective and hence it is not clear what this gets a special term. Moreover, why do mix Boolean logic (propostional logic) and first order logic? Any how to you deal with the free variables, i.e., the variables that are not bounded by a quantifier? The semantics you define later actually assumes that all free variables (in your notation) are bounded by all quantifiers since you apply the same rule to all ground instances. Given that you argue that you want a neural extension of symbolic logic (\"NLM is a neural realization of (symbolic) logic machines\") this has to be clarified as it would not be an extension otherwise. \n\nFurthermore, Section 2.2 argues that we can use a MLP with a sigmoid output to encode any joint distribution. This should be proven. It particular, given that the input to the network are the marginals of the ground atoms. So this is more like a conditional distribution? Moreover, it is not clear how this is different to other approaches that encode the weight of weighted logical rule (e.g. in a MLN) using neural networks, see\ne.g. \n\nMarco Lippi, Paolo Frasconi:\nPrediction of protein beta-residue contacts by Markov logic networks with grounding-specific weights. \nBioinformatics 25(18): 2326-2333 (2009)\n\nNow of course, and this is the nice part of the present paper, by stacking several of the rules, we could directly specify that we may need a certain number of latent predicates. \nThis is nice but it is not argued that this is highly novel. Consider again the work by Lippi and Frasconi. We unroll a given NN-parameterized MLN for s fixed number of forward chaining steps. This gives us essentially a computational graph that could also be made differentiable and hence we could also have end2end training. The major difference seems to be that now objects are directly attached with vector encodings, which are not present in Lippi and Frasconi's approach. This is nice but also follows from Rocktaeschel and Riedel's differentiable Prolog work (when combined with Lippi and Frasconi's approach).\nMoreover, there have been other combinations of tensors and logic, see e.g. \n\nIvan Donadello, Luciano Serafini, Artur S. d'Avila Garcez:\nLogic Tensor Networks for Semantic Image Interpretation. \nIJCAI 2017: 1596-1602\n \nHere you can also have vector encodings of constants. This also holds for \n\nRobin Manhaeve, Sebastijan Dumancic, Angelika Kimmig, Thomas Demeester, Luc De Raedt:\nDeepProbLog: Neural Probabilistic Logic Programming. CoRR abs/1805.10872 (2018)\n\nThe authors should really discuss this missing related work. This should also involve\na clarification of the \"ILP systems do not scale\" statement. At least if one views statistical relational learning methods as an extension of ILP, this is not true. Probabilistic ILP aka statistical relational learning has been used to learn models on electronic health records, see e.g., the papers collectively discussed in \n\nSriraam Natarajan, Kristian Kersting, Tushar Khot, Jude W. Shavlik:\nBoosted Statistical Relational Learners - From Benchmarks to Data-Driven Medicine. Springer Briefs in Computer Science, Springer 2014, ISBN 978-3-319-13643-1, pp. 1-68\n\nSo the authors should either discuss SRL and its successes, separating SRL from ILP, or they cannot argue that ILP does not scale. In the related work section, they decided to view both as ILP, and, in turn, the statement that ILP does not scale is not true. Moreover, many of the learning tasks considered have been solved with ILP, too, of course in the ILP setting. Any ILP systems have been shown to scale beyond those toy domains.   \nThis also includes the blocks world. Here relational MDP solvers can deal e.g. with BW worlds composed of 10 blocks, resulting in MDPs with several million states. And the can compute relational policies that solve e.g. the goal on(a,b) for arbitrary number of blocks. This should be incorporated in the discussion of the introduction in order to avoid the wrong impression that existing methods just work for toy examples. \n\nComing back to scaling, the current examples are on rather small datasets, too, namely <12 training instances. Moreover, given that we learn a continuous approximation with a limit depth of reasoning, it is also very likely that the models to not generate well to larger test instances. So the scaling issue has to be qualified to avoid to give the wrong impression that the present paper solves this issue. \n\nFinally, the BW experiments should indicate some more information on the goal configuration. This would help to understand whether an average number of moves of 84 is good or bad. Moreover, some hints about the MDP formulation should be provided, given that there have been relational MDPs that solve many of the probabilistic planning competition tasks. And, given that the conclusions argue that NLMs can learn the \"underlying logical rules\", the learned rules should actually be shown. \n\nNevertheless, the direction is really interesting but there several downsides that have to be addressed. ", "rating": "5: Marginally below acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}