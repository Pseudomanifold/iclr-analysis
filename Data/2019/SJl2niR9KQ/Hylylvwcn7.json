{"title": "Good paper, but please address questions ", "review": "The paper demonstrates a method for constructing adversarial examples by modifications or perturbations to physical parameters in the scene itself---specifically scene lighting and object geometry---such that images taken of that scene are able to fool a classifier. It achieves this through a novel differentiable rendering engine, which allows the proposed method to back-propagate gradients to the desired physical parameters. Also interesting in the paper is the use of spherical harmonics, which restrict the algorithm to plausible lighting. The method is computationally efficient and appears to work well, generating plausible scenes that fool a classifier when imaged from different viewpoints.\n\nOverall, I have a positive view of the paper. However, there are certain issues below that the authors should address in the rebuttal for me to remain with my score of accept (especially the first one):\n\n\n- The paper has no discussion of or comparisons to the work of Athalye and Sutskever, 2017 and Zeng et al., 2017, except for a brief mention in Sec 2 that these methods also use differentiable renderers for adversarial attacks. These works address the same problem as this paper---computing physically plausible adversarial attacks---and by very similar means---back-propagation through a rendering engine. Therefore it is critical that the paper clarifies its novelty over these methods, and if appropriate, include comparisons.\n\n- While the goal of finding physically plausible adversarial examples is indeed important, I disagree with the claim that image-level attacks are \"primarily tools of basic research, and not models of real-world security scenarios\". In many applications, an attacker may have access to and be able to modify images after they've been captured and prior to sending them through a classifier (e.g., those attempting to detect transmission of spam or sensitive images). I believe the paper can make its case about the importance of physical adversarial perturbations without dismissing image-level perturbations as entirely impractical.\n\n- The Athalye 18 reference noted in Fig 1 is missing (the references section includes the reference to Athalye and Sutskever '17).\n\n===Post-rebuttal\n\nThanks for addressing my questions. With the new comparisons and discussions wrt the most relevant methods, I believe the contributions of the paper are clearer. I'm revising my score from 6 to 7.\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}