{"title": "some interesting observations", "review": "The paper states that basic transformation (translation and rotation) can easily fool a neural network in image classification tasks. Thus, image classification models are actually more vulnerable than people thought. The message conveyed by the paper is clear and easy to get. The experiments are natural and interesting. Some interesting points:\n  --The model trained with data augmentation that covers the attack space does not alleviate the problem sufficiently.\n  --Gradient descent does not provide strong attack, but grid search does. This may be due to the high non-concavity, compared to the small perturbation case.\n\nOne possible question is the novelty, as this idea is so simple that probably many people have observed similar phenomenon--but have not experimented that extensively. \nAlso, there are some related works that also show the vulnerability under spatial transformations. But some are concurrent works to 1st version of the paper (though published), so I tend to not to judge it by those works.  \n\nOther comments: \n1. page 3 in the paragraph starting with \u2018We implement \u2026\u2019, the author chooses a differentiable bilinear interpolation routine. However, the interpolation method is not shown or explained. \n2. In term of transformation, scaling and reflecting are also transformations. It should be straightforward to check the robustness with respect to them. Comments? \n3. Header in tables is vague. Like \u2018Natural\u2019 or \u2018Original\u2019, etc. More description of the Header under tables is helpful.\n4. For CIFAR10 and especially for ImageNet dataset, Aug30 and Aug40 models showed lower accuracy\u00a0than No Crop model\u00a0on Nat test set. This is little strange because data augmentation (such as random rotation) is commonly used strategy to improve test accuracy. I think this might mean that the model is not trained enough and underfitted, maybe because excessive data augmentation lowered the training speed.\n", "rating": "6: Marginally above acceptance threshold", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}