{"title": "Nice but straightforward idea to attack graph CNNs; paper not always well-written", "review": "The main idea of this paper is that a 'realistic' way to attack GCNs is by adding fake nodes. The authors go on to show that this is not just a realistic way of doing it but it can done in a straightforward way (both attacks to minimize classification accuracy and GAN-like attacks to make fake nodes look just like real ones). \n\nThe idea is neat and the experiments suggests that it works, but what comes later in the paper is mostly rather straightforward so I doubt whether it is sufficient for ICLR. I write \"mostly\" because one crucial part is not straightforward but is on the contrary, incomprehensible to me.  In Eq (3) (and all later equations) , shouldn't X' rather than X be inside the formula on the right? Otherwise it seems that the right hand side doesn't even depend on X' (or X_{fake} ). \nBut if I plug in X', then the dimensions for weight matrices  W^0 and W^1 (which actually are never properly introduced in the paper!) don't match any more. So what happens? To calculate J you really need some extra components in W0 and W1. Admittedly I am not an expert here, but I figure that with a bit more explanation I should have been able to understand this. Now it remains quite unclear...and I can't accept the paper like this.\n\nRelatedly, it is then also unclear what exactly happens in the experiments: do you *retrain* the network/weights or do you re-use the weights you already had learned for the 'clean' graph? \n\nAll in all: \nPRO:\n- basic idea is neat \nCON:\n- development is partially straightforward, partially incomprehensible.\n\n(I might increase my score if you can explain how eq (3) and later really work, but the point that things remain rather straightforward remains). ", "rating": "3: Clear rejection", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}