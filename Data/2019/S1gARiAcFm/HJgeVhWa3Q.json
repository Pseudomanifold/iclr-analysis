{"title": "Modelling dynamics of biological data with deep Neural Networks (NN)", "review": "This paper tackles the important challenge of making sense of temporal measurements made in biological systems. Among other, those have the peculiarity that they are not independent but with a dependency structure, which can be encoded as a graph or a network. The authors claim that their approach, DyMoN is adapted to the many challenges of biological high-throughput data sets: noise, sparsity and lack of temporal resolution. The paper presents three very different use of the method in complex biological systems in Section 3: (i) Calcium imaging of visual cortex neurons, (ii) T--cell development in the thymus, and (iii) Human embryonic stem cell differentiation. Section 4 assesses the performance of the method on simulated data sets as well as on a face-recognition data set. Moreover, the authors demonstrate how the features of the NN can be interrogated to shed new insight about the process under scrutiny. They also show the gain in running time a comapred to other approaches.\n\nRemarks:\n - I know very little about the literautr in the subject, could you clarify how your work relates to/can be distinguished from: Testolin and Zorzi, Front Comput Neurosci. 201, Kiegeskorte's Ann. Rev. Vis. Sc. 2015 (https://doi.org/10.1146/annurev-vision-082114-035447), Kai Fan's PhD work (@ Duke University), Betzel and Bassel, Interface 2017, Wang et al. bioRxiv 2018 (https://doi.org/10.1101/247577), etc.\n - l-4p2: 'repetitions': what are those? Line below: 'sufficient for estimating $ P_{x}(y) $, means large sample size, no? No contradictory? And one line below: what is the precise meaning of 'similar' (twice)?\n - top p3: line continued from bottom of p2 -> is it to rubber out noise?\nwhat is $ n $ in $ \\mathbb{R}^{n} $?\n - Make Fig 1 (B) and (C) clearer, since the transition vectors are learnt, why are they in (B) (input states)?\n - below \"...distribution approximates the distribution $ \\mathcal{P}_{x} $...\" -> but $ P_{x} $ also depends on $ \\theta $, not an issue?\n - remark at the end of Section 2: extending DyMoN to higher-order: OK, but this might be computationally VERY expensive, don't you think?\n - link how your empirical validation data have features that, even remotely resemble those of the kind of biological data sets (on which no ground truth exist, I sympathise) you focus on.", "rating": "6: Marginally above acceptance threshold", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}