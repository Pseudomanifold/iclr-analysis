{"title": "Official review", "review": "This paper presents a spatiotemporal convolutional autoencoder trained for video compression. The basic model follows the logic of traditional autoencoders, with an intermediate quantizer:\n\ninput -> convolutional neural network with a skip connection as an encoder -> quantizer -> transposed convolutional neural network with a skip connection as a decoder.\n\nAs the quantizer is a non-differentiable operation, the paper proposes to follow (Toderici et al  2016, Balle et al, 2018) and cast quantization as adding uniform noise to the latent variables. The pre-quantized variables are modelled as Gaussians with variance that is predicted by a second \"hyperprior\" network dedicated to this task. The final model is trained to minimize three losses. The first loss minimizes the difference between the true frame pixel values and the predicted pixel values. The second loss minimizes the entropy of the latent codes. The third loss minimizes the difference between neighboring pixels in subsequent frames, ignoring those pixels that are not linked between frames. The model is trained on 10,000 videos from the Youtub-8M dataset and tested on 10 videos from the MCL-V database, with rather ok results.\n\nGenerally, parts of the proposed approach sound logical: an autoencoder like architecture makes sense for this problem. Also, the idea of using uniform noise to emulate quantization is interesting.  However, the paper has also weaknesses.\n\n- The added novelty is limited and unclear.  Conceptually, the paper is overclaiming. Quoting verbatim from the conclusion: \"Our work is, as far as we are aware, the first end-to-end learned video compression architecture using DL.\", while already citing few works that also rely on deep networks (Wu et al., 2018, Chen et al., 2016). In the related work section it is noted that these works are computationally heavy. However, this doesn't mean they are not end-to-end. The claims appear to be contradicting.\n\n- The technical novelty is also limited. What is new is the combination of existing components for the task of video compression. However, each component in isolation is not novel, or it is not explained as such.\n\n- Parts of the model are unclear. How is the mask M computed in equation (7)? Is M literally the optical flow between frames? If yes, what is the percentage of pixels that is zeroed out? Furthermore, can one claim the model is fully end to end, since a non-differentiable optical flow algorithm is used?\n\n- The purpose of the hyperprior network is unclear. Why not use a VAE that also returns the variance per data point?\n\n- Most importantly, it is not clear whether the model is trained as a generative one, e.g., with using a variational framework to compute the approximate posterior. If the model is not generative, how can the model be used for generation? Isn't it then that the decoder simply works for reconstruction of already seen frames? Is there any guarantee that the model generalizes well to unknown inputs? The fact that the model is evaluated only on 10 video sequences does not help with convincing with the generalization.\n\n- The evaluation is rather weak. The method is tested on a single, extremely small dataset of just 10 videos. In this small dataset the proposed method seems to perform worse in the majority of compression ratios (bits per pixel). The method does seem to perform a bit better on the very low bits per pixel regime. However, given the small size of the dataset, it is not clear whether these results suffice.\n\n- Only two baselines are considered, both hand-crafted codecs: H.264/AVC and MPEG-4. However, in the related work section there are works that could also be applied to the task, e.g., the aforementioned ones. Why aren't these included in the comparison?\n\n- Although it is explained that the focus is on the very low bitrates, it is not clear what part of the model is designed with that focus in mind. Is this just a statement just so to focus on the part of the curve in the experiment where the proposed method is better than the reported baselines? Is there some intrinsic model hypothesis that makes the model suitable for low bit rates?\n\nIn general, the paper needs to clarify the model and especially explain if it is (or not a generative one) and why. Also, a more extensitve arrays of experiments need to be executed to give a better outline of the methods capabilities and limitations.\n", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}