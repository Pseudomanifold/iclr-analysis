{"title": "Interesting paper, but maybe less significant than it appears to be", "review": "This paper attempts to account for the success of SGD on training deep neural networks. Starting from two empirical observations: (1) deep neural networks can almost achieve zero training loss; (2) the path of iterates generated by SGD on these models follow approximately the \u201cstar convex path\u201d, under the assumptions that individual functions share a global minima with respect to which the path of iterates generated by SGD satisfies the star convexity properties, the papers shows that the iterates converges to the global minima. \n\nIn terms of clarity, I think the paper can definitely benefit if the observations/assumptions/definitions/theorems are stated in a more formal and mathematically rigorous manner. For example:\n- On page 3, \u201cfact 1\u201d: I don\u2019t think \u201cfact\u201d is the right word here. \u201cFact\u201d refers to what has been rigorously proved or verified, which is not the case for what is in the paper here. I believe \u201cobservation\u201d is more appropriate. Also the assumption that l_i is non-negative should be formally added.\n- On page 3, section 3.1: the x^* here is the last iteration produced by SGD. Then how can it be called the \u201cglobal minima\u201d? The caption of Figure 1 on page 4 is simply misleading.\n- On page 4, the statement in definition 1 is more like a theorem than a definition. It is giving readers the impression that any path generated by SGD satisfies the star-convex condition, which is not the case here. A definition should look like \u201cwe call a path generated by SGD a star-convex path if it satisfies \u2026\u201d. Definition 2 on page 6 has the similar issue.\n\nIn terms of quality, while I believe the paper is technically correct,  I have one minor question here:\nPage 3, Fact 1: How can you conclude that the set of common global minimizers are bounded? In fact I don\u2019t believe this is true at all in general. If you have a ReLu network, you can scale the parameters as described in [1], then the model is invariant. Therefore, the set of common minimizer is definitely NOT bounded. \n\nIn terms of significance, I think this paper is very interesting as it attempts to draw the connection between the aforementioned observations and the convergence properties of SGD. Unfortunately I think that this paper is less significant than it has appeared to be, although the analysis appears to be correct. \n\nFirst of all, all the analysis of this paper is based on one very important and very strong assumption, namely, all individual functions $l_i$ share at least one common global minimizer. The authors have attempted to justify this assumption by empirical evidences (figure 1). However, achieving near-zero loss is completely different from achieving exact zero because only when the model achieves exact zero can you argue that a common global minimizer exists. \n\nSecondly, the claim that the iterate converges to the global minima is based on the assumption that the path follows an \u201cepoch-wise star-convex\u201d property. From this property, it only takes simple convex analysis to reach the conclusion of theorem 1 and 2. Meanwhile, the assumption that the path does follow the \u201cepoch-wise start-convex\u201d properties is not at all informative. It is not clear why or when the path would follow such a path. Therefore theorem 1 and 2 are not more informative than simply assuming the sequence converges to a global minimizer. \n\nIn fact, it is well-known that SGD with constant stepsize converges to the unique minimizer if one assumes the loss function F is strongly convex and the variance of the stochastic gradient g_k is bounded by a multiple of the norm-square of the true gradient:\nVar(g_k) <= M ||\u2207F(x_k)||^2\nWhich is naturally satisfied if all individual functions share a common minimizer. Therefore, I don\u2019t think the results shown in the paper is that surprising or novel. \n\nWith respect to the empirical evidence, the loss function l_i is assumed to be continuously differentiable with Lipschitz continuous gradients, which is not true for networks using ReLU-like activations. Then how can the paper use models like Alexnet to justify the theory? Also, if what the authors claim is true, then the stochastic gradient would have vanishing variance as it approaches x^*. Can the authors show this empirically?\n\nIn summary, I think this paper is definitely interesting, but the significance is not as much as it would appear.\n\nRef: \n[1] Dinh, L., Pascanu, R., Bengio, S., & Bengio, Y. (2017). Sharp minima can generalize for deep nets. arXiv preprint arXiv:1703.04933.", "rating": "5: Marginally below acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}