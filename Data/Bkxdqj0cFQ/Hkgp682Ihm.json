{"title": "Review", "review": "Strength: \n\nIntuition that multiple sources of uncertainty are relevant to adversarial examples \n\nWeaknesses:\n\nThreat model is unclear\nNo adaptive adversaries are considered\nAttack parameters could be better justified\n\nThe intuition presented at the beginning of Section 4 is interesting. There are indeed multiple sources of uncertainty in machine learning, and the softmax probability only captures confidence partially. In particular, estimating the support of training data for a particular prediction and the density of that support is conceptually relevant to understanding and mitigating outlier test points like adversarial examples. \n\nGiven that the approach is motivated as a defense (see Section 7 for instance), it needs to be evaluated in a realistic adversarial setting. In particular, it would greatly strengthen the paper if a clear threat model was specified. In your rebuttal, would you be able to formulate clearly what adversarial capabilities and goals were assumed when designing this defense? \n\nAll experiments are performed on a binary variant of CIFAR-10. In addition, all pairs chosen for the experiments are well-separated: dogs are semantically further apart from airplanes than they are from horses. Would you be able to clarify in your rebuttal how the approach would generalize to multi-class classification? \n\nPerhaps the strongest limitation of the evaluation is that it does not consider adaptive adversaries. This goes back to the threat model point raised previously. Adaptive strategies will be put forward by adversaries aware of the defense being deployed (security should not be obtained through obscurity). For instance, the adversary could modify their attack to have it minimize the difference between logits on the training and adversarial data. This would help evading detection by the proposed scheme. However, results from Section 6 are shown for attacks that do not attempt to reduce the L1 difference between adversarial and training data. \n\nSome attack parameters could also be better justified. The naming convention for the perturbation sizes reads a bit imprecise and is perhaps more confusing than it is informative. Furthermore, could you explain in your rebuttal why epsilon is larger than 1.0 for the FGSM---when the inputs where normalized between 0 and 1?\n\nDetails: \n\nPage 1: Typo in \u201cdefence\u201d\nPage 2: Notation s_i is overloaded multiple times making it difficult to parse expressions\nPage 2: Citation to Kull et al. should use \\citep after \u201cBeta calibration\u201d\nPage 3: Citation to Rozsa et al. should use \\citep after \u201cPASS score\u201d\nPage 5: Generally-speaking, it\u2019s best to compute attacks at the logit layer rather than the probabilities to avoid numerical instabilities, which can then lead to gradient masking. However, the following sentence suggests the opposite: \u201cThe attacks were all white-box attacks and performed on the network which included a final softmax layer in its structure.\u201d\n", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}