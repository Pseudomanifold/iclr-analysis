{"title": "A interesting Ideas, but the evaluation is not enough. ", "review": "This paper presents a retriever-reader model for open domain QA, which follows the pipeline of 1) selecting the keywords/essential terms of a question; 2) retrieving related evidence for passage construction; and 3) predicting final answer via a proposed attention-enhanced reader.  \n\nAlthough the proposed method achieves the good performance on ARC, I have concerns about both of the model design and evaluations.  \n\nI am wondering how useful the essential term selection is?  The module is trained as a separate binary sequence tagging task on the dataset of Khashabi.   I am wondering the difference between the Khashabi's dataset and these datasets used for evaluation in this paper.   Authors need to show how well the trained essential term selection module on Khashabi can be transferred on the question of ARC, RACE, etc.   In the paper, authors mentioned that they removed questions of that less than a specific number of words for both RACE and MCScript dataset to ensure a sufficient number of retrieved data.   Such a kind of data manipulation is unacceptable and unfair to other baseline methods.   Authors need to demonstrate the generated essential terms on these short questions.  My guess is that the essential term selection fails on these short questions due to the mismatch between the source dataset it trained on and the target dataset.   The ablation study in table 8 does not convince me that the essential term selection has a significant effect.  \n\nThe novelty in terms of the RC model of this paper is limited.   Authors claim one of their contributions is the design of the attention and fusion layers that aggregates information among questions, passages, and answers choices.  However, the design is heuristic, complex and without any intuition.   Three Match-LSTM-like sequence encoders are used for sequence modeling, which makes the number of the parameters of the model large (authors needs to report the total number of parameters of their model for the experiment).   The sequence encoder is followed by the fusion layer, choice interaction and the output layer.    I cannot identify the significance of each of the design to the final performance.  Although authors had an ablation study shown in table 6, it is hard to understand.  ", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}