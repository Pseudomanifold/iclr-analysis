{"title": "Review for ABM-Nets", "review": "In this work, the authors tackle the problem of few-shot learning and open-set classification using a new type of NNs which they call alignment-based matching networks or ABM-Nets for short. They main idea is to benefit from binary maps between the query image and the support set (for the case of few-shot learning for the sake of discussion here) to guide the similarity measure. \n\nI have quite a few concerns;\n\n- After reading the paper two times, I still couldn't find a clear explanation as how the binary map C is constructed. The paper says the cost of M,i,j,k = 1 is C. So what exactly happens given I_t and I_k. My understanding is that a vector representation of each image is obtained and then from those representations the matrix C is constructed (maybe an outer product or something). This does not come out clearly. \n\n- Nevertheless, I suspect if such a construction (based on my understanding) is the right approach. Firstly, I guess the algorithm should somehow encourage to match more points between the images. Right now the loss  does not have such a term so hypothetically you can match two images because they just share a red pixel which is obviously not right. \n\n- Aside from the above (so basically regularizing norm(C) somehow), one wonders why matching a point to several others (as done according to matrix C) is the right choice. \n\n- Related to the issues mentioned before, I may also complain that matching far away points might not be ideal. Currently I do not see how this can be avoided nor a solid statement as why this should not be a problem.  \n\n\n- Another comment is how the alignment here differs from attention models? They surely resemble each-other though the alignment seems not that rich.\n\n\n-  last but not least, I have found the language confusing. Some examples,\n   -p2 bandwidth signal than the traditional label-only signal : I am very confused by how bandwidth comes to the picture and how this can be measured/justified\n\n  - fig.1, what are \\phi and \\psi. paper never discussed these.\n\n  - the authors say M is a tensor with 3dimensions. Then the marginalization before eq.1 uses M_{i,\\cdot,\\cdot} = 1 . What does this really mean?\n\n    ", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}