{"title": "point wise embedding (+) with greedy matching (-)", "review": "Authors argue that using average (independent) greedy matching of pixel embedding (based on 4-6 layer cnn hypercolumns) is a better metric for one-shot learning than just using final layer embedding of a 4-6 layer cnn for the whole image.  Their argument is backed by outperforming their baseline and getting competitive results on few shot learning tasks. Their method is much more computationally heavy than the baseline matching networks. In order to make training feasible, in practice they train with 90% dropout of test pixels embedding & 80% dropout of reference pixels embedding. \n\n\nThe caveats: \n-> Using hyper-columns is related to adding residual connections. The question remains how much performance can be gained by just adding residual connections (with dropout) to the matching networks and letting the network automatically (or with a probability) choose to embed higher layers or lower ones. Adding the residual connection and just comparing the final layer embeddings is a cleaner method than ABM which  provides a richer embedding than baseline and could potentially close the performance gap between ABM and final layer matching.\n\n->It is strictly designed for one-shot learning. It does not benefit from few shots (extra shots) and the fact that these different shots are getting classified as the same label. Vinyal et al mitigates this shortcoming by adding the FCE. However FCE is not directly applicable anymore. Author\u2019s don\u2019t suggest any alternatives either. Their smaller gains (or even worse than baseline without self-regularization) in the 5-shot cases is an evidence of this shortcoming. \n\nThe fact that SNAIL (TCML Mishra et al. (2017)) consistently outperforms this method puts a question mark on the significance of this work. If it was computationally feasible, authors could have used SNAIL and replaced the 64 dimensional embedding of each picture with the 10-20% hypercolumns. Essentially due to computational costs authors are sacrificing a more thorough matching system (non-greedy) for a richer embedding and they don\u2019t get better results. \n\n\nOn the other hand, authors may argue that the hyper-column matching is not just about performance, whereas it also adds interpretability to why two images are categorized the same. Illustrations like fig. 3 for example shows that the model is not matching semantically similar points and can be used to debug & improve the model. While understanding why a blackbox matching network is making a mistake and improving, is  harder. \nIt would have been nice if authors used this added interpretability in some manner. Such as getting an idea about a regularizer, a prior, a mask, etc. and improved the performance.\n\nI would argue for accepting this paper for two reasons.\n-> Given that they beat their baseline and  they get comparable performance to sota even with a greedy matching (min-pooling followed by average pooling), is impressive. Furthermore, it is orthogonal to methods like SNAIL if the computational cost could be resolved.\n\n-> They not only provide which image is a match but how they are matched, which could be interesting for one-shot detection as well as classification. \n\n\nQuestion: At test/validation: do you still only categorize with 10,20% samples or do you average the full attention map for all test pixels?\n\n\nNit: The manuscript needs several passes of proofreading, spell & grammar checking. A few examples in the first couple of pages:\n-> The citing format needs to be fixed (like: LSTMsRavi, there should be () around citations). \n-> are not incompatible: are compatible\n->incomprehensible sentence with two whiles: ABM networks outperforms these other state-of-the-art models on the open-set recognition task while in the one-shot setting by achieving a high accuracy of matching the non-open-set classes while maintaining a high F1 score for identifying samples in the open-set. \n-> add dots to the end of contribution list items.\n-> we first look pairwise matchings: we first look at the pairwise matchings\n", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}