{"title": "recommending rejection because of lack of analyses and questionable novelty", "review": "The authors propose to use k-DPP to select a set of diverse parameters and use them to search for a good a hyperparameter setting. \n\nThis paper covers the related work nicely, with details on both closed loop and open loop methods. The rest of the paper are also clearly written. However, I have some concerns about the proposed method.\n- It is not clear how to define the kernel, the feature function and the quality function for the proposed method. The choices of those seem to have a huge impact on the performance. How was those functions decided and how sensitive is the result to hyperparameters of those functions?\n- If the search space is continuous, what is the mixing rate of Alg. 2? In practice, how is \"mixed\" decided? What exactly is the space and time complexity? I'm not sure where k log(N) comes from in page 7.  \n- Alg. 2 is a straight forward extension of Alg. 1, just with L not explicitly computed. I think it would have more novelty if some theoretical analyses can be shown on the mixing rate and how good this optimization algorithm is. \n\nOther small things:\n- citation format problems in, for example, Sec. 4.1. It should be \\citep instead of \\cite. \n- it would be good to mention Figure 2 in the text first before showing it. \n\n[Post rebuttal]\nI would like to thank the authors for their clarifications. However, I am still concerned with the novelty. The absence of provable mixing rate is also a potential weakness. I think a clearer emphasis on the novelty, e.g. current algorithm with mixing rate analyses or more thorough empirical comparisons will make the paper stronger for resubmission.", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}