{"title": "This work in a very preliminary stage.", "review": "This paper is concerned with improving generalization within GANs by employing adversarial training techniques. The authors propose an architecture that augments the AC-GAN architecture with a PGD attack module that generates adversarial examples for the discriminator. The authors report that an adversarially trained GAN is more robust to PGD attacks than state of the art adversarial discriminative models. Moreover, adversarial training seems to improve convergence rates for training. The authors offer some intuition behind why these phenomena take place. \n\nThe investigation of possible synergies between adversarial attacks and generative models is definitely an intriguing endeavor, however, the evidence offered in the paper (in its current form) is not solid enough to build a convincing argument. \n\nSome major issues relating to the main claims of this paper:\n\n* ideas of combining adversarial training and GANs have already appeared in the literature, and the authors even cite one such paper (Defense-GANs, Samangouei et al.). The citation appears amongst a long list of references that are summarily considered to provide \"an illusion of safety\". This to some degree challenges the novelty of the claims.\n\n* it is very hard to evaluate the generality of the claims based on what is essentially a relatively small portion of ImageNet. Especially when arguing about losses and architectures. \n\n* it is not clear whether the improved convergence rate is actually worth it -- the computational cost of running the adversarial example generation is not reflected in the epoch plot. \n\nApart from that, the paper contains a significant number of typos, and the exposition is confusing even though the arguments are not heavily technical. \nFor this paper to be considered for publication, one would expect either a stronger theoretical analysis or a more rigorous empirical evaluation that shows that the reported phenomena persist across different problems/datasets.", "rating": "3: Clear rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}