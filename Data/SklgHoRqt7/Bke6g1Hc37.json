{"title": "This paper motivates using a nonlinear function based on an autoencoded representation to derive training sample weights to optimize any test metric. It seems like a significant contribution, particularly for analyzing datasets where training and validation data are known to be drawn from different distributions.", "review": "This proposal learns training data weights that optimize any given test metric.\nThey do this by learning both a weighting function and a classifier. They \niteratively train an ensemble of K {weighting_k,classifier} pairs, and\nselecting the pair that presents the best best metric-of-interest value over\nthe test set (over all iterations) as the final output.\n\nThe paper provides a large set of references that I found useful, and is\nclearly written.\n\nEach training iteration of their MOEW algorithm first optimizes classifiers \nover all training examples, for each of the K sample weightings.  Each\nweighting gives rise to one converged classifier, whose metric-of-interest is\nevaluated on the validation set.  Given K sets of weighting functions and their\nmetric-of-interest values, new parameters for the weighting functions are\ngenerated.\n\nThe weighting function choice is a simple function, based on a linear transform\nof autoencoder features, a normalization factor, and factor to account for\ndiffering label frequencies in training and test data.  The low-dimensional\nauto-encoding of {data,label} pairs is trained once, using the training data.\nThe weighting function parameters are a linear transformation matrix. They\nalso have a sigmoid non-linearity in their weighting function.\n\nIf I understand correctly, their approach seems to generalize the importance\nsampling methods that they reference by using a nonlinear combination of autoencoder\nfeatures.  They reference importance sampling methods that, for example, use \nGaussian kernel basis functions to model training/test example densities.\nWhile they do provide extensive references to previous approaches, I would have\nenjoyed a clearer explanation of main differences between their weighting\nfunction and ones that have previously been used in importance sampling.\n\nTheir main contribution seems to be the procedure (Alg. 2) used to updated the\nweighting function parameters.  They first fit a model that predicts\nmetric-of-interest values given all previous weighting function parameters used\nin the algorithm.  Then they use this model to generate the next set of\nweighting function parameters.  Their method adapts a Gaussian Process\nUpper-Confidence Bound to batch-wise processing.  Within-batch and between\nbatch exploration of the weighting function parameters is controlled by two\nparameters, which they held fixed at values corresponding to +/-1 for a normal\ndistribution.\n\nOnly the validation set need be iid with the test set, so their method seems\nquite general.\n\nTheir MNIST results use very simple networks to show that learning weighting\nfunctions has the most benefit when classifier networks are severely\nunder-parameterized.  Their wine price example addresses the choice of\nembedding dimension, and they found their error metric decreased from 52% with\nuniform weighting, to around 46% as they approached ~10 dimensions in the\nautoencoded {data,label} representation of the training data.  They then use a\nsmall crime dataset with a complicated test metric measuring *fairness*, based\non dividing the dataset into 4 quantiles based on white population. Using\nMOEW they could improve the fairness metric with little effect on the accuracy\nmetric.  They could also preset thresholds to achieve very good fairness on the\ntraining data and use MOEW to maximize the accuracy metric, which resulting\nin improving both fairness and accuracy compared to uniform sample weighting.\n\nFor spam blocking and web page quality, I would like to see a little more \ninterpretation of their results. They again show improvements using MOEW to\nprovide weights for training data.  This time, Table 2 presents a comparison\nwith importance sampling, but the methodology they used for importance sampling\nis not well described.  I'd like to understand where this improvement came\nfrom. What model/procedure was used for importance weighting? Gaussian rbfs?  \nDo the authors attribute the dramatic improvement for MOEW for Spam Blocking \nsimply to having a more flexible sample distribution function?  Or is it mainly\ndue to their adapting to the test metric?  Then for Web Page Quality, would it\nbe correct to conclude that the old and new web pages (training vs\nvalidation/test) are actually fairly similary distributed?\n\nWhat values of B and K are reasonable values in Alg. 1?  When applied to larger\nproblems, where do the authors feel the bottlenecks in Algs 1 and 2 will lie?\nDo the authors find that retuning the classifier for different weighted samples\nto take a lot of time?\n\nPros:\n - tests on several datasets\n - seems fairly generally applicable.\n \nCons:\n - To reproduce, I guess I'd need to adapt existing GP-UCB code from python or\n   C++, and I'm not sure how easy this would be. Releasing code to reproduce\n   the results might be nice.\n - Better understanding of differences wrt. typical Importance Sampling methods\n   would nice.\n", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}