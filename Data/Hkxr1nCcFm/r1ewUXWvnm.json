{"title": "Is it really planning, or something else? ", "review": "The authors hypothesize that, under appropriate conditions, neural networks without specific architectural biases trained by model-free reinforcement learning algorithms are capable of learning procedures that are analogous to planning. This is certainly an important area of research in reinforcement learning.\n\nUnfortunately, the approach employed to demonstrate this hypothesis seems flawed, which is why this submission should be rejected in its present form.\n\nThe authors suggest that the presence of planning should be accompanied by three observable characteristics: generalization of desired behavior to radically different situations, learning of desired behavior from small amounts of data, and ability to benefit from additional \"thinking\" time. Instead of trying to identify how an environmental model is represented by a network and how it is used for planning, the authors focus on checking for the aforementioned characteristics.\n\nEven after conceding their strong claim despite weak argumentation provided by the authors, there are fundamental experimental issues that make the conclusions of this study unwarranted. Regarding the first two characteristics, the concepts of \"radically different situations\" or \"small amounts of data\" are extremely vague. Basically the authors assume that their problems are difficult enough to require planning. Having solved these problems with their proposed architecture, they conclude that planning must have occurred. Regarding the use of additional \"thinking time,\" the authors claim that the improvement in performance caused by providing additional micro-steps to a recurrent neural network is clear evidence that something analogous to planning is happening, which is obviously not the case.\n\nWhile it would not be surprising if there was indeed something analogous to planning happening inside the networks under consideration, this paper presents no stronger evidence for this claim than most other deep reinforcement learning papers that tackle complex environments.\n\nPerhaps the most important contribution of this submission is the architecture based on ConvLSTMs proposed by the authors, which apparently surpasses many alternatives, including some biased towards planning. However, surpassing planning models is not strong evidence of planning. When stripped of unwarranted claims made by the authors regarding implicit planning, the proposed architecture does not seem sufficiently novel to warrant acceptance.\n\nThe authors should be commended for what was certainly very demanding experimental work, even though it does not support their core claims. Their second most important contribution is the experimental comparison between several recent architectures in a diverse selection of environments. \n\nThe writing is clear and accessible, except possibly for the architectural details described in Section 2.1.2, which do not seem very important. There are also several typos in Appendix D.2.\n\nRegarding related work, the authors mention that Pang and Werbos [1] \"advanced the approach.\" But they do not explain how they advanced this approach. In fact, we could not find much about this in the 1998 paper. Also, to our knowledge, \"additional thinking time\" was first proposed in the context of reinforcement learning and planning with two interacting RNNs by Schmidhuber [2, Section: \"more network ticks than environmental ticks\"].\n\n[1] Xiaozhong Pang & Paul J. Werbos (1998): Neural Network Design for J Function Approximation in Dynamic Programming\n[2] J.  Schmidhuber. Making the world differentiable: On using fully recurrent self-supervised neural networks for dynamic reinforcement learning and planning in non-stationary environments. TR FKI-126-90, TU Munich, November 1990.\n\nPerhaps a strongly revised version the paper might become more acceptable if the authors addressed the issues above and especially toned down their claims about having experimentally identified the emergence of planning. Instead they should be extremely careful here, perhaps present this as \"intriguing results,\" and address all possible counter arguments.\n", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}