{"title": "Good motivation but empirical evidence shows limited improvements.", "review": "The paper introduces a new cost function for training Wasserstein Autoencoders that combines reconstruction error with Sinkhorn distance on the latent space. Authors provide nice theoretical motivation, yet empirical results seem incremental and do not fully support the effectiveness of this approach.\n\nPros:\n- Theorem 3.1 (although trivial) provides motivation for optimizing Wasserstein distance in the latent space in WAEs.\n- Theorem 3.2 shows sufficiency of optimization over deterministic encoders in WAEs.\n- The proposed SAE virtually does not favor any prior and can preserve some aspects of geometry of the original space. \n\nCons:\n- It is unclear why Sinkhorn algorithm would provide better estimate of Wasserstein distance than e.g. adversarial WGANGP (which would be a variant of GAN-WAE). Sinkhorn convergence is discussed only in terms of sample size and  smoothing regularizer, not in the context of batch training. \n- Quantitative results are on par or marginally better than other methods, they also lack some comparisons (see details below).\n- There is no comparison to relevant models outside VAE scope, e.g. ALI [4]. \n\nThe novelty of this paper is combining WAEs with Sinkhorn algorithm. Overall, it has potential, but the proposed method would probably require clearer evaluation. \n\nDetailed issues:\n- Notation for posterior seems somewhat inconsistent and misleading, namely push-forward G#P_Z = P_G, while Q#P_X = Q_Z.\n- It is unclear why MMD or GAN losses on WAS's latent space are referred to as heuristics, each of these constitutes a divergence in the same way as the proposed Sinkhorn distance.\n- FID scores for MNIST are incomparable due to the use of own network; using LeNet has been proposed [3].\n- It is unclear what \u2018Empirical lower bounds\u2019 for MMD mentioned in Table 1. caption mean, as unbiased MMD estimator (e.g. [2]) is available. On the other hand, FID is known to be biased [3], so test-set FID should be provided for comparison.\n- Table 2. lacks comparison of SAE with normal prior even though a) authors note that MMDs are incomparable with different priors, b) SAEs is claimed to be prior-agnostic, c) in such setting MMD-WAE might be advantageous [1]. Again, no test-set FID scores.\n- Samples in Figure 2 too small.\n- MMD lacks citation (e.g. [2]).\n\nTypos:\np.6 line 3 construcetion -> construction\np.6 line 30 Hypersherical -> Hyperspherical \nP.8 line 1 this a sign -> this is a sign\n\n[1] Ilya Tolstikhin, Olivier Bousquet, Sylvain Gelly, and Bernhard Sch\u00f6lkopf. Wasserstein Auto-Encoders. ICLR 2018.\n[2] Arthur Gretton, Karsten M. Borgwardt, Malte J Rasch, Bernhard Sch\u00f6lkopf, and Alex J. Smola. A kernel two-sample test. The Journal of Machine Learning Research, 13, 2012a.\n[3] Miko\u0142aj Bi\u0144kowski, Dougal J. Sutherland, Michael Arbel, Arthur Gretton. Demystifying MMD GANs. ICLR 2018.\n[4] Vincent Dumoulin, Ishmael Belghazi, Ben Poole, Olivier Mastropietro, Alex Lamb, Martin Arjovsky and Aaron Courville. Adversarially Learned Inference. ICLR 2017\n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}