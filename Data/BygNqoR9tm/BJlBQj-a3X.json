{"title": "Well-written and significant novelty paper ", "review": "The paper proposes a new representation of Wasserstein AutoEncoder and provides the formal analysis of learning autoencoders with optimal transport theory. The proposed model, SAE, employs the constraints on the equality of prior and posterior latent spaces with a Sinkhorn distance. Moreover, the proposed model is also backed up with some theoretical guarantees.\n\nThe paper is well-written and easy to follow. The experimental results with different priors have demonstrated the effectiveness of the newly formulated model. However, it is not convinced that what is the advantages of the proposed model with WAE. Can the authors provide more insight and comparison with its counterpart, WAE?\n\nIn term of time-complexity, computing Sinkhorn distance in Alg 1 introduces computation overhead, especially with small \\epsilon. In compared with WAE, what is the computation overhead of the proposed model? Can the authors provide some theoretical analysis of time-complexity and experimental results?\n\nIn Table 2, there are only FID values for WAE with MMD cost. Can the authors show the numbers with WAE-GAN on these datasets?\n\nConclusion: The theoretical and experimental contributions are significant to publish at the venue.", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}