{"title": "Technical contribution and readability needs to be improved given the  niche subject  ", "review": "In this paper the authors analyse the role of residuals in the performance of residual networks (res-nets) with shared layer weights and propose a method to adapt the depth of such networks during training. They exploit  the fact that res-nets identical blocks / shared layer weights are discrete time dynamical systems to conduct their analysis. Their main contribution seems to be an empirical evaluation of the role of transient dynamics in the performance of such res-nets. Experiments are done on a toy dataset on concentric circles and MNIST data.\n\nI find the scope of the paper very narrow (res-nets with shared weights) even though there seem to be quite some other papers addressing this problem.\n\nClarity and quality of writing. It seems to me that the paper could  be much better written, the authors present long trains of thoughts and sometimes unsubstantiated arguments and at times there seems to be no clear storyline. In particular I would strongly  suggest a rewrite of  Sections 1, 2.1, and 4.  The storyline often very sketchy and is littered with hypothetical claims or less relevant information that can distracts and confuse the reader. I find that the hypotheses are not well formulated,   the claimed contributions of the paper don't seem to be significant enough and they should also be better connected to the experimental sections. Sometimes there are some odd choices of concepts/words such as \"softmax algorithm\" and \"classification behaviour.\"\n\nTechnical quality and contribution. The main technical contribution of the paper seems to be the observation that  that the solution of an  ODE if the integral of the RHS an that one can derive an ODE for the residuals only. I don't find  these results significant/relevant enough to justify the publication of this paper.  I expected a better written and more informative Section 2.1: some approximations of rates of convergence, a bit more about basins of attraction. I am also a bit skeptical about the claim that the analysed network us a prey-predator model. \n\nExperimental section. I find the description of experiments in Sec 4 very hard to read. The metrics are not clearly defined (not sure visualisations serve the purpose either), and the performed experiments are not well motivated and explained, for example in Section 4/P2 while I think I understand what the authors want to show (path of relevant neurons), I find the purpose of the whole experiment not very relevant.  I better analysis of the number of fixed points for classification tasks should be added, comparison of resulting features to other methods such as simple MLPs with same last layer could help . More relevant datasets should be be added e.g. CIFARxxx., ImageNet.\n\nOverall: I find that this paper needs to be improved both in terms of readability and technical contribution to ready for publication.", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}