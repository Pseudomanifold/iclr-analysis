{"title": "Privacy preserving Deep learning on distributed data sets", "review": "Summary: The paper studies the problem of training deep neural networks in the distributes setting while ensuring privacy. Each data sample is held by one individual (e.g., on a cell phone), and a central algorithm trains a learning model on top of this data. In order to protect the privacy of the individuals, the paper proposes the use of multi-layer encoders (E) over the raw data, and then send them across the server. The privacy is ensured by exemplifying the inability to reconstruct the original data from the encoded features, via running a reverse deep model (X). The notion of privacy is quantified by the Euclidian distance between the reconstructed vector via the best X and the original feature vector, maximized over E. The overall framework resembles a GAN, and the paper calls it RAN (Reconstructive Adversarial Network).\n\nPositive aspects: The problem of training privacy preserving deep models over distributed data has been a significant and important challenge. The current solutions that adhere to differential privacy based approaches are not yet practical. In my view, it is a very important research question.\n\nNegative aspects: One major concern I have with the paper is the notion of privacy considered. The notion of privacy considered in the paper makes two assumptions which I am not comfortable with: i) The protection that the notion assures is against reconstruction attacks. There has been a large body of work which shows that weaker attacks like membership attacks can be equally damaging, ii) Privacy is a worst-case guarantee. I do not see the GAN style approach taken by the paper, ensures this. ", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}