{"title": "marginally novel, evaluation is very flawed, and incomplete ", "review": "First off, the paper presents a relatively straight-forward extension to video from the work done in image compression. The work uses 3D volumes instead of 2D images, and exploits this structure by adding a secondary network to both the encoder/decoder.\n\nThe work is therefore *marginally* novel, but it is one of the first to propose neural methods for compressing video.\n\nMy biggest complaint about this paper, however, is about evaluation. I don't think it's possible to take this paper seriously as is, due to the fact that the metrics use in the evaluation are absolutely skipped.\n\nGiven that this is such a crucial detail, I don't think we can accept this paper as is. The metrics need to be described in detail, and they should follow some previously used protocols (see below). \n\nFor example, in libvpx and libaom (which is the current best performing method for video compression - AV1), there are two versions of PSNR: Global and Average PSNR respectively, and this is what gets reported in publications/standards meetings.\n\nGlobal PSNR: Compute MSE for the entire sequence combining Y, Cb, Cr components, and then compute PSNR based on the combined MSE.\nAverage PSNR: Compute MSE for each frame combining Y, Cb, Cr, components; then compute PSNR for the frame based on the combined MSE and cap it to a max of 100. Then average the PSNR over all the frames.\n\nMPEG uses something like computing Average PSNR for each component (similar to what I mentioned above, but for each component) and then combine the Y-, Cb- and Cr- PSNRs using a weighted average. For 420 that will be equivalent to [4*MSE(y) + MSE(Cb) + MSE(Cr)/6. For 422 that will be equivalent to [2*MSE(y) + MSE(Cb) + MSE(Cr)/4. For 444 that will be equivalent to [MSE(y) + MSE(Cb) + MSE(Cr)/3.  Additionally, when using YCbCr, the authors also need to refer to which version of the color standard is employed, since there are multiple ITU recommendations, all of which differ in how to compute the color space transforms.\n\nPlease note that video codecs DO NOT OPTIMIZE FOR RGB reconstruction (humans are much more sensitive to brightness details than they are to subtle color changes), so comparing against them in that color space puts them at a distinct disadvantage. In the video compression literature NOBODY reports RGB reconstruction metrics.\n\nPlease note that I computed the PSNR (RGB) for H.264, on the resized MCL-V dataset (640x360) as the authors proposed and I observed that the metric has been ***MISREPRESENTED*** by up to 5dB. This is absolutely not OK because it makes the results presented not be trustworthy at all.\n\nHere is the bpp/RGB PSNR that I obtained for H.264 (for completeness, this was computed as follows: used version 3.4.2 of ffmpeg, and the command line is \"ffmpeg -i /tmp/test.y4m -c:v h264 -crf 51 -preset veryslow\", tried many settings for crf  to be able to get roughly the same bpp per video, then compute RGB PSNR for each frame per video, aggregate over each video, then average cross videos):\n\nBPP, Average PSNR RGB (again, not a metric I would like to see used, but for comparison's sake, I computed nonetheless -- also, note that these numbers should not be too far off from computing the average across all frames, since the video length is more or less the same)):\n0.00719, 23.46\n0.01321, 26.38\n0.02033, 28.92\n0.03285, 31.14\n0.05455, 33.43\n\nSimilar comments go for MS-SSIM. \n\nLastly, it is unfair to compare against H263/4/5 unless the authors specify what profiles were used an what kind of bitrate targeting methods were used. ", "rating": "2: Strong rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}