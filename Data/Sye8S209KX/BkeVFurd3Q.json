{"title": "Limited Novelty with questionable \"improvements\" over simpler setups from prior work", "review": "The paper introduces an approach to train sentence representations from multiple text classification tasks. Two variants of shared private multi-task learning are employed to train BiLSTM based sentence encoders. Experiments were conducted with care and nicely compared to existing results from the literature. However, these show only incremental improvements over recent baselines. \n\nThe idea of using shared and private encoders in the multitask setup is interesting, however, results do not indicate much improvements over simple MTL settings like the one from Conneau et al. Overall, the paper seems to be a straight-forward combination of 2 existing ideas: the model and datasets (except for QQP) from Conneau et al. and the SP setup from Liu et al. The additional QQP dataset actually doesn't seem to offer all that much looking at the appendix. Furthermore, the authors simply concatenate all embeddings that exist to build their universal representations which is fairly obvious that this helps. They also concatenate all private embeddings with the shared one, which is not all that fair in comparison to other results, because the larger dimensionality typically helps in these tasks, even with random projections [1]. Nevertheless there is no real gain over previous approaches.\n\n\nSo overall I believe that the incremental contributions in this paper as well as the lack of favorable results that would support the additions made over Conneau et al. make this paper rather an interesting workshop addition than a conference full-paper.\n\n\nComment:\nOn a sidenote, as a line of research I would also like to raise awareness on how little trained sentence representations actually offer over simple BoW representations. See for instance the following parallel submission [1] that uses BoW representations with random projections. This paper also points out a problem in InferSent that prevents proper evaluation when using max-pooling. In case the InferSent library was used to obtain results for this paper, this would make it hard to trust the results.\n\n[1] https://openreview.net/forum?id=BkgPajAcY7", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}