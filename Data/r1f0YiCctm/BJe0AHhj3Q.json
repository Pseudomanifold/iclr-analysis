{"title": "Interesting argument", "review": "In this paper the authors propose to use MLD principle to encode the weights of NNs and still preserve the performance of the original network. The main comparison is from Han 2016, in which the authors use ad-hoc techniques to zero some coefficient and prune some connection + Huffman coding. In this case , the authors uses as a regularizer (See equation 3) a constraints that the weights are easy to compress. The results seem significant improvement with respect to the state of the art. \n\n", "rating": "6: Marginally above acceptance threshold", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}