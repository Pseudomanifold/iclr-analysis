{"title": "The technical contribution is minor", "review": "Summary: \nThe authors investigate the Breiman\u2019s dilemma in the context of deep learning. They show generalization bounds in terms of the margin distribution. They also perform experiments showing the Breiman\u2019s dilemma.\n\nComments: \nI am afraid the authors miss an important related paper:\n\nLev Reyzin, Robert E. Schapire:\nHow boosting the margin can also boost classifier complexity. ICML 2006: 753-760\n\nReyzin and Schapire explain the Breiman\u2019s dilemma based on base classifiers\u2019 complexity. In particular, their experiments show that arc-gv tends to use more complex decision trees than AdaBoost while it achieves better margin distribution over sample. That is, not only margin distribution, but also the complexity of base classifiers\u2019 class matters. This is already explained by known Rademacher complexity based margin bounds.\n\nAs for quiantile-based analyses on margin bounds the following result is known:\n\nLiwei Wang et al: A Refined Margin Analysis for Boosting Algorithms via Equilibrium Margin, \nJournal of Machine Learning Research 12 (2011) 1835-1863.\n\nThey proved a shaper bound using the notion of equibrium margin. The authors should compare the presented results with this. \n\nThe technical results of the paper look quite similar to known margin bounds and I am afraid the contribution is minor or redundant.\n\nAfter the rebuttal:\nI read the authors' comments and understand more the technical results. I raised my score. But I still feel that the techniccal contribution is a bit weak.\n\n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}