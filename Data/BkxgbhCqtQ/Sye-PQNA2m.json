{"title": "Too many moving parts", "review": "The authors consider uncertainty estimation in deep latent variable models. They propose to use quantised latent variable and argue that this solves the overconfidence problem, commonly encountered in variational inference. The proposed approach relies on optimizing an information bottleneck objective instead of  the ELBO.\n\nWhile the approach is of interest, a number of questions, central to the work, remain. For example, it is not clear how parameter \\beta is chosen/optimised, how the number of bins C is chosen and how the annealing scheme is tuned. The authors do not discuss the quantisation parameters, such as bin size and location, which are likely to have a major effect on the performance (and the complexity). Then the authors propose to use a hierachical set of latent variables without properly justifying the need, nor discuss how to select the depth and its impact on the performance. Finally the authors propose yet another extension based on a matrix-factorization with little justification.\n\nOverall, this paper does not fully develop the ideas proposed in the paper or discuss them in sufficient detail. The experiments do not provide additional intuition on what's going on and why this helps and are insufficiently documented/made accessible to be convincing. For example, I am not sure what to conclude from experiments that rely on no (or \"light\") hyperparameter tuning, when the proposed method has many and not discussion is provided about how to set them or how sensitive results are to their actual value. More importantly, the initial claim that uncertainty is better captured relies on SGR, a metric which is not standard and mentioned in passing without being properly defined. The evaluation further depends on a \"selective classifier\" which is not detailed, but critical to understanding the experiments.\n\nFinally, the presentation of Section 3 could be significantly improved. For example, I would suggest distinguishing the neural network parameters of the encoder and the decoder as well as the encoder and decoder networks.  I would also refrain using notations like \"...\" or and always specify what is left and right of an equality. Please spell out all abbreviations at least once in the paper and define all important quantities and concepts.\n\n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}