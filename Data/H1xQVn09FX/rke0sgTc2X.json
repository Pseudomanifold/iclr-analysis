{"title": "Interesting take on GAN audio synthesis - accept", "review": "This paper proposes a strategy to generate audio samples from noise with GANs. The treatment is analogous to image generation with GANs, with the emphasis being the changes to the architecture and representation necessary to make it possible to generate convincing audio that contains an interpretable latent code and is much faster than an autoregressive Wavenet based model (\"Neural Audio Synthesis of Musical Notes with WaveNet AutoEncoders\" - Engel et al (2017)). Like the other two related works (WaveGAN - \"Adversarial Audio Synthesis\" - Donahue et al 2018) and the Wavenet model above, it uses the NSynth dataset for its experiments. \n\nMuch of the discussion is on the representation itself - in that, it is argued that using audio (WaveGAN) and log magnitude/phase spectrograms  (PhaseGAN) produce poorer results as compared with the version with the unrolled phase that they call 'IF' GANs, with high frequency resolution and log scaling to separate scales.  \n\nThe architecture of the network is similar to the recently published paper  (Donahue et al 2018), with convolutions and transpose convolutions adapted for audio. However, there seem to be two important developments. The current paper uses progressive growing of GANs (the current state of the art for producing high resolution images), and pitch conditioning (Odena et al, where labels are used to help training dynamics). \n\nFor validation, the paper presents several metrics, with the recently proposed \"NDB\" metric figuring in the evaluations, which I think is interesting. The IF-Mel + high frequency resolution model seems to outperform the others in most of the evaluations, with good phase coherence and interpolation between latent codes. \n\nMy thoughts: \nOverall, it seems that the paper's contributions are centered around the representation (with \"IF-Mel\" being the best). The architecture itself is not very different from commonly used DCGAN variants - the authors say that using PGGAN is desirable, but not critical, and the use of labels from Odena et al. \n\nMany of my own experiments with GANs were plagued by instability (especially at higher resolution) and mode collapse problems without special treatment (largely documented, such as adding noise, adjusting learning rates and so forth). To this end, what do the authors see as 'high' resolution vis a vis audio signals? \n\nI am curious if we can adapt these ideas for recurrent generators as might appear in TTS problems. \n\nI rate this paper as an accept since this is one of the few existing works that demonstrate successful audio generation from noise using GANs, and  owing to its novelty in exploring representation for audio. \n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}