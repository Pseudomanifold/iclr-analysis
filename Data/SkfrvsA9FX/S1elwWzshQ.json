{"title": "Well written, addresses relevant problem in reinforcement learning, proposes interesting solution ", "review": "This work tackles the difficult problem of solving Constrained Markov Decision Processes. It proposes the RCPO algorithm as a way to solving CMDP. The benefits of RCPO is that it can handle general constraints, it is reward agnostic and doesn't require prior knowledge. The key is that RCPO trains the actor and critic using an alternative penalty guiding signal.\n\nPros:\n- the motivations for the work are clearly explained and highly relevant\n- comprehensive overview of related work \n- clear and consistent structure and notations throughout\n- convergence proof is provided under certain assumptions\n\n\nCons:\n- no intuition is given as to why RCPO isn't able to outperform reward shaping in the Walker2d-v2 domain\n\nminor remarks:\n- in Table 2, it would be good if the torque threshold value appeared somewhere \n- in Figure 3, the variable of the x-axis should appear either in the plots or in the legend\n- in appendix B, r_s should be r_step and r_T should be r_goal to stay consistent with notation in 5.1.1", "rating": "7: Good paper, accept", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}