{"title": "Computational costly heterogeneous graph embedding", "review": "This paper proposed a heterogeneous graph embedding method P^2IR. The author(s) first\nargued that such an embedding should be invariant to partial permutations of nodes.\nThen the authors gave a general formulation of such an embedding in theorem 3.1.\nThen the authors instantiated this general formulation by a neural network\nparametrization, which can be optimized based on the L^2 loss and a supervised\nregularizer. The method is tested against graph embedding methods that do not\nneed node attributes (in GCN the authors \"eliminated\" the node attributes) on\nsemi-supervised node classification tasks, showing a significant improvement.\n\nMy main criticism is that the authors did not clarify or put any efforts on\nsolve the high computational complexity.\nThe proposed method needs to perform a spectral decomposition of\nthe adjacency matrix, which has cubic complexity. This is unacceptable,\nmaking the method less useful for real networks.\nFurthermore, to optimize the embedding using SGD requires graph\nFourier transformations that have quadratic complexity.\nIn section 3.3, the exact complexity should be given, without which\nthe technique is incomplete.\n\nAn important reference \"Graph Attention Networks. P. Veli\u010dkovi\u0107 et al. 2018.\"\nis missing, which has the similar idea to automatically learn the neighborhood\nproximities. It should be cited as this is a key idea to motivate the paper.\n\nThe presentation quality is not satisfactory. For example, in page 3, f() has K\nmatrix arguments, then in page 4 theorem 3.1, f() takes KN arguments.\nPlease make it consistent.\n\nIn page 5, the formulations from eq.(3) to eq.(5) can be further unified\nand simplified. From eq.(3) to eq.(4) is not straightforward and need more\nexplanations. If you use \\mathcal{R} as the embedding, it should appear in\neq.(4) to be consistent.\n\nTable 1 has no contents.\n\nIn the experimental results, the performance of GCN with node attributes\nshould be given for completeness (although the comparison is less fair).\nA related question is how to incorporate node attributes in your framework?\n\nIn the heterogeneous experiments, for completeness, the authors are suggested\nto compare against a heterogeneous version of GCN (again, with and without node\nattributes) such as \"Modeling Relational Data with Graph Convolutional Networks.\nSchlichtkrull et al. 2017.\"\n\nThe paper is longer than the recommended length.", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}