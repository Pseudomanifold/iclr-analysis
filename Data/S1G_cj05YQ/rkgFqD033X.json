{"title": "The authors proposed a new regulariser for continual learning. However, the novelty is not clear and experiments setting needs improvement.", "review": "The authors proposed a new regularizer for continual learning to tackle the catastrophic forgetting problem. The proposed method minimizes the KL-divergence between the prediction of previous models and current models on the stored samples of previous tasks. The idea is straightforward and sounds technical. Experiments show the effectiveness of the methods compared to state-of-the-art. Although the idea sounds interesting and the experiments look promising, the novelty of the paper seems to be limited. In addition, the experiments setting needs to be improved as well. In the following, you have detailed comments. \n\n1. It seems to be an extension of Learning without Forgetting (LwF) Li & Hoiem 2017 with simply on the examples of previous tasks in the memory. LwF only regularizes on the current task. It is not clear what is the difference between the proposed method and LwF except this.\n2. The authors fixed many critical hyper-parameters: temperature(5), learning rate(0.05), epochs(10). The author should report the results for all methods with these hyper-parameters chosen on the validation set.\n3. The authors presented how they split the training and testing data. Please be clear how you split the validation set.\n4. The authors argued that sample quality does not affect the proposed methods. Then the authors should show the variance from different random sampling.\n", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}