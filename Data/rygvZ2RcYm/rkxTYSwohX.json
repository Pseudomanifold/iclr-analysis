{"title": "Very interesting paper", "review": "The authors present an interesting analysis of generalized value functions (GVFs) and demonstrate that several RL algorithms including policy gradient, successor features, options, etc. are special cases of GVFs. The paper is reasonably well-written, and empirical studies demonstrate the benefits of using the GVF formulation to tweak existing algorithms. \n\nPros:\n1. Very interesting analysis of the various algorithms and unification into the single GVF framework. \n2. Especially ike the fact that these connections help discover flaws in existing algorithms (like the mode-collapse issue in FuN)\n\nCons:\n1. The options experiments (and comparison to FuN) are done on simple Atari games, which do not benefit as much from hierarchical policies. It would be good to perform empirical studies on more suitable environments (like 3D mazes / Montezuma's revenge).\n", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}