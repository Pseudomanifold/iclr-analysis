{"title": "Good paper, low confidence.", "review": "Paper formalizes the gradient estimation problem in a black-box setting, and provs the equivalence of least Squares with NES. It then improves on state of the art by using priors coupled with a bandit optimization technique.\n\nThe paper is well written. The idea of using priors to improve adversarial gradient attacks is an enticing idea. The results seem convincing.\n\nComments:\n- I missed how data dependent prior is factored into the algorithms 1-3. Is it by the choice of d? I suggest a clearer explanation.\n- In fig 4, I was confused that the loss of the methods is increasing. it took me a minute to realize this is the maximized adversarial loss, and thus higher is better. you may want to spell this out for clarity. I typically associate lower loss with better algorithms.\n- I am confused by Fig 4c. If I am comparing g to g*, I do expect a high cosine similarity. cos = 1 is the best. Why is correlation so small? and why is it 0 for NES? You may also want to offer additional insight in the text explaining 4c. \n\nMinor comments:\n- Is table one misplaced?\n- The symbol for \"boundary of set U\" may be confused with a partial derivative symbol\n- first paragraph of 2.4: \"our estimator a sufficiently\". something missing?\n- \"It is the actions g_t (equal to v_t) which...\" refering to g_t as actions is confusing. Although may be technically correct in bandit setting\n- Further explain the need for the projection of algorithm 3, line 7.\n- Fig 4: refer to true gradient as g*\n\nCaveat: Although I am well versed in bandits, I am not familiar with adversarial training and neural network literature. There is a chance I may have misevaluated central concepts of the paper.", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}