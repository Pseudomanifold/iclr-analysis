{"title": "interesting derivation of 2nd gradient flows but with limited practical usefulness", "review": "This paper derives accelerated gradient flow formula in the space of probability measures from the view of optimal control formalism. The generalization of variational formulation from finite space to the space of probability measures seems new, but the resulting PDE seems to be a known result, which is the Fokker-Planck equation (with some minor modifications) for the 2nd order Langevin dynamic. From this point of view, the resulting algorithm from the derived PDE seems not having much practical advantage over SGHMC (a stochastic version of 2nd order Langevin dynamics).\n\nActually, I think the derivation of accelerated gradient flow formula from the view of optimal control formalism does not seem necessary. One can get the same formula by deriving it from Wasserstein gradient flows. When considering the functional as relative entropy, one can derive the formula simply from the Fokker-Planck equation of 2nd order Langevin dynamics. As a result, the proposed methods seems to be a new way to derive the Wasserstein gradient flow (or Fokker-Planck equation), which does not make impact the algorithm, e.g., both ways result in the same algorithm.\n\nBesides, I found the writing needs to be improved. There are a lot of background missing, or the descriptions are not clear enough.  For example:\n1. Page 2: the divergence operator is not defined, though I think it is a standard concept, but would be better to define it.\n2. Page 2: the Wasserstein gradient and Gateaux derivative are not defined, what are the specific meanings of \\nabla_\\rho F(\\rho) and \\partial F / \\partial \\rho?\n3. 1st line in Section 2: convex function f of d real variables seems odd, I guess the author means argument of f is d-dimensional variable.\n4. Section 2, the authors directly start with the variational problem (3) without introducing the problem. Why do we need to variational problem? It would be hard to follow for some one who does not have such background.\n5. Similarly, what is the role of Lyapunov function here in (6)? Why do we need it?\n6. Why do you define the Lagrangian L in the form of (10)? What is the relation between (10) and (2)?\n7. It is not clear what \"The stochastic process (X_t, Y_t) is Gaussian\" means in Proposition 1? It might need to be rephrased.\n8. Second last line in page 5: I guess \\nabla \\log(\\rho) should be \\nabla\\log(\\rho_t).\n\nFor the theory, I think eq.15 only applies when the PDE, e.g. (13), is solved exactly, thus there is not too much practical impact, as it is well known from the Wasserstein gradient theory that the PDE decays exponentially, as stated in the theorem. When considering numerical solutions, I think this results is useless.\n\nFor the relation with SGHMC, let's look at eq.16. Actually, the derivative of the log term \\nabla \\log \\rho_t(X_t)) is equivalent to a brownian motion term. This can be seen by considering the Fokker-Planck equation for Brownian motion, which is exactly d \\rho_t = \\Delta \\rho_t. Consequently, instead of using the numerical approximations proposed later, one cane simply replacing this term with a Brownian motion term, which reduces to SGHMC (with some constant multipliers in front). \n\nThe authors then shows empirically that the proposed method is better than SGHMC, which I think only comes from the numerical methods.\n\nFor the kernel approximation, it makes the particles in the algorithm interactive. This resembles other particle optimization based algorithms such as SVGD, or the latest particle interactive SGLD proposed in [1] or [2[.  I think these methods need to be compared.\n\n[1] Chen et al (2018), A Unified Particle-Optimization Framework for Scalable Bayesian Sampling.\n[2] Liu et al (2018), https://arxiv.org/pdf/1807.01750.pdf\n\nTo sum up, though the derivation of accelerated gradient flow formula seems interesting, the resulting algorithm does not seem benefit from this derivation. The algorithm seems to be able to derived from a more direct way of using Wasserstein gradient flows, which results in a Wasserstein gradient flow for 2nd order Langevin dynamics, and is thus well known. The experiments are not convincing, and fail to show the advantage of the proposed method. The proposed method needs to be compared with other related methods.", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}