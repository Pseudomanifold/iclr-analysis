{"title": "The primary claim is not surprising, but an exciting result is buried at the end", "review": "This paper proposes to investigate recent popular approaches to pruning networks, which have roots in works by Lecun \u201890, and are mostly rooted in a recent series of papers by Song Han (2015-2016). The methods proposed in these papers consist of the following pipeline: (i) train a neural network, (ii) then prune the weights, typically by trimming the those connections corresponding to weights with lowest magnitude, (iii) fine tune the resulting sparsely-connected neural network. \n\nThe authors of the present work assert that traditionally, \u201ceach of the three stages is considered as indispensable\u201d. The authors go on to investigate the contribution of each step to the overall pipeline. Among their findings, they report that fine-tuning appears no better than training the resulting pruned network from scratch. The assertion then is that the important aspect of pruning is not that it identifies the \u201cimportant weights\u201d but rather that it identifies a useful sparse architecture.\n\nOne problem here is that the authors may overstate the extent to which previous papers emphasize the fine-tuning, and they may understate the extent to which previous papers emphasize the learning of the architecture. Re-reading Han 2015, it seems clear enough that  the key point is \u201clearning the connections\u201d (it\u2019s right there in the title) and that the \u201cimportant weights\u201d are a means to achieve this end. Moreover the authors may miss the actual point of fine-tuning. The chief benefit of fine-tuning is that it is faster than training from scratch at each round of retraining, so that even if it achieves the same performance as training from scratch, that\u2019s still a key benefit.\n\nIn general, when making claims about other people\u2019s beliefs, the authors need to provide citations. References are not just about credit attribution but also about providing evidence and here that evidence is missing. I\u2019d like to see sweeping statements like \u201cThis is\nusually reported to be superior to directly training a smaller network from scratch\u201d supported by precise references, perhaps even a quote, to spare the reader some time. \n\nTo this reader, the most interesting finding in the paper by far is surprisingly understated in the abstract and introduction, buried at the end of the paper. Here, the authors investigate what are the properties of the resulting sparse architectures that make them useful. They find that by looking at convolutional kernels from pruned architectures, they can obtain for each connection, a probability that a connection is \u201ckept\u201d. Using these probabilities, they can create new sparse architectures that match the sparsity pattern of the pruned architectures, a technique that they call \u201cguided sparsification\u201d. The method yields similar benefits to pruning. Note that while obtaining the sparsity patterns does require running a pruning algorithm in the first place, ***the learned sparsity patterns generalize well across architectures and datasets***. This result is interesting and useful, and to my knowledge novel. I think the authors should go deeper here, investigating the idea on yet more datasets and architectures (ImageNet would be nice). I also think that this result should be given greater emphasis and raised to the level of a major focal point of the paper. With convincing results and some hard-work to reshape the narrative to support this more important finding, I will consider revising my score. \n", "rating": "6: Marginally above acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}