{"title": "Review", "review": "Paper summary: The paper presents a robust Analysis by Synthesis classification model that uses the input distribution within each class to achieve high accuracy and robustness against adversarial perturbations. The architecture involves training VAEs for each class to learn p(x|y) and performing exact inference during evaluation. The authors show that ABS and binary ABS outperform other models in terms of robustness for L2, Linf and L0 attacks respectively. \n\nThe paper in general is well written and clear, and the approach of using generative methods such as VAE for better robustness is good. \n\nPros: \nUsing VAEs for modeling class conditional distributions for data is an exhaustive approach. The authors show in Fig 4 that ABS generates adversarials that are semantically meaningful for humans, which is not achieved by Madry et al and other models. \n\nCons: \n1) The main concern with this work is that it is heavily tailored towards MNIST and the authors do mention this. Scaling this to other datasets does not seem easy. \n2) Using VAEs to model the conditional class distributions is a nice idea, but how does this scale for datasets with large number of classes like imagenet? This would result in having 1000s of VAEs. \n3) It would be nice to see this model behaves for skewed datasets. \n\n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}