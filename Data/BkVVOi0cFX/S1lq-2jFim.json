{"title": "Interesting exploration, but weak novelty", "review": "This paper aims for open-domain question answering with distant supervision. First, the authors proposed an aggregation-based openQA model with sentence discriminator and sentence reader. Second, they use a semantic labeler to handle distant supervision problem by utilizing other span supervision tasks, and propose two different denoising methods. They run experiments on 3 open-domain QA datasets and achieve SOTA.\n\n\nStrengths\n\n1) Their semantic labeler and exploration of two different denoising methods are interesting and meaningful.\n2) They conducted experiments on 3 widely-used open-domain datasets, and the performance gain is impressive.\n\n\nWeakness\n\nAlthough there is an impressive performance gain, the contribution of the paper seems to be marginal.\n1) First of all, it is hard to say there is a contribution to the idea of sentence discriminator and sentence reader \u2014 people have used this framework for large-scale QA a lot. Also, the architecture of the models in this paper are almost identical to Chen et al (ACL 2017) and Lin et al (ACL 2018).\n2) Thus, the contribution is more on semantic labeler and denoising method. However, this contribution is marginal as well since its role is almost the same as sentence discriminator plus pretraining methods which have widely used already.\n\n\nQuestions\n\n1) What exactly is the difference between semantic labeler and sentence discriminator? For me, it seems like both of them label each sentence `yes` or `no`. My thought is sentence discriminator is only trained on the target dataset (distant supervision dataset) while semantic labeler is also trained (either jointly or separately) trained on the source dataset (span supervision dataset). (If my thought is wrong, please let me know, I would like to update my score.)\n2) Chen et al (ACL 2017) have shown that pretraining QA model on span supervision dataset (SQuAD) is effective to train the model on distant supervision dataset. Similarly, Min et al (ACL 2018) have pretrained both QA model and sentence selector on SQuAD. While I think pretraining sentence selector on SQuAD is almost identical to sentence labeler with SSL method, could you give exact comparison of these different methods? For example, remove sentence labeler, and pretrain both sentence discriminator and reader on SQuAD, or jointly train them on SQuAD & target dataset.\n\n\nMarginal comments\n\n1) At the beginning of Section 2.4.1, it says the semantic labeler is able to transfer knowledge from the span supervised data \u2014 however, the authors should be careful since people usually refers to `knowledge` as an external knowledge. This method is more like better learning of accurate sentence selection, not transferring knowledge.\n2) Please mention the TriviaQA data you used is Wikipedia domain, since there are two different domains (Wikipedia and Web).\n3) In References section, the conference venues in many papers are omitted.\n\n\nOverall comments\n\nThe paper explored several different methods to deal with distant supervision via sentence labeling, and I really appreciate their efforts. While the result is impressive, the idea in the paper is similar to the methods that have widely used already.", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}