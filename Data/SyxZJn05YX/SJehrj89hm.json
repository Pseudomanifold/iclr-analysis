{"title": "An interesting take on the problem of detecting small objects", "review": "OVERVIEW:\nThe authors tackle the problem of detecting small/low resolution objects in an image. Their key idea is that detecting bigger objects is an easier task and can be used to guide the detection of smaller objects. This is done using the \"Feature Intertwiner\"  which consists of two branches, one for the larger objects (more reliable set that is also easier to detect) and one for the smaller objects (less reliable set). The second branch contains a make-up layer learned during training (which acts as the guidance from the more reliable set) that helps compensate details needed for detection. The authors define a class buffer that contains representative elements of object features from the reliable set for every category & scale and an intertwiner loss that computes the L2 loss between the features from the less reliable set & the class buffer. They also use an Optimal Transport procedure with a Sinkhorn divergence loss between object features from both sets. The overall loss of the system is now a sum of the detection loss, the intertwiner loss and the optimal transport loss. They evaluate their model on the COCO Object detection challenge showing state-of-the-art performance. They also provide thorough ablation analysis of various design choices. The qualitative result in Fig.1 showing well clustered features for both high & low resolution objects via t-SNE is a nice touch.\n\nCOMMENTS:\nClarity - The paper is well written and easy to follow.\nOriginality & Significance - The paper tackles an important problem and provides a novel solution. \nQuality - The paper is complete in that it tackles an important problem, provides a novel solution and demonstrates via thorough experiments the improvement achieved using their approach. \n\nQUESTIONS:\n1. The Class Buffer seems very restricted in having a single element per object category per scale to represent all features. The advantage of forcing such a representation is tight clustering in the feature space. But, wouldn't a dictionary approach with multiple elements give more flexibility to the model and learn a richer feature representation at the cost of not-so-good clustering ?\n2. Any comment on why you drop performance for couch ? (and baseball bat + bedroll)\n3. In Table 4 of Appendix where you compare with more object detection results, I find it interesting that Mask RCNN, updated results has a might higher AP_S (43.5) compared to you (27.2) and everyone else. I was expecting you to be the best under that metric due to the explicit design for small objects. They (MaskRCNN, updated results) are also significantly better than the rest under AP_M but worse under AP_L. Can you explain this behavior ? Is the ResNeXt backbone that much better for small objects ?\n", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}