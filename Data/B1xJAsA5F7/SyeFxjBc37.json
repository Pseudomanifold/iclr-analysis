{"title": "Interesting idea, issues in the execution", "review": "Update:\nThe score has been updated to reflect the authors' great efforts in improving the manuscript. This reviewer would suggest to accept the paper now.\n\n\nOld Review Below:\n\nThe paper describes a graph-to-graph translation model for molecule optimization inspired from matched molecular pair analysis, which is an established approach for optimizing the properties of molecules. The model extends a chemistry-specific variational autoencoder architecture, and is assessed on a set of three benchmark tasks.\n\n\nWhile the idea of manuscript is interesting and promising for bioinformatics, there are several outstanding problems, which have to be addressed before it can be considered to be an acceptable submission. This referee is willing to adjust their rating if the raised points are addressed. Overall, the paper might also be more suited at a domain-specific bioinformatics conference.\n\n\nMost importantly, the paper makes several claims that are currently not backed up by experiments and/or data. \n\nFirst, the authors claim that MMPs \u201conly covers the most simple and common transformation patterns\u201d. This is not correct, since these MMP patterns can be as complex as desired. Also, it is claimed that the presented model is able to \u201clearn far more complex transformations than hard-coded rules\u201d. The authors will need to provide compelling evidence to back up these claims. At least, a comparison with a traditional MMPA method needs to be performed, and added as a baseline. Also, it has to be kept in mind that the reason MMPA was introduced was to provide an easily interpretable method, which performs only local transformations at one part of the molecule. \u201cFar more complex transformations\u201d may thus not be desirable in the context of MMPA. Can the authors comment on that?\n\nSecond, the authors state that they \u201csidestep\u201d the problem of non-generalizing property predictors in reinforcement learning, by \u201cunifying graph generation and property estimation in one model\u201d. How does the authors\u2019 model not suffer from the same problem? Can they provide evidence that their model is better in property estimation than other models?\n\n\nIn the first benchmark (logP) the GCPN baseline is shown, but in the second benchmark table, the GCPN baseline is missing. Why? The GCPN baseline will need to be added there. Can the authors also comment on how they ensure the comparison to the GPCN and VSeq2Seq is fair? Also, can the authors comment on why they think the penalized logP task is a good benchmark?\n\nAlso, the authors write that Jin et al ICML 2018 (JTVAE) is a state of the model. However, also Liu et al NIPS 2018 (CGVAE) state that their model is state of the art. Unfortunately, both JTVAE and CGVAE were never compared against the strongest literature method so far, by Popova et al, which was evaluated on a much more challenging set of tasks than JT-VAE and CGVAE. The authors cite this paper but do not compare against it, which should to be rectified. This referee understands it is more compelling to invent new models, but currently, the literature of generative models for molecules is in a state of anarchy due to lack of solid comparison studies, which is not doing the community a great service.\n\n\nFurthermore, the training details are not described in enough detail. \nHow exactly are the pairs selected? Where do the properties for the molecules come from? Were they calculated using the logP, QED and DRD2 models? How many molecules are used in total in each of these tasks?\n", "rating": "7: Good paper, accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}