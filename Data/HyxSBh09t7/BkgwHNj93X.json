{"title": "Simple combination of existing works", "review": "The paper used the graph scattering network as the encoder, and MLP as the decoder to generate links/graph signals/graphs.\n\nPros:\n1.\tClearly written. Easy to follow.\n2.\tNo need to train the encoder\n3.\tGood results on link prediction tasks\n\nCons:\n1.\tLack of novelty. It is a simple combination of existing encoders and decoders. For example, compared to VGAE, the only difference in the link prediction task is using a different encoder. Even if the performance is very good, it can only demonstrate the effectiveness of others\u2019 encoder work and this paper\u2019s correct selection of a good encoder. \n2.\tLack of insights. As a combination of existing works, if the paper can deeply explain the why this encoder is effective for the generation, it is also beneficial. But we also do not see this part. In particular, in the graph generation task, the more important component may be the decoder to regulate the validness of the generated graphs (e.g. \u201cConstrained Generation of Semantically Valid Graphs via Regularizing Variational Autoencoders. In NIPS 2018\u201d which used the similar decoder but adding strong regularizations in VAE). \n3.\t Results on QM9 not good enough and lack of references. Some recent works (e.g. \u201cJunction Tree Variational Autoencoder for Molecular Graph Generation, ICML 2018\u201d) could already achieve 100% valid. \n\n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}