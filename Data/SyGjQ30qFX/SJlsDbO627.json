{"title": "This paper presents a topic model based on adversarial training.", "review": "This paper presents a topic model based on adversarial training. Specifically, the paper adopts the framework of InfoGAN to generates the bag-of-words of a document and the latent codes in InfoGAN correspond to the latent topics in topic modelling. In addition to the above framework, to make the model work better, several add-ons are also proposed, combining autoencoder, loss clipping, and a generative model to generate text sequences based on the bag-of-words.\n\nMy comments are as follows:\n\n1. There are several issues of this paper on clarity:\n\n(1) The first major one for me is that the authors did not give any details on how to interpret the latent code (i.e. the topics here) with the top words. In conventional topic models, usually a topic is a distribution of words, so that top words can be selected by their weights. But I did not see something similar in the proposed model.\n\n(2) Another major one is why the word sequence generator is introduced in the proposed model. I did not see the contribution of this part to the whole model as a topic model, although the joint training shows the marginal performance gain on text generation.\n\n(3) Some of the experiment settings are not provided, for example, the number of topics, the value of \\alpha and \\lambda in the proposed model, the hyperparameters of LDA, which are crucial for the results.\n\n(4) Why is the size of the bag-of-words vocabulary set to be 3K whereas that of the word generation vocabulary set to be 15K?\n\nMinor issues:\n\n(5) In the related work of InfoGAN, there are a lot of cross-references to the following sections, before they are properly introduced.\n\n(6) Typo of \"Accurcay\" in Table 4(a).\n\n2. Using adversarial training for topic models seems to be an interesting idea. There is not much work in this line and this paper proposes a model that seems to be working. But it seems to be that the proposed model has several issues as follows:\n\n(1) Each document seems to have only one topic, which can be an impractical setting for long documents.\n\n(2) The proposed model ignores the word counts, which can be important for topic modelling.\n\n(3) I did not see a major improvement of the proposed model over others, given that the only numerical result reported is classification accuracy and the state-of-the-art conventional topic models are not compared. This also leads to my concern about the experiments. I would expect more comparisons than classification accuracy, such as topic coherence and perplexity (for topic modelling) and with more advanced conventional models. From the low values of the accuracy on 20NG, I am wondering if LDA is working properly.  \n\n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}