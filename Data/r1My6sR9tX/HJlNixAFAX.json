{"title": "nice and simple idea with well carried and thorough empirical experiments", "review": "summary\nThe goal of meta-learning is to train a model on a variety of learning tasks, such that it can solve new learning tasks using only a small number of training samples. SoTA meta-learning frameworks (MAML and ProtoNet) typically require rather large labeled datasets and hand-specified task distributions to define a sequence of tasks on which the algorithms are trained on. This paper proposes to unsupervised generate the sequence of tasks using multiple partitions as pseudo labels via k-means and other clustering variants on the embedding space. Empirical experiments show the benefit of the meta-learning on the M-way K-shot image classification tasks.  Also, \u201csampling a partition from U(P)\u201d on page 4, the U(P) notation seems not defined.\n\nEvaluation\n- The writing and presentation of the paper are in general well carried, except some part seems a little unclear, taking me quite a while to understand. For example,  in the \u201ctask generation for meta-learning\u201d paragraph on page 3, the definition of task-specific labels (l_n) is puzzling to me at first glance.     \n\n- The proposed task construction in an unsupervised manner for the meta-learning framework is indeed simple and novel. \n\n- The empirical experiments are thorough and well-conducted with good justifications. The benefit of unsupervised meta-learning compared to simply supervised learning on the few-shot downstream tasks is shown in Table 1 and 2; Different embedding techniques have also been studied; the results of Oracle upper bound are also presented; task construction ablation is also shown. \n\n- Unsupervised meta-learning consists of multiple components such as learning embedding space, clustering methods, and various choices within the meta-learning frameworks. This together consumes a lot of hyper-parameters and the choice can somehow seem heuristic.\n\nConclusion\n- In general, I like this paper especially the empirical analysis section. Therefore, I vote for accepting this paper.\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}