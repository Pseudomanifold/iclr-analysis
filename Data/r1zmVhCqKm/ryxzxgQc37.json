{"title": "The authors present an interesting new conditional generation task, but the paper lacks critical implementation details and the experimental setting is too restricted to fully support the claims.", "review": "The paper proposes a setting for evaluation of a text infilling task, where a system needs to fill in the blanks in a provided incomplete sentences. The authors select sentences from three different sources, Yahoo Reviews, fairy tales, and NBA scripts, and blank out words with varying strategies, ranging from taking out prepositions and articles to removing all but two anchor words from a sentence. On this data, they compare the performances of a GAN model, Recurrent Seq2seq model with attention, and Transformer model in terms of BLEU, perplexity, and human evaluation.\n\nThe setting is certainly interesting, and the various data creation strategies are reasonable, but the paper suffers from two main flaws. First, the size of the data set is far from sufficient. Unless the authors are trying to show that the transformer is more data-efficient (which is doubtful), the dataset needs to be much larger than the 1M token it appears to be now. The size of the vocabularies is also far from being representative of any real world setting.\n\nMore important however is the fact that the authors fail to describe there baseline systems in any details. What are the discriminator and generator used in the GAN? What kind of RNN is used in Seq2seq? What size? Why not use a transformer seq2seq? How exactly is the data fed in / how does the model know which blank it's generating? It would be absolutely impossible for anyone to reproduce the results presented in the paper.\n\nThere are some other problems with the presentation, including the fact that contrary to what is suggested in the introduction, the model seems to have access to the ground truth size of the blank (since positional encodings are given), making it all but useless in a real world application setting, but it is really difficult to evaluate the proposed task and the authors' conclusions without a much more detailed description of the experimental setting.", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}