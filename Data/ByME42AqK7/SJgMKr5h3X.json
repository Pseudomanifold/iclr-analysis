{"title": "An interesting method with a troubled presentation", "review": "This paper proposes LEMONADE, a random search procedure for neural network architectures (specifically neural networks, not general hyperparameter optimization) that handles multiple objectives.  Notably, this method is significantly more efficient more efficient than previous works on neural architecture search.\n\nThe emphasis in this paper is very strange.  It devotes a lot of space to things that are not important, while glossing over the details of its own core contribution.  For example, Section 3 spends nearly a full page building up to a definition of an epsilon-approximate network morphism, but this definition is never used.  I don't feel like my understanding of the paper would have suffered if all Section 3 had been replaced by its final paragraph.  Meanwhile the actual method used in the paper is hidden in Appendices A.1.1-A.2.   Some of the experiments (eg. comparisons involving ShakeShake and ScheduledDropPath, Section 5.2) could also be moved to the appendix in order to make room for a description of LEMONADE in the main paper.\n\nThat said, those complaints are just about presentation and not about the method, which seems quite good once you take the time to dig it out of the appendix.\n\nI am a bit unclear about how comparisons are made to other methods that do not optimize for small numbers of parameters? Do you compare against the lowest error network found by LEMONADE? The closest match in # of parameters?\n\nWhy is the second objective log(#params) instead of just #params when the introduction mentions explicitly that tuning the scales between different objectives is not needed in LEMONADE?\n\nIt seems like LEMONADE would scale poorly to more than 2 objectives, since it effectively requires approximating an #objectves-1 dimensional surface with the population of parents.  How could scaling be handled?\n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}