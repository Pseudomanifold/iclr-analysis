{"title": "The paper does not solve the question it proposed", "review": "The paper describes a question about discretize continuous features or group discrete features in the preprocessing step, which they call feature quantification. It considers that a joint training of feature quantification and a discriminative model can lead to a better performance than treating feature quantification as a preprocessing step. \n\nThis paper has many typos, grammar mistakes and question marks, which make it hard to follow. The question proposed is simple and easy to understand. However, I don't convinced by the solution in this paper. Since it is a hard optimization question, the authors proposed a relaxation approach in section 3.1. I do not think that exp(a+bx) is able to approach step functions since exp(a+bx) is monotone. I think Figure 1 is misleading. For grouping discrete features, the author propose to use exp(\\alpha_{x_j, j}^h) and hoping that some \\alpha parameters can be optimized to be equal, which is too simple. The exponential transformation here does not have an effect. It is more interesting to consider how to add some constraints. For example, if the discrete feature is ordinal, how one can assure that the grouped discrete feature is still ordinal. The relaxation in this paper is too much without handling any interesting constraints and the proposed exp(a+bx) can not approach step functions. The authors do not provide a good way to select number of cut points, which I think is a hard but interesting question.\n\nThe work also lacks value in literature review, optimization and experiments.", "rating": "2: Strong rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}