{"title": "learning 3D or depth images from 2D images", "review": "The paper deals with creating 3D representations or depth maps from 2D image data using adversarial training methods. \nThe flow makes the paper readable.\n\nOne main concern is that most of the experiments seem to have results as visual inspections of figures provided. It is really hard to judge the correctness or how well the algorithms do.\n\nIt would be useful to provide references of equation 1 if used from previous text.\n\nIn the experiments, it is usually not clear how many training images were used, how many test. How different were the objects used in the training data vs test? Were all the test objects novel? How useful were the GAN techniques? Which part of the GAN did the most work i.e. the usefulness and accuracy of the different parts of the net? Even in 4.2, though it mentions use of 6 object types for both training and testing, using the figures is hard to estimate how well the model does compared to a reference baseline.\n\nIn 4.4.1, the discussion on how much improvement there is due to use of unlabeled images is missing? Do they even help? It is not quite clear from table 1. How many unlabeled images were used? How many iterations in total are used of the unlabeled ones (given there is 1 in 100 update of labeled ones). \n\nMissing reference: http://www.cs.cornell.edu/~asaxena/reconstruction3d/saxena_make3d_learning3dstructure.pdf\n", "rating": "6: Marginally above acceptance threshold", "confidence": "1: The reviewer's evaluation is an educated guess"}