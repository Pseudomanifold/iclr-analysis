{"title": "Review for Paper \"Multi-agent Deep Reinforcement Learning with Extremely Noisy Observations\"", "review": "This paper addresses the challenge of learning in extremely noisy environments. The fundamental idea is to combine deep reinforcement learning of individuals, in which individuals can choose whether they share information in order to maximise the overall reward, which is a substantial difference from existing solutions in the area. To achieve this, the authors propose a hierarchical approach in which agents learn from experience, before deciding whether to share information. \n\nTo explore the performance, the authors modify an existing scenario and implement baselines that represent idealised outcomes and contemporary approaches with varying levels of communication among agents. The proposed approach performs favourable compared to alternative approaches, despite its strongly decentralised operation, and is surprisingly close (and in some cases exceeds) the ideal solution with optimal communication. \n\nThe paper is well structured and systematic in the introduction of the underlying concepts in order to retrace the complex architectural setup. Experiment and alternative architectures are described in sufficient level of detail. \n\nThe quality of the presentation is high and accessible. Prospects for future work are highlighted. At this stage, observations are limited to a single observation at a time. The authors could be more explicit about potential further challenges in using the current solution and discuss its versatility in other scenarios. However, overall, the described hierarchical approach provides an interesting avenue to address the issue of noisy observations, which warrants discussion. ", "rating": "7: Good paper, accept", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}