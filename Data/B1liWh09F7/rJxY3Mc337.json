{"title": "Strong experimental results but the technical novelty is limited", "review": "Building on prior work  exploring Adversarial Autoencoder (AAE) and Adversarial Regularized Autoencoder \n(ARAE) for text generation (Cifka et al., 2018), this paper proposes to employ widely adopted Self Attention \nand Transformer to enhance the modeling capabilities of the generator and discriminator in AAE and ARAE \nfor text generation. Experiments on the Google Sentence Compression dataset show that, AAE and ARAE \nenhanced with self attention and Transformer generate long and high-quality sentences with much higher \ndiversity than the corresponding models without attention, although ARAE without attention achieves higher \nBLEU and human evaluation scores.\n\nThis paper is well written and organized, the experiments are well executed, and the results are convincing,\nwhich demonstrates the effectiveness of Self Attention and Transformer that have been widely adopted in \nnatural language processing recently.\n\nMajor:\n\n1. The technical novelty of this paper is very limited. It is a trivial combination of Self Attention, Transformer, \nand previous models for text generation. The experimental results are not surprising. \n\n2. The experimental results in Table 2-5 just list the performance of AAE and ARAE with/without attention. \nIn-depth analyses about the performance of different model variants will make the paper much more \ninteresting.\n\n3. The current model generates sentences by fixing the length to 50 first. It is important to explore other more\nnatural modeling variants  for generating sentences of variable lengths.\n\n4. In Fig. 1, it is surprising that one 100-d noise vector passed to a fully connected layer is copied T times. \nIs it better to use a different noise vector in each step?\n\n5. On page 8, the last sentence above Section 5 is inappropriate. Table 2 and 5 clearly show that ARAE has \nthe best performance on BLEU and human evaluation scores, although it lacks generation diversity.\n\nIn conclusion, this paper has well-executed experiments. But the novelty is very limited, the model design might \nneed more exploration, and detailed analyses of the results are required.", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}