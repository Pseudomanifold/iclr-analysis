{"title": "SupportNet offers a new method to perform class incremental learning with an support vectors from the last layers and subsequent two learning constraints, showing some improved performance compared to previous approaches.", "review": "Summary:\nThe authors offer a novel incremental learning method called SupportNet to combat catastrophic forgetting that can be seen in standard deep learning models. Catastrophic forgetting is the phenomenon where the networks don\u2019t retain old knowledge when they learn new knowledge.  SupportNet uses resnet network with 32 layers, trains an SVM on the last layer and the support vector points from this SVM are given to the network along with the new data. Furthermore, two regularizers, feature and EWC regularizer, are added to the network. The feature regularizer forces the network to produce fixed representation for the old data, since if the feature representation for the old data changes when the network is fine-tuned on the new data then the support vectors generated from the old feature representation of the old data would become invalid.  The EWC regularizer works by constraining parameters crucial for the classification of the old data, making it harder for the network to change them. SupportNet is compared to five methods (all data: network is re-trained with new and old data, upper bound for performance, iCaRL: state-of-the-art method for incremental learning, EWC: Only EWC regularizer added, Fine tune: Only new data, Random guessing: Random guess to assign labels) on six datasets (MNIST, CIFAR-10, CIFAR-100, Enzyme Function Prediction, HeLa Subcellular Structure Classification, Breast Tumor Classification). It shows some improvement in overall accuracy with each newly added class when compared to iCaRL, EWC, Fine Tune and Random guessing.  Additionally, they show that overfitting for the real training data (a chosen subset of old data and the new data) is a problem for the competition iCaRL and affects SupportNet to a much lesser degree.\n\nPros:\n(1)\nThe authors propose a sensible approach, which is also novel to be best of our knowledge, using SVM to select support data from old data to be fed to the network along with the new data in the incremental learning framework to avoid catastrophic forgetting. Additionally, they offer a feature regularizer that penalizes the network for changing the feature representation of the support data when training the network on new data and an EWC regularizer that constrains the parameters that are crucial for the classification of the old data and makes it harder to change them. \n(2)\nThe authors use six different datasets and several other approaches (subsets of their method\u2019s components, other competing methods) to show these three components alleviate catastrophic forgetting and show improvement in overall accuracy.\n(3)\nThe paper is well written and easy to follow. \n\n\nCons:\nMajor Points:\n(1)\nTo show that the method proposed in the paper addresses catastrophic forgetting, in addition to the overall accuracy shown in Figure 3, it is also necessary to show the accuracy of different models on old classes when new classes are added to the network. This will strengthen the argument that the improvement in accuracy is indeed due to correct classification on old data.\n (2)\nThe authors claim that iCaRL suffers from overfitting on real training data (section 4.1) however Table 2 shows iCaRL only on the enzyme function prediction which is also the dataset where the difference in performance between iCaRL and SupportNet is the largest. To support the general overfitting claim made in section 4.1, the authors should repeat this analysis on any of the other five datasets where the performance difference between the two methods is much smaller.  SupportNet also suffers from overfitting (Table 3, Accuracy: test data: 83.9%, real training data: 98.7%) although to a lesser extent than iCaRL.\n(3)\nThe individual impact of the support points and the joint impact of support points with feature regularizer on accuracy is not assessed. To prove their usefulness, add two methods to Figure 3:\n(a)A method that uses support points without any regularizer.\n(b) A method that uses support points with just the feature regularizer. \n\nOther points:\n(1) \nIn section 2.3.2, EWC regularizer, Eq. 9: We think F(theta_new) should be F(theta_old) since we want to constrain parameters crucial for classification of old data and should be computing Fisher Information for the old parameters. \n(2)\nIn section 2.1 Deep Learning and SVM: additional steps are needed to show how Eq. 3 is derived from Eq. 2.\n(3)\nIn section 2.1 Deep Learning and SVM: In the line before Eq. 4. \u201ct represtent\u201d instead of \u201ct represents\u201d.\n(4)\nFigures are small and hard to read. Please increase the size and resolution of the figures.  \n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}