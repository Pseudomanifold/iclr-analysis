{"title": "Experimental results are not convincing", "review": "Although, I liked the exploratory part of the paper I must admit that I found myself confused a few times. The results given in the paper suggest that the proposed HCGD does not demonstrate any advantages on CIFAR-10 and has a limited impact on seq. MNIST. I think that section 3.3 of the paper should be extended and demonstrate some more convincing results.    \nOverall, I am not certain about my assessment. Therefore, I set my confidence level to \"2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper\". \n\nUpdate on 17 Nov:\n\nSection 2. \nI am not sure that the results shown in Figure 2 tell more answers than they pose new questions. \nFor instance, \"In particular, the parameter distance between successive epochs is negatively correlated with the L^2 distance for most of optimization (Fig. 2b). The distance from initialization shows a clean and positive relationship, but the relationship changes during optimization\"  \nWould it be possible to have a supplementary figure with weight decay switched-off? I am not sure why you need it at all since the purpose is not to get state-of-the-art results. Could it also explain the angle for L^2/l^2 shown in the third column since weight decay is something that affects l^2? \nI am not sure that the discussion of the negative correlation is sufficient. The actual correlation is linked to the stage of convergence, it would be nice to have a figure showing its average value per epoch (you say it is negative for the most part of optimization) and some discussion on its impact for the remaining part of your paper. \n\nSection 3.\nI am not an expert in online learning, this is probably why I don't recognize the novelty of the proposed approach. Is it novel to train networks for new tasks while making the objective function accounting for the old tasks? It sounds like a definition of online learning of multiple tasks. Importantly, here it is done while keeping training data from the old tasks. I understand your arguments about storage, but I find it surprising that your proposed change to the objective function is novel. If it is the case, please emphasize it more and mention that despite its simplicity, this idea is very novel. Otherwise, please cite relevant papers where similar methods were used. \n\nI am not sure it is optimal to put Algorithm 1 in experimental results and applications. I don't see it as an application of your observations. I can imagine that the algorithm was inspired by your observations but it is your primary contribution and if possible should be discussed in a separate section. Here, you present it and then discuss how it is related to the natural gradient. \nPlease consider an alternative presentation where you first discuss the natural gradient and its various related works and algorithms, then present your algorithm and then demonstrate your empirical observations. This presentation might contradict the timeline of the development of your approach but it might help to better connect your work to other works  on the same topic. Also, it might help to better show novelties of your approach/observations. \n\nPlease comment if you find some interesting connection with [1].\n\n[1] \"Regularizing neural networks by penalizing confident output distributions\" https://arxiv.org/pdf/1701.06548.pdf\n\nUpdate on Nov 30:\nI updated my score to 6 and my confidence level to 3.  \n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}