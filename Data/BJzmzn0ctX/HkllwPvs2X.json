{"title": "Interesting results, slightly unbalanced presentation", "review": "The authors propose several techniques to speed up the previously proposed Neural Theorem Prover approach. The techniques are evaluated via empirical results on several benchmark datasets.\n\nLearning interpretable models is an important topic and the results here are interesting and valuable to the community. However, I feel that the paper in its current form is not yet ready for publication in ICLR, for the following reasons:\n\n1) The authors propose three improvements. The first is a speed-up through nearest neighbor search instead of a brute-force search. This is the most elaborated section out of the three, yet seems like the most trivial -- unless the authors can provide an analytical bound on the loss in ntp score w.r.t the neighborhood size. It is a standard and well-known technique to restrict the search to a neighborhood, widely used in any applications of word embedding (e.g. in Khot et el's Markov Logic Networks for Natural Language Question Answering). The attention mechanism (essentially reducing the model capacity) is also well-known but its effect in this particular framework is not properly elaborated. The same can be said for the use of mentions.\n\n2) The section on experiment results seems a bit rushed -- the authors did mention some last-minute discovery that may affect some of the presented results. The section can be a little hard to parse. In particular, it would be useful for the authors to focus on providing more insights on how the proposed techniques improve the results, and in what ways.\n\n3) Section 2 on the NTP framework is not very helpful for a reader that has not read the previous paper on NTP (in particular, the part on training and rule learning). For a reader that has done so, the section feels redundant.\n\n", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}