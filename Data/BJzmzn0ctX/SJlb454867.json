{"title": "Interesting direction but needs more discussion", "review": "[Summary]\nThis paper scales NTPs by using approximate nearest neighbour search over facts and rules during unification. Additionally, the paper incorporates mentions as additional facts where the predicate is the text that the entities of the mention are contained in. The paper also suggests parameterizing predicates using attention over known predicates. The increments presented are reasonable and justified, but the experimental results, specifically on the larger datasets, warrant further investigation.\n\n[Pros]\n- Reasonable and interesting increments on top of NTP.\n- Scaling the approach to larger datasets is well motivated.\n- Utilizing text is an interesting direction for NTP in terms of integrating it with past work on KG completion.\n\n[Cons]\n- Empirical performance on larger datasets needs further investigation.\n- No ablation study is performed so the effect of incorporating mentions and attention are unclear.\n- Baseline performance on FB15k-237 seems weak compared to the original papers as well as more recent papers re-examining baselines for KG completion (http://aclweb.org/anthology/W17-2609). Is this due to the d=100 restriction, or were pretrained embeddings not used? Without further explanation, the claim that scores are competitive with SOTA seems unjustified, at least for FB15k-237 since the model performs significantly worse than the baselines which seem to be worse than previously reported.\n\n[Comments]\n- For reproducibility: it is unclear whether evaluation in FB15k-237 is carried out on the KB+Text, KB, or Text portions of the dataset.\n\n[Overall]\nIt\u2019s great that NTP was scaled up to handle larger datasets, however further analysis is needed. The argument that performance is given up for interpretability needs more discussion, and the effect of each addition to the system should be discussed as well.\n", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}