{"title": "Nice experiments although it lacks a bit of novelty", "review": "# 1. Summary\nThis paper presents a model for future video prediction, which integrates 3D convolutions into RNNs. The internal operations of the RNN are modified by adding historical records controlled via a gate-controlled self-attention module. The authors show that the model is effective also for other tasks such as early activity recognition.\n\nStrengths:\n* Nice extensive experimentation on video prediction and early activity recognition tasks and comparison with recent papers\n* Each choice in the model definition are motivated, although some clarity is still missing (see below)\n\nWeaknesses:\n* Novelty: the proposed model is a small extension of a previous work (Wang et al., 2017) \n\n\n# 2. Clarity and Motivation\nIn general, the paper is clear and general motivation makes sense, however some points need to be improved with further discussion and motivation:\n\nA) Page 2 \u201cUnlike the conventional memory transition function, it learns the size of temporal interactions. For longer sequences, this allows attending to distant states containing salient information\u201d: This is not obvious. Can the authors add more details and motivate these two sentences? How is long-term relations are learned given Eq. 1? \nB) Page 5 \u201cThese two terms are respectively designed for short-term and long-term video modeling\u201d: How do you make sure that Recall(.) does not focus on the short-term modeling instead? Not clear why this should model long-term relations.\nC) Page 5 and Eq 1: motivation why layer norm is required when defining C_t^k is not clear\nD) What if the Recall is instead modeled as attention? The idea is to consider only C_{1:t-1}^k (not consider R_t) and have an attentional model that learn what to recall based only on C. Also, why does Recall need to depend on R_t?\nE) Page 5 \u201cto minimize the l1 + l2 loss over every pixel in the frame\u201d: this sentence is not clear. How does it relate to Eq. 2?\n\n\n# 3. Novelty\nNovelty is the major concern of this paper. Although the introduced new concepts and ideas are interesting, the work seems to be an extension of ST-LSTM and PredRNN where Eq 1 is slightly modified by introducing Recall. \nIn addition the existing relation between the proposed model and ST-LSTM is not clearly state. Page 2, first paragraph: here the authors should state that model is and extension of ST-LSTM and highlight what are the difference and advantage of the new model.\n\n\n# 4. Significance of the work\nThis paper deals with an interesting and challenging topic (video prediction) as well as it shows some results on the early activity recognition task. These are definitively nice problem which are far to be solved. From the application perspective this work is significant, however from the methodological perspective it lacks a bit of significance because of the novelty issues highlighted above.\n\n\n# 5. Experimentation\nThe experiments are robust with nice comparisons with recent methods and ablation study motivating the different components of the model (Table 1 and 2). Some suggested improvements:\n\nA) Page 7 \u201cSeq 1 and Seq 2 are completely irrelevant, and ahead of them, another sub-sequence called prior context is given as the input, which is exactly the same as Seq 2\u201d: The COPY task is a bit unclear and need to be better explained. Why are Seq. 1 and 2 irrelevant? I would suggest to rephrase this part.\nB) Sec. 4.2, \u201cDataset and setup\u201d: which architecture has been used here?\nC) Sec. 4.3, \u201cHyper-parameters and Baselines\u201c: the something-something dataset is more realising that the other two \u201ctoy\u201d dataset. Why did the authors choose to train a 2 layers 3D-CNN encoders, instead of using existing pretrained 3D CNNs? I would suspect that the results can improve quite a bit.\n\n\n# 6. Others\n* The term \u201cself-supervised auxiliary learning\u201d is introduced in the abstract, but at this point it\u2019s meaning is not clear. I\u2019d suggest to either remove it or explain its meaning.\n* Figure 1(a): inconsistent notation with 2b. Also add citation (Wang et al., 2017) since it ie the same model of that paper\n\n-------\n# Post-discussion\nI increased my rating: even if novelty is not high, the results support the incremental ideas proposed by the authors.\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}