{"title": "metric-based meta-learning via individual feature space embedding", "review": "Summary:\nOne of popular approach to few-shot classification is to learn an embedding function to a common feature space where the similarity between two examples is expected to be well determined. The current work claims that query-dependent feature space (referred to as individualized feature space) gains over the common feature space, in the task of few-shot classification. To this end, the paper employed a technique 'kernel generator' which has been recently proposed in [Han et al., 2018]. Few-shot classification is done using distance (e.g. Euclidean) in the query-dependent feature space. \nThe paper evaluates this method using Omniglot and miniImagenet.\n\nStrengths:\n- Constructing individualized feature space tailored to each query is a novel idea.\n- The paper shows strong quantitative results.\n\nWeaknesses:\n- The clarity is a big obstacle in this paper. Section 3 contains the main idea on 'kernel generator' which is the critical technique to map input images to individualized feature spaces. Unfortunately Section 3 is hard to follow. \n- Moreover, the idea of kernel generator is the one used in [Han et al., 2018], so the contribution of this paper is very limited.\n- In a nutshell, the current work can be considered as a mix of matching network and kernel generator. \n\nSpecific comments:\n- Regarding terminology, authors state that \"there are three sets of examples in a few-shot classification task: a training set, a support set, and a testing set. The training set and the support set have disjoint label spaces with each other while the testing set shares the same label space with the support set.\" I am very confused with what authors mean by support set. In general, each episode has a support set as well as queries in both meta-training and meta-test phases. Meta-training and meta-test has disjoint label spaces. \n- It is not clear to me what the problem setting is here. Queries in training and test phases have different label spaces. So, I am wondering feature space tailored to queries in the training phase can be well generalized to the test phase. Or you assumes that both cases have the same label space?\n-Fig 2: The kernels and the conv features interact in a node which says \u201cX\u201d, making it seem like we are either pointwise multiplying or taking an outer product. The figure would be clearer if it somehow expressed that the two interact via convolution. (To add to this confusion, the kernels are thin which makes them look like vectors)\n-eq(6): the index i is used to denote two things at once (g_i, c_ij). This notation should be different.\n-eq(6): it says g_i is a fully-connected layer, but P_q^ij is a 3d tensor. Is g_i a 1x1 convolution, or do you flatten P?\n-eq(9): what is H? Does it mean entropy? How is the set K_q a distribution of kernels? How does this loss relate to capturing the intrinsic characteristics of an object? This whole part should be clearer.\n\n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}