{"title": "Good paper, needs some clarification in the experimental section and the introduction", "review": "PAPER SUMMARY\n-------------\nThis paper proposes an approach to video prediction which autonomously finds an action space encoding differences between subsequent frames. This approach can be used for action-conditioned video prediction and visual servoing. \nUnlike related work, the proposed method is initially trained on video sequences without ground-truth actions. A representation for the action at each time step is inferred in an unsupervised manner. This is achieved by imposing that the representation of this action be as small as possible, while also being composable, i.e. that that several actions can be composed to predict several frames ahead.\nOnce such a representation is found, a bijective mapping to ground truth actions can be found using only few action-annotated samples. Therefore the proposed approach needs much less annotated data than approaches which directly learn a prediction model using actions and images as inputs.\n\nThe approach is evaluated on action-conditioned video prediction and visual servoing. The paper shows that the learned action-space is meaningful in the sense that applying the same action in different initial condition indeed changes the scenes in the same manner, as one would intuitively expect. Furthermore, the paper shows that the approach achieves state of the art results on a action-conditioned video prediction dataset and on a visual servoing task.\n\nPOSITIVE POINTS\n---------------\nThe idea of inferring the action space from unlabelled videos is very interesting and relevant.\n\nThe paper is well written.\n\nThe experimental results are very interesting, it is impressive that the proposed approach manages to learn meaningful actions in an unsupervised manner (see e.g. Figure 3).\n\nNEGATIVE POINTS\n---------------\nIt is not exactly clear to me how the model is trained for the quantitative evaluation. On which sequences is the bijective mapping between inferred actions and true actions learned? Is is a subset of the training set? If yes, how many sequences are used? Or is this mapping directly learned on the test set? This, however, would be an unfair comparison in my opinion, since then the actions would be optimized in order to correctly predict on the tested sequences.\n\nThe abstract and introduction are too vague and general. It only becomes clear in the technical and experimental section what problem is addressed in this paper.", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}