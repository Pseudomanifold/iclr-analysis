{"title": "interesting and thorough theory of generalization and transfer learning", "review": "Pros: The paper tackles an interesting problem of generalization and transfer learning in deep networks. They start from a linear network to derive the theory, identifying phases in the learning, and relating learning rates to task structure and SNR. The theory is thorough and backed up by numerical simulations, including qualitative comparisons to nonlinear networks. \n\nThe intuition behind alignment of tasks \n\nCons: Most of the theory is developed on a linear network in an abstracted teacher/student/TA framework, where the analysis revolves around the the SVD of the weights. It's unclear to what extent the theory would generalize not only to deep, nonlinear networks (which the paper addresses empirically) but also different structures in the task that are not well approximated by the SVD.", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}