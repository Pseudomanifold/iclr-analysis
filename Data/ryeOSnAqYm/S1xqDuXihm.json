{"title": "Nice presentation of a serious issue, with some flaws", "review": "This paper provides a good presentation of a serious problem in evaluating (as well as training!) performance of machine learning models for program synthesis / program induction: considering specifically the problem of learning a program which corresponds to given input/output pairs, since large datasets of \"real-world\" programs typically do not exist it necessary to construct a synthetic dataset for training and testing; this requires both (a) generating programs, and (b) generating input/output examples for these programs. Enumerating either all possible programs or examples is typically impossible, and so a sampling scheme is used to simulate \"reasonable\" programs and examples. This may hinder generalization to other data not often produced by the sampling scheme.\n\nTo address this, the paper then argues that programs should be synthesized from a distribution which as as uniform as possible over a set of user-specified statistics (the \"salient variables\") as well as over the input space. Intuitively, this makes sense: maximizing the entropy of the synthetic data should provide good coverage over the entire input space. However, there are a few ways in which the particular approach is unsatisfying:\n\n(1) It requires manual curation of salient random variables. This sort of punts the decision of \"what should my sampling procedure be\" to \"what is my choice of salient variables to make uniform\". I agree that this is still an improvement.\n\n(2) The procedure described for generating synthetic examples is essentially a rejection sampling algorithm, and it will fail to generate examples in a reasonable timeframe if the original proposal distribution is highly non-uniform, or if the salient random variables include values which fall in the tail of the proposal distribution.\n\nAlso, relatedly, I don't follow the description of correctness in section 8.2 at all. What is meant by the \"= 1\" at the end of the line right before \"\u2026 And thus\u2026\"? Clearly P_r[X=x] cannot both equal 1, and equal k. Is the \"=1\" meant to only mean the summand itself? If so, please fix the notation. Also, I assume that k is meant to be the cardinality of the set {s: X(s) = x}, but this is not defined anywhere. Notational issues aside, unless the mapping X(s) from sample to salient variable is one-to-one, then I'm not clear how the P_q[X = X(s)] would relate to q(s). This should be made more clear. Also, I believe there need to be conditions on q(s), e.g. such that min_x P_q[X = x] must always be greater than zero.\n\n\nThese issues aside, the empirical demonstrations on the Karel the Robot examples are nicely presented and make the point well. My primary question here would be around section 5, the \"real-world benchmarks\", where it is observed that the baseline model performs less well than re-training on a uniform / homogenized dataset. While it is nice that it performed better, I don't understand why even the better number (19.4%) is so low; the performance of the uniform model in table 1 tends to be much higher (in the 60% to 70% range). This would suggest that the uniform model perhaps is significantly *underweighting* important parts of the space. What is causing this? e.g. what do the salient variables look like for real-world examples?\n\n\nFinally, I am not sure I understand how the calculator example fits into this paper. Unless I misunderstand, it is not a program synthesis task, but rather a regression task. Clearly it does still depend on generation of synthetic data, but that is more a different task (as described in section 2). I feel its inclusion somewhat dilutes the paper. Rather, it would be nice to see more discussion or investigation into the failure modes of these trained models; for example, looking deeper at the handling of control flow and recursion, or at whether particular values of salient variables tended to be correlated with success or failure under different train / test regimes.\n\n\n\n===== after updates =====\n\nThanks for the edits \u2014 I believe the overall paper is more clearly presented, now.\n\nI still think it is a stretch to consider the calculator domain is a program induction problem: it is a regression problem, from an input string to an output integer, or alternately a classification problem, since it computes the result mod 10. The only way I could understand this as a program induction problem is rather obliquely, if the meaning is that any system which is able to compute the result of the calculator evaluation has implicitly replicated internally, in some capacity, the sequence of instructions which are evaluated. I don't think this is really very clear though; for example, given two calculator programs, one a subprogram of another (e.g., \"4*(3+2)\" and \"3+2\"), do the resulting \"induced\" computations share the same compositional structure? The examples of program induction in section 2 are largely architectures which are explicitly designed to have properties which mimic conventional programming languages (e.g. extra data structures as memories, compositionality, \u2026). In contrast, the calculator example in this paper simply uses an LSTM. \n\nThat said, I think it's still a great example! Learning a fast differentiable model which accurately mimics existing non-differentiable model has tons of applications, and has exactly the same challenges regarding synthetic data. \n\n\n\nI have to say I find the new section 8.3 a bit intuitively challenging; e.g. it's not clear really how long a waiting time of 48 log(2|X|/\\delta) / (p|X|^2 z^2) really is. But, to that end, I appreciate the empirical discussion in 8.4\u20138.6.\n\nI've updated my review to increase my score \u2014 I lean towards accepting this paper, as it is a timely contribution and I think it is important for future program synthesis papers to take the results here to heart. I've reduced my confidence slightly, as I have not fully reviewed the new proof in 8.3.", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}