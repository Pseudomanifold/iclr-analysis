{"title": "Review", "review": "The authors propose an exploration bonus that is aimed to aid in sparse reward RL problems. The bonus is given by an auxillary network which tries to score whether a candidate observation is difficult to reach with respect to all previously observed novel observations which are stored in a memory buffer. The paper considers many experiments on complex 3D environments. \n\nThe paper is well written and very well illustrated. The method can be clearly understood from the 3 figures and the examples are nice. I think the method is interesting and novel and it is evaluated on a realistic and challenging problem.\n\nIt would be good if the authors could further elaborate on the scalability of the method in terms of compute/memory requirements and related to that if the implementation is cumbersome. I didn\u2019t understand well how the method avoids the issue of old memories leaving the buffer. It seems for a large enough environment important observations will eventually become discarded causing a poor approximation of the curiosity bonus? For the large scale experiments I would like to know more rough details of the number of the compute time needed for the method relative to the PPO baseline and the other baseline (e.g. number of nodes for example and how long they run approximately)\n\nAre there any potential issues with adapting the method on 2D environments like Atari? this could permit direct comparisons with several other recently proposed techniques in this area.\n\nThe Grid-Oracle result is very interesting and a contribution on it\u2019s own if similar results for complex 3D environments are not published anywhere else. It demonstrates well that exploration bonuses can help drastically in these tasks. I think if possible it would be interesting to have an idea how fast this method converges (number of training steps) and not just the final reward as reported in the tables. Indeed as a general problem the current number of training steps of any methods shown seem to indicate these techniques are too data hungry for non-simulated environments. For some applications (e.g. aimed at sim-to-real transfer) the grid-oracle approach might be a good alternative to consider. I would be interested to know if the authors had some thoughts on this.\n\nOverall I lean towards accept, the method is shown to work on relatively very complex problems in DMLab and VizDoom while most sparse reward solutions proposed are typically evaluated on relatively simpler and unrealistic tasks. I would consider to further increase my score if the authors can address some of the comments. \n", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}