{"title": "Interesting direction and discussion to study the relationship \u201cmost\u201d with limited experimental evaluation focusing on a single model.", "review": "Problem and contribution:\nThe paper studies if the Visual Question answering model \u201cFILM\u201d from Perez et al (2018) is able to decide if \u201cmost\u201d of the objects have a certain attribute or color. \nFor this it tries to mimic the setup used to test human abilities in the study by Pietroski et al. (2009).\n\nThe main contribution of this is work is a discussion of how a model could solve the problem of deciding \u201cmost\u201d and the study which shows that the studied model has some ability to do this. From this the paper concludes that the model is likely to have some approximate number system.\n\n\nStrengths:\n1.\tThe paper looks at a new angle to study and characterize CNN models in general, and VQA models in particular by looking into the psycholinguistic literature experimental setup studied with human subjects.\n2.\tThe paper studies different variants of controlling for different factors (e.g. pairing data points, area used, different training data and pre-trained vs. trained from scratch CNN models)\n3.\tIt is interesting to see that the models performance reasonably aligns with the curve predicted by \u201cWeber\u2019s law\u201d.\n\n\nWeaknesses:\n4.\tNumber of objects vs. ratios is not disentangled: While the paper clarifies that not only a smaller number of objects are used, it would be interesting to understand if similar conclusions hold if only the same number or about the same number of total objects are used but the ratios change (at least for more extreme ratios, 1:2, this seems to be the case as they achieve 100% accuracy).\n5.\tThe paper only focusses on a single VQA model (FILM) which limits the understanding if this observation is specific to this model; what about other models such as the one from Hudson & Manning (2018), or Relation Networks (Santoro et al) or even simpler baselines: A system which two attention mechanisms (without normalizations) which are sum pooled and then compared would sort of explicitly encode the idea of the APN system. It would be valuable to compare them to see how different systems (can) solve this task. I would expect that the architecture favors certain capabilities; e.g. Relation Networks might lead more to a paring-based strategy. Or Zhang et al. (2018) might be able to exploit explicit counting to solve the task.\n6.\tThe \u201cmost\u201d ability or APN ability seems to be highly related to accumulation in neural networks. The paper FiLM uses global max-pooling and I am wondering if this affect this ability. \n7.\tThe study is only performed on symbols which a very large training set (given the difficulty of the problem) and it not clear how well this generalizes to real images or scenarios with less training data. \n7.1.\tMaybe beyond the scope of this work, but it would be interesting to understand how much training data different models need to obtain this capability.\n8.\tFor evaluation: Are there distractors, i.e. elements which don\u2019t belong to set A or B? If not, how would distractors affect it.\n9.\tClarity: \n9.1.\tThe equation between equation (1) and (2) misses a number [I will call it 1.5 for now]\n9.2.\tIn formula (1.5) \u201c<=>\u201d seems to be used at different levels (?) it would be good to use brackets to make clear which level \u201c<=>\u201d refers to.\n\nMinor:\n10.\tThe title suggests that the paper studies multiple VQA models but only a single model is studied.\n\nConclusion:\nThe paper looks into an interesting direction to study CNN models but has some limitations including studying only a single VQA model type, limited to artificially generated images. \n", "rating": "5: Marginally below acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}