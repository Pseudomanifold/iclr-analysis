{"title": "Good paper!", "review": "This paper introduces a high-level semantic description for 3D shapes. The description is given by the so-called ShapeProgram,  Each shape program consists of several program statements. A program statement can be either Draw, which describes a shape primitive as well as its geometric and semantic attributes, or For, which contains a sub-program and parameters specifying how the sub-program should be repeatedly executed. The ShapeProgram is connected with an input through two networks, the program generator (encoder) and a neural program executor (decoder). Both encoder/decoder are implemented using LSTM. The key ML contribution is on the decoder, which leverages a parametrization to make the decoder differentiable. The major advantage of the proposed technique is that it does not need to specify the ShapeProgram in advance. In the same spriit of training an auto-encoder. It can be learned in a semi-supervised manner. However, in practice, one has to start with a reasonably good initial program. In the paper, this initial program was learned from synthetic data. \n\nThe paper presents many experimental results, including evaluation on synthetic datasets, guided adaptation on ShapeNet, analysis of stability, connectivity measurement, and generalization, and application in shape completion. The presented evaluations, from the perspective of proposed experiments, is satisfactory. \n\nOn the downside, this paper does not present any baseline evaluation, party due to the fact that the proposed problem is new. In fact, existing inverse procedural modeling techniques require the users to specify the program. However, the proposed approach could be even more convincing if it evaluates the performance of semantic understanding. For example, would it be possible to evaluate the performance on shape segmentation?\n\nAdditional comments:\n1. How important is the initial program? \n\n2. The interactions among shape parts usually form a graph, not necessarily hierarchical. This should be discussed.\n\n3. What is the difference between 3D shapes and 3D scenes? Does this approach require a front/up-right orientation?\n\n4. It would be interesting to visualize/analyze the intermediate representations of the neural shape generator. Does it encode meaningful distributions among shape parts?\n\nOverall, it is a good paper, and I would like to see it at ICLR 2019.\n", "rating": "7: Good paper, accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}