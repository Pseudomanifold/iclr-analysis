{"title": "Essential concepts and quantities undefined", "review": "The authors propose an information theoretic metric to determine a priori if a representation learned from a source task can be useful when learning another task. This is a timely topic and being able to compute such as metric between tasks upfront would be of great interest.\n\nWhile the motivation and contributions of the paper are clearly stated, a number of questions remain. Central concepts like error exponent or maximal HGR correlation are mentioned in passing. The former is important to understand whether (1) makes sense and the latter is a fundamental quantity for this work. The surprising fact is that HGR is not discussed at all, nor is there any intuition provided of what this quantity represents.\n\nWhile the proposed H-score is attractive when a source task has to be selected, as the denominator of the task transferability itself does not need to be computed, it is not straightforward to compute this quantity in general. The authors suggest to use the alternative conditional expectation (ACE) algorithm in order to optimize (2). ACE is not discussed in any detail (e.g., how accurate is this procedure; what are the choices and/or trade-offs if any?) and (2) is not justified. Overall, I felt section 4.2 was relatively inaccessible, but important as it indicates whether the proposed metric is of any use in practice.\n\nFinally, I did not understand the argument that says the H-score is to be prepared over the mutual information. To me the mutual information is still the golden standard. It was also not clear why the proposed approach would not straightforwardly apply to non classification problems as suggested in the future work.", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}