{"title": "Unclear whether this paper surpasses prior research", "review": "The paper describes a cache side-channel attack on a deep learning model. In a cache side-channel attack, the attacker sets up a process on the same machine where the victim process (that is running the training or evaluation job for the DNN model) is running. It is assumed that the victim process uses a common shared library for DNN computations as the attacking process. The attacking process flushes the cache, then observes access times for key functions. The paper shows that, based on the speed of accessing previously flushed functions, the attacker can discover the high-level network architecture, namely the types of layers and their sequence. The paper shows that, by spying on such cache access patterns in the Tensorflow library, this method can reliably extract the above high-level information for 11 different network architectures. It also describes a few counterattack alternatives whereby the victim can obfuscate its cache access patterns for self-protection.\n\nThe significance of the results is not clear to me. The extracted information is very high level. What realistic attacks can be constructed from such a coarse-grained fingerprinting? The experimental results show that the fingerprint can be used to map the architecture to one of the 13 well-known architectures (VCC16, ResNet, DenseNet, Inception, etc.). But so what? What does the victim lose by revealing that it's using one of a few very well known types of DNNs (the ones tested in this paper). There may very well be a good reason why this is very dangerous, but that is not explained in the paper. Not being familiar with this line of research and its significance, I looked up several of the related papers (Suciu et al., 2018, Tramer et al., 2017, Papernot et al., 2017, Yan et al., 2018). None of them could explain why this particular type of fingerprinting is dangerous.\n\nOf the cited previous work, Yan et al., 2018 seems to present the most closely related approach. The method described in that paper is very similar: cache side attack on a shared library through a co-located attacker process. They monitor at a finer grain -- Generalized Matrix Multiplications -- and are thus able to infer more details such as the size of the layers. This also makes the inference problem harder -- they were able to narrow down the search space of networks from >4x10^35 to 16 (on VGG16). On the surface, the results presented in this paper seem stronger. But they are actually solving a much easier problem -- their search space is one of 13 well-known networks. To me, Yan et al.'s approach is a much more powerful and promising setup.\n\nOverall, while the paper is clearly written and presents the idea succinctly, it is derivative of previous research, and the results are not stronger. I'm not an expert in this area, so it's possible that I missed something. Based on my current understanding, however, I recommend reject.", "rating": "4: Ok but not good enough - rejection", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}