{"title": "Interesting but limited study", "review": "This paper follow recent trend of adversarial examples which is on generating images with small differences in the input space, but that are misclassified by a large margin by a neural net. The key idea of the paper is that any negative component before a ReLU activation share the same zero feature after the ReLU. Thus, any neural network that has ReLU activations have a polytope in the input space that will have identical activations in the later layers. Based on this observation, the paper assert that such polytope always exist and describe how to find its corners with a gradient descent based method. Two simple experiments on MNIST and ImageNet datasets are carried to show the feasibility of the method in practice and the existence of images with feature collision, together with their average L2 distance from real images. Since the images are clearly not \"natural\" images, a further method based on selecting patches of real images is reported and tested on ImageNet. This shows that the approach can be further applied on macro-level differences.\n\nStrengths\n+ The observation of the existence of the polytope in presence of ReLU activation is interesting and can probably be used to further refine attacks for generating adversarial examples.\n+ The paper is clear and is comprehensive of all the basic steps.\n+ Examplar experiments show the possibility of using the key idea to generate adversarial examples\n\nWeaknesses:\n- The experiments are very limited and show just 5 examples of generated images on MNIST and ImageNet. In Sect 3.2 it is observed that it is hard for human eyes to notice the difference but that is clearly not the case for the figure reported. The same for Fig. 7 on the macro-level which are even more distorted. Although this is minor, since the method is still shown to be working, the statements on the similarity of images seem incorrect. Beside the qualitative examples, the measurement of average similarity based on L2 is not so indicative at the perception level, but still interesting to see.\n- No comparison with other methods to generate adversarial examples are reported (e.g. Shafani et al 2018, Szegedy et al. 2013).\n\nMinor issues:\n- Figure 2, Figure 3 show the results, but it would also be interesting to observe what happens from the starting image to the final generated images.    \n- Personally, I prefer to see related work after the introduction section. Reading it at the end breaks the flux of the paper.\n- The observation is only applicable to ReLU activations (but other activation functions may be in the last layer), limiting the impact of the paper.\n\n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}