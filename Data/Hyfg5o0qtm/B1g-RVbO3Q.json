{"title": "An Official Review: Temporal Gaussian Mixture Layer for Videos", "review": "This paper presents Temporal Gaussian Mixture (TGM) layer, efficiently capturing longer-term temporal dependencies with smaller number of parameters. The authors apply this layer to the activity recognition problem, claiming state-of-the-art performance compared against several baselines.\n\nStrong points of this paper:\n - The authors clearly described the proposed layer and model step by step, first explaining TGM layer, followed by single layer model, then generalizing it to multi-layer model.\n - The authors achieved state-of-the-art performance on multiTHUMOS dataset. The results look great in two aspects: the highest MAP scores shown in Table 1, and significantly smaller number of parameters shown in Table 2 to achieve the MAP scores.\n\nQuestions:\n - Basically, the idea in this paper is proposing to parameterize conv layers with Gaussian mixtures, with multiple pairs of mean and variance. Although Gaussian mixtures are powerful to model many cases, it might not be always to perfectly model some datasets. If a dataset is highly multi-modal, Gaussian mixture model also needs to have large M (number of mixture components). It is not clear how the authors decided hyper-paramter M, so it will be nicer for authors to comment the effect of different M, on various dataset/task if possible.\n - Same for the hyper-parameter L, the temporal duration. It will be nicer to have some experiments with varied L, and to discuss how much this model is sensitive to the hyper-parameter.", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}