{"title": "The proposed method is interesting and promising approach, but the contribution is not clear. ", "review": "\n- Summary\nThis paper proposes an evolutionary-based method for the multi-objective neural architecture search, where the proposed method aims at minimizing two objectives: an error metric and the number of FLOPS. The proposed method consists of an exploration step and an exploitation step. In the exploration step, architectures are sampled by using genetic operators such as the crossover and the mutation. In the exploitation step, architectures are generated by a Bayesian Network. The proposed method is evaluated on object classification and object alignment tasks.\n\n- Pros\n  - The performance of the proposed method is better than the existing multi-objective architecture search methods in the object classification task.\n  - The effect of each proposed technique is appropriately evaluated. \n\n- Cons\n  - The contribution of the proposed method is not clear to me. The proposed method is compared with the existing multi-objective methods in terms of classification accuracy, but if we focus on that point, the performance (i.e., error rate and FLOPs) of the proposed method is almost the same as those of the random search judging from Table 4. It would be better to compare the proposed method to the existing multi-objective methods in terms of classification accuracy and other objectives.\n  - This paper argues that the choice of the number of parameters is sub-optimal and ineffective in terms of computational complexity. Please provide more details about this point. For example, what is the drawbacks of the number of parameters, what is the advantages of FLOPs for multi-objective optimization?\n  - Please elaborate on the procedure and settings of the Bayesian network used in this paper.\n  - It would be better to provide discussions of recent neural architecture search methods solving the single-objective problem.\n", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}