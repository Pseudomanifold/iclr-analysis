{"title": "interesting idea but the significance of the experimental results is unclear and the motivation should better match the evaluation ", "review": "The paper proposes to use a regularization which preserves nearest-neighbor smoothness from layer to layer. The approach is based on controlling the extent to which examples from different classes are separated from one layer to the next, in deep neural networks. The criterion computes the smoothness of the label vectors (one-hot encodings of class labels) along the nearest-neighbor graph constructed from the euclidian distances on a given layer's activations. From an algorithmic perspective, the regularization is applied by considering distances graphs on minibatches. Experiments on CIFAR-10 show that the method improves the robustness of the neural networks to different types of perturbations (perturbations of the input, aka adversarial examples, and quantization of the network weights/dropout0.\n\nThe main contribution of the article is to apply concepts of graph regularization to the robustness of neural networks. The experimental evaluation is solid but the significance is unclear (error bars have rather large intersections), and there is a single dataset.\n\nWhile the overall concept of graph regularization is appealing, the exact relationship between the proposed regularization and robustness to adversarial examples is unclear. There does not seem to be any proof that adersarial examples are supposed to be classified better by keeping the smoothness of class indicators similar from layer to layer. Section 3.4 seem to motivate the use of the smoothness from the perspective of preventing overfitting. However, I'm not sure how adversarial examples and the other forms of perturbations considered in the experiments (e.g., weight quantization) are related to overfitting.\n\nstrengths:\n- practical proposal to use graph regularization for neural network regularization\n- the proposal to construct graphs based on the current batch makes sense from an algorithmic point of view\n\n\ncons: experimental results are a bit weak -- the most significant results seem to be obtained for \"implementation robustness\", but it is unclear why the proposed approach should be particularly good for this setting since the theoretical motivation is to prevent overfitting. The results vs Parseval regularization and the indications that the metohd works well with Parseval regularization is a plus, but the differences on adversarial examples are tiny.\n\nother questions/comments:\n- how much is lost by constructing subgraphs on minibatches only?\n- are there experiments (e.g., on smaller datasets) that would show that the proposed method indeed regularizes and prevents overfitting as motivated in Section 3.4?\n\n\n", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}