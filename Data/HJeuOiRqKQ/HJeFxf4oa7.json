{"title": "Serious empirical study, but somewhat unsurprising and expected conclusions. ", "review": "This paper asks what is the role of pooling in the success story of CNNs applied to computer vision. \nThrough several experimental setups, the authors conclude that, indeed, pooling is neither necessary nor sufficient to achieve deformation stability, and that its effect is essentially recovered during training. \n\nThe paper is well-written, it is clear, and appears to be readily reproducible. It addresses an interesting and important question at the interface between signal processing and CNNs. \n\nThat said, the paper does not produce any clear novel results. It does not provide any theoretical result, nor any new algorithm. Its contributions consist of three empirical studies, demonstrating that (i) the benefits of pooling in terms of deformation stability can be achieved through supervised learning the filters instead (sec 3), (ii) the mechanism to obtain stability through learning essentially consists on reducing the bandwidth of (some) filters (sec4), and (iii) that this mechanism is data-dependent (sec 5). None of these studies strike the reviewer as particularly revealing. Moreover, the reviewer felt that the authors could have built on those findings to ask (and hopefully answer) a few interesting questions, such as:\n-- Nowhere in the paper there is a discussion about critical Nyquist sampling and the need to reduce the bandwidth of a signal prior to downsampling it in order to avoid aliasing. Average pooling provably does it, and learnt filters do it provided they indeed become bandlimited. What are the links between deformation stability and the ability to avoid aliasing? \n-- How many lowpass antialiasing filters are needed per layer to provide sufficient stability? \n-- Also, the authors should relate this study with similar works that do the same in speech (e.g. https://www.isca-speech.org/archive/Interspeech_2018/abstracts/1371.html). \n\nIn conclusion, my impression is that this paper requires a major iteration before it can be of widespread interest to the community. I encourage the authors to think about the above points. \n\n\n ", "rating": "5: Marginally below acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}