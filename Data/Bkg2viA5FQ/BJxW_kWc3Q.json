{"title": "A comprehensive consideration of hindsight for policy gradients", "review": "Following recent work on Hindsight Experience Replay (Andrychowicz et al. 2017), the authors extend the idea to policy gradient methods. They formally describe the goal-conditioned policy gradient setup and derive the extensions of the classical policy gradient estimators. Their key insight to deriving a computationally efficient estimator is that for many situations, only a small number of goals will be \"active\" in a single trajectory. Then, they conduct extensive experiments on a range of problems and show that their approach leads to improvements in sample efficiency for goal-conditioned tasks.\n\nAlthough the technical novelty of the paper is not high (many of the estimators follow straightforwardly from previous results, however, the goal subsampling idea is a nice contribution), the paper is well written, the topic is of great interest, and the experiments are extensive and insightful. I expect that this will serve as a nice reference paper in the future, and launching point for future work. \n\nThe only major issue I have is that there is no comparison to HER. I think it would greatly strengthen the paper to have a comparison with HER. I don't think it diminishes their contributions if HER outperforms HPG, so I hope the authors can add that.\n\nComments:\n\nIn Sec 6.1, it seems surprising that GCPG+B underperforms GCPG. I understand that HPG+B may underperform HPG, but usually for PG methods a baseline helps. Do you understand what's going on here?\n\nIn Sec 6.2, it would be helpful to plot the average return of the optimal policy for comparison (otherwise, it's hard to know if the performance is good or bad). Also, do you have any explanations for why HPG does poorly on the four rooms?\n\n====\n\nRaising my score after the authors responded to my questions and added the HER results.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}