{"title": "Incremental over previous literature. Contributions not thoroughly validated by experiments", "review": "This paper is essentially a combination of a modified meta-learning reweighting framework plus self-training. The proposed reweighting framework is largely similar to Ren et al. ICML18, with certain changes including cosine similarity based meta-learning objective, layer-wise weighting, and adaptive learning rate. \n\nClarity:\n- The paper is well-written with good clarity.\n\nConcerns:\n- There are several significant weaknesses in the paper that points to a clear rejection of this work:\n\n1) The proposed methods seems incremental, given the existence of Ren et al. ICML18. The idea of self-training is not new either. The authors also failed to cite several highly related works that used pseudo-label/self-training for domain adaptation:\nZou et al., Domain Adaptation for Semantic Segmentation via Class-Balanced Self-Training, ECCV18\nInoue et al., Cross-Domain Weakly-Supervised Object Detection through Progressive Domain Adaptation, CVPR18\nLee, Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks, ICML13 Workshop\n\n2) With all proposed modifications on top of Ren et al. ICML18, there is not any theoretical or empirical justification to support these modifications except the ablation study on adaptive learning rate. The proposed method is not even compared with Ren et al. ICML18, or other meta-learning methods. \n\n3) The proposed GradMix module doesn't seem to outperform many previous literature in the experiment. The only part that gives a very clear gain happens to be the pseudo-label module, which has been investigated widely by many previous works and is not a major contribution of this work.\n\nSummary:\n- Overall, it is hard to see substantial contributions of this work given the incremental improvements, limited justifications, and the limited performance gain from the main technical method.", "rating": "3: Clear rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}