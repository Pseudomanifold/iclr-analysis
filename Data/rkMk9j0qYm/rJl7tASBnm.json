{"title": "Training networks with multiplicative input noise: interesting but with questions", "review": "In this paper, a so-called explainable adversarial learning approach is proposed. It is shown that the use of multiplicative input noise can enhance the robustness of neural networks. My detailed comments are as below. \n\n1) The definition of 'Explainable' is not convinced. The authors claimed that \"the model not only finds the right prediction but also the right explanation. Noise inculcates this explainable behavior by discovering some knowledge about the input/output distribution during training.\" The distribution of the learnt noise is not surprising since by minimizing the training loss, the noise should reflect the example pattern. I am not convinced about the name 'explainable adversarial learning'.\n\n2) In ExL (Algorithm 1), why not consider the affine transformation X N_1 + N_2, where both N_1 and N_2 are learnt from the training process? Is this better than X N_1? What is the rationale behind using universal noise pattern over different minibatches. \n\n3) The proposed ExL framework is quite similar to training over perturbed examples. Here the perturbation is given by X \\times N.  It is expected that ExL will not outperform adversarial training but will outperform the plain training in robustness. From this perspective, I feel that the results are not very impressive. \n\n4) The study on Sec. 2.3 via PCA is nice and Figure 3 is informative. \n\n5) Since the proposed ExL training framework is scaled to large datasets, it is better to cover more experiments, e.g., ImageNet. \n\n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}