{"title": "A new formulation of knowledge distillation", "review": "This paper proposes a framework for few-sample knowledge distillation of convolution neural networks. The basic idea is to fit the output of the student network and that of the teacher network layer-wisely. Such a regression problem is parameterized by a 1x1 point-wise convolution per layer (i.e. minimizing the fitting objective over the parameters of 1x1 convolutions). The author claims such an approach, called FSKD, is much more sample-efficient than previous works on knowledge distillation. Besides, it is also fast to finish the alignment procedure as the number of parameters is smaller than that in previous works. The sample efficiency is confirmed in the experiments on CIFAR-10, CIFAR-100 and ImageNet with various pruning techniques. In particular, FSKD outperforms the FitNet and fine-tuning by non-trivial margins if only small amount of samples are provided (e.g. 100).\n\nHere are some comments:\n\n1. What exactly does \u201cabsorb\u201d mean? Is it formally defined in the paper?\n\n2. \u201cwe do not optimize this loss all together using SGD due to that too much hyper-parameters need tuning in SGD\u201d. I don\u2019t understand (1) why does SGD require \u201ctoo much\u201d hyper-parameters tuning and (2) if not SGD, what algorithm do you use?  \n\n3. According to the illustration in 3.3, the algorithm looks like a coordinate decent that optimizing L over one Q_j at a time, with the rest fixed. However, the sentence \u201cuntil we reach the last block in the student-net\u201d means the algorithm only runs one iteration, which I suspect might not be sufficient to converge.\n\n4. It is also confusing to use the notation SGD+FSKD v.s. FitNet+FSKD, as it seems SGD and FitNet are referring to the same type of terminology. However, SGD is an algorithm, while FitNet is an approach for neural network distillation. \n\n5. While I understand the training of student network with FSKD should be faster because the 1x1 convolution has fewer parameters to optimize, why is it also sample-efficient? \n\n6. I assume the Top-1 accuracies of teacher networks in Figure 4 are the same as table 2 and 3, i.e. 93.38% and 72.08% for CIFAR-10 and CIFAR-100 respectively. Then the student networks have much worse performance (~85% for CIFAR-10 and ~48% for CIFAR-100) than the teachers. So does it mean FSKD is not good for redesigned student networks?\n\n7. While most of the experiments are on CIFAR10 and CIFAR100, the abstract and conclusion only mention the results of ImageNet. Why?", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}