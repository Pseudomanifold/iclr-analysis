{"title": "An apparent flaw in the motivation of the proposed approach undermines confidence", "review": "The paper proposes a multi-discriminator based extension to GAN training. Specifically, it proposes to split a minibatch of samples into further smaller minibatches (microbatches) and train different discriminators on each. The authors state that \"since each D is trained with different fake and real samples, we encourage them to focus on different data properties\". This seems incorrect. Random samples drawn from a distribution do not change various statistics of the distribution in expectation (such as means). It only introduces differences due to noise in the sampling process and this noise is not correlated across training iterations or consistent within a microbatch. Without a meaningful/consistent change in the distributions between microbatches there should be no different data properties for the various discriminators to focus in on. As a consequence, a discriminator which evaluates samples independently should not be able to perform this task. Using batchnorm in the discriminator introduces some batch level interactions via the mean and variance statistics but this appears to be serendipity that the authors do not highlight explicitly. As a sanity check - given a fixed generator - if you continue to train the discriminators on randomly drawn samples from this generator distribution does the microbatch discrimination objective continue to make progress and converge to a minimum? What happens if you remove batchnorm so that the samples are processed independently? Is there an additional detail to your paper/method that I missed or misunderstood that addresses the issue raised here? Can you better articulate your intuition on how randomly assigning data to different microbatches results in different data properties? Does the discriminator make use of batch level statistics in some more advanced way beyond just batchnorm such as the minibatch features in Improved GAN (Salimans 2016)? \n\nA baseline of always having alpha set to zero in order to tease out the potential improvements of the proposed approach from the potential benefits of having multiple discriminators would increase confidence in the approach.\n\nPros: \n+ The proposed IntraFID is interesting but is missing two baselines (IntraFID for two batches of real data and IntraFID for two batches of a baseline GAN without the proposed technique) which would help calibrate and contextualize the newly introduced metric.\n\nCons:\n- The paper seems to have a flaw which calls into question whether it is well motivated (see main text).\n- The paper does not have any direct/controlled comparisons with other methods that utilize multiple discriminators or batch based discrimination.\n- The paper mis-states the Inception Score of Improved GAN. The best result from the Improved GAN paper achieves 6.86 in an unlabeled setting (see -L+HA in the ablation study in Table 3) but is listed as 4.36. \n- The paper misses relevant literature - CatGAN (Springenberg 2015) which trains a discriminator to minimize entropy over a categorical distribution assigned to the generator's samples while the generator is trained to maximize entropy of discriminator in this space.  It also misses PACGan (Lin 2017) which also augments a discriminator to look at multiple samples to improve diversity.", "rating": "3: Clear rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}