{"title": "Closely related to the recent spherical CNN and SE(n) equivariant network papers, but mathematically less clean", "review": "There is a great amount of interest in extending the notion of equivariance in neural networks from \njust translations to other groups. In particular, in the past year a sequence of papers have appeared \nstarting with (Cohen, Geiger et al.) on \"spherical CNNs\" that achieve equivariance to rotations for images \npainted on the surface of the unit sphere.\n\nThe present paper extends these ideas to volumetric data in the unit ball (rather than just the sphere) \nby the use of Zernike polynomials. Since Zernike polynomials can be expressed as the product of spherical \nharmonics with a radial function, this is essentially the same as adding a radial component to a spherical \nCNN. \n\nThe main result of the paper appears to be Theorem 1, which shows that what the authors define as \nvolumetric convolution is equivariant to rotations. This is split across Sections 4.2 and 4.3.. However, \napart from the radial component, this result is bascally the same as the SO3-equivariance of spherical CNNs, \nas discussed in three very recent spherical CNN papers: (Cohen, Geiger et al.) (Esteves Allen-Blanchette et al) \nand (Kondor, Lin and Trivedi). However, the somewhat more abstract, representation theoretic approach \nof some of these works allows a more compact derivation than the one in the present paper.\n\nThe authors also fail to cite recent work on SE(2) and SE(3) equivariant neural networks. SE(3) comprises \nall rotations and translations of R^3, so the latter, in particular, encapuslates SO(3) equivariance as \na special case. In particular, part of the construction in (Weiler, Hamprecht and Storath, CVPR 2018) \nis to add  Gaussian radial functions to SO(2) equivariant filters, which is just the 2D analog of \nwhat is happening in the present paper. Then in (Weiler, Geiger, et al., 2018) the same is done in 3D, \nexcept of course they go further by also adding translation equivariance. Admittedly, these papers are \nvery new, so the authors might not have known about them.\n\nI also find some of the mathematical details a little puzzling:\n\n1. As explained in the spherical CNN papers, taking the cross correlation of two functions on the sphere \n(by extension, in the unit ball) naturally results in a function that lives on the rotation group SO(3), i.e. \nthe cross-correlation (or convolution) is parametrized by three Euler angles. I don't understand why the \nauthors restrict themselves to considering just two angles, forcing their filters to be polar, as \nderived in Section 5. This seems like an artificial restriction that will limit the power of their approach. \n\n2. The paper mentions that Zernike polynomials are \"orthogonal and complete in B^3\". I think what they mean \nis that they are an ortogonal and complete basis for an appropriate space of functions on B^3, and that \nspace of functions is L_2(B^3). However, this is still not enough. For (3) to hold, one also needs the \nbasis to be orthonormal. Please be more precise.\n\n3. In the same vein, at one point in the proof, the authors mention that \"rotations are unitary operators \nin a Hilbert space\". This is not true of Hilbert spaces in general. It requires the above orthonormality etc.. \n\n4. Exactly as a consequence of orthonorlamity, Equation 5 is essentially just a generalized Fourier transform \non B^3, hence, in principle, it can be inverted analytically. I understand that the fact that the input \nimage is rasterized complicates things and in a practical implementation it might be expedient to invert (5) \nby using the pseudo-inverse. However, this is a one-time operations and is really just a hack. It seems strange \nthat the authors use a special iterative method just to invert a close to unitary matrix.\n\nThe mathematical shortcomings of the paper could be compensated by amazingly good experimental results. \nThe actual results are good, but still not best-in-class, possibly because at the end of the day the network \nis still only rotationally equivariant and does not take into account translations. \n\nThe spherical CNN and SE(n) equivariance papers generally apply the group equivariant operations consistently \nacross multiple layers. In contrast, the present paper only applies it in the first layer, and then uses a \ncombination of tricks like multiple viewpoints and bilinear pooling to boost performance. Unfortunately, the \nbenefits of this additional conceptual complexity are not entirely borne out in the experimental results.\n", "rating": "5: Marginally below acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}