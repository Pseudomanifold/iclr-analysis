{"title": "Interesting paper; being more careful about experiments would strengthen it further.", "review": "The paper considers the problem of obtaining reliable predictive uncertainty estimates. The authors propose noise contrastive priors \u2014 the idea being to explicitly encourage high uncertainties for out of distribution (OOD) data through a loss in the data space.  OOD data is simulated by adding noise to existing data and the model is trained to maximize the likelihood wr.t. training data while being close in the KL sense to a (wide) conditional prior p(y | x) on the OOD responses (y).  The authors demonstrate that the procedure leads to improved uncertainty estimates on toy data and can better drive active learning on a large flight delay dataset.\n\nThe paper is well written and makes for a nice read. I like the idea of using \u201cpseudo\u201d OOD data for encouraging better behaved uncertainties away from the data. It is nice to see that even simple schemes for generating OOD data (adding iid noise) lead to improved uncertainty estimates. \n\nMy main concern about this work stems from not knowing how sensitive the recovered uncertainties are to the OOD data generating mechanism and the parameters thereof. The paper provides little evidence to conclude one way or the other.  The detailed comments below further elaborate on this concern.\n\nDetailed Comments: \na) I like the sensitivity analysis presented in Figure 4, and it does show for the 1D sine wave the method is reasonably robust to the choice of \\sigma_x. However, it is unclear how problem dependent the choice of sigma_x is. From the experiments, it seems that \\sigma_x needs to be carefully chosen for different problems, \\sigma^2_x < 0.3 seems to not work very well for BBB + NCP for the 1D sine data, but for the flight delay data \\sigma^2_x is set to 0.1 and seems to work well. How was \\sigma_x chosen for the different experiments?\n\nb) It is also interesting that noise with a shared scale is used for all 8 dimensions of the flight dataset. Is this choice mainly governed by convenience \u2014 easier to select one hyper-parameter rather than eight? \n\nc) Presumably, the predictive uncertainties are also strongly affected by both the weighting parameter \\gamma and the prior variance sigma^2_y . How sensitive are the uncertainties to these and how were these values chosen for the experiments presented in the paper? \n\nd) It would be really interesting to see how well the approach extends to data with more interesting correlations. For example, for image data would using standard data-augmentation techniques (affine transformations) for generating OOD data help over adding iid noise. In general, it would be good to have at least some empirical validation of the proposed approach on moderate-to-high dimensional data (such as images).\n\n==============\nOverall this is an interesting paper that could be significantly strengthened by addressing the comments above and a more careful discussion of how the procedure for generating OOD data affects the corresponding uncertainties.", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}