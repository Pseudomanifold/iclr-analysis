{"title": "Continuous time flows with symmetries motivated from the Monge-Ampere equation", "review": "Summary:\nThis paper introduces a continuous-time flow, which is motivated from continuous-time gradient flow in the Monge-Ampere equation in optimal transport theory. They relate the resulting generative model to a dynamical system with a learnable potential function that controls a compressible fluid (representing the probability density), towards the target density. The resulting set of differential equations for the evolution of the samples and the density is solved through a fourth-order Runge-Kutta ODE solver. By imposing symmetries on the scalar potential function, symmetries of the resulting target distribution can also be enforced, a property that is desirable in many applications.\n\nThe scalar potential is modeled using a fully connected MLP with a single hidden layer. Forward propagating of samples requires obtaining the gradient of the scalar potential (output of MLP) with respect to its input (the sample). Forward propagation of the log density requires computation of the Laplacian (not the hessian) of the scalar potential. Both of these quantities can easily be computed with automatic differentiation (in O(D) where D is data dimension). The potential is kept constant over time, although this is not necessary.\n\nThe proposed method is evaluated on density estimation for MNIST, and variational inference with respect to the Boltzmann distribution of the 2D Ising model at the critical temperature. \nOn MNIST, comparison is done with respect to MADE, MAF and realNVP. Monge-Ampere flows outperforms the baselines. On the variational inference task one baseline is used, and the result is compared to the exact known free energy. Monge-Ampere flows are reported to approximate the exact solution to comparable accuracy as a baseline. As the authors show that they can easily enforce symmetries, it would be very informative to see the performance of Monge-ampere flows with and without these symmetries enforced on for instance the Ising model. Have the authors looked at this?\n\nIt is not clear from the paper how much the ODE solvers used in the forward pass, as well as backpropagating through it with respect to model parameters, will influence the run time. I suspect the training time of models like MAF to be significantly shorter than that of Monge-Ampere flows. For sampling, the comparison would also be interesting. Where sampling from MAF is O(D), with D the data dimension, sampling from the Monge-Ampere flows requires propagating through an ODE solver. Can the authors comment on the runtimes for these settings?\n \nThe experimental validation is not extensive, but the proposed method is well motivated and as far as I can tell original. It is a useful contribution to the field of normalizing flows/invertible networks. The ability to easily enforce symmetries into the density seems to be promising and could lead to interesting future work on permutation invariant systems.\n\nSee below for comments and more questions:\n\nQuality\nThe paper is well structured. The experimental validation is not extensive, and perhaps even on the low side.\n\nClarity\nThe paper is overal clearly written. One small nuisance is that the citations are not in brackets in sentences, even if they are not part of the actual sentence itself. This interrupts reading. It would be greatly appreciated if the authors could change this. The authors leave out some details with regards to the experiments, but with code available this should be sufficient for reproducibility. \n\nOriginality\nTo my knowledge the idea of using the Monge-Ampere equation for continuous normalizing flows is new. Note that it is also significantly different from a concurrent ICLR submission entitled \u2018Scalable Reversible Generative Models with Free-form Continuous Dynamics\u2019, which also discussed continuous normalizing flows with ODE\u2019s.\n\nSignificance\nThis work is of use to the research community. The method is memory efficient and appears to perform well. Especially the ability to enforce symmetries seems very appealing. If the authors can comment on the runtime in comparison to other flow methods, both in terms of training time and sampling, this would enable a better view on practical use. \n\nDetailed questions/comments:\n\n1. In Fig. 3a, the train and test error during training are shown to follow each other very closely. How long was the model trained, and did the train and test curve at some point start to diverge?\n2. In Section 4.2, the results are said to be of comparable accuracy as the baseline by Li & Wang. It would be informative to actually state the result of Li & Wang, so that the reader can judge too if this is comparable. \n3. Out of curiosity, did the authors also consider using other activation functions that have higher order derivatives, such as tanh?\n\n\n***** EDIT ******\n\nI thank the authors for their clarifications. They have sufficiently answered my questions/comments, so I will stick with my score.\n\n", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}