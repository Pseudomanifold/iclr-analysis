{"title": "Interesting first step, but hard to follow and no practical demonstrations.", "review": "Summary\n\nThe authors consider RL with safety constraints, which is framed as a multi-reward problem. At a high-level, this involves finding the Pareto front, which optimally trades off objectives. The paper primarily introduces and discusses a discretization scheme and methods to model the Q-value function as a NIPWC (non-increasing piecewise constant function). NIPWC are stored as values over discrete partitions of state-action spaces. To do so, the authors introduce two data structures DecRect and ContDecRect to store Q function values over geometric combinations of subsets of state-action space.\n\nThe authors discuss how to execute elementary operations on these data structures, such as computing max(f(x), g(x)), weighted sums, etc. The goal is to use these operations to compute Bellman-type updates to compute optimal value/policy functions for multi-reward problems. The authors also present complexity analysis for these operations. \n\nPro\n- Extensive discussion and analysis of discrete representations of Q-functions as NIPWCs. \n\nCon\n- A major issue with this work is that it is very densely written and spends a lot of time on developing the discretization framework and operations on NIPWC. However: \n- There is no clear practical algorithm to solve (simple) multi-reward RL problems with the authors' approach.\n- No experiments to demonstrate a simple implementation of these techniques.\n- Even though multi-reward settings are the stated problem of interest, authors don't discuss Pareto front computations in much detail, e.g., section 4.3 computing non-dominated actions is too short to be useful.\n- The discussion around complexity upper bounds is too dense and uninsightful. For instance, the bounds in section 5 all concern bounds on the Q-value as a function of the action, which results in upper bounds as a function of |A|. But in practice, the action is space is often small, but the state space is high-dimensional. Hence, these considerations seem less relevant. \n\nOverall, this work seems to present an interesting computational scheme, but it is hard to see how this is a scalable alternative. Practical demonstrations would benefit this work significantly.\n\nReproducibility\nN/A \n", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}