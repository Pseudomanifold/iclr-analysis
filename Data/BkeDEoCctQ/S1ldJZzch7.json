{"title": "More experiments might be required.", "review": "The reinforcement learning tasks with sparse rewards are very important and challenging. The main idea of this work is to encourage intra-life novelty. The authors introduce the curiosity grid and the intrinsic reward term so that the agent can explore toward unvisited states at every episode. \n\nHowever, the results are not enough to be accepted to ICLR having a very high standard. In Section 3, the authors compare the game scores of DeepCS proposed in this paper only against to A2C. There are some RL algorithms reported to be better than A2C. For instance, I would like to see the comparison between DeepCS and SmartHash by Tang et al 2017. \n\n=================================================================================================\nI've read the rebuttal. I updated my score but still not vote for accept. \n\nThis paper is not my main research area. Very unfortunately, this paper was assigned to me. The main issue of this paper is the fair comparisons with other works. However, I don't have enough knowledges to judge this point.  So please assess this paper with other reviewers comments.\n", "rating": "5: Marginally below acceptance threshold", "confidence": "1: The reviewer's evaluation is an educated guess"}