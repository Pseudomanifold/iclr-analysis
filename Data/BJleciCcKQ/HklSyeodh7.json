{"title": "review of the paper", "review": "This paper investigates a number of techniques and neural network architectures for embedded acoustic modeling.  The goal is to reduce the memory access and make efficient computation, in the meantime, to sustain good ASR performance.  Overall, the paper is well motivated and well written.  However, I have following concerns.\n\n1. It is not clear from the paper whether both the training and inference are conducted on embedded devices or only the inference?  I assume it is the latter but can't find it explicitly mentioned in the paper.  \n\n2. The exploration carried out in the paper is more on the system level and the novelty is not overwhelmingly significant.\n\n3. My major concern is that the reported WERs on WSJ and phoneme classification accuracy are quite off.  20%-30% WERs for WSJ  do not seem to be usable in real applications.  Honestly, I don't even think this performance is better than well-trained GMM-HMM acoustic models using a Viterbi decoder.  Furthermore, there is no clear winners across the investigated architectures  in terms of performance.  One question is if one wants to deploy such an on-device system, which architecture shall be chosen?  \n\n4. A more general comment on the work explored  in the paper.  First of all, the on-device memory issue puts a heavy constraint on the capacity of acoustic models, which will significantly hurt the modeling capability for the DNN-based acoustic models.  Deep learning acoustic models can outperform GMM-HMM because they can use large model capacity with very deep and complex architectures when a large amount of training data is available.  Second, for CTC, when the training data is limited,  its performance is far worse than the hybrid DNN-HMM model, let alone a pure end-to-end fashion without using external LM and dictionary.  If WFST-based decoders (composition of WFSTs of LM, dictionary and deblank/repetition) are used, then the memory issue will surface again. \n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}