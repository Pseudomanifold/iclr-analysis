{"title": "Review", "review": "This paper present a study on efficient acoustic modeling using neural networks-based model. Four approaches are presented and evaluated: diag LSTM, QRNN, Gated ConvNet and adding a 1D convolution layer. The evaluation is done on ASR task using WSJ and in phoneme classification task using the TIMIT corpus. The study show that the inference speed is improved with comparable of better performance than the standard LSTM model.\n\nThe findings presented in this paper are interesting and quite useful when one wants to implement a LSTM-based acoustic model on mobile devices. The paper is well written and easy to ready. \n\nThe main issue of this paper is the lack of novelty: the three evaluated approaches (Diag LSTM, QRNN and Gated ConvNet) are not novel, the only novelty is the addition of a 1D convolution, which is not enough for a conference like ICLR. \n\nMinor comments on the experiments:\n* The network quantization approach has been shown to lead to efficient neural networks, could the authors provide a comparison between their approach and the quantization approach ?\n* On the TIMIT experiment, the authors could add a decoder and use the PER metric instead of the frame accuracy, so they could provide comparison with the literature. \n* WSJ and TIMIT are quite small corpora compared to the available corpora, maybe the authors should consider using large corpora like Librispeech. It could be interesting to see the performance of the presented approaches.\n\nOverall, this paper feels more like a technical report: the findings could be useful, but its novelty is too limited for ICLR. Hence I argue for rejection, and suggest that the authors consider submitting the paper to a speech conference like ICASSP.", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}