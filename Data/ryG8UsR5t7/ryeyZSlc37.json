{"title": "Lacking novelty and rigor.", "review": "The main contribution of this paper is a new proposed score to evaluate models that yield uncertainty values for regression.\n\nAs constituted, the paper can not be published into one of the better ML conferences. The novelty here is very limited. Furthermore there are other weaknesses to the study.\n\nFirst, the stated goal of the \"metric\" is that \"reflects the correlation between the true error and the estimated uncertainty ... (and is) scale independent and robust to outliers.\" Given this goal (and the name of the paper) it is perplexing why the correlation (https://en.wikipedia.org/wiki/Pearson_correlation_coefficient) of true error and predicted error (\\sigma_i) was not tried as baseline score. The correlation would have some \"scale independence\" and I'm sure that there are robust estimates (a simple thing would be to consider the median instead of mean, but there are probably more sophisticated approaches). This just feels like an obvious omission. If one wants to mix both predictive quality and correctness of uncertainty assessments then one could just scale the mean absolute error by the correlation: MAE/Corr, which would lead to a direct comparison to the  proposed MeRCI.\n\nSecond, the paper does a poor job of justifying MeRCI. On toy data MeRCI is justified by a confluence with existing scores. Then on the depth prediction task, where there are discrepancies among the scores, MeRCI is largely justified qualitatively  on a single image (Figure 4). A qualitative argument on a single instance in a single task can not cut it. The paper must put forth some systematic and more comprehensive comparison of scores.\n\nEven with the above issues resolved, the paper would have to do more for publication. I would want to see either some proof of a property of the proposed score(s), or to use the proposed score to inform training, etc.", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}