{"title": "good insight on understanding adversarial examples", "review": "This paper uses several lemmas in geometry to prove that adversarial examples\nare hard to avoid under the assumption that there is no \"don't know\" class and\nthe distribution of each class is not too concentrated. The paper first starts\nwith a simple case where the data points are distributed on a sphere, and then\nextends the results to the realistic case where data points are inside a cube\n[0,1]^n. \n\nThe paper uses epsilon expansion of a set as a mathematical tool, and borrows\nsome important lemmas from geometry to the case of adversarial learning.  In\nthe sphere case, the results come from a fact that high dimensional\nhalf-spheres can almost cover all points in the sphere after an epsilon\nexpansion, and the results depend on dimension n. For the unit cube case, the\nauthors borrow a result from Talagrand, to show that the epsilon expansion of a\nset can cover a large portion of the cube as long as the set distribution is\nnot very concentrated.  In this case, the results (for l_2 norm) do not depend\non dimension n.\n\nExperimentally, the authors show that inputs with higher dimension can actually\nget better robustness, aligning with the provided analysis.  The primary reason\nthat current adversarial defense does not work well on CIFAR is due to the fact\nthat dataset is more spread out in high dimensional space. This is a good\ninsight for understanding adversarial examples.\n\nThe paper is overall well written and easy to follow. The interpretation of\neach lemma and proposition is clear. Although the paper mostly depend on\nwell-known results in geometry and the ideas used are simple, it does provide\ngood insight on explaining the prevalence of adversarial examples. I recommend\nto accept this paper.\n\nQuestion:\nIs there any good method to estimate U_c for a dataset? Although it is intuitive\nthat CIFAR may have a smaller U_c than MNIST, is it possible to numerically\nestimate this quantity? This is necessary to fully support the conclusions made\nin experiments.\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}