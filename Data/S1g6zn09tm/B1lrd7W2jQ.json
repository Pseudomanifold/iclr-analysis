{"title": "review ", "review": "This paper preposed a conditional generative model for image generation. The proposed contributions include a conditional transformation unit that learns the latent space transformations corresponding to specified target views, a consistency loss term to guide the encoding, a task-divided decoder for generation refinement, and an adaptive discriminator.  Below are the evaluations.\n\nAbout the novelty of the proposed conditional transformation unit. Please be more specific about its novelty and significant difference compared with existing ones, for example, https://arxiv.org/pdf/1807.04812.pdf , https://academic.oup.com/bioinformatics/article/34/17/i603/5093214 , etc.\n\nAbout the consistency loss term, what type of consistency do you claim? Any proof or evaluation of the consistency?\n\nFor the ablation analysis, any result for the model without generation refinement?\n\nThe claim of lightweight and real-time solution needs more evidence. For the experiment, is there any comparison on training time? Although the proposed model is claimed to be a lightweight neural network that is suitable for real-time applications, it seems to me the parameters to train still have much bigger size than baselines. Also all the training are done using GPU. Not many real-time applications have GPU resources.", "rating": "5: Marginally below acceptance threshold", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}