{"title": "Interesting idea, poor exposition", "review": "This paper describes an approach for automated curriculum learning in a deep learning classification setup. The main idea is to weigh data points according to the current value of the loss on these data points. A naive approach would prevent learning from data points that are hard to classify given parameters of the current mode, and so the authors propose to use an additional loss term for these hard data points, which encourages the hidden representation of these data points to be closer to representation of points that are close in the hidden space and yet are easier to classify (in the sense that the loss of easy samples is lower by some threshold value then the loss of hard samples). This last part is implemented by caching hidden representations and classification loss values during training and fetching nearest neighbours in the feature space whenever a hard data point is encountered. The final loss takes the form of a linear combination of the classification loss and the representation loss.\n\nThe idea is interesting in the sense that it tries to use information about how difficult classification of a given data point is to improve learning. The proposed representation loss can lead to forming tight cluster of similar data point in the feature space and can make classification easier. It is related to student-teacher networks, where a student is trained to imitate the teacher in generated similar feature representations.\n\nThe authors justify the method by introducing the notion of \u201cinverse internal covariate shift\u201d. However, it is not defined formally, nor is it supported empirically, and is based on the (often criticized [1]) notion of \u201cinternal covariate shift\u201d. For this reason, it is hard to accept the presented argumentation in its current state.\n\nMoreover, there seems to be a mistake in equation (2) in \u00a74.2. The equation defines the method of computing loss weighting for a given datapoint. The authors note that it converges to the value of one with increasing training iterations, but for correctness it should be \\in [0, 1]. If it is > 1, one of the losses in equation (3) is negated and is therefore maximised (instead of being minimised), which can lead to unexpected behaviour. Current parameterization allows it to be \\in [0, + infinity].\n\nExperimental evaluation consists of quantitative evaluation of random sampling (usual SGD) and the proposed approach in training a classification model on MNSIT, CIFAR-10 and CIFAR-100. The proposed approach outperforms random sampling. This is encouraging, but the method should be compared to state of the art in curriculum learning in order to gauge how useful this approach is.\n\nThe paper is poorly written, with many grammatical (lack of \u201cs\u201d at the end of verbs used in singular 3rd person, many places in the paper) and spelling mistakes (e.g. \u00a73.2\u00b66 \u201ctough\u201d instead of \u201cthrough\u201d, I think). Some descriptions are unclear (e.g. \u00a74.2\u00b62), while some parts of the paper seem to be irrelevant to the problem at hand (\u00a73.1 describes training on a single minibatch for multiple iterations as if it were a separate task and motivates random sampling, which is just SGD).\n\nTo summarize, the paper presents a very interesting idea. In its current state it is hard to read, however. It also contains a number of unsupported claims and can be misleading. It could also benefit from a more extensive evaluation. With this in mind, I suggest rejecting this paper.\n\n[1] Rahimi, A (2017). Test of Time Award Talk, NIPS.", "rating": "3: Clear rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}