{"title": "Interesting idea but limited experiments and analysis", "review": "This paper proposes a curriculum that encourages training on easy examples first and postpones training on hard examples. However, contrary to common ideas, they propose to keep hard examples contribute to the loss and only forcing them to have internal representations similar to a nearby easy example. The proposed objective is hence biased at the beginning but they dampen it over time to converge to the true objective at the end.\n\nPositives:\n- There is not much work considering each example as an individual subtask.\n- The observation that an under-fitted classifier can destroy a good feature extractor is good.\n\nNegatives:\n- In the intro it says \u201c[update rule of gradient descent] assumes the top layer, F2, to be the right classifier.\u201d. This seems like a fundamental misunderstanding of gradient descent and the chain rule. The term d output/d F1 takes into account the error in F2.\n- The caption of figure 2 says the \u201c... they cannot separate from its neighbors\u2026\u201d. If the loss of all examples in a cluster is high, all are being misclassified. A classifier then might have an easy job fixing them if all their labels are the same or have a difficult job if their labels are random. The second scenario is unlikely if based on the claim of this figure, the entropy has decreased during training. In short, the conclusion made in fig 2 does not necessarily hold given that figure.\n- This method is supposed to speed up training, not necessarily improve the final generalization performance of the model. The figures show the opposite outcomes. It\u2019s not clear why. The improvement might be due to not tuning the hyperparameters of the baselines.\n- Figure 3 does not necessarily support the conclusion. The fluctuations might be caused by any curriculum that forces a fixed ordering across training epochs. Often on MNIST, the ordering of data according to the loss does not change significantly throughout training.", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}