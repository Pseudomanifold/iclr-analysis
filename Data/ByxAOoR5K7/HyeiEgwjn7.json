{"title": "Inciteful and of general interest.", "review": "## Summary\n\nThe authors identify a synergy between the rate distortion (RD) and reinforcement learning (RL) literature. RD work shows how to optimise resources when capacity is limited and the authors transfer this idea to RL and posit a novel algorithm based on the Actor critic algorithm. In experiments this is shown to learn more quickly and transfer between similar tasks more easiliy than the conventional AC algorithm.\n\nThis is a genuinely inciteful piece of work and may be of very significant interest to the community. Particuarly to those in transfer learning, heirarchical learning and other areas of RL where an adaptable rate limited policy is an advantage. \n\nThe experiments are limited to a single domain, and ideally this would be demonstrated across more than just those examples explored. However, I think that the value of the theoretical advance, and the clarity/readability of the paper warrants acceptance.", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}