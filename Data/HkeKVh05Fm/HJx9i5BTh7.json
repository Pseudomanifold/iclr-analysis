{"title": "Lack of comprehensive related work and lack of clarity in the writing", "review": "This paper proposed a entity proposal network for named entity recognition which can be effectively detect overlapped spans. The model obtain good performance on both Multi-grained NER task and traditional NER task. The paper is in general well written, the idea of proposal network break the traditional framework of sequence tagging formulation in NER task and thus can be effectively applied to detect overlapped named entities.\n\nHowever, I still have many concerns regarding the notation, the novelty of the paper, and the comparison with related literature, especially on previous overlapped span detection NER papers. The detailed concerns and questions are as follows:\nThe notations are very confusing. Many of the notations are not defined. For example, what does $T$ in $2D_sl*2T$ below Eq. 4 indicates?  What does $R$ scores means? I guess $R$ does not equal to number of entity types, but I\u2019m not sure what $R$ exactly indicates. If $R$ is not number of entity types, why do you need R scores for being an entity and R scores for not being an entity? And what is $t$ in Eq 5? Is that entity type id or something else?\nI\u2019m still confused how you select the entity spans from a large number of entity candidates. In Figure 5, if the max window length is 5, there may be more span candidates than the listed 5 examples, such as t_3 t_4 t_5. How do you prune it out?\nTable 5 is weird. There is not comparison with any baselines but just a report of the performance with this system. I don\u2019t know what point this table is showing.\nThis is not the first paper that enumerates all possible spans for NER task.The idea of enumerating possible spans for NER task has appeared in [1] and can also effectively detect overlapped span. I would like to see the performance comparison between the two systems. The enumerating span ideas has been applied in many other tasks as well such as coreference resolution [2]and SRL[3], none of which is mentioned in related work.\nI feel that most of the gain is from ELMo but not the model architecture itself, since in Table 4, the improvement from the ELMo is only 0.06. The LSTM-LSTM-CRF is without adding ELMo, which is not a fair comparison. \nThe comparison of baselines is not adequate and is far from enough. The paper only compares with LSTM+CRF frameworks, which are not designed for detecting overlapped spans. There are many papers on detecting overlapping spans, such as [4], [5] and [6]. It\u2019s important to compare with those paper since those methods are especially designed for overlapped span NER tasks.\n[1] Multi-Task Identification of Entities, Relations, and Coreferencefor Scientific Knowledge Graph Construction, EMNLP 2018\n[2] End-to-end neural coreference resolution, EMNLP 2017\n[3] Jointly predicting predicates and arguments in neural semantic role labeling, ACL 2018\n[4] Nested Named Entity Recognition Revisited, NAACL 2018\n[5] A Neural Layered Model for Nested Named Entity Recognition, NAACL 2018\n[6] Neural Segmental Hypergraphs for Overlapping Mention Recognition, EMNLP 2018", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}