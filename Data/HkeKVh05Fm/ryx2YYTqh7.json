{"title": "Interesting task of multi-grained NER, reasonable models. ", "review": "\n<Summary>\nAuthors propose the \u201cMulti-grained NER (MGNER)  task\u201d which aims at detecting entities at both coarse and fine-grained levels. Authors propose a Multi-grained Entity Proposal Network (MGEPN) which comprises (1) a Proposal Network that determines entity boundaries, and (2) a Classification network that classifies each proposed segment of an entity.\n\nThe task is primarily tested against the proposed method itself. The proposed method does outperform traditional sequence-labeling baseline model (LSTM-LSTM-CRF), validating the proposed approach. When the proposed model (trained with extra MG data) is evaluated on the traditional NER task (on test sets), however, no significant improvement is observed -- I believe this result is understandable though, because e.g. MG datasets have slightly different label distributions from original datasets, hence likely to result in lower recall, etc.\n\n<Comments>\nThe task studied is interesting, and can potentially benefit other downstream applications that consume NER results -- although it seems as though similar tasks have been studied prior to this study. The novelty of the proposed architecture is moderate - while each component of the model does not have too much technical novelty, the idea of separating the model into a proposal network and a classifier seems to be a new approach in the context of NER (that diverges from the traditional sequence labelling approaches), and is reasonably designed for the proposed task.\n\nThe details for creating the MG datasets is missing - are they labeled by human labelers, or bootstrapped? Experts or crowd-sourced? By how many people? Will the new datasets be released? Please provide clarifications.\n\nThe proposed approach does not or barely outperform base models when tested on the traditional NER task -- the proposed work thus can be strengthened by better illustrating the motivation of the MGNER task and/or validating its efficacy in other downstream tasks, etc. \f\n\nAuthors could provide better insights into the new proposed task by providing more in-depth error analysis - especially the cases when MG NER fails as well (e.g. when coarse-grained prediction predicts a false positive named-entity, etc.)\n", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}