{"title": "resutls are simple, interesting but seem not very helpful in practice", "review": "This paper shows that the training of deep ReLU neural networks will converge to a constant classifier with high probability over random initialization (symmetric weight distributions) if the widths of all hidden layers are too small.\n\nOverall, the paper is clearly written. I like the main message of the paper and the simplicity of its analysis. To some extent, I think that the results could add to our current understanding of the limitations of deep narrow networks, both theoretically and practically. \n\nOn the other hand, my main concern at the moment is that the results seem to be informative only for low dimensional data and networks of small width. In particular, the bound on depth in eq (5) scales too fast with width. Figure 6 shows that with width 16 the bound on depth is already too loose that it could be of any use in practice.\n\nOther comments and questions:\nIn Figure 6+7, it's not clear how many times each experiment is repeated in order to get the numerical estimations of probabilities, and which exactly weight distributions are used here?\n\nThe statement of Theorem 1 and its proof looks a bit suspicious to me. This theorem first makes an assumption on a given network with fixed weights, but then makes some statement about random weights...This apparently does not make much sense to me because a given network has nothing to do with random weights, but the current proof is actually using the assumption made on the given network as a constant classifier to prove the probabilistic statement. I hope to see some clarification here.\n\nIt would be interesting to discuss the results of this paper with recent work [1,2] which also studied deep narrow networks but from other perspectives:\n[1] Neural networks should be wide enough to learn connected decision regions. ICML 2018\n[2] The Expressive Power of Neural Networks: A View from the Width. NIPS 2017", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}