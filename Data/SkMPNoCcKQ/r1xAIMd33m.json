{"title": "[Review] Linearizing Visual Processes with Deep Generative Models", "review": "[Paper Summary]\n- The proposed work proposes a new method that model non-linear visual process with a deep version of a linear process (Markov process). The latent space is described by the linear process and the nonlinear mapping function from the latent space to image distribution.\n\n[Pros]\n- The model gives a well defined deep approximation to the Markov process (with Gaussian Form). The reviewer didn't follow every detailed step, but the overall direction seems fair.\n\n[Cons]\n- First of all, the practical strongpoints of the proposed work (applying linear process) compared to the existing deep sequential approaches (using the recurrent network) are not well investigated. The reviewer was difficult to find the benefit of using the proposed algorithm than RNN+VAE such as DRAW [1]. The proposed method can also use GAN for latent-to-image mapping, but using GAN to sequential model itself is not a novel techniques [2]. Maybe the existence of variance would be the difference, then the author should clarify it into the experiment section (more than the current version).\n\n[1] Gregor, Karol, et al. \"Draw: A recurrent neural network for image generation.\" arXiv preprint arXiv:1502.04623 (2015).\n[2] Walker, Jacob, et al. \"The pose knows: Video forecasting by generating pose futures.\" Computer Vision (ICCV), 2017 IEEE International Conference on. IEEE, 2017.\n\n- Related work seems to omit some of the similar existing studies. The author should clarify the novelty of the proposed work from the mentioned papers.\n\n[1] Karl, Maximilian, et al. \"Deep variational bayes filters: Unsupervised learning of state space models from raw data.\" arXiv preprint arXiv:1605.06432 (2016).\n[2] Gao, Yuanjun, et al. \"Linear dynamical neural population models through nonlinear embeddings.\" Advances in neural information processing systems. 2016.\n[3] Yoo, Y., Yun, S., Chang, H. J., Demiris, Y., & Choi, J. Y. (2017, July). Variational autoencoded regression: high dimensional regression of visual data on complex manifold. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (pp. 3674-3683).\n\n- The video generation sequence in figure 5 seems little trivial because most parts of the image are static. Is it possible to try the model with more complicated video such as UCF 101 (like [1])?\n\n[1] Walker, Jacob, et al. \"An uncertain future: Forecasting from static images using variational autoencoders.\" European Conference on Computer Vision. Springer, Cham, 2016.\n\n[Summary]\nThe proposed paper provides well described linear model approximated by the deep network.  However, the reviewer is still skeptical for the novelty of the paper, and the strong point of the work compared to the existing deep sequence generation algorithms. The profound explanation of the problems would be required.\n", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}