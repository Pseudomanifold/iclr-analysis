{"title": "Good review on algorithms for VIs in the context of GANs", "review": "Overall, the paper is well-written and of high quality, therefore I recommend acceptance. \n\nPros:\n+ The work gives an accessible but still rigorous introduction to the literature on VIs which I find highly valuable, as it creates a bridge between the classical mathematical programming literature and applications in AI. \n\n+ The theory for optimization of VIs with stochastic gradients (though only in monotone setting) was very interesting to me and contains some novel results (Theorem 2, Theorem 4)\n\nCons:\n- I'm a bit skeptical about the experiments on GANs. They indicate that for the specific choice of architectures and hyper-parameters \"ExtraAdam\" works better, but the chosen architectures are not state-of-the art. What would convince me if the algorithm can be used to improve a current best inception score of 8.2 reached with SNGANs. Also with WGAN-GP, scores of ~7.8 are reported which are much higher than the 6.4 reported in the paper. But I understand that producing state-of-the-art inception scores is not the focus of the paper, therefore I would suggest that the authors release an implementation of the proposed new optimizers (ExtraAdam) for a popular DL framework (e.g. pytorch) such that practitioners working with GANs can quickly try them out in a \"plug-and-play\" fashion.\n\n- Proposition 2 is a bit misleading. While for \\eta \\in (0, 1) implicit and extrapolation are similar, adding the remark that implicit method is stable for any \\eta > 0 (and therefore can lead to an arbitrary fast convergence) would give a more balanced view. Right now, only the advantages of extrapolation method and disadvantages of implicit method are mentioned which I find unfair for the implicit method.\n\n- The theory is presented for variational inequalities with monotone operators. For clarity it should be mentioned that GANs parametrized with neural nets lead to non-monotone VIs. A provably convergent algorithm for that setting is still an open problem, no?\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}