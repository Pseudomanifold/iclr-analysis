{"title": "An Important Problem, but insufficient experiments and unsure about some details of method", "review": "Review: This paper deals with the issue of learning rotation invariant autoencoders and classifiers.  While this problem is well motivated, I found that this paper was fairly weak experimentally, and I also found it difficult to determine what the exact algorithm was.  For example, how the optimization was done is not discussed at all.  At the same time, I'm not an expert in group theory, so it's possible that the paper has technical novelty or significance which I did not appreciate.  \n\nStrengths: \n\n -The challenge of learning rotation equivariant representations is well motivated and the idea of learning representations which transfer between different scales also seems useful.  \n\nWeaknesses: \n  \n-I had a difficult time understanding how the preliminaries (section 2) were related to the experiments (section 3).  \n\n-The reference (Kondor 2018) is used a lot but could refer to three different papers that are in the references.  \n\n  -Only reported results are on rotated mnist, but the improvements seem reasonable, but unless I'm missing something are worse than the 1.62% error reported by harmonic nets (mentioned in the introduction of the paper).  In addition to rot-mnist, harmonic nets evaluated boundary detection on the berkeley segmentation dataset.  \n\n  -It's interesting that the model learns to be somewhat invariant across scales, but I think that the baselines for this could be better.  For example, using a convolution network with mean pooling at the end, one could estimate how well the normal classifier handles evaluation at a different scale from that used during training (I imagine the invariance would be somewhat bad but it's important to confirm).  \n\n\nQuestions: \n\n-Section 3.1 makes reference to \"learning parameters\".  I assume that this is done in the usual way with backpropagation and then SGD/Adam or something?  \n\n-How is it guaranteed that W is orthogonal in the learning procedure?  \n", "rating": "6: Marginally above acceptance threshold", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}