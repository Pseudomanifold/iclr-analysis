{"title": "simple but effective method in triaining but its utility as a defender not quite clear to me why it works  ", "review": "The authors propose a defense technique to make the NN model more robust to adversarial events by redrawing the images and use them for training the model so that the model can prevent future attacks. The idea itself is simple but seems to be effective as shown in Tables 2 and 3.\n\nWhat I\u2019m missing here is a simple experiment to see the difference in accuracy performance between 1) when using PR for training the model (which is Case B in Table 2) against attacks versus 2) when not using PR for training the model against other attacks (similar to Table 2, Testing phase but using other attack models not PR as an attack model).\n\nIt is not quite clear to me why using PR as a defense mechanism helps the NN model.  I see its utility when training the NN model but using it as a defense mechanism is not quite clear why it works. \n\nMinor:\nIt is not quite clear how the author chose the hyperparameters, maybe by changing those hyperparameter the attacker could have much clever ways to attack the NN model.", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}