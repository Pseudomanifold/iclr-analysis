{"title": "heuristic combining environment rewards with an IRL-style rewards", "review": "The draft proposes a heuristic combining environment rewards with an IRL-style rewards recovered from expert demonstrations, seeking to extend the GAIL approach to IRL to the case of mismatching action spaces between the expert and the learner. The interesting contribution is, in my opinion, the self-exploration parameter that reduces the reliance of learning on demonstrations once they have been learned sufficiently well.\n\nQuestions:\n\n- In general, it's known that behavioral cloning, of which this work seem to be an example in so much it learns state distributions that are indistinguishable from the expert ones, can fail spectacularly because of the distribution shift (Kaariainen@ALW06, Ross&Bagnell@AISTATS10, Ross&Bagnell@AISTATS11). Can you comment if GAN-based methods are immune or susceptible to this?\n   \n- Would this work for tasks where the state-space has to be learned together with the policy? E.g. image captioning tasks or Atari games.\n\n- Is it possible to quantify the ease of learning or the frequency of use of the \"new\" actions, i.e. $A^l \\setminus A^e$?. Won't learning these actions effectively be as difficult as RL with sparse rewards? Say, in a grid world where 4-way diagonal moves allow reaching the goal faster, learner is king 8-way, demonstrations come from a 4-way expert, rewards are sparse and each step receives a -1 reward and the final goal is large positive -- does the learner's final policy actually use the diagonals and when?\n\nRelated work:\n   \n- Is it possible to make a connection to (data or policy) aggregation methods in IL. Such methods (e.g. Chang et al.@ICML15) can also sometimes learn policies better than the expert.\n\nExperiments:\n- why GAIL wasn't evaluated in Fig. 3 and Fig. 4?\n\nMinor:\n- what's BCE in algorithm 1?    \n- Fig.1: \"the the\"\n- sec 3.2: but avoid -> but avoids\n- sec 3.2: be to considers -> be to consider\n- sec 3.2: any hyperparameter -> any hyperparameters\n- colors in Fig 2 are indistinguishable\n- Table 1: headers saying which method is prior work and which is contribution would be helpful\n- Fig. 3: if possible try to find a way of communicating the relation of action spaces between expert and learner (e.g. a subset of/superset of). Using the same figure to depict self-exploration make it complicated to analyse.\n- sec 3.2: wording in the last paragraph on p.4 (positive scaling won't _make_ anything positive if it wasn't before)", "rating": "6: Marginally above acceptance threshold", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}