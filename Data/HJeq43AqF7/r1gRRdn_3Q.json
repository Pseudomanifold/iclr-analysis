{"title": "The paper combines neural modeling with the inside-outside algorithm for unsupervised dependency parsing. The model is interesting and seems to be novel, but there is a serious lack of knowledge reagrding previous work on unsupervised parsing", "review": "This paper proposes a model for unsupervised dependency parsing (latent tree induction) that is based on a combination of the inside-outside algorithm with neural modeling (recursive auto-encoders). The paper is clearly written and the model seems interesting and, as far as I can tell, also novel.\n\nYet, the paper suffers from a major limitation that deems its rejection. Unfortunately, the authors seem to be totally unaware of previous work on unsupervised parsing. It may sound surprising but people have worked on this problem even before 2014 and there are some strong results that do not involve deep learning. I am sorry for the sarcasm, but it was really frustrating to see not only the lack of citation, but also the statement (already in the abstract and throughout the paper) that an F-score of 46.9 set a SOTA for unsupervised parsing with WSJ PennTreebank.\n\nParticularly, the authors ignore works of Cohen and Smith, Spitkovsy et al., Seginer and many others. A quick look at Spitkosky et al., 2013 (EMNLP) would reveal that the reported result is not SOTA (although Spitkovsky et al report results for sentences no longer than 40 words, but given the numbers they report for several models - an F1 score of 54 and more - the full WSJ number is likely to be higher than 46.9). But all the papers cited at Spitkovsky et al. 2013 are even not cited here. \n\nI would also like to refer the authors to work by Cohen and Collins (2012-2013) on latent variable PCFG, which presents a provably consistent parameter estimation for the problem. The presented techniques may also be an interesting point of comparison to this work and phrase representation may also be extracted from that algorithm.", "rating": "2: Strong rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}