{"title": "Interesting idea and well-written paper. Missing evaluation on downstream applications.", "review": "This paper describes a neural latent tree model (DIORA) trained with an auto-encoding objective. The proposed model performs an inside-outside pass to construct vector representations for all possible tree nodes. Full constituency trees can be extracted from the model by doing a CKY pass with the internal node-pair scores.  It  achieves the state of the art on unsupervised constituency parsing. On the other tasks/datasets (unsupervised segmentation, phrase similarity), the model is either on par with or a bit worse than the previous best systems. \n\nStrengths:\n- The proposed model is quite interesting. Judging from the empirical results, it captures syntactic structure better than the other latent tree models.\n\n- The paper is well-written and easy to understand.\n\nWeaknesses:\n- It would be nice to see at least one task that involves the application of the DIORA model. \n\nOther comments and questions below:\n- Table 1 shows that DIORA is trained on sentences with a maximum length of 20, while Section 4 says that the model is evaluated on the full WSJ test set. Is this setup affecting the performance? It would be nice to see some accuracy breakdown by sentence lengths.\n\n- Is it possible to compare to other unsupervised parsing/grammar induction models, despite the fact that they often evaluate on shorter sentences (e.g. 20 or 40 words)?\n\n- This paper reports parsing performance on the MultiNLI dataset against the automatic parser, is there a plan for getting the final accuracy on MultiNLI as well?\n\n- It would be nice to have more discussions in Section 3.4 on the qualitative examples. Moreover, is it possible to show examples where DIORA makes mistakes as well? \n\nIn 3.2.1, what are the possible reasons behind DIORA performing poorly on prepositional phrases?\n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}