{"title": "An interesting proposal for deep-learning-based video compression, but somewhat limited experimental results and unclear applicability. ", "review": "The paper is well written and the basic ideas are reasonably well explained and supported. However, several aspects are insufficiently explained. Several examples follow.\n\nIn Figure 1, it is not clear at all how the bitstream is formed; frames 1 to T are compressed jointly with frame t; but frame t is part of the set of frames from 1 to T. How the global state updated when compressing frame t+1? Using frames 2 to T+1?\n\nWriting that you use a Laplacian distribution because l1 regularized loss typically outperforms the l`2 loss for autoencoding images is clearly an insufficient justification, if not backed by experiments or references. Moreover, the authors seem to confuse regularization with loss; by using a Laplace density for the generative model, they are using a l1 loss, not an l1 regularizer. \n\nThere is absolutely no information about implementation details.\n\nThe video sequences used in the experiments are extremely small, both in spatial and temporal terms. A collection of 10 64*64 frames has fewer pixels than even a moderately sized still image. As the authors acknowledge, standard video codecs are far from optimized for video sequences of this size, making the comparisons unfair. The extreme compression results on the sprites and BAIR datasets may be quite misleading, since the data lives in a very low dimensional manifold, due to the simplicity of the scenes. For the more realistic Kinetics dataset, the proposed method is competitive with H264 and H265, but only in a very limited range of bit rates. In fact, the authors do not explain why they have not show results for wider ranges of bitrates.\n\n\n", "rating": "6: Marginally above acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}