{"title": "Missing important connections to existing works", "review": "Paper Summary: \nThis paper proposes to reconstruct the generated images to the their corresponding latent code. As claimed, the goal is to improve the accuracy and efficiency of inference mapping better than other inference mapping techniques, while maintaining their generation quality.\n Instead of using an independent encoder, the authors propose to share the encoder parameters with the discriminator: a Connection Network (CN) is built on top of the features extracted by the discriminator. The weight-sharing machisme shows better performance in Figure 1.\nThe proposed method has two benefits: : a) manipulating the image by disentangling the latent space and b) suggesting a new metric for assessing the GAN model by measuring reconstruction errors of real data.\n\nGeneral Comments:\nIn term of algorithm, the paper essentially adds the conscontruction term (CN) to the standard GAN loss, and partially shares the weights of the \u201cencoder\u201d and discriminator. However, it is almost identical to the existing works, which are NOT cited, and the connections are not discussed.\n\nConnection to InfoGAN: To relate the generated images to the latent code,  the proposed method employs the reconstruction loss, InfoGAN employs the mutual information. Note that reconstruction loss = negative log likelihood, and effectively is equivalent to Mutual Information and Conditional Entropy in the case. Please see the discussion in Lemma 3 and Appendix A of [3] for detailed discussion.  Further, InfoGAN has proposed to to sharing weights of the encoder and discriminator, exactly the same with this submission. The claimed advantage is to disentangle the latent space. It is not surprise at all, once the authors see the connection to InfoGAN, which was originally proposed to disentangle the latent codes.\n\nConnection to CycleGAN: CycleGAN consists of four losses: two reconstruction losses and two standard GAN losses. As shown in Section 4 of [3] \u201cConnecting ALI and CycleGAN\u201d, one reconstruction loss and  one standard GAN loss is sufficient to achieve CycleGAN\u2019s objective, the other two losses would only help to accelerate. In another word, the proposed method is exactly half of the CycleGAN losses.\n\nThe author mention in Abstract that \u201cthe bidirectional generative models introduce an encoder to establish the inverse path of the generation process. Unfortunately, their inference mapping does not accurately predict the latent vector from the data because the imperfect generator rather interferes the encoder training.\u201d This is the non-identifiable issue of ALI/BiGAN discovered in [3]. Please clarify. \n\nThe proposed method should compare with [1] and [2] in great detail, to demonstrate its own advantages. Given the missing literature, the current experimental comparisons seem not that meaningful, because the baseline methods are not really the competitors. \n\nOne interesting contribution of the submission is to consider the reconstruction errors to measure the quality of GANs. To my best knowledge, it is original. \n\n\nReferences:\n\n[1] InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets, NIPS 2016\n[2] Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks, ICCV 2017\n[3] ALICE: Towards Understanding Adversarial Learning for Joint Distribution Matching, NIPS 2017\n", "rating": "3: Clear rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}