{"title": "This paper addresses the important limitation of the prior work and improves the generalization of the model.", "review": "The goal of this paper is to build a task-oriented dialogue generation system that can continuously generate questions and make a guess about the selected object.\n\nThis paper builds on the top of the previously proposed AQM algorithm and focuses on addressing the limitation of the AQM algorithm, which chooses the question that maximizes mutual information of the class and the current answer, but uses fixed sets of candidate questions/answers/classes.\nThe proposed AQM+, the extension of AQM, is to deal with 1) the natural language questions / answers using RNN as the generator instead of selecting from the candidate pool (RNN as generator) and 2) a large set of candidate classes (from 10 to 9628). \nThe novelty is relatively limited, considering that the model is revised from AQM.\nAlthough this work is incremental, this paper addresses the important issue about the generalization.\n\nThe experiments show that the model achieves good performance in the experiments.\nHowever, some questions should be clarified.\n\n1) In the ablation study, what is the performance of removing Qpost and remaining Qinfo (asking questions using AQM+, and guessing with an SL-trained model)?\n\n2) In the experiments, the baselines do not contain AQM. \nAlthough AQM has more constraints, it is necessary to see the performance difference between AQM and AQM+, . \nIf the difference is not significant, it means that this dataset cannot test the generalization capability of the model, so experiments on other datasets may be considered.\nIf the difference is significant, then the effectiveness of the model is well justified.\nThe authors should include the comparison in the experiments; otherwise, it is difficult to justify whether the proposed model is useful.\n", "rating": "6: Marginally above acceptance threshold", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}