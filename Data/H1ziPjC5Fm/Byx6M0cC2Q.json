{"title": "A great contribution to the visual explanation literature!", "review": "Pros:\n\nThis paper\n - Proposes a method for producing visual explanations for deep neural network outputs,\n - Improves quality of the guided backprop approach for strided layers by converting stride 2 layers to stride 1 and resampling inputs (improving on a longstanding difficulty with such approaches),\n - Shows fairly rigorous experimentation demonstrating the applicability and properties of the proposed approach, and\n - Releases a new synthetic dataset and benchmark for visual explanation methods.\n\nAlthough producing visual explanations is a task fraught with difficulty for many reasons, including that explanations for complex decisions may not necessarily be communicable via one or a small number of saliency maps over the image pixels, this paper strives valiantly in this admittedly difficult direction.\n\nThe experimentation is fairly rigorous, which is a welcome departure from and improvement on the norm for this type of paper. I hope such more quantitative evaluation will become more common in papers evaluating visual explanations.\n\nCons:\n\nWhat about features that are very important but not linearly predictive on their own? This approach (and many others) would not work in that case; recognizing this, extending the an8Flower dataset to include such images and labels may be motivating for the field. For example, flowers where the class is determined not by a specific single color or feature (thorns or spots) but by the combination. In these cases, it\u2019s not clear what the right answer would even be in the form of a saliency map, so the first task for researchers would be to determine in what format the answer should even be provided! So: less a benchmark than a motivating open question.\n\n\nSmaller notes:\n\nI found the presentation of the stride 1 resampling approach a little confusing. When performing the backward pass through the network from, say, layer 20, is the approach followed at every stride 2 layer on the way back? If so, I don\u2019t think I saw this mentioned. If not, wouldn\u2019t artifacts be introduced and compounded at any stride 2 layer during the backward pass?\n\n\n====== Update 12/12/18 ======\n\nThanks for your notes in reply. I'll just add that if the dataset can be extended to slightly greater complexity either for this version or for submission to a subsequent venue, it would be impactful. Simple extensions could include scenes with multiple flowers and classes where the explanatory factor is tricker to uncover. For example, a dataset could be created with scenes of three flowers: two of one color and one of another color, with the class determined by the color of the lone flower. The correct explanation (the color of the lone flower) is still clear, and it would be great to see if the proposed LASSO approach (or a future approach) could correctly identify those pixels.", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}