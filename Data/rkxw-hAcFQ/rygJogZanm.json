{"title": "Heuristic labeling enables learning of hierarchical model without needing to marginalize over latent variables", "review": "# Summary\n\nThe paper proposes training generative models that produce multi-agent trajectories using heuristic functions that label variables that would otherwise be latent in training data. The generative models are hierarchical, and these latent variables correspond to higher level goals in agent behavior. The paper focuses on basketball offenses as a motivating scenario in which multiple agents have coordinated high-level behavior. The generative models are RNNs where each output is fed into the decoder of a variational autoencoder to produce observed states. The authors add an intermediate layer to capture the latent variables, called macro-intents. The parameters are learned by maximizing an evidence lower bound.\n\nExperiments qualitatively and quantitatively show that the hierarchical model produces realistic multi-agent traces.\n\n# Comments\n\nThe paper presents a sensible solution for heuristically labeling latent variables. It is not particularly surprising that the model then learns useful behavior because it no longer has to maximize the marginal likelihood over all possible macro-intents. What is more interesting is that a heuristic labeling function is sufficient to label macro-intents that lead to learning realistic basketball offenses and swarm behavior.\n\nAre any of the baselines (VRNN-single, VRNN-indep, and VRNN-mi) equivalent to training the hierarchical model by maximizing an ELBO on the marginal likelihood? I do not think this comparison is done, which might be interesting to quantify how much of a difference heuristic labeling makes. Of course, the potentially poor fit of a variational distribution would confound the results.\n\n# Minor things\n\n1) In the caption of Table 1, it says \"Our hierarchical model achieves higher log-likelihoods than baselines for both datasets.\" Are not the reported scores evidence lower-bounds? So it achieves a higher evidence lower bound, but without actually computing the true likelihood, could not the other models have higher likelihoods?\n\n2) Under \"Human preference study\" it says \"All judges preferred our model over the baselines with 98% statistical significance.\" I am not familiar with this terminology. Does that mean that a p value for some null hypothesis is .02?\n\n3) Something is wrong with the citation commands. Perhaps \\citep should be used.", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}