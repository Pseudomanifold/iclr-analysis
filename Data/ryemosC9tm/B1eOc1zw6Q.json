{"title": "Applies a distance constraint to the latent space of auto-encoders", "review": "[I'm a fallback reviewer assigned after initial reviewer failed to submit]\n\nQuality/Clarity:\nThe work is fine. The presentation is clear enough. The experiments are all on simulated data, with 2GHz scattering simulation derived from more sophisticated software suites than the 4 toy manifold problems initially considered.\n\n\nOriginality/Significance:\nThe work does not seem particularly novel. Perhaps the specific application of regularized autoencoders to the channel charting problem is novel. The regularizers end up looking a lot like a variety of margin losses. The idea of imposing some structure on the latent space of an autoencoder is not particularly new either. Consider, for example, conditional VAEs. Or this work from last year's ICLR https://openreview.net/forum?id=Sy8XvGb0- This work is straightforward multi-task learning with dimensionality reduction with similarity loss tasks.\n\nOn the whole, I don't think there is enough novel work for the venue.", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}