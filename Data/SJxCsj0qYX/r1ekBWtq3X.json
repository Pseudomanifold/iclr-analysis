{"title": "A nice approach for training multi-generator", "review": "This paper proposes a way of training multi-generator in the GAN setting.\nWhile a proposed approach is simply to put N generators and form a sum of GAN losses to train a model, the paper carefully presents a theoretical analysis on the duality gap, and shows as N goes infinity, the duality gap can shrink to zero.\nOne can think of this as a usual ensemble approach to increase model's capacity and performance, but the main difference to the usual ensemble approach is to form a sum of losses (ensemble losses) instead of a loss on output of ensemble.\nThe paper shows this can be more effective approach to train a multi-generator architecture and I believe that this can be an effective approach to capture multi-modal sample distributions.\nFinally, a paper is well-written and well-organized. ", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}