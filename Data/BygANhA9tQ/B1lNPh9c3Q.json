{"title": "An incremental paper that straightforwardly applies cost-sensitive loss to robust adversarial learning.", "review": "The paper introduces a new concept of certified cost-sensitive robustness against adversarial attacks. A cost-sensitive robust optimization formulation is then proposed for deep adversarial learning. Experimental results on two benchmark datasets (MNIST, CIFAR-10) are reported to show the superiority of the proposed method to overall robustness method, both with binary and real-value cost matrices. \n\nThe idea of cost-sensitive adversarial deep learning is well motivated. The proposed method is clearly presented and the results are easy to access. My main concern is about the novelty of the approach which looks mostly incremental as a rather direct extension of the robust model (Wong & Kolter 2018) to cost-sensitive setting. Particularly, the duality lower-bound based loss function and its related training procedure are almost identical to those from (Wong & Kolter 2018), up to certain trivial modification to respect the pre-specified misclassification costs. The numerical results show some promise. However, as a practical paper, the current empirical study appears limited in data scale: I believe additional evaluation on more challenging data sets can be useful to better support the importance of approach. \n\nPros: \n\n- The concept of certified cost-sensitive robustness is well motivated and clearly presented.\n\nCons:\n\n-  The novelty of method is mostly incremental given the prior work of (Wong & Kolter 2018).\n- Numerical results show some promise of cost-sensitive adversarial learning in the considered settings, but still not supportive enough to the importance of approach.\n\n", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}