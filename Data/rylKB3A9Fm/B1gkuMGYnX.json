{"title": "Interesting topic and solid experiments", "review": "Update: Lower the confidence and score after reading other comments. \n===\n\nIn this paper, the authors benchmark several RL algorithms on their abilities of generalization. The experiments show interpolation is somehow manageable but extrapolation is difficult to achieve. \n\nThe writing quality is rather good. The authors make it very clear on how their experiments run and how to interpret their results. The experiments are also solid. It's interesting to see that both EPOpt and RL^2, which claim to generalize better, generalize worse than the vanilla counterparts. Since the success rates are sometimes higher with more exploration, could it be possible that the hyperparameters of EPOpt and RL^2 are non-optimal? \n\nFor interpolation/extrapolation tasks, all 5 numbers (RR, EE, DR, DE, RE) are expected since the geometric mean is always 0 once any of the numbers is 0. \n\nWhat does ``\"KL divergence coefficient\" in RL^2-PPO mean? OpenAI's Baselines' implementation includes an entropy term as in A2C. \n", "rating": "5: Marginally below acceptance threshold", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}