{"title": "Not enough novelty and missing key references", "review": "This paper proposes a knowledge distillation based framework to train an action recognition model with fewer video frames as input. I don\u2019t think the paper is novel enough as a number of knowledge distillation works exist which are closely related; some of them are on training efficient networks for action recognition.\n\nPros:\n\n\u2022\tIt is interesting to see how compact deep neural network can be trained with knowledge distillation.\n\nCons:\n\n\u2022\tMy main concern is the limited novelty of the work. The knowledge distillation approach proposed in this work (a combination of feature alignment and prediction KL loss) is a standard one and has been applied to a variety of vision problems.\n\u2022\tIn particular, the parallel training has been used in Y. Zhang, T. Xiang, T. Hospedales and H. Lu, \"Deep Mutual Learning\", CVPR'2018. In fact, that papers shows that if the teacher and student, or peers, teach each other, rather than the teacher-to-student one-way traffic, it is more effective. \n\u2022\tFor action recognition, this paper: B. Zhang, L. Wang, Z. Wang, Y. Qiao, and H. Wang, \u201cReal-time action recognition with enhanced motion vector cnns,\u201d in CVPR, 2016, proposed something very similar: instead of teacher network having more frames as input, in their work, the teacher network has access to the more expensive optimal flow modality, whilst the student network uses the motion vector as a by-product of video compression (hence free). Apart from this difference, the formulation is very similar. This paper should certainly be cited. \n\u2022\tApart from the novelty, the experiment is also limited in that only one dataset is used. The hierarchical RNN model may be effective on the YouTube-8M dataset, but other models such as the two-stream model from Simonyan and Zisserman and I3D from Carreira and Zisserman are popular on other datasets such as Kinetics. It would be useful to see some additional experiments on another benchmark with a different network architecture. \n", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}