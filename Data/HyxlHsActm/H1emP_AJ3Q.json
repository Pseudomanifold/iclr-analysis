{"title": "I believe I miss some thing important in this paper. This paper seems not to be self contained. I do not understand the paper very well. Therefore, I have reservations about the paper.", "review": "This paper analyzes the surface of the complete orthogonal dictionary learning problem, and provides converge guarantees for randomly initialized gradient descent to the neighborhood of a global optimizer. The analysis relies on the negative curvature in the directions normal to the stable manifolds of all critical points that are not global minimizer.\n\nExploring the surface of a function and analyzing the structure of the negative curvature normal to the stable manifolds is an interesting idea. However, I believe I miss some thing important in this paper. This paper seems not to be self contained. I do not understand the paper very well. See details below. Therefore, I have reservations about the paper.\n\n*) The terminology \"stable manifolds\" is used from the first page, while its formal definition is given on page 4.\n*) P3, the dictionary learning problem is not formally given. It is stated in the paper that the task is to find A and X, given Y. However, what optimization problem does the author consider? Is it \\min_{A, X} \\|Y - A X\\|_F^2? assuming both dictionary A and sparse code X are unknown or \\min_{A} \\|Y - A X\\|_F^2 assuming only dictionary is unknown?\n*) P3, second paragraph in Section 3: what is the variable q? It is not defined before.\n*) P3, third paragraph in Section 3: What is the function row()? Why does row(Y) equal row(X)?\n*) P3: How does the dictionary learning problem reformulate into the problem in the third paragraph of Section 3? If I understand correctly, the task is to find A, X such that A^* Y = X since A is orthogonal. Consider the first column in A and denote it by q. Then the first column of X is approximated by q^* Y. Since X is sparse, the task is to find q so that q^* Y as sparse as possible. But how about the other columns in matrix $A$? \n*) The Riemannian gradient algorithm is not stated in this paper.\n\n\n", "rating": "5: Marginally below acceptance threshold", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}