{"title": "Interesting ideas; unclear if assumptions are too strong", "review": "Summary: by assuming a correct, strongly factored environment model, improved estimators useful for policy search can be derived by \"counterfactual reasoning\", where data sampled from experience is used to refine initial conditions in the model; this translates into improved estimators of policy values, which improves policy search.\n\nMajor comments:\n\nI enjoyed this paper.  I think that model-based RL deserves more work, and I think that this is a simple, reasonably workable approach with some nice theoretical benefits.  I like the idea of SCMs; I like the idea of counterfactual reasoning; I like the idea of leveraging models in this unique way.\n\nOn the negative side, I felt that the paper makes some rather strong assumptions - specifically, that the agent has access to a perfect model with no mismatch, and that the model decomposes neatly into noise variables plus deterministic functions.  Given such a model, one wonders if there are other techniques, say, from classical planning, that could also be used for some sort of policy search.\n\nI have a few questions about approximations.  First, I see that probabilistic inference is a core element of each algorithm (where p(u|h) must be computed).  For large, complex models, I assume this must be approximate inference.  This leads naturally to questions about accuracy (does approximate inference result in biased estimators? [probably yes]), efficacy (do the inaccuracies inherent in approximate inference outweigh the benefits of using p(u|h) vs. p(u)?) and scalability (how large of a model can we reasonably cope with before degradation is unacceptable, or no better than non-CF algorithms?).  As far as I can tell, none of this was addressed in the paper, although I do not expect every paper to answer every question; this is a first step.\n\nI wish the experiments were a little more varied.  The experimental results really only show marginal improvement in one small task.  While I understand that this is not an empirical paper, neither does it fit strongly into the category of \"theory paper\".  For example, there are no theory results indicating what sort of benefit we might expect from using the methods outlined here, and in the absence of such theory, we might reasonably look to various experiments to demonstrate its effectiveness.\n\nPros:\n+ Integration with SCMs is interesting\n+ Counterfactual variants of algorithms are clearly motivated and interesting\n+ Paper is generally well-written\n\nCons:\n- Assumption that the agent is given a model with no mismatch is very strong\n- Model class (noise variables + deterministic functions) seems potentially restrictive\n- Questions about impact of approximate inference\n- Experiments could have been more varied\n\n", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}