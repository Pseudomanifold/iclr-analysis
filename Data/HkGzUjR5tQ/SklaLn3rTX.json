{"title": "Nicely and clear written paper with innovative aspects. The results look strong but could increase confidence in results via reporting of variance / stat sig; Paper is a bit narrow as applied new method to one task only.", "review": "The authors propose a new architecture Dual Adversarial Transfer Network for addressing low-resource NER. They achieve a new SOTA on low resource language. The authors compare a base-line with two alternatives based on variants of GANs.  \n\nThe results go beyond SOTA for low resource NER which seems a solid contribution. The paper is well and clearly written and I would be able to replicate the experiments. I wonder if this is a new architecture that works well for one task or if it could be applied to other tasks too. This would strengthen the approach and paper quite a bit. Could the method for instance be applied to other labeling tasks: POS tagging, morphological features. This would increase the potential impact substantially.  \n  \nIn low resource scenarios often methods work that do stop working at a some point with more resources. For this methods the boundary when this effect occurs would be interesting to explore; Figure 2 goes into this direction which is a quite nice study but the boundary is not  explored further; by using for instance the English NER data. Additionally, the performance on the English data set would indicate what the method could perform in comparison to current SOTA for normal resource setting - you could use some of the low resources in addition. The English data set was used but only to exploit it for the transfer learning. \nTable 2 is a good overview on SOTA. I really wonder about the variance of the results of the system which can be depending on the network quite large. Why not running repetition test, this  would enable the authors to report variance and statistically significance between the baseline and their other systems. \nI wonder also how more standard exploitation of additional data would do such as Bert, ELMO or older methods such as up-training - this would help to get a more complete picture and strength the paper further. \n\nThe paper could be stronger by applying the method to other task too as stated the authors - this is a \u2018new architectures\u2019 (for NER) which triggers the question and does it generalize to other tasks? In the conclusion there is even the claim as a statement! that this can be generalized to other NLP task without actually trying. I think, this can not be claimed in the conclusions without pursuing this in some other task and I suggest to tune this down.   \n\nOverall:\nNicely and clear written paper containing innovative elements. The results look strong too me but due to the lack of variance and stat sig., I am not sure if they are really super strong. The paper could be stronger by applying the method to other task too as stated \u2018new architectures\u2019 which triggers the question if the method generalizes to other tasks?   \n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}