{"title": "CONFIDENCE CALIBRATION IN DEEP NEURAL NETWORKS THROUGH STOCHASTIC INFERENCES", "review": "The authors propose a generic framework to calibrate predictions in deep-neural-network-based classifiers. They do this using a new variance-weighted loss function that does not introduce additional (hyper-)parameters. Results on various datasets using various architectures demonstrate how the framework result in models with well calibrated predictions, i.e., not under or overconfident probabilistic estimates of labels.\n\nIn Section 3.3, \\theta is, I think, not a deterministic parameter, though the authors may refer to the fact that it is learned as a point estimate.\n\nEquation (7) should be conditioned on \\theta.\n\nIn section 3.3, expected predictions and their variances can be approximated by MC not \"calculated\" as the authors write.\n\nIn Figure 1 (right), the authors should use the same range for x and y axis to make more evident that the models are poorly calibrated. A diagonal line may also make the deviations from perfect calibration easier to see.\n\nIn Section 4.2, the authors do not provide a theoretical justification for the choice of the variances as the weights for the loss function in (9). Other than that the proposed loss is very similar to that in (10). Also the authors do not properly justify/discuss the use of the Bhattacharyya coefficient as the variance metric or why T=5 samples are enough to get a good estimate of \\alpha.\n\nThe experiments although relatively extensive are not very convincing because results in Table 1 are to be expected (given CI is an average of multiple \\beta values), and Table 2 shows that TS case 2 has better calibration results (ECE) than VWCI, although VWCI has in general better accuracy (at the cost of some calibration loss).\n\nIt is not clear why the authors do not show calibration plots like in Figure 1(right) or Figure 4 in Guo et al, 2017.", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}