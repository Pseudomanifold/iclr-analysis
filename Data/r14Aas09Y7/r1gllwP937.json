{"title": "Interesting idea but needs more work", "review": "This paper proposes to constrain the Generator of a WGAN-GP on patches locations to generate small images (\u201cmicro-patches\u201d), with an additional smoothness condition so these can be combined into full images. This is done by concatenating micro-patches into macro patches, that are fed to the Discriminator.  The discriminator aims at classifying the macro-patches as fake or real, while additionally recovering the latent noise used for generation as well as the spatial prior.\n\nThere are many grammar and syntax issues (e.g. the very first sentence of the introduction is not correct (\u201cHuman perception has only partial access to the surrounding environment due to the limited acuity area of fovea, and therefore human learns to recognize or reconstruct the world by moving their eyesight.\u201d). The paper goes to 10 pages but does so by adding redundant information (e.g. the intro is highly redundant) while some important details are missing  \n\nThe paper does not cite, discuss or compare with the related work \u201cSynthesizing Images of Humans in Unseen Poses\u201d, by G. Lalakrishan et al. in CVPR 2018. \n\nPage. 3, in the overview the authors mention annotated components: in what sense, and how are these annotated?\nHow are the patches generated? By random cropping? \n\nStill in the overview, page 3, the first sentence states that D has an auxiliary head Q, but later it is stated that D has two auxiliary prediction heads.  Why is the content prediction head trained separately while the spatial one is trained jointly with the discriminator? Is this based on intuition or the result of experimentations?\n\nWhat is the advantage in practice of using macro-patches for the Discriminator rather than full images obtained by concatenating the micro-patches? Has this comparison been done?\n\nWhile this is done by concatenation for micro-patches, how is the smoothness between macro-patches imposed?\n\nHow would this method generalise to objects with less/no structure?\n\nIn section 3.4, the various statements are not accompanied by justification or citations. In particular, how do existing image pinpointing frameworks all assume the spatial position of remaining parts of the image is known?\n\nHow does figure 5 show that model can be misled to learn reasonable but incorrect spatial patterns?\n\nIs there any intuition/justification as to why discrete uniform sampling would work so much better than continuous uniform sampling? Could these results be included?\n\nHow were the samples in Figure.2 chosen? Given that the appendix. C shows mostly the same image, the reader is led to believe these are carefully curated samples rather than random ones.", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}