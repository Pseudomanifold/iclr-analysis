{"title": "Borderline: Manifold Regularization with GANS for SEMI-Supervised Learning ", "review": "This paper builds upon the assumption that GANs successfully approximate the data manifold, and uses this assumption to regularize semi-supervised learning process.\nThe proposed regularization strategy enforces that a discriminator or a given classifier should be invariant to small perturbations on the data manifold z. It is empirically shown that naively enforcing such a constraint by randomly adding noise to z could lead to under-smoothing or over-smoothing in some cases which can harm the final classification performance. Consequently, the proposed regularization technique takes a step of tunable size in the direction of the manifold gradient, which has the effect of smoothing along the direction of the gradient while ignoring its norm.\n \nExtensive experiments have been conducted, showing that the proposed approach\noutperforms or is comparable with recent state-of-the-art approaches on cifar 10, especially in presence of fewer labelled data points. On SVHN however, the proposed approach fails in comparison with (Kumar et al 2017) but performs better than other approaches.\n\nFurthermore, it has been shown that adding the proposed manifold regularization technique to the training of GAN greatly improves the image quality of generated images (in terms of FID scores and inception scores). Also, by combining the proposed regularizer with a classical supervised classifier (via pre-training a GAN and using it for regularization) decreases classification error by 2 to 3%.\n \nFinally, it has also been shown that after training a GAN using the manifold regularization, the algorithm is able to produce similar images giving a low enough perturbation of the data manifold z.\n \nOverall, this paper is well written and show significant improvements especially for image generation. However, the novelty is rather limited as similar ideas have been undertaken (e.g., Mescheder et al 2018), but in different contexts. The paper would be improved if the following points are taken into account:\n \nA comparison with Graph Convolutional Network based techniques seems appropriate (e.g. Kipf and Welling 2017).\nHow do the FID/Inception improvements compare to (Mescheder et al 2018)?\nIt would be interesting to discuss why the FID score for SVHN gets worse in presence of 1000 labels.\nAlthough there is a clear improvement in FID scores for Cifar10. It would be informative to show the generated images w/ and w/o manifold regularization.\nMore analysis should be provided on why (Kumar et al 2017) perform so well on SVHN.\nIt should be stated that bold values in tables do not represent best results (as it is usually the case) but rather results for the proposed approach.\n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}