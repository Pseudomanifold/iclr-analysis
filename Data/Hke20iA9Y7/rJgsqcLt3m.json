{"title": "Nice work", "review": "This paper proposes an efficient algorithm to learn  neural embedding models with a dot-product structure over very large corpora. The main method is to reformulate the objective function in terms of generalized Gramiam matrices, and maintain estimates of those matrices in the training process. The algorithm uses less time and achieves significantly better quality than sampling based methods. \n\n1. About the experiments, it seems the sample size for sampling based experiments is not discussed. The number of noise samples have a large influence on the performance of the models. In figure 2, different sampling strategies are discussed. It would be cool if we can also see how the sampling size affects the estimation error. \n\n2. If we just look at the sampling based methods, in figure 2a, uniform sampling\u2019s Gramian estimates is the worst. But the MAP of uniform sampling on validation set for all three datasets are not the worst. Do you have any comments?\n\n3. wheter an edge -> whether an edge.\n", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}