{"title": "Review", "review": "The idea proposed in this paper is to aid in understanding networks by showing why a network chose class A over class B.  To do so, the goal is to find an example that is close to the original sample, but belongs to the other class. As is mentioned in the paper, it is crucial to stay on the data manifold for this to be meaningful. In the paper, an approach using a GAN to traverse the manifold is proposed and the experimental evaluation is done on MNIST.\n\nIf my understanding is correct the proposed approach requires:\nFinding a noise code z_0 such that the GAN generates an image G(z_0) close to the original input x. As a metric L2 distance is proposed.\nFind a point close to z_b that is close z_0  s.t. Class B is the most likely class and class A is the second most likely prediction. Specifically it is required that\nThe log likelihood of but classified as class B with the same log likelihood of class B for G(z_b) is the same as the log likelihood of class A for the input x.\nSuch that all other classes have a log likelihood that is at least epsilon lower than both the one of class A and class B.\n\nThe proposed approach is compared to a set of other interpretability methods, which were \nGrad-Cam, lime, PDA, xGEM on MNIST AND Fashion MNIST data. The proposed evaluation is all qualitative, i.e. subjective. It must also be noted that in the methods used for comparison are not used as originally intended.\n\n\nCurrently, I do not recommend this paper to be accepted for the following reasons.\nThe idea of using a GAN is to generate images in input space is not novel by itself. Although the application for interpretability by counterfactuals is. It is unclear to me how much of the appealing results come from the GAN model and how much come from truly interpreting the network. I have detailed this below by proposing a very simplistic baseline which could get similar results.\nThe experimental approach is subjective and I am not convinced by the experimental setup.\nOn the other hand, I do really appreciate the ideas of traversing the manifold. \n\nRemarks \nRelated work and limitations of existing interpretability methods are discussed properly. Of course, the list of discussed methods is not exhaustive. The work on the PPGAN and the \u201cSynthesizing the preferred inputs for neurons in neural networks via deep generator networks\u201d is not mentioned although it seems very related to the proposed approach to traverse the manifold. What that work sets apart from the proposed approach is that is could be applied to imaganet and not just MNIST. \n\nTraversing the manifold to generate explanations is certainly a good idea and one that I completely support. One limitation of the proposed approach is that it is unclear to me whether a point on the decision boundary is desirable or that a point that is equally likely is desirable. My reasoning is that the point on the decision boundary is the minimal change and therefore the best explanation. In such a setup, the GAN is still crucial to make sure the sample remains on the data manifold and is not caused by adverarial effects.\n\nThe exact GAN structure and training approach should be detailed in this paper. Now only a reference is provided. \n\nCan you clarify how the constraints are encoded in the optimization problem?\n\nThe grad cam reference has the wrong citation\n\nI do not understand the second paragraph of section 4.1. As mentioned in the paper, these other methods were not designed to generate this type of application. Therefore the comparison could be considered unfair. \n\nI would propose the following baseline. For image x from class A, find image y from class B such that x-y has minimal L2 norm and is correctly classified. Use y instead of the GAN generated image. Is the result much less compelling? Is it actually less efficient that the entire GAN optimization procedure on these relatively small datasets? \n\n\nI do have to say that I like the experiment with the square in the upper corner. It does show that the procedure does not necesarrily exploits adversarial effects. However, the baseline proposed above would also highlight that specific square?\n\n\nFigure 5 shows that multiple descision boundaries are crossed. Is this behaviour desired? It seems very likely to me that it should be possible to move from 9 to 8 while staying on the manifold without passing through 5? Since the method takes a detour through 5\u2019s is this common behaviour?\n\n\nFINAL UPDATE\n--------------------\nUnfortunately, I am not entirely convinced by the additional experiments that we are truly looking into the classifier instead of analyzing the generative model. \nI believe this to be currently the key issue that, even after the revision, needs to be addressed more thoroughly before it can be accepted for publication. ", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}