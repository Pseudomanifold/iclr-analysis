{"title": "Nice idea with solid experiments", "review": "In this paper the authors propose optimizing for adversarial examples against black box models by considering minimizing the distance to the decision boundary.  They show that because this gives real valued feedback, the optimizer is able to find closer adversarial examples with fewer queries.  This would be heavily dependent on the model structure (with more complex decision boundaries likely being harder to optimize) but they show empirically in 4 models that this method works well.\n\nI am not convinced that the black box model setting is the most relevant (and 20k queries is still a fair bit), but this is important research nonetheless.  I generally found the writing to be clear and the idea to be elegant; I think readers will value this paper. \n", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}