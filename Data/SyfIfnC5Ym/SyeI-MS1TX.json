{"title": "Good idea and experimental evidence but lacking in rigor and more empirical analysis", "review": "The paper casts the problem of learning from adversarial examples to make models resistant to adversarial perturbations to a domain adaptation problem. The proposed method Adversarial training with Domain adapatation( ATDA) learns a representation that is invariant to clean and adversarial data achieving state of the art results on CIFAR. \n\nquality - Paper is well written, explanation of the mathematical parts are good, experimental quality can be much better.\nclarity - the problem motivation as well as the methodology is clearly explained. the learning from the experiments are unclear and need more work.\noriginality - The casting of the problem as domain adaptation is original but from the experiments it was not conclusive as to how much benefit we get. \nsignificance of this work -  Current models being sensitive to adversarial perturbations is quite a big problem so the particular problem authors are trying to address is very significant.\n\npros\n\nA good idea, enough experiments that indicate the benefit of casting this as a domain adaptation problem.\n\ncons \n\nI feel, the authors should have extended the experiments to ImageNet which is a much larger dataset and validate the findings still hold, I feel the discussion section and comparison to other methods needs to be worked to be more thorough and to tease out the benefit of each of the various terms added to the loss functions as currently all we have is final numbers without much explanation and details. TSNE embeddings part is also very qualitative and while the plots indicate a better separation for ATDA, I feel authors should do more quantitative analysis on the embeddings instead of just qualitative plots.", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}