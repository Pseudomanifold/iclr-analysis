{"title": "Continuous generators in GANs don\u2019t capture discrete statistics?", "review": "The paper proposes statistics to identify fake data generated using GANs based on simple marginal (summary) statistics or formal specifications automatically generated from real data. The proposed statistics mostly boil down to the fact that continuous-valued generator neural networks can\u2019t adequately generate data distributions that are topologically different from the distribution in the latent z-space. The differences in the summary data/ feature statistics and statistics corresponding to formal specifications between fake and real data are of the above nature. \n\nThis seems fairly obvious but I haven\u2019t seen this property of GANs being exploited to distinguish between GAN generated and real-data\n\nThis property/ shortcoming of the generator is not surprising at all and has been acknowledged before. See, for example, the discussions in,\n\nKhayatkhoei et al, Disconnected Manifold Learning for Generative Adversarial Networks, arXiv:1806.00880 (NIPS, 2018)\n\nThis has spurred various approaches to mitigate this shortcoming. See, for example,\n\nBen-Yosef and Weinshall, Gaussian Mixture Generative Adversarial Networks for Diverse Datasets, and the Unsupervised Clustering of Images, arXiv:1808.10356\n\nJang, Gu and Poole, Categorical Reparameterization with Gumbel-Softmax, arXiv:1611.01144 (ICLR 2017)\n\nSo, the fact that summary statistics predicated on discreteness of data or discreteness of their dependencies can distinguish GAN-generated data from real data is not surprising at all. In fact, in the paper itself, figure 10 and 11 show that for continuous data like speech, the proposed statistics are unable to distinguish between the fake and real data. \n\nBeyond this, even though it's interesting, there isn\u2019t enough contribution in the paper.  It would be great if the authors can extend this observation and show if such statistics can always be found and tricks like Gumbel-Softmax/ GMM-GANs etc are doomed to fail or if certain extentions of GAN architectures can handle such statistics.\n\nFurthermore, the paper needs to provide more clarity/ clarifications about the following:\n\n1.\tApart from formal specifications, the rest of the statistics are ad-hoc (e.g. the spectral centroid or the spectral slope which are just borrowed from the audio domain) \u2013 why should these be good for images? \n2.\tTraining choices do not seem principled \u2013 GANs are trained till generated samples look like real samples. Why not use parameter settings and train to produced state of the art results with chosen architectures?\n3.\tFigure 1: Why does the CDF for the real data start in the middle of the figure? The figure purportedly shows bimodal 1D data for which the CDF should be a step function whereas the reference data has an inclined line. Why?\n4.\tUsing the term \u2018spectral\u2019 (centroid and slope) for image features is misleading when spectral features are not computed.  Do these features capture spectral properties of images. How? Why are these good features?\n5.\tWhat does an \u201casymptotically converging activation function\u201d mean?\n\n6. Some typos need to be corrected. Figure # and caption (with dataset name) for Figure 6 needs to be provided, etc.\n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}