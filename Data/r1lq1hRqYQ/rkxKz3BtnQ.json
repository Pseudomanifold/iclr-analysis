{"title": "Interesting paper, but results are not very convincing.", "review": "Paper Summary: This paper studies the inverse reinforcement learning problem for language-based navigation. Given the panorama image as its observation, language embedding as its goal, a deep neural network architecture is proposed to predict the reward function from the input observation and goal. Maximum causal entropy IRL has been adopted to learn such language-conditioned reward function. This paper used the SUNCG environment for experiments and designed two tasks (navigation and pick-and-place) for evaluation.\n\n==\nNovelty & Significance:\nThis paper studies a very interesting topic in reinforcement learning and the problem has potential usage when training robot agent in the real world.\n\n==\nQuality:\nOverall, reviewer feels that the experimental results are not very strong. Some of the points are not clearly presented. \n\nFirstly, is not very clear whether the argument made in the abstract \u201cdirectly learning a language-conditioned policy leads to a poor performance\u201d is justified or not. Please clarify this point in the rebuttal.\n\nSecondly, Table 1 and Table 2 can only be treated as ablation studies. The \u201creward-regression\u201d is not a baseline but more about a oracle model. \nIs it possible to compare against some recent work such as Tung et al 2018 or Bahdanau et al 2018? Otherwise, it is not very clear whether the proposed approach is the state-of-the-art or not.\n\nThirdly, using the panorama image as observation seems not a practical choice. Is it possible to provide some ablation studies or discussions on the performance over number of views? \n\nFinally, the architecture design is not well-justified. Why not using pre-trained image classifiers (or DQN encoder) as feature extractor (or finetune the model from pre-trained image classifier)? The actual resolution (32 x 24 x 3) in the paper looks a bit unusual. \n\nOne more thing, the url provided in the paper directs to an empty project page. \n\nIf these concerns can be addressed in the rebuttal, reviewer is happy to re-evaluate (e.g., raise scores) this work.\n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}