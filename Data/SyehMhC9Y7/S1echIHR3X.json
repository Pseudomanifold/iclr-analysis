{"title": "This paper combines Imitation Learning (IL) and Model Base Reinforcement Learning (RL) to come up with a novel algorithm that can take in user-defined targets while maintaining expert like behaviors.   This  promising approach that combines the benefits of IL and RL but with result performed only in simulation.", "review": "- Does the paper present substantively new ideas or explore an under explored or highly novel\nquestion? \n\nYes, the paper combines two frameworks (Imitation Learning and Model Base\nReinforcement Learning) to incorporate target information while fitting to the expert distribution. Maybe, the idea is novel but experiments are only in simulation. \n\n- Does the results substantively advance the state of the art?\n\n No, the compared methods are not state-of-the-art.\n\n-  Will a substantial fraction of the ICLR attendees be interested in reading this paper? \n\n Yes a substantial fraction of ICLR attendees might be interested in reading the paper.\n\n - would I send this paper to one of my colleagues to read?\n\nYes. \n\n\n- Quality: \n\nThe key point of this paper is that the proposed algorithm is novel and combines\nthe advantages of Imitation Learning and Model Base Reinforcement Learning. However, the\nauthors do not address the problem of IL when the stochasticity in the environment and/or model\nresults in trajectories outside of expert\u2019s distribution. Additionally, all experiments are done in\nsimulation only and comparisons are made against components of the proposed algorithm instead\nof the state-of-the-art.  This is definitely a limitation of the paper given recent works on imitation learning and model predictive control  as applied to real robotic systems in the task of agile off-road visual navigation. \n\nIn addition, the paper does not provide any detail on the training procedure (Network architecture, cost\nfunction, etc), which makes results hard to reproduce. In addition, the experiments only compare\nthe proposed algorithm to its components, namely proportional controller, IL only controller and\nModel Basel RL only controller.\n\n- Clarity: \n\nEasy to read. Thorough comparison with existing frameworks (Advantages compared to IL and model\nbased RL). \n\nOriginality: \n\n\u2013 Novel algorithm presented with success in simulation. \n\n", "rating": "5: Marginally below acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}