{"title": "significant clarification needed", "review": "This paper has potential, but I do not think it is ready for publication. I will ask some questions / make some suggestions:\n\n1) Your first sentence makes a claim about there being a large body of research on traffic flow forecasting. I don't doubt this, but you should cite some papers, please.\n\n2) Your contributions raise the following questions for me: \n\n- Contribution 1 is that you use a very large dataset (for training? you don't say.) and a small dataset (for testing), thus proving that your method works and generalizes. Your method may be effective, but compared to what? Your method may generalize, but how do we know that if you've only tested it on one small dataset?\n\n- Contribution 2 says that you creatively used lagged data in a time series model. This is probably a good idea, but it does not sound all that creative to me, compare with, e.g. an AR model.\n\n- Contribution 3 says that you use driving distance to model spatial correlation. Again, this is probably a good idea, and when we get further we learn that you applied a Graph Convolution Network. Were these the choices that you claim are novel? Are they novel? What other choices might be reasonable and how would they compare?\n\n3) Section 3 immediately jumps into the use of autoencoders. But I think you need to justify why we care about using autoencoders in the first place. If the problem is traffic forecasting, why don't you tackle that problem head on?\n\n4) Section 3 mentions sparsity without justifying why I care about sparsity. This might be an important tool for regularization in a deep neural network. Or it might not be--given enough data and other regularization techniques (weight decay, early stopping, dropout).\n\n5) Is the spatial dependency that you end up learning qualitatively different than the spatial dependency you would get by instead assuming a particular parametric form as is done in kernel methods / Gaussian processes, e.g. the Gaussian kernel or the Matern kernel parameterizes the covariance between observations at two spatial locations?\n\n6) In your experiment I believe you randomly split 15 minute blocks into train/test/validate. I think this evaluation will be over-optimistic insofar as if 10:30-10:45 and 11:00-11:15 are in the train set, but 10:45-11:00 is in the test set, it will be relatively easy to predict 10:45-11:00. I would suggest considering train/test/validate splits based on larger chunks, e.g. leave the data in 15 minute blocks, but randomly select hours (4 blocks) to put in train/test/validate.", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}