{"title": "universal image prior with compelling results, but more limited than specialized restoration nets", "review": "# Summary\nThe paper proposes to embed natural images in a latent convolutional space of high dimensionality to obtain a universal image prior. Concretely, each image is embedded as a custom parameter vector of a CNN, which turns random noise into the input of a universal generator network to restore the image in pixel space.\nInference for image restoration is performed by minimizing the energy of a likelihood objective while constraining the latent representation of the restored image to be part of the learned latent space. Experiments for inpainting, super-resolution, and colorization are performed to evaluate the proposed method.\n\n# Positive\nAs mentioned in the paper, I agree that the idea of learning a universal image prior is appealing, since it can be applied to (m)any image restoration tasks without adjustment.\nI am not very familiar with the related work, but if I understood correctly, the paper seems to combine deep latent modeling (GLO, Bojanowski et al., 2018) and deep image priors (Ulyanov et al., 2018). The experiments show good results which qualitatively appear better than those of related methods. A user study also shows that people mostly prefer the results of the proposed method.\nDid you try other standard restoration tasks, such as image denoising or deblurring? If not, do you think they would work equally well?\n\n# Limitations\nWhile I agree that a universal image prior is valuable, the paper should (briefly) mention what the disadvantages of the proposed approach are:\n- A limitation (at least as presented) is that the corruption process has to be known analytically (as a likelihood objective) and must be differentiable for gradient-based inference.\n- Furthermore, the disadvantage of the universal prior as presented in the paper is that restoring an image requires optimization (e.g. gradient descent). In contrast, corruption-specific neural nets typically just need a forward pass to restore the image and are thus easier and faster to use.\n\n# Restoration inference\n- How dependent is the restoration result with respect to the initialization? For example, when starting gradient descent with the degraded image vs. a random image.\n- Roughly, how many iterations and runtime is needed for inference?\n- Did you try different optimizers, such as L-BFGS?", "rating": "7: Good paper, accept", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}