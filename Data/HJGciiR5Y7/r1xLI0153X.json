{"title": "[Review] Latent Convolutional Models", "review": "[Summary]\n- This work proposes a new complex latent space described by convolutional manifold, and this manifold can map the image in a more robust manner (when some part of the image are to be restored).\n\n[Pros]\n- The results show that the latent variable mapped to the image well represents the image, and it will be helpful for the image restoration problem.\n- it seems novel to adapt the idea of DIP for defining complex latent space.\n\n[Cons]\n- The main concern is that there is no guarantee that the defined latent space is continuous. \nIt means that it is difficult to judge whether the interpolated point (phi_in, s_in) between two points: (phi_1, s_1) and (\\phi_2, s_2), will be matched to the image distribution. \nEquation 2 in the paper seems that it just fit the generator parameter theta to map the phi_i and x_i and memorize the mapping between the training images and the given latent convolutional variables. \nIf the proposed algorithm just memorizes the training image and map them into given the latent convolution, the result cannot justify the proposal that the author proposes a new latent space.\n\n[Summary]\n- This work proposes an interesting idea of defining complex latent space, but It is doubtful that this work just memorized the mapping between the training images and the latent convolutional parameters.\n- I want to see the (latent space) interpolation test for the proposed latent convolutional space. If the author provides a profound explanation of the problem, I would consider changing the rating.\n\n--------------------------\nSee the additional comment for the changed rating\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}