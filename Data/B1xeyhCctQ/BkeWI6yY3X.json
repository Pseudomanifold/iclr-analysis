{"title": "interesting direction; preliminary result", "review": "The paper starts by establishing that biases play an important, negligible role in existing DNNs.\nSpecifically, they help improve classification performance, and networks trained with biases do make use of biases.\n\nThen, the authors recognize that the state of the art DNNs use ReLU and variants, which are a piece-wise linear function.\nOver the linear regions, the entire DNN can be collapsed into a single linear model f(x) = Wx + b.\n\nThen the authors argue that the existing gradient-based attribution methods (for interpreting DNNs) often ignore the attribution of the `b` terms in the heatmap.\nThat is, when backpropagating the DNN outputs back to the input, the gradient of (Wx + b) wrt x is exactly W only (ignoring the contribution of b).\n\nThe paper then proposes a method for backpropagating biases.\nFrom the presented results, I only can conclude that bias backpropagation does show a different heatmap compared to regular gradient-based methods.\nHowever, it is unclear how much this BBp result is advancing our understanding of DNNs.\nThe result for this is still preliminary.\n\n- Clarity\nResearch is well motivated, and paper presentation shows a nice, coherent story.\n\n- Originality\nAFAIK, the direction of looking at bias attribution is novel.\n\n- Significance\nThe significance of the paper is limited because (1) the paper only considers the positive region of ReLUs; (2) the empirical results are preliminary and do not show a convincing usefulness of BBp.\nSuggestions: authors may design a toy dataset or find a dataset that has some inherent biases (e.g. data imbalance) to show that DNNs do capture interesting information in the biases. From there, hopefully the impact of BBp can be clearer.\n\nAt the moment, the paper appears not ready for publication.", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}