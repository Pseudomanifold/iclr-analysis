{"title": "An elegant method with comprehensive evaluations", "review": "The paper presents a method for learning policies for transitioning from one task to another with the goal of completing complex tasks. In the heart of the method is state proximity estimator, which measures the distance between states in the originator and destination tasks. This estimator is used in the reward for the transition policy. The method is evaluated on number of MojoCo tasks, including locomotion and manipulation.\n\nStrengths:\n+ Well motivated and relevant topic. One of the big downsides in the current state of the art is lack of understanding how to learn complex tasks. This papers tackles that problem.\n+ The paper is well written and the presentation is clear.\n+ The method is simple, yet original. Overall, an elegant approach that appears to be working well.\n+ Comprehensive evaluations over several tasks and several baselines.\n\nQuestions:\n- In the metapolicy, what ensures consistency, i.e. it selects the same policy in the consecutive steps?\n- Can the authors comment on the weaknesses and the limits of the method?", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}