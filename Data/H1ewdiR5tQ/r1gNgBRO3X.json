{"title": "Interesting approach", "review": "This is an empirical paper that proposes to design wavelets on graphs, that can be integrated to neural networks on graphs. It permits to reducing the number of parameters of the \u00ab convolution \u00bb and exploits the sparsity of sparse weighted graphs for computations. I think it\u2019s an interesting work.\n\nThe perspective I enjoy in using wavelets is that they typically provide a good trade-off in localization in the spectral and graph domains. For instance, large eigenvalues of the laplacian could be potentially captured in a more stable way. This type of work might be a first step.\n\nPros :\n- good numerical results\n- nice incorporation of structure via wavelets\nCons :\n- Sometimes the paper is not really clear\n\nI have severals comments:\n\n1/ (1) \u00ab Some subsequent works devote to making spectral methods spectrum-free\u2026 avoiding high computational cost \u00bb. I think also those types of representations can be potentially unstable. That\u2019s a second reason.\n\n2/ I\u2019m not sure to understand the point (1) of the fourth paragraph of the introduction. (1.)\u00ab graph wavelet does not depend on the eigen decomposition of Laplacian matrix \u00bb. Does it mean numerically ? This sentence is not clear, because even numerically, it can be done in a dependent way to this matrix. However, if it is implied that the fastest algorithm can be obtained without eigen-decomposition of the Laplacian Matrix, in a cheap way, then I agree and a small rephrasing could be nice.\n\n3/ Please remove all the sentences that are supposed to be an introduction for a section, i.e. the sentences between 2 and 2.1 (\u00ab We use graph\u2026 \u00bb) and 3 and 3.1 (\u00ab In many research\u2026 \u00bb). They are poorly written and do not help the reader.\n\n5/ .(2.2) \u201cHowever, such a polynomial approximation also limits the flexibility to define appropriate convolution on graph\u201d I\u2019m not sure to understand. In the paper you refer to, the set of filters span the polynomial of degree less than n, of a diagonalizable matrix of size nxn. Thus, lagrange polynomial basis could be used to interpolate any desired values? Does it signify learning non-diagonal(in the appropriate basis) matrix?\n\n6/ (2.3) $s$ how is this parameter chosen, crossvalidation? Is it adjusted such that the singular values of $\\psi_s$ have a certain decay? Why is $s$ constant across layers? How is the spectrum of psi_s? Is it well conditionned? A huge difference with (Hammond et al,2011) is that they use a collection of wavelets. Did you consider this kind of approach ? Is there a loss of information in some cases?(like if $\\psi_s$ has a fast decay)\n\n7/ (2.3) \u201cThe matrix $\\psi_s$ and $\\psi_s^{-1}$ are both sparse\u201d. This is a critical affirmation which is not in general true. It is possibly sparse if the weighted laplacian graph is sparse as well, as explained by the remark after theorem 5.5 of page 16 of (Hammond et al, 2011). However, I do agree this typically happens in the application you present. \n\n8/ The (c) of Figure 1 is missing.(in my version at least)\n\n9/ In section 5.3, why not trying to compare the number of parameters with other papers? I think also more results, with maybe a bit higher performances, could be reported, such as: GraphSGAN, GAT. But that\u2019s fine to me.\n\n10/ Appendix A, isn\u2019t it a simple rephrasing of (Hammond et al, 2011)?\n\n11/ How do you compare in term of interpretability with [1]?\n\n12/ Just as a suggestion and/or a comment: it seems similar to approaches such as lifting schemes(which basically builds wavelets on graphs/manifolds), except that there is no learning involved. (e.g. [2]) I think there could be great connexions.\n\n\n[1] Relational inductive biases, deep learning, and graph networks, Battaglia et al 2011?\n[2] THE LIFTING SCHEME: A CONSTRUCTION OF SECOND GENERATION WAVELETS, Wim Sweldgens", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}