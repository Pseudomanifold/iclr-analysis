{"title": "Intersting idea", "review": "Summary:\nThis paper is about adversarial imitation learning and how data from non experts can be used to improve representation learning of the discriminator function. They also change the training objective because minmax does not lead to an optimal policy in the proposed setting. The data from non experts is used a separate class (so the discriminator learns to discriminate between expert, agent and non-expert policy). \n\nClarity: well written, with an intro to both relative fields - reinforcement learning and imitation learning. \n\nComments:\nOverall, quite a neat idea - the information from non expert policy can help with representation learning, and the authors show that it is indeed the case via a number of experiments \nAt the same time, i wonder if the third class is required. It seems that gail in the experiments eventually reaches the same performance (figure 1) by looking at more agents trajectories. why can't non expert trajectories be considered as an initial set of agent trajectories? If multiclass is indeed required, it would be nice to see a comparison of what happens when non experts trajectories were just considered agents\nAnother thing i am surprised about is the leel of variance of GAIL in Figure 1. In table 1 we see that standard errors between the new method and gail are comparable, where does such a huge diff in var come from in Figure 1?\nAlso the sensitivity of the algorithm to lambda - how would one go setting it? In the experiments it seems that authors just try two different values (0.1 and 0.5) but i assume this really should be a hyperparameter search for this. Is lambda dependent on the number of expert and non expert demonstrations that are available?\n\n\n\n", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}