{"title": "The motivation is clear but the experiments are not sufficient.", "review": "In this work, authors consider transfer learning problem when labels for the target domain is not available. Unlike the conventional transfer learning, they introduce a new loss that separates examples from different domains. Besides, they apply the multi-class entropy minimization to optimize the performance in the target domain. Here are my concerns.\n1.\tThe concept is not clear. For domain adaptation, we usually assume domains share the same label space. When labels are different, it can be a transfer learning problem.\n2.\tOptimizing the verification loss is conventional for distance metric learning based transfer learning and authors should discuss more in the related work.\n3.\tThe empirical study is not sufficient. There lacks the method of transfer learning with distance metric learning. Moreover, the major improvement seems from the MCEM rather than the proposed network. How about DANN+MCEM?\n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}