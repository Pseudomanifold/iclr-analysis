{"title": "Interesting attempt at understanding prototypes but needs more work", "review": "Summary: This paper attempts to better understand the notion of prototypes and in some sense create a taxonomy for characterizing various prototypicality metrics. While the idea of thinking about such a taxonomy is novel, I think the paper falls in clearly justifying certain design choices such as why are the properties outlined at the beginning of Section 2 desirable. I also felt that the paper is resorting to rather informal ways of describing various properties and metrics without precisely quantifying them. \n\nPros:\n1. Novel attempt at understanding prototypes. Two specific contributions: a) outlining the properties desirable in prototypicality metrics b) proposing new prototypicality metrics and demonstrating the relevance of the various prototypicality metrics. \n2. Detailed experimental analysis along with some user studies\n\nCons:\n1. An important drawback of this paper is that the notion of prototype is not very clearly contextualized and explained. There is often a purpose associated with identifying prototypes - are we summarizing a dataset? are we thinking about helping humans understand the behavior of a specific learning model? Answers to these questions guide the process of choosing prototypes. However, this paper seems to approach the problem of choosing prototypes via the \"one approach fits all\" strategy which I am not sure is even possible. \n2. The choice of desirable properties is not clearly justified (Beginning of Section 2). For instance, why should prototypes be independent of learning tasks? \n3. Lack of rigor in defining prototypicality metrics as well as properties in Section 2. For example, wouldn't it be possible to theoretically prove that the metrics outlined in Section 2 satisfy the desired properties? \n\nDetailed Comments: \n1. I would strongly encourage the authors to illustrate using examples in the introduction the significance of finding prototypes. What are the end goals for which these prototypes would be used? Why do you think the metric for chooosing prototypes should be independent of the learning task or model? \n2. Along the same lines as the comment above, please provide detailed justifications for the list of properties provided in the beginning of Section 2. It would be even better if you could formalize these a bit more.\n3. Would it be possible to theoretically show that the metrics defined in Section 2 satisfy any of the desirable properties highlighted in Section 2? ", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}