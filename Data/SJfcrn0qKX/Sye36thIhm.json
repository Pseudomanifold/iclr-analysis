{"title": "designing adversarial examples in 3D meshes", "review": "The paper introduces meshAdv, a new adversarial attack method by manipulating shape and texture on 3D meshes. Experimental results suggest that even with hard-to-notice maipulations, the generated 3D mesh can accurately fool image recognition systems. Such generated 3D meshes can also be rendered to natural images and fool popular object detection algorithms.\n  \nPros:\n- The ideas in this paper are novel and interesting. Manipulating 3D meshes is also an alternative for the adversarial attack, and this paper proposed an approach for designing such algorithms.\n- Experimental results in the paper are strong, and experimental settings are easy to understand. There are experiments to show that meshAdv can attack several vision systems for various tasks, and learned representation can transfer to new renderers and settings. The paper also contains intuitive visual results for readers to understand the manipulation flow of 3D meshes.\n\nQuestions/Suggestions:\n- In the experimental settings in \"outdoor scene\" in sec 4.3, I was wondering why estimating the lighting direction is necessary -- after all, the generated object (Stanford bunny) is not photo-realistic anyway, so it might be sufficient to use any arbitrary lighting for the object rendering step.\n- In figure 4, the \"benign\" detection for the Stanford bunny is \"bird\". This is already wrong, and I didn't find any explanations for the case.\n- One of the issues in image recognition is that 3D objects are rendered in various viewing angles, and such ambiguity is what makes vision systems vulnerable.  I think it would be nice if authors can report performances when the rendered object are facing different directions.\n\nCons:\nThe biggest issue is that the overall presentation of the paper is weak, with several noticeable grammar mistakes and obscure sentences that are hard to follow. As a simple example, in the abstract \"So far adversarial examples have been heavily explored for 2D images, while few work has tried to understand the vulnerabilities of 3D objects which exist in real world, where 3D objects are projected to 2D domains by photo taking for different learning (recognition) tasks\" -- ignoring grammar errors, I find it very hard to understand, and this is just the abstract.\n\nThe paper has some interesting points and novelties, and experimental results are strong. However, paper writing seems to be done in a rush, and I wish the description of the approach can be significantly improved. Therefore I'm hesitating to accept the paper for this round of publication. ", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}