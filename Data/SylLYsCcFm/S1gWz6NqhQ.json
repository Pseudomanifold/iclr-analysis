{"title": "The paper describes an approach to train neural networks for analogical reasoning tasks by selecting training instances that force the network to learn relational structure", "review": "The paper describes an approach to train neural networks for analogical reasoning tasks.\n\nGeneral analogical reasoning is quite a significant milestone in Machine learning. Therefore, the paper tackles an extremely challenging problem.  The paper does a good job of constructing various tasks to show that analogies can be learned in different scenarios which are complex analogy tasks. Specifically, visual analogy and symbolic analogies are considered. The main idea is to choose training examples such that the model is forced to learn the relational structure rather than simply learn superficial features. One weakness is that we need to hand code the training examples to force it to have contrasting relational structure for different tasks. Is this realistic in different problems? That is maybe a limiting factor of this work. An automated method for generating such examples is given, but there is not too much detail on this (5.3). Maybe this needs to be expanded.\n\nAlso, is the idea of LABC different from SMT. The novelty may be a bit weak in this aspect. If LABC  can be described in a more general manner, it would help a reader not familiar with the other related work.  Since the baseline comparison is with a very weak method (randomly chosen examples), it is hard to judge the impact of the proposed approach. In summary, I think the paper has nice ideas, particularly, if we can automatically generate examples using LABC. but maybe there is a need to work on better organizing the ideas, more general formulation of LABC and a more convincing experimental evaluation that includes a state-of-the-art method if available", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}