{"title": "Unconvincing newness,  but a good GAN model to understand Private Presententation Learning, ", "review": "    The paper authors provide a good overview of the related work to Private/Fair Representation Learning (PRL). Well written, The theoretical approach is extensively explained and the first sections of the paper are easy to follow. The authors demonstrate the model performance on or the GMM, the comparison between theoretical and data driven performance is a good case study to understand the PRL.\n\nWe usually expect to see related work in the first sections, in this case it's has been put just before the conclusion. It can be still justified by the need o introduce the  PRL concepts before comparing with other works.\nThe GMM study case is interesting, but incorporates strong assumptions. Moreover, for a 4 or 8 dimensional GM, 20K data points are more than enough to infer the correct parameter. It would have been more useful if it was used to comapre between the mentioned methods in \"Related Work\".\n\nThere seems to be important parts of the paper that has been put in the appendices: how to solve the constrained problem, Algorithm.... Similarly, some technical details were expanded in the paper body (Network structure).\n\nThe authors mentioned the similarities with other works and their model choices that set theirs apart from other. Yet, the paper doesn't provide performance ( accuracy, MI) comparison to other works. There seems to be a strong similarity with Censoring representations with an adversary, Harrison Edwards and Amos Storke (link: https://arxiv.org/abs/1511.05897). Difference : distortion instead of H divergence, non-generative autoencoders.\n\nConsequently, I question the novelty of the paper's contribution. Without extensive comparison with other methods and especially to similar ones mentioned in the related work, there is little to say about the \"state-of-the-artness\". Yet, it is important to acknowledge the visible effort behind the paper and how the author(s) managed to leverage the simplicity and power of GANs.\n\nOn a lighter note:\nA)- the paper mention \"state-of-the-art CNNs, state-of-the-art entropy estimators, MI, generative models\", for the Machine Learning community, many of these elements have been around for a while now.\nB)- \"Observe that the hard constraint in equation 2 makes our minimax problem different from what is extensively studied in the machine learning community\": I would argue it's not an objective statement.\n \n\n\n", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}