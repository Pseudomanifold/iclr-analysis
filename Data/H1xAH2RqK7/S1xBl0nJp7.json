{"title": "Interesting direction and formulation but no enough novelty", "review": "This paper present an adversarial-based approach for private and fair representations. This is done by learned distortion of data that minimises the dependency on sensitive variable while the degree of distortion is constrained. This problem is important, and the analysis from game-theory and information theory perspectives is interesting. However, the approach itself is similar to Edwards & Storkey 2015, and I find the presentation of this paper confusing at a few points. \n\nFirst, while both the title and abstract suggest it is about learning representation, the approach might be better considered as data-augmentation. As described a bit later: \"...modifying the training data is the most appropriate and the focus of this work\". This contradiction with more commonly accepted meaning of representation learning (learning abstract/high level representation of data) is confusing.\n\nAlthough the authours argued this work is different from Edwards & Storkey 2015, I think they are quite similar. The presented method is almost a special case of this previous work: it seems that one can obtain this model by modifying Edwards & Storkey's model as follows (referring to the equations in Edwards & Storkey's paper): (1) removing the task (Y) dependent loss in eq. 9. (2) assume the encoder transforms X to the same data space so the decoder can be removed, so eq. 7 become equivalent to the distortion measure in this paper. There are other small differences, such as adding noise and the exact way to impose constraint, but I doubt whether the novelty is significant in this case.\n\nOther places that are unclear include: proposition 1 -- what does \"demographic parity subject to the distortion constraint\" mean? demographic parity was defined earlier as complete independence on sensitive variable, so how can \"complete independence\" subject to a constraint? In addition, it would be helpful introduce S is binary. This information was delayed to section 3 after the cross-entropy loss that assumes binary S was presented.\n\nOverall, I think this paper is interesting, and the analysis offers insights into related areas. However, the novelty is not enough for acceptance at ICLR, and the presentation can be improved.", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}