{"title": "Good analysis and provides empirical value of gradient compression", "review": "Paper focuses on Residual Gradient Compression (RGC) as a promising approach to reducing the synchronization cost of gradients in a distributed settings. Prior approaches focus on the theoretical value of good compression rates without looking into the overall cost of the changes. This paper introduces RedSync that builds on the existing approaches by picking the most appropriate ones that reduce the overall cost for gradient reduction without unduly focusing on the compression rate.\nThe paper does this by providing an analysis of the cost of RGC and also the limitations in scaling as the bandwidth required grows with the number of nodes. It also highlights the value of applying different algorithms in this process for compression and the benefits and issues with each.\n\nPros:\n- Useful analysis that will help direct research in this area\n- Shows that this approach works for models that have a high communication to computation ratio\n- Provides a useful approach that works for a number of models\n\nCons:\n- Positive experimental results are on models that are typically not used in practice e.g. AlexNet and VGG16\n- Speedups shown on LSTMs don't see worthwhile to scale, and in practice a model-parallelism approach may scale better\n\nCorrections:\n- Typo in notes for Table 1 last sentence RCG => RGC\n- Typo in first sentence in section 3.2: RedSycn => RedSync\n- Section 3.3, #2 last sentence: maybe overdrafts => overshadows ?\n", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}