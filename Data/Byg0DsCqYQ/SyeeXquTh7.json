{"title": "Simple but effective method, methodological novelties are limited though!", "review": "This manuscript proposes a robust version of conditional GAN (named RoC-GAN) that leverage the intrinsic structure in the output space. To achieve robustness, the authors replace the single pathway in the generator with two different pathways that partially share weights. The authors study the theoretical properties of RoC-GAN and prove that it shares the same properties as the vanilla GAN. For quantitative evaluations, the authors use two datasets of natural scenes and faces and evaluate denoising and sparse inpainting using the SSIM metric.\n-\tThe idea is simple and seems to be working. The methodological novelties seem more-or-less limited, but the theoretical analysis and the intuitive (and well-motivated) modification over CGANs add merits to the paper. \n-\tThe theoretical analysis of the method relates RoC-GAN to the original GAN, rather than CGAN! What is the connection here? If RoC-GAN is very similar to CGAN from a theoretical point of view (which it seems to be), then all the analysis to relate it to traditional GAN seem useless.\n-\tThe extensive experiments in the supplementary material are appreciated. But the authors only compare their method with one single previous work (i.e., Rick Chang et al. (2017)), while there are several similar related works (either based on adversarial training strategies or simple denoising AEs).\n-\tAlso, ablation studies can further show how each component of the model contributes to the final results. What if we were to only use the two-path generator without adversarial training? Different components of the final loss function can be removed and analyzed one at a time!\n-\tWhat are the conditions for mode-collapse for the proposed GAN? There are no discussions on this.\n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}