{"title": "2 time scales stochastic approximation for approximately minimizing the Bellman residual", "review": "The paper analyzes a 2 time scales stochastic approximation algorithm for approximately solving a minmax formulation of a Bellman residual minimization problem. The minmax approach is used as a way to avoid the bias introduced when directly trying to minimize the squared norm of the Bellman residual from transition samples. As acknowledged by the authors this formulation is not new and has been described in [Dai et al. 2017] and can be traced back to [Antos et al. 2008]. Now the way to solve it using a 2 timescale SA constitutes the main contribution of the paper. \n\nHowever, I am surprised by the requirement of Assumption 4.2 (that the class of functions under which we project the Bellman residual is linear). Indeed, under this assumption, the inner maximization problem could be solved by least squares instead of gradient ascent, which could be much faster. So my question is why do you think a 2 time scales SA algorithm is better than a single time scale SA using as inner loop the LS solution? \n\nI would think the main merit of the 2 scales SA algo would be to get rid of this assumption of linear function space for the inner loop (in order to reduce the bias as much as possible by optimizing over a larger class of functions), so I find that the need for Assumption 4.2 reduces considerably the motivation for a 2 time scales algo, which is your main contribution.\n\nOther comments:\n- You should provide arguments for why minimizing the Bellman residual (eq. (3.1)) is a good things for approximating the optimal value function or the optimal policy. This is not clear, specially in the control case when the behavior policy is fixed.\n- Minimizing (3.10) (using approximate function spaces) may not give you a solution close to that of the (3.5) problem. It would be interesting to analyse how far the solution to those two problems are as a function of the capacity of the spaces.\n- Also the local minimum reached by the algorithm may be far away from the solution to (3.10). So in the end, it's not clear if we can say anything about the Bellman residual of the solution found by the algorithm.\n- It\u2019s not clear how to implement the projection onto a compact set of parameters (in Algorithm 1), specially using neural nets.\n- Finally the experiments are not very convincing. The proposed algorithm does not seem to do better than a 5 years old DQN algorithm\u2026 I know this was not the main contribution of the paper, which is theoretical, but then it\u2019s not clear to see the added value of the experiments.\n\n\n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}