{"title": "Solving the Saddle-Point objective of Dai et al. by two-timescale SA", "review": "The contribution of this paper is to solve the optimization problem from the problem \"Smoothed dual embedding control\" by Dai et al. (2017) using two-timescale stochastic approximation. The inner \"max\" problem is optimized by stochastic gradient ascent at a higher learning rate, in parallel with the outer \"min\" so that the inner problem appears quasi-stationary to the outer one. In my understanding, the analysis follows the usual template per Borkar or Konda in actor-critic methods and is not new. The proposed method is demonstrated in Cartpole and Mountain car and against a DQN baseline.  It is not clear why the author chose the heavy-duty DQN as a baseline in such simple environments when they could have compared directly against Dai et al. (2017) using the same architecture. While the idea of using two-timescale stochastic approximation to solve the saddle point formulation of Dai & al. (2017) is sound, the contribution of this paper is insufficient for the main conference.  The saddle-point formulation in the title really comes from Dai: the title should rather include \"two-timescale\" somewhere because this is main contribution.\n\nI would suggest enriching the experiments section by including an empirical study of the effect of the ratio of the learning rates on the stability and convergence rate. You should also really compare against Dai et al. (2017) and highlight why your method would be preferable (potentially computationally cheaper and more scalable than other alternatives). \n\n# Typos \n\n> an stochasitc \n> the iterates onto [the] compact sets\n> in (3.5) for [a] fixed \u03b8\n> in different [s]paces", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}