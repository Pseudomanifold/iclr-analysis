{"title": "The InfoGail method extended to online latent code estimation at test time", "review": "The paper presents a learning-based method for learning the latent context codes from demonstrations along with a GAIL model. \nThis amounts to learning the option segments and the policies simultaneously. \nThe main contribution is the model the problem as a time-dependent context and then use a directed information flow loss instead of the mutual information loss.\n\n1. What is the effect of models of the underlying distribution of latent codes. \nCan it be categorical only, or can it be continuous? \nCould we also model it as multidimensional?\nThe current results only provide single dimensional categorial distribution as latent codes. \n\n2. The paper missed an important line of work which solves nearly the same problem -- option discovery and policy learning. \nKrishnan -- Discovery of Deep Option(1703.08294). This work was used by authors in continuous options and then again for program generation (https://openreview.net/pdf?id=rJl63fZRb). \n\nThey explicitly infer the option parameters, along with termination conditions with the Expectation Propagation method. \nThe results are in very similar domains hence comments, if not a comparison, would be useful. \n\n\n3. The authors state that the main problem with an InfoGail style method is dependence on the full trajectory as in eq 1. Hence the directed info flow is required to solve the problem. However in the actual model, the authors make a sequence of variational approximations -- (a) reduction of eq2 to eq1 with a variation lower bound on posterior p(c|c,\\tau) and then replace the prior p(c) with q(c|c,\\tau) in eq 5. But looking at the model diagram in fig 2. the VAE actually makes the Markovian assumption -- i.e. c only depends on c_{t-1} and s_{t}. If that is true then how would this be very different from InfoGAIL mutual information loss. \nIt appears that to capture the authors' mathematical intuition the VAE should have a recurrent generator which should have a hidden state factor passing in to capture dependence on history until the current time. \n\n3a. In fact the first term in eq 6 looks closer to the actually used model. If that is not true then the authors should clarify. \n\n4. Experiments do capture the notion discovery of options. But the simplicity of data leaves much to be desired. \nOne of the main difference of this work in comparison to unsupervised segmentation models GMM or BP-AR-HMM is the fact that the options learned are composable. But the authors only show this composability on the circle domain -- which is arguably a toy-domain. \nA reasonable confirmation that the model indeed learns composition is to generate a trajectory for a sequence of latent code not seen in data. -- like walking -- normal -- left-right-left can be converted to limping gait -- left-left-right-right. This is only a suggestive example. \n\n5. In appendix eq 8 how is the reduction from line 3 to line 4 of the equation made -- what is the implicit assumption. \njoint distribution p(c, \\tau) is written out as p (\\tau|c) p(c) without an integral.\n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}