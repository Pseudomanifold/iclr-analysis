{"title": "Spatio-temporal attention weighted LSTM for action recognition is proposed. The novelty is low and the empirical evaluations are limited.", "review": "Summary:\nThe paper proposes a spatio-temporal attention weighting mechanism in LSTM, applied to the task of human action recognition. VGG19 based frame features are fed to LSTM, soft attention is calculated based on previous works and temporal attention is predicted using another small neural network. The features are weighted by these attentions and eventually the network is trained with a regularized cross entropy loss. Empirical results are given on three datasets for action recognition, UCF11, UCF101 and HMDB51.\n\nPositives:\n- The problem addressed is a relevant and challenging CV problem\n- The idea of using of spatio-temporal attention is also interesting, as the actions are expected to have salient parts relatively sparsely located in space and time and focusing on them seems like an interesting direction to investigate.\n\nNegatives:\n- The paper is not well written in general\n- The novelty is low as similar attention mechanisms have been used before. Papers have been cited in related works but differentiation in terms of what the current method adds is largely missing. The spatial attention is borrowed from Xu et al. (2015) and Sharma et al. (2016) and the temporal attention is relatively simple (similar ideas have been explored with CNNs as well eg. [A,B]) so the exact contribution and it's novelty is not convincing\n- The results are not very convincing either, UCF11 is a very small dataset, on the bigger datasets the improvements over Video LSTM are small\n- Self implemented baseline (the current implementation with same base CNN and LSTM networks without any spatial or temporal attention, \\alpha=\\beta=1 fixed) as well as ablation studies (what happens when only spatial or temporal attentions are used) should be added for assessing the contribution of the different components\n- Some actual qualitative results should be added demonstrating the effectiveness of the proposed approach\n\n[A] Kar et al., AdaScan: Adaptive Scan Pooling in Deep Convolutional Neural Networks for Human Action Recognition in Videos, CVPR 17\n[B] Bilen et al., Action Recognition with Dynamic Image Networks, accepted for TPAMI 2018, arxiv 1612.00738\n\nI feel that in the current form the paper is not ready for publication.", "rating": "3: Clear rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}