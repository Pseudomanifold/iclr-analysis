{"title": "Two-stage VAE method to generate high-quality samples and avoid blurriness", "review": "This paper proposed a two-stage VAE method to generate high-quality samples and avoid blurriness. It is accomplished by utilizing a VAE structure on the observation and latent variable separately. The paper exploited a collection of interesting properties of VAE and point out the problem existed in the generative process of VAE.  I have several concerns about the paper:\n\n1.\tIt is necessary to explain why the second-stage VAE can have its latent variable more closely resemble N(u|0,I). Even if the latent variable closely resemble N(u|0,I), How does it make sure the generated images are realistic? I admit that the VAE model can reconstruct realistic data based on its inferred latent variable, however, when given a random sample from N(u|0,I), the generated images are not good, which is true when the dimension of the latent space is high. I still can\u2019t understand why a second-stage VAE can relief this problem.\n2.\tThe adversarial auto-encoder is also proposed to solve the latent space problem, by comparison, what is the advantage of this paper?\n3.\tWhy do you set the model as two separate stages? Will it enhance the performance if we train theses two-stages all together?\n4.\tThe proofs for the theory 2 and 3 are under the assumption that the manifold dimension of the observation is r, while in reality it is difficult to obtain this r, do these theories applicable if we choose a value for the dimension of the latent space that is smaller than the real manifold dimension of the observation? How will it affect the performance of the proposed method?\n5.\tThe value of r and k in each experiment should be specified.\n\n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}