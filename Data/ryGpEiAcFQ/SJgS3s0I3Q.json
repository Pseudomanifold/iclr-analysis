{"title": "Complicated math, terminology and network to obtain standard MLP performance", "review": "Quality - poor\nThe highly complicated work is evaluated only on the simplest of benchmarks with no significant results. \n\nClarity - poor\nThe paper seems to amount to gobbledygook, many disparate terminology strung together. \n\nOriginality\nNo idea. \n\nSignificance \nNone. \n\ncons: the paper to me seems a hashing of citations to the main works in neuroscience and deep learning for which only the simplest network is demonstrated (single hidden layer MLP on MNIST) with results that do not exceed that of a standard MLP.\npros: the only pro I can think of for this work is that synaptic computing imo deserves more consideration, as real synapses are very complicated beasts, the functioning of which relatively little is known about. ", "rating": "2: Strong rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}