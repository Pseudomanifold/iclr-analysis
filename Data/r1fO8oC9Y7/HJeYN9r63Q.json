{"title": "Overall score 3", "review": "Overall Score 3\n\nThis paper introduces \u201cCross domain schemas\u201d (CDS) for semantic parsing of utterances made to a virtual assistant. CDS captures similarities in requests according to the underlying actions or attributes being discussed, regardless of the user\u2019s high-level intent. Also introduced is a model which leverages CDS to improve semantic parsing of utterances to a meaning representation language (MRL). This model first parses an utterance to CDS, then uses an encoding of the CDS jointly with the utterance encoding to decode a meaning representation. By treating different intents as separate domains, the authors construct a multi-task learning setup for CDS and MRL parsing. Results are provided for the Snips dataset of virtual assistant queries. \n\nUnfortunately, this paper fails to sufficiently explain its main proposal, the CDS. The stated goal is to explicitly define the cross-domain features that would otherwise be implicitly learned by the parameters of a neural network, yet no explicit definition is given. No rough quantification of how many or what percent of features appear across domains is provided. Rather, significant time and space is given to describing a fairly unsophisticated two-decoder model for inserting the mysterious CDS representation into the final decoding task. \n\nThe paper ignores standard semantic parsing datasets (GeoQuery and ATIS) due to their size and scope. However, comparable models (Goo et al. 2018) are trained and tested on ATIS. Moreover, an evaluation on a small, unseen target domain would be the perfect justification for the kind of cross-domain learning proposed here. \n\nInstead, this paper opts only to evaluate on the recent Snips dataset. This dataset seems to be best suited to evaluating intent classification and slot filling (intent-slot), but the current work fails to improve over what Goo et al. 2018 report on this data. In the current work, the Snips dataset is used to evaluate MRL parsing, where the CDS model shows improvements over other seq2seq models. However, since MRL can be parsed from intent-slot format by predefined rules, it is uncertain whether the CDS model outperforms the Goo et al. model at even the task of MRL parsing (no such comparison is provided). \n\nOverall, the paper suffers from some clarity issues especially regarding the definition and value of CDS. The model provided may be slightly original but is quite similar to the model of Dong and Lapata 2018. The significance of this work is questionable due to the poor comparison with recently released baseline models for the more common intent-slot task. \n\nPros\n\nIntroduces \u201cCross Domain Schemas\u201d (CDS) for semantic parsing, which help improve robustness of semantic parsers by allowing models to learn patterns in one domain for use in another. \n\nThrough the use of CDS, train semantic parsers in a multi-task learning setup\n\nCons\n\nCDS is not described in sufficient detail. In particular, the possible actions and attributes are not defined. \n\nThe model is described as \u201cmulti-task learning\u201d, however all tasks are parsing requests made of a virtual assistant. \n\nResults on standard data for semantic parsing such as GEO or ATIS are not reported.\n\nThe model does not appear to improve the results on the Snips dataset compared to the paper that introduces this dataset. Thus, the value of CDS is difficult to judge. \n\nNo per-domain analysis of the impact of CDS is provided.", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}