{"title": "missing a lot of details in the proposed model ", "review": "The paper presented a new training-free way of generating sentence embedding. The proposed work is along the same motivation from Arora et al.,  2017. A systematic analysis has been done on a number of tasks to show the strong performance (close or higher than the specifically \"supervised\" strategies). \n\n- I suggest the author to re-ward the category terms of the existing methods. Un-supervised and training-free are confusing. Unsupervised and supervised should be all in a group of training-required methods. unsupervised in this paper is more task-agnostic but domain specific and supervised is to extract sentence emb that is prediction task specific. \n\n- The evaluation tasks are rich but not clearly stated. For instance, the supervised taske are only discussed at high-level. Not clear what each task is and how one should interpret the results from each experiments.  The way author presented it suggests the detail here were not important. It is also good to include discussion on how the baseline algorithms are tuned and/or trained on these tasks. Readers cannot reproduce the same results based on the current paper. \n\n- Notation and Math: \n--r-1 in (4) is not clear as \\mathbf{r} is not defined properly\n--based on sec 2.2., it is easy to motivate the novelty score from subspace projection rather than QR/GS; \n-- a_n and a_s are both functions of r_{-1} which is the perp. energy of the words w.r.t. its contexts. Is there a fundamental difference?\n-- Figure 1 is a little bit confusing. Not clear what is word and what is a sentence/corpus. \n-- in Eq(8), better not to use r as it confuses with the GS coeffs. \n-- 2.4.1 is a bit confusing, sentence embeddings c_1, \\ldot, c_N are introduced, but so far no sentence embedding has been formally introduced. Is this initialized from some heuristic? It is confusing in the sense that eq (9) c_s are defined by a_u, but a_u defined in eq (8) depends on sigma_d that relies on X^{c}, which is a funcion of all c_s's. \n-- there are several parameters for GEM, please add some discussion on how these are selected in each of the evaluated tasks. \n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}