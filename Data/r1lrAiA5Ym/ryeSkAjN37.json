{"title": "Meta-learning to dynamically set the plasticity learning rate", "review": "Paper summary - This paper extends the differentiable plasticity framework of Miconi et al. (2018) by dynamically modulating the plasticity learning rate. This is accomplished via an output unit of the network which defines the plasticity learning rate for the next timestep. A variation on this dynamic learning rate related to eligibility traces is also proposed.\n\nBoth dynamic modulation variations strikingly outperform non-plastic and plastic non-modulated recurrent networks on a cue-reward association task with high-dimensional cues. The methods marginally outperform plastic non-modulated recurrent networks on a 9x9 water maze task. Finally, the authors show that adding dynamic plasticity to a small LSTM without dropout improves performance on Penn Treebank.\n\nThe paper motivates dynamic plasticity by analogy to the hypothesized role of dopamine in reward-driven learning in humans and animals.\n\nClarity -  The paper is very clear and well written. The introduction provides useful insights, motivates the work convincingly, and provides interesting connections to past work.\n\nOriginality - I don't know of any other work that models the role of dopamine in quite this way, or that applies dynamic plasticity modulation in settings like these.\n\nQuality - The experiments are well chosen and seem technically sound.\n\nSignificance - The results show that meta-learning by gradient descent to modulate the plasticity learning rate is a promising direction -- a significant contribution in my view.\n\nOther Comments - The citation to Zaremba et al. in Table 1 made it seem like the perplexity result on that line of the table was directly from Zaremba et al's paper. I'd recommend removing the citation from that line to avoid confusion.\n\nOne thing I would have loved to see from this paper is a comparison of modulated-plasticity LSTMs with the sota from Melis et al., 2017. I gather that Experiment 3 presents small LSTMs without recurrent dropout instead because combining plasticity and dropout proved challenging (or at least the authors haven't tried it yet). I think the paper is solid as-is; positive results in this comparison would take it to the next level.\n\nQuestions:\nWhy were zero-sequences necessary in Experiment 1? This aspect of the task seems somewhat contrived, and it makes me wonder whether the striking failure of the non-modulated RNNs depends on this detail. Perhaps the authors could clarify on what a confounding \"time-locked scheduling strategy\" would look like in this task?\nWhy does Experiment 1 present pairs of stimuli, rather than high-dimensional individual stimuli?\nWhy is non-plastic rnn left out of Figure 2b?\n\nTypos\n\"However, in Nature,\" -- no caps\nin appendix: \"(see Figure A.4)\" -- the figure is labeled \"Figure 3\"\n", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}