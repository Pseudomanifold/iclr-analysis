{"title": "Good paper on regularizing the hidden state of LSTM to make sure it uses the cell state properly.", "review": "\nSummary:\n\nThis paper is based on the observation that LSTMs use the hidden state to memorize information and the cell state (memory) is not fully utilized. To encourage the LSTM to utilize the cell state, authors constraint the hidden state to a set of centroid states and learn to transition between these centroids in a soft way. Authors demonstrate their model in learning simple regular and context-free languages and also in a couple of non-synthetic tasks. The proposed model also has some interpretability of internal state transitions.\n\nMajor comments:\n\n1.\tThe main claim of the paper is that SR-LSTM can extrapolate to longer sequences, unlike LSTM. However, the sequence lengths considered are too small. It would be interesting to train both models with specific sequence length and then keep testing them with longer sequence length and compare the performance. If SR-LSTM behaves like a DPDA, then with larger cell state, the performance should not drop as you increase the sequence length till the capacity of the cell state.\n\n2.\tTheorem 3.1 and 3.2 have no proofs. Please make them as notes rather than theorems.\n\n3.\tWhat do different colors in Figure 6 stands for?\n\n4.\tIn the MNIST task authors claim that they have significant improvement when compared to LSTM. I am not sure if that is accurate. Also, why do you compare SR-LSTM-p only with LSTM? What is the performance of LSTM-p? Please report that as well.\n\n5.\tEven in table 3, can you please report the performance of LSTM-p?\n\nEven though the paper does not show strong empirical performance in real-world tasks, I would still recommend for accepting this paper for its contributions in understanding RNNs better, provided authors answer to question 1, 4, and 5.\n\n\nMinor comments:\n\n1.\tFig 6 is not referred anywhere.\n\n", "rating": "6: Marginally above acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}