{"title": "A good topic to explore, but suffers from methodological problems", "review": "This paper introduces a family of attack on confidence thresholding algortihms. Such algorithms are allowed to refuse to make predictions when their confidence is below a certain threshold. \n\nThere are certainly interesting links between such models and KWIK [1] algorithms (which are also supposed to be able to respond 'null' to queries), however they are not mentioned in this paper, which focuses mainly on evaluation methodologies.\n\nThe definition of the metric is certainly natural: you would expect some trade-off between performance in the normal versus the adversarial regime. I am not certain why the authors don't simply measure the success rate on both natural and adversarial conditions, so as to have the performance metric uniform. Unfortunately the paper's notationleaves something to be desired, as it fails to concretely define the metric.\nLet me do so instead, and consider the classification accuracy of a classification rule $P_t$ using a threshold $t$ under a (possibly adaptive) distribution $Q$ to be $U(P,Q)$. Then, we can consider $Q_N, Q_A$ as the normal and adversarial distribution and measure the corresponding accuracies. \n\nEven if we do this, however, the authors do not clarify how they propose to select the classification rule. Should they employ something like a convex combination:\n\\[\nV(P_t) := \\alpha U(P_t, Q_N) + (1 - \\alpha) U(P_t, Q_A) \n\\]\nor maybe take a nimimax approach\n\\[\nV(P_t) := \\min \\{U(P_t, Q) | Q = Q_A, Q_N\\}\n\\]\n\nIn addition, the authors simply plot curves for various choices of $t$, however it is necessary to take into account the fact that measuring performance in this way and selecting $t$ aftewards amounts to a hyperparameter selection [2]. Thus, the thresholding should be chosen on an independent validation set in order to optimise the chosen performance measure, and then the choice should evaluated on a new test set with respect to the same measure $V$\n\nThe MaxConfidence attack is not very well described, in my opinion. However, it seems it simply wishes to find to find a single point $x \\in \\mathbb{S}$ that maximises the probability of misclassification. It is not clear to me why performance against an attack of this type is interesting to measure.\n\nThe main contribution of the paper seems to be the generalisation of the attack by Goodfellow et al to softmax regression. The proof of this statement is in a rather obscure place in the paper. \n\nI am not sure I follow the idea for the proof, or what they are trying to prove. The authors should follow a standard Theorem/Proof organisation, clearing stating assumptions and what the theorem is showing us. It seems that they want to prove that if a solution to (1) exists, then MaxConfidence() finds it. But the only definition of MaxConfidence is (1). Hence I think that their theorem is vacuous. There are quite a few details that are also unclear such as what the authors mean by 'clean example' etc. \n\nHowever the authors do not explain their attack very well, their definition of the performance metric is not sufficiently formal, and their evaluation methodology is weak. Since evaluation methodology is the central point of the paper, this is a serious weaknes. Finally, there doesn't seem to be a lot of connection with the conference's topic.\n\n[1] Li, Lihong, Michael L. Littman, and Thomas J. Walsh. \"Knows what it knows: a framework for self-aware learning.\" Proceedings of the 25th international conference on Machine learning. ACM, 2008.\n\n[2] Bengio, Samy, Johnny Mari\u00e9thoz, and Mikaela Keller. \"The expected performance curve.\" International Conference on Machine Learning, ICML, Workshop on ROC Analysis in Machine Learning. No. EPFL-CONF-83266. 2005.\n", "rating": "2: Strong rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}