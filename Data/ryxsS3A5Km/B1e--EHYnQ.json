{"title": "review", "review": "\nThis paper proposes a new approach to mitigate the catastrophic forgetting for continual learning. The model is composed to the neural architecture search and parameter learning based on the intuition that largely different tasks should allow to use different network structure to train them. In structure learning, they introduce three candidate to decide network architecture, reuse, adaptation and new. In the experiments, they show that their model outperforms SGD and EWC.\n\nBasically, the intuition of structure learning and the validation of that is straight forward and easy to follow. However, I\u2019m not sure that the proposed model can outperform the recent continual learning methods, such as IMM(Lee et al, 2017), DEN or  RCL(Ju Xu et al, 2018). There is only a relatively weak(and old) comparison with l2, and EWC.\n\n-\tIn the equation (4), I wonder that, in the model, the hyperparameter(lambda_i or beta_i) of regularizer looks different according to the task, is it correct?\n-\tAs shown in the Fig. 2) three choice-reuse, adaptation, and, new, is decided in the layer level. But with a semantic intuition, such that two different task can share specific features and simultaneously each of them requires the different neural space to learn discriminative ones at layer l, it seems better if the model could search structure much flexible. Is there some of experimental trial or plan about these kind of joint-adoption?\n-\tWhat is the main contribution of adaptation? I wonder that only reuse and new can work well including the role of adaptation, or not.\n-\tIs there any experiments to compare the recent continual learning methods(as I mentioned), in terms of AUC(or accuracy) and the network capacity?\n\nMinor remarks,\nPage 3: \t\u201cis been\u201d -> is\n\t\u201cunlikely\u201d-> unlike\nPage 4: \t\u201csharealbe\u201d -> shareable\nPage 5: \t\u201c, After\u201d -> , after\n\t\u201cpermuated\u201d -> permuted\nPage 6:\t\u201cFig. 5\u201d -> Fig. 4\n\n", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}