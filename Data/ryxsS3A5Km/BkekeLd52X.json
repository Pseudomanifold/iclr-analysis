{"title": "Review of \"Continual Learning via Explicit Structure Learning\"", "review": "The paper considers the problem of sequential learning where data access for the previous tasks is completely prohibited. Authors propose a conceptually simple framework to learn structures (it is the selection of reusing, adapting previously learned layers or training new layers) as well as corresponding parameters in the sequential learning.\n\nThe paper is potentially interesting and providing possibly important framework for life-long learning. It is well written in most of cases and easy to follow (however I got the impression that the paper was rushed in the last minute; there are some trivial typos and very low resolution images etc.)\n\nHowever, I have a huge concern about the empirical evaluations.  This area is really huge and has attracted lots of interest from many researchers, meaning that we lots of methods to compare. Nevertheless, authors only focus on providing insights on effects of different components of the propose model. This is also critical but comparing against state-of-the-arts is also very important. Especially, comparing against Lee et al 2017 seems essential. I can see the difference against that paper from the authors' argument in the related work, but that is the difference not comparison. It would be great to compare the performances as well as the number of increased memory sizes as the number of task increases.\n\nMoreover, the details should be provided; for instance provide the explicit form of R(s). \n\n---------------------------------------------\n\nThanks for the update. But are they fair comparisons (evaluation only in terms of accuracy)? Different methods expand the network different amount. Hence, they should be compared on this metric too.", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}