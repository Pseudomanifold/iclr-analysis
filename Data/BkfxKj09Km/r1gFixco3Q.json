{"title": "Well written and organized paper. Domain concepts presented fairly clearly. The approach and choices of classification algorithms is well articulated and results interesting. Good combination of known algorithms on a purposely built dataset (Originality questionable).", "review": "Contribution:\n\t- Using a known parameters crystallography simulator (X-ray beam, structure being analyzed, environment (crystalline or not)) built a dataset (called DiffraNet) of 25,000 512x512 grayscale labeled images of resulting diffraction images of various materials/structures (crystalline or not) .\n\t- carried various classification approaches of the dataset (labelled) images in two steps:\n\t\t- Feature extraction (Scale Invariant Feature Transform with the Bag-of-Visual-Words approach as local feature extractor, and the Gray-level Co-occurrence Matrix and Local Binary Patterns as global feature extractor) then\n\t\t- Classification of the diffraction images is carried with three approaches. Two using images described by extracted features (from the previous feature extraction step) coupled with either random Forests or Support Vector Machines and a third consisting in a Convolution Neural Network (CNN) topology named DeepFreak.\n\t\t- The images are classified according to the diffraction patterns they encompass into one of 5 classes: blank, no-crystal, weak, good and strong. The last three describing presence of a crystalline structure.\n\t\t- A fine tuning step of the various algorithms was carried using AutoML optimization tools.\nAll algorithms were off the shelf publicly available implementations and have previously been used for such domain applications (crystallography patterns).\nThe approach and choices of classification algorithms is well articulated and results interesting.\n\nA few questions though:\n\u2022\tIn what way the diffraction images are \u2018synthetic\u2019? Aren\u2019t they actual diffraction images but in a controlled known and controlled setting: set of parameters (beam, structure to analyze)?\no\tMore like a library of diffraction pattern images for various materials/structures.\n\u2022\tHow many structures were analyzed (Were there 25000 for the 25000 pattern images), one image each?\no\tThis is to understand  the representability of the samples (structures) analyzed regarding the possible structures (Hundreds of thousands as per paper\u2019s 2.1 ) .\n\u2022\tWhat variations for each of the setting variabilities (X Ray beam(flux, beam size, divergence, and bandpass), crystal properties (unit cell, number of cells, and a structure factor table), and the experimental parameters (sources of background noise, detector point-spread, and shadows)) were used? \no\tThis is to assess the size of the pattern space.\n\u2022\tWere any real-life setting obtained pattern samples classified using DiffraNet dataset patterns\u2019 fine-tuned classification algorithms?\no\tThis is to assess the generalization level of the DiffraNet dataset patterns\u2019 fine-tuned classification algorithms to real-life obtained patterns (relates to the previously stated representability of the samples).\no\tIf not, your statement \u201c \u2026 we plan to add new images and new classes that are common place in serial crystallography\u201d (in 6. Conclusions) would be an appreciated validation of general usability of your DiffraNet fine\u2013tuned setting.\n\u2022\tWere all the structures analyzed crystalline? \no\tIt\u2019s stated in Figure 2 and Table 6 that 2 classes are either blank or no-crystal but is that a known fact (purposely chosen) or no pattern images for crystalline structures due to inadequate experimental settings to uncover the crystalline nature of the analyzed structure?\n\u2022\tWere the pattern images pre-processed in any manner before being classified?\n\n\nNota: In table 6, use no-crystal class as in Figure 2 for consistency. ", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}