{"title": "a hybrid SGLD - SVGD", "review": "Two promising methods for scalable sample-based Bayesian inference are:\n1) SGLD: simply discretize a standard Langevin dynamics to construct a Markov chain that approximate the correct invariant distribution. This reads: \n\nx_{t+1} = x_t + \\nabla \\log \\pi(x_t) \\delta + \\sqrt(2 \\delta) \\xi\n\n2) SVGD: the method can be expressed as a type of gradient descent of an appropriate functional on the space of probability distributions. A cloud of particles {x_i}_{I=1}^M evolves according to:\n\nx^i_{t+1} = x^i_t + (some functional of all the particles) \\, \\delta\n\nThe method proposed in the article is not very different from alternating the two above mentioned update, which is indeed quite a natural idea, and can work pretty well I think. The method reads:\n\nx^i_{t+1} = x^i_t + [ \\nabla \\log \\pi(x_t) \\delta + (some functional of all the particles) \\, \\delta ] + \\sqrt(2 \\delta) \\xi.\n\nPROS:\n- yes, I think that the method can work quite OK since it may be borrowing the strengths of both SGLD and SVGD.\n- It seems that the meat of the paper consists in proving some (non-asymptotic) convergence result. Unfortunately, this went above my head and I cannot claim that I have read the details of the proofs. \n\nCONS:\n- it is (very) difficult to fairly evaluate this type of methods in high-dimensional settings. I thus appreciate that the numerical section starts with a toy very simple Gaussian model. I would have been much more interested  in fair and extensive simulations in this type of settings where it is relatively easy to compare the proposed method with SGLD and SGVD. In other words, after reading the paper, I must say that I am not at all convinced that the method does bring something over SGLD or SVGD (although it is very possible that it does).  For example, comprehensive and fair comparisons with SGLD and SVGD  in Gaussian settings (not necessarily one-dimensional) could have been presented. The delicate tuning of the different methods, the speed of convergence wrt algorithmic time, the speed of comparison wrt the number of particles, etc.. could have been investigated numerically: this would have been, I think, much more convincing.\n\nMINOR comments:\n- I did check the proof of Theorem 2, which seems hand-wavy and overly complicated.  What is the function G? It seems that the proof of Theorem 2 simply consists in establishing that if each particle x_i follows the dynamics dx = F(x)*dt then the associated densities satisfy \\partial_t \\mu_t = -\\partial_x(F(x) * \\mu_t(x))  , which is obvious. But the situation in the paper is indeed more delicate since the particles are interacting, etc... Reading this proof got me very worried and did not motivate me to read the rest of the paper.\n\nSUMMARY:\n- the method is not terribly original -- this is a simple hybrid SVGD / SGLD -- but may work very well.\n- unfortunately, the numerical experiments are not convincing.\n\n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}