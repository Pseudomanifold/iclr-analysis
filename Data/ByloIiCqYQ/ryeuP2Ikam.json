{"title": "Potentially useful dataset of compiled code snippets classified as \"vulnerable\" or \"not vulnerable\", interesting story emerges from evaluation of family of classifiers evaluated on this dataset", "review": "This paper sets out to classify source code snippets are \u201cvulnerable\u201d or \u201cnot vulnerable\u201d using sequential auto-encoders with two latent distributions (corresponding to the output classes), regularized to maximize divergence between theses two distributions (named Maximal Divergence Sequential Auto-Encoder).  The authors created a compiled subset of the NDSS18 vulnerable vs. non-vulnerable software dataset (which is listed as one of their primary contributions). The dataset construction required non-trivial effort since example code snippets are often incomplete and the authors needed to \u201cfix\u201d these code examples in order to compile them. The fixed code examples are then compiled against both Windows and Linux and both the x86 and x86-64 architectures. The inputs to all predictive models are the opcode sequence of the compiled programs. \n\nThis paper compares against one previously published vulnerability detection method (VulDeePecker) which is a bidirectional RNN followed by a linear classifier. They also compare with a cascade of models with increasingly complex components:\n\n* RNN-R: A recurrent neural network trained in an unsupervised fashion (language modeling over opcode sequences), whose representations are then fed into an independent linear model. \n* RNN-C: End-to-end training of a recurrent model over opcodes, followed by a single dense layer.\n* Para2Vec: Encoding of the opcode sequence using the paragraph-to-vector architecture \u2014 I\u2019m curious what they used as the paragraph boundaries in the compiled programs and whether the subsequent classifier was the same as RNN-C. \n* SeqVAE-C: Sequential variational auto encoder trained end-to-end with a final classification layer. \n* MDSAE-RKL:  Maximal divergence sequential auto-encoder with KL divergence between the two class\u2019s latent distributions, final classifier trained independently. \n* MDSAE-RWS: Maximal divergence sequential auto-encoder with L2/Wasserstein  divergence between the two class\u2019s latent distributions, final classifier trained independently. \n* MDSAE-CKL: Maximal divergence sequential auto-encoder with KL divergence between the two class\u2019s latent distributions, final classifier included as the final layer of the whole model.\n* MDSAE-CWS: Maximal divergence sequential auto-encoder with L2/Wasserstein  divergence between the two class\u2019s latent distributions, final classifier included as the final layer of the whole model.\n\nThe two MDSAE models using Wasserstein divergence vastly outperform the two equivalent models using KL divergence. Another generalization that can be drawn from the evaluation is that models which are trained  with supervision end-to-end outperform those which train representation and classifier separately. \n\nOverall, I think this is an interesting and cool paper but I\u2019m not sure I actually buy into the basic premise that it makes sense to model vulnerable vs. non-vulnerable code as two different latent spaces. Aren\u2019t the changes to make a vulnerable function safe again rather small and/or subtle? I think that beyond visualizing the convergence of properties of the latent spaces it would greatly improve this paper to inspect which aspects of the source contribute to both the latent representation and final classification as vulnerable vs. non-vulnerable. \n\nAlso, I wish the process of \u201cfix\u201ding the input code was better described, since the failure of this procedure excluded 4k/13k of the programs/functions in their initial dataset and had the potential to introduces learnable biases in the source code. At the very least, the authors should list how many vulnerable vs. non-vulnerable samples required fixing vs. could be compiled in their original form. \n\nLastly, the definition of \"vulnerable\" may be obvious to someone more familiar with the domain but seemed to me somewhat vague and never directly addressed. \n\nTypo:\np3, need space in \"obtain32, 281\"", "rating": "7: Good paper, accept", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}