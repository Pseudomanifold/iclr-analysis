{"title": "Nice speedup over DenseCRF", "review": "+ well written\n+ Good idea\n- Technical section not fully clear\n- Some experimental issues\n\nThe paper is well written, and clearly explains the background material and concepts. It might almost be a bit too detailed, as the main technical section (4) feels a bit rushed. (more below). \n\nFrom what I can judge the main idea in the paper is sound. The authors replace the large filtering step in the permutohedral lattice with a spatially varying convolutional kernel. They show that inference is more efficient and training is easier.\n\nThe technical section is not very clear. For example: Are the filter weights recomputed for each spatial location, is there any acceleration that speeds this up? How large can the authors make the filter kernel, before the perhutohedral lattice is faster again?\n\nFinally, the experimental section has some room for improvement. I liked the comparison of decoupled and coupled CRF training, but I didn't get much out of the synthetic experiments. I found it particularly confusing since Table 1 doesn't mention that the experiments use ground truth (test) labels that were corrupted.\nSecond, it would be nice to have a side-to-side comparison between ConvCRF and CRFasRNN. I'd recommend the authors to either use the CRFasRNN training setup for both methods, or spend the week or two training CRFasRNN using their training procedure. It is fine to do either of the two experiments and have four entries in that table.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}