{"title": "Okay contribution, but exposition could be better and lacks good take home messages", "review": "(As a disclamer I want to point out I'm not an expert in GANs and have only a basic understanding of the sub-field, but arguably this would make me target audience of this paper).\n\nThe authors presents a large scale study comparing a large number of GAN experiments, in this study they compare various choices of architechtures, losses and hyperparameters. The first part of the paper describes the various losses, architectures, regularization and normalization schemes; and the second part describes the results of the comparison experiments.\n\nWhile I wish there were more such studies -- as I believe reproducing past results experimentally is important, and so is providing practical advice for practitioners -- this work in many parts hard to follow, and it is hard to get lot of new insight from the results, or a better understanding of GANs. As far I can see the most important take home message of the paper can be summarized in \"one should consider non-saturating GAN loss and spectral normalization as default choices [...] Given additional computational budget, we suggest adding the\ngradient penalty [...] and train the model until convergence\".\n\nPros:\n- available source code\n- large number of experiments\n\nCons:\n- the exposition could be improved, in particular the description of the plots is not very clear, I'm still not sure exactly what they show\n- not clear what the target audience of the first part (section 2) is, it is too technical for a survey intended for outsiders, and discusses subtle points that are not easy to understand without more knowledge, but at the same time seems unlikely to give additional insight to an insider\n- limited amount of new insight, which is limiting as new and better understanding of GANs and practical guidelines are arguably the main contribution of a work of this type\n\n\nSome suggestions that I think could make the paper stronger\n\n- I believe that in particular section 2 goes into too many mathematical details and subtleties that do not really add a lot. I think that either the reader already understand those concepts well (which I admit, I don't really, I'm merely curious about GANs and have been following the action from a distance, hence my low confidence rating to this review), or if they does not, it will be very hard to get much out of it. I would leave out some of the details, shortening the whole sections, and focus more on making a few of the concepts more understandable, and potentially leaving more space for a clearer description of the results\n- it is not really clear to be what data the graphs show: the boxplots show 5% of what data? does it also include the models obtained by gaussian process regression? and what about the line plots, is it the best model so far as you train more and more models? if so, how are those models chosen and ordered? are they the results of single models or average of multiple ones?\n- \"the variance of models obtained by Guassian Process regression is handled implicitely so we tran each model once\"? I do not understand what this means, and I work with hyper-parameter tuning using gaussian processes daily. It should probably be rephrased\n- at the start of section 3: what is an \"experiment\"?\n- in 3.1 towards the end of the first paragraph, what is a \"study\", is that the same as experiment or something different?\n- (minor) stating that lower is better in the graphs might be useful\n- (minor) typo in page 5 \"We use a fixed the number\"", "rating": "4: Ok but not good enough - rejection", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}