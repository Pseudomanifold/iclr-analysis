{"title": "Layer-wise explicit IB functional training in DNNs", "review": "This paper provides a method to do explicit IB functional estimation for deep neural networks inspired from the recent mutual information estimation method (MINE).  By using the method, the authors 1) validate the IB theory of deep nets using weight decay, and 2) provides a layer-wise explicit IB functional training for DNN which is shown to have better prediction accuracy.\n\nPros:\n- The paper carefully constructs a method to estimate the mutual information between high dimensional variables and address the infinite mutual information issue by adding noise to the output. This is novel and theoretical sounding. \n- The paper connects the IB theory of DNN with weight decay, which is a novel founding.\n\nCons:\n- The paper claims no literature has been doing IB functional on a layer-by-layer objective, however, see [1, 2] for the total correlation explanation work which is closely related to IB functional and they have also verified the effectiveness of layer-by-layer objective. \n- The scope of the paper is unclear. It seems that the paper is trying to convince two things to the readers: 1) The compression phase in DNN does exist 2) Layer-wise training helps to improve the accuracy. Although these two things are close related to each other (because they all requires to estimate the IB functional), it seems that neither these two conclusions are convincing. First, the compression phase is achieved only through weight decay; without weight decay, as shown in the paper, the compression phase is gone. Does that verify the incorrectness of IB theory of deep nets? Second, for the layer-wise training, the paper only compares the layer-wise IB objective with the cross entropy loss. But if we really want to show the `effectiveness` of `layer-wise` training, one should compare the `layer-wise` training with `end-to-end` training while keeping the objective itself fixed. Otherwise, it is really difficult to draw conclusions about why the accuracy is improving, it is because of the objective changes or because of the `layer-wise` training.\n- How does the beta (in IB objective) selected in the experiments for comparison? Do you use a validation dataset, and what is the final beta? If the paper fine-tune beta on the validation dateset, then the comparison of \"IB functional, only the first term\" and \"IB functional\" is unfair. \n\n[1]  Ver Steeg et al. Maximally Informative Hierarchical Representations of High-Dimensional Data. AISTATS 2015\n[2]  Gao et al. Auto-Encoding Total Correlation Explanation. Arxiv 1802.05822.\n\n[update] After carefully reading the response (also from other reviewers), I decide not to change my rating.", "rating": "5: Marginally below acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}