{"title": "Interesting idea but needs significant improvement in terms of presentation and design of method and experiments", "review": "Summary: \nThis paper presents a new interpretable prediction framework which combines rule based learning, prototype learning, and NNs. The method is particularly applicable to longitudinal data. While the idea of bringing together rules, prototypes, and NNs is definitely novel, the method itself has some unclear design choices. Furthermore, the experiments seem pretty rudimentary and the presentation can be significantly improved. \n\nDetailed Comments: \n1. In Section 2, the authors seem to define rule list as a set of independent if-then rules. Please note that rule lists have an \"else if\" clause which creates a dependency between the rules. Please refer to \"Interpretable decision sets\" by Lakkaraju et. al. for understanding the differences between rule lists and rule sets. \n2. Section 3.1 is quite confusing. It would be good to give an intuition as to how the various pieces are being combined and in why it makes sense to combine them in this way. The data reweighting process seems a bit adhoc to me. What other choices for reweighting were considered?\n3. I would strongly encourage the authors to carry out at least a simple user study before claiming that the proposed method is more interpretable than existing rule lists. Adding both prototypes and rules, in fact, adds to the cognitive burden of an end user - it would be interesting to see when and how having both prototypes and rules will help an end user. \n\nPros:\n1. First approach to combine NNs, rule learning, prototype learning\n2. Provides an interpretable method for predictions on longitudinal medical data\n3. Experimental results seem to suggest that the proposed approach is resulting in accurate and interpretable models.\n\nCons:\n1. The various pieces in the method (rule learning, prototype, NNs, data reweighting) seem to be somewhat haphazardly connected. Section 3.1 does not give me a good idea about how the different pieces are resulting in an accurate and interpretable model\n2. The paper makes claims such as \"Experimental results also show the resulting interpretation\nof PEARL is simpler than the standard rule learning.\" without actually doing any significant user studies. Furthermore, any other synthetic data experiments which could demonstrate the various facets of accuracy-interpretability tradeoffs are missing\n3. The presentation of the paper is quite unclear. See detailed comments above. \n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}