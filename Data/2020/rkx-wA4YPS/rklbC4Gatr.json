{"experience_assessment": "I do not know much about this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review": "The paper considers the label shift problem and investigates the role of the calibration in improving the results of two different domain adaptation solutions including EM and BBSE. They show with having better estimation of conditional distribution in the source domain the final label distribution obtained by EM and BBSE in the target domain is more accurate. They conduct the experiments on three different datasets i.e. CIFAR10, CIFAR100 and Kaggel Diabetic Retinopathy as the proof of concept.\n\nOverall, I think the paper should be rejected as it suffers from not high enough level of novelty in proposed method. The paper used different variants of famous Platt Scaling family approaches as the calibration methods to improve the estimation of conditional distribution of the training data $p(y|x)$ and showed the positive influence of that on label shift approaches like EM and BBSE, which is not enough contribution. \n\nThe paper is well-written and point the interesting problem. But the way of reporting the results are not clear enough. It would be better that the accuracy is reported for the baseline, EM,  BBSE-Soft and BBSE-hard at the same table with mean and std values. The tables some how should show the impact of using the calibration to improve significantly the final label shift accuracy. But in this way of reporting the results it is not clear how big calibration can improve the final accuracy. Comparing to other baselines like RLLS [1] is also missing in this table.\n\nPointing out that ECE is not a good metric to measure the calibration is also reported before in the related research works [2]. \n\n\nReferences\n[1] Azizzadenesheli, Kamyar, et al. \"Regularized learning for domain adaptation under label shifts.\" arXiv preprint arXiv:1903.09734 (2019).\n[2] Vaicenavicius, Juozas, et al. \"Evaluating model calibration in classification.\" arXiv preprint arXiv:1902.06977 (2019).\n"}