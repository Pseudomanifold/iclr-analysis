{"rating": "8: Accept", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper presents an unbiased estimator of marginal log likelihood given a latent variable model. \nThe method extends the importance-weighted log marginal using the Russian roulette estimator. \nThe marginal log probability estimator is motivated for entropy maximized density estimation and use of REINFORCE (log-derivative) gradient for learning a policy with a latent variable. \n\nThe paper is well-organized and provides a contribution for optimizing latent variable models in certain scenarios. \nThus, I vote for its acceptance. \n\nSome questions follow.\n1) Is it trivial to show the absolute convergence of \\Delta_k(x) series?\nThe absolute convergence is mentioned above equation (8), I am not convinced of this point. \nPerhaps, if its expectation with respect to q(z;x) is applied, this can be shown from equation (6). \nOtherwise we need some assumption on q(z;x) like q(z;x) is reasonably close to p(z) or p(z|x).\n\n2) How was parameter m set for the experiments?\n\n3) I assume the expectation operator is taken over z and K in equations (9, 12). \nIs this correct? An explicit notation should be informative."}