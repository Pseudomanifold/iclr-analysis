{"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #4", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper deals with the problem of missing data imputation in multivariate time series and subsequent classification of the imputed time series. It combines a time-step-wise imputation step using a VAE with a full-time-series imputation using an RNN. The RNN uses special GRU cells that take the missigness pattern and the output variance of the VAE into account.\n\nGenerally, I believe the idea has conceptual merit, but the empirical evaluation is not sufficient to finally judge its practical value. Evaluations of the actual imputations, experiments on simple benchmark tasks, and more thorough ablation studies of different parts of the model would greatly strengthen this work.\n\n\nMAJOR COMMENTS\n--------------\n\n- It seems plausible that the prediction loss (L_pred) and the imputation losses (L_reg, L_vae) do not always favor the same solution. It could for instance happen that a \"wrong\" imputation of the time series (compared to the ground truth) would be easier to classify than the correct imputation. Can we be sure that this is not happening here? It would be useful to actually evaluate the quality of the imputations themselves on held-out data with and without L_pred in the loss function.\n- In Figure 3, it looks like the lowest value for alpha almost consistently outperforms the other values. Does this suggest that the VAE might actually not be useful in this architecture? Section 4.3.1 says that the performance degrades with an increasing beta parameter and that the VAE loss is thus still important. I don't think this conclusion is fully supported by the data, since it does not take the prediction loss (L_pred) into account. Increasing beta may well degrade the prediction performance because it weakens the influence of L_pred on the total loss, without any knowledge about the influence of L_vae.\n- Looking at the error bars in Table 2, I don't think the conclusion that the full V-RIN model poses a \"significant enhancement\" over the other one is statistically supported. The confidence intervals seem to be well overlapping. Looking more closely, they actually also seem to overlap with some of the RITS and BRITS models on some measures. Those values should probably also be printed in bold face and the claim in the text should be respectively weakened.\n\n\nMINOR COMMENTS\n--------------\n\n- The grammar and orthography should be checked here and there.\n- The reconstruction loss in the VAE-ELBO (Eq. 9) seems to encourage \\hat{x} to be close to \\tilde{x}. But \\tilde{x} contains zeros in place of all the missing features. Would this not encourage the VAE to just also put zeros there and therefore lead to \\bar{x} being roughly equal to \\tilde{x}? Maybe the \\hat{x} could actually be shown in the experiments to give an intuition for whether or not this is happening.\n- While I agree that medical time series are a challenging task to tackle and appreciate the usage of real data in the experiments, I think some aspects of the model could be more easily studied on some simpler benchmark task, where for instance the imputations could be visualized and ground-truth data for the missing values could be used for evaluation."}