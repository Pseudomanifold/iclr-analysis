{"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "This paper studies the problem of learning from multiple tasks and additional noisy data. The proposed representation learning method first assigns each noisy data a relevance score using the topological information. Then the authors propose to minimize a combination of the loss of a class-prototype learning loss and a cosine classifier learning loss to learn a good representation generator g_theta. The empirical study validates the effectiveness of the proposed method.\n\nI have the following comments,\n\n1. The studied problem that learning from few-shot data and large-scale noisy data is interesting. According to the experimental results, the proposed method seems to be promising.\n\n2. The learning procedure is confusing. It is highly recommended to provide the pseudocode of the proposed method.\n\n3. Since there are many tasks and each task has a large-scale data, I'm afraid that the running time will explode. How to deal with this issue?"}