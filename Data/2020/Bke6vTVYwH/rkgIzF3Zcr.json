{"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review": "This paper presents a classification method when the data consists of few clean labels and many noisy labels. The authors propose to construct a graph structure within each class and use graph convolutional network to determine the clean/noisy labels of samples in each class. The model is based on a binary cross entropy loss function in each class, which learns the probability of labels to be clean. And such \"clean\" probability is used as the measure of relevance score between the sample different classes.\n\nThe idea of this paper is straightforward and the experimental results seem promising. The authors compare with several related methods and show the proposed method has better performance in few shot learning experiments.\n\nFor the motivation of this methods, why would the graph be constructed within each class? If there is correlation between different classes, how could the model use such class-wise correlation to clean the label?\n\nMaybe I missed it, but how is the relevance score / predicted label determined for testing data given the graphs constructed in each class of training data?"}