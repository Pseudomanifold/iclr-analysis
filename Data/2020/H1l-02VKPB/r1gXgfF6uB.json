{"rating": "3: Weak Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This paper proposed a topology-aware-pooling method to generate ranking scores for each node and so the pooling (or coarsening) of the graph can be achieved by picking those nodes with higher aggregated attention scores. The ranking scores for each node are computed by taking the average of the scores of its neighbors, by doing which the authors claim that the topological information of the graph is taken into direct account in the pooling steps. \n\nThe proposed method indeed shares some common idea with \u201cHierarchical Graph Representation Learning with differentiable pooling\u201d by Xing et al. There, a differentiable pooling procedure is used to progressively coarsen the graph to achieve global representation, and the assignment matrix is learned in each hierarchies. This is very similar to the proposed method, since those nodes with higher attention scores are those with more neighbors, which can be considered as ``local cluster centers\u2019\u2019 on a graph. In other words, both methods perform some kind of hierarchical clustering to coarsen the graph. The authors claim that an assignment matrix may cause (1) overfitting, and (2) the coarsened graph may have a different structure than the original graph, which I believe are not justified criticisms. In many cases of clustering the assignment matrix  is auxiliary variables; and even if the assignment matrix is learned as a whole matrix variable, as long as the loss terms is properly defined (such as reconstruction loss in k-means), it can be learned very well because it does not need labels as a unsupervised term.  Second, computing the assignment matrix has more flexibility, especially considering that the coarsening step is not just to perform clustering but rather to facilitate the final classification, therefore locating ``important\u2019\u2019 nodes (in terms of fully representing the graph) is not the only goal, but locating both important and discriminative nodes (i.e., those nodes that can lead to informative features for final classification) is. In this sense, learning an assignment matrix obviously has the benefit of receiving back-propagated gradients from class labels, while the proposed method does not have this flexibility in the pooling step since the neighborhood structure of the graph is fixed throughout the iterations. \n\nAnother important observation is that The proposed method seems to connect each hierarchy directly to the final layer, which is similar to skip-connections. Can this be the main reason why the performance shows improvement, as has been validated in extensive studies in the computer vision community? Some ablation studies are needed to verify that the performance gains are mainly due to the key idea of TAP but not due to the skip connections that have been widely used in computer vision tasks.\n\nSome minor comments:\nHow do you implement the ranking_k() function? Is it differentiable?\n"}