{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper presents a few different results surrounding smooth relaxations of classical algorithms. While the ideas (particularly the smooth rendering system) are interesting, the limited nature of the experiments and the lack of comparisons with baselines or prior work makes it difficult for me to support acceptance.\n\nSome feedback:\n\n- Re: \"the output of C\u221e smooth WHILE-programs differs from the discrete WHILE-programs by a small factor.\" Can you talk about the math here? Maybe mention bump functions (some of your relaxations have infinite support, and others have finite support, i.e. they use bump functions--this is likely to be an important distinction in practice).\n\n- I'd want to see examples of softsort in action; especially examples that help me understand that the gradients are meaningful.\n\n- The smooth renderer, and in particular the advantages it has over existing differentiable renderers, seem like the most important contributions of the paper (although they're relegated to the appendix). Can you expand on what you mean by \"fully\" vs \"locally\" differentiable? Can you provide empirical comparisons with other differentiable renderers?\n\n- Can you optimize a scene with an unknown or variable number of triangles?\n\n- I'm skeptical that all of the complexity of the RAN architecture and training setup is necessary. Is it possible to compare with other options, including baselines that leave out one or more of the components or training losses?"}