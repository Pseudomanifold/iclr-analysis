{"rating": "3: Weak Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "N/A", "review": "\nThe paper makes the following two contributions: 1) a new metric to measure the realism of uncertainty estimates for regression problems which uses a Mahalanobis distance-based statistical test. 2) a new probabilistic architecture for semantic segmentation.\n\nOverall I do not think that the paper is qualifies for acceptance, because a) both contributions are only loosely connected and b) some parts are confusingly written or poorly motivated, making the paper hard to follow.\n\nAfter reading the paper it still remains unclear to me why the proposed statistical test is superior to other popular metrics, such as the log-likelihood or the metrics proposed by Mukhoti and Gal. I think the paper would benefit from a more detailed discussion that highlights the differences between the proposed metric and other commonly used metrics.\nFurthermore, in the experiments, the paper only shows that MC dropout doesn't achieve realistic uncertainty estimates. I think concluding that variational approaches underestimate the variance is a bit of stretch (see section 4.1) , i e. it would be more convincing if other approaches (e.g Blundell et al. Hernandes-Lobato and Adams) are also considered.\nThe paper also just states that uncertainty estimates obtained by MC dropout are unrealistic but doesn't elaborates how to improve them.\n\nThe second contribution, a probabilistic architecture for semantic segmentation, is not introduced in the main paper. Instead details are only provided in the appendix. In my opinion the paper would be easier to follow if it would contain a section that motivates and described the proposed architecture before jumping directly to the experiments.\n\nMinor comments:\n\n- the acronym FRRN is not defined\n\n- Section 4.2 last paragraph: I don't understand why samples obtain by MC dropout and from the latent space are considered to be from the same distribution? While both methods approximate the weight posterior they use different approximations for that.\n\n- In the introduction the paper states that the proposed segmentation network is a U-net like FRRN architecture , however in section 3 it says instead of a U-net based architecture a FRRN based architecture is used. This is somewhat confusing.\n\n- Section 4.1: how are the variances scaled for Figure 3 middle?\n\n- Section 4.1 It would be also interesting if other metrics, such as log-likelihood or RMSE, to see how well the model is able to fit the data.\n\n- I am also surprised that CVAE + MC underperforms to just using CVAE?\n\n- Section 4.1: how are the variances scaled for Figure 3 middle?\n\nReferences:\n\nEvaluating Bayesian Deep Learning Methods for Semantic Segmentation\nJishnu Mukhoti, Yarin Gal\narXiv:1811.12709 [cs.CV]\n\nWeight Uncertainty in Neural Networks\nCharles Blundell, Julien Cornebise, Koray Kavukcuoglu, Daan Wierstra\nICML 2015\n\n\nHern\u00e1ndez-Lobato J. M. and Adams R.\nProbabilistic Backpropagation for Scalable Learning of Bayesian Neural Networks,\nICML 2015"}