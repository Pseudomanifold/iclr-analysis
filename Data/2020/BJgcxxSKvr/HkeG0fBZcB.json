{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "[Overview]\n\nIn this paper, the authors proposed a dynamic graph message passing network which learns to dynamically capture the structural context information in the images for various vision tasks. In the dynamic graph message passing network, the authors proposed to learn to adjust the positions of neighbor nodes in the graph for a target node, and then learn a node-specific filters for performing message passing. By applying the proposed dynamic graph message passing network, the authors showed superior results on various vision tasks, such as detection, semantic and instance segmentations. A further detailed ablation analysis help to understand the different components in the model.\n\n[Pros]\n\n1. The paper is well-written and the model is clearly motivated and explained. I enjoyed reading the paper and the presentation of the experiments are also very comprehensive and impressive.\n\n2. The authors proposed to learn position-dependent random walk to construct the graph structure, and also learn node-specific filters and affinities for the message passing across the graph. Both of these two components are intuitive.\n\n3. The authors evaluated the proposed model on various vision tasks under different backbone architectures. It is shown that the proposed model can achieve better performance over various previous models, such as deformable conv, non-local networks, etc. \n\n4. Finally, the authors also performed a number of ablation studies to show the effectiveness of the proposed model on various tasks, with different ablated settings. It shows that all of the separate components contribute the final performance on semantic segmentation task. \n\n[Cons]\n\n1. Though the model is well-motivated. The proposed model have limited novelty. The reasons are three-folds: \n\na) the authors proposed dynamic walk method to learn to find the graph nodes, which is similar to the strategy used in deformable conv. Both of them are trying to learn the offset for the grid location based on some learnable parameters. Looking at Figure 4, the learned walks for nodes looks similar to the learned patterns in deformable conv.\n\nb) in dynamic filter, the authors attempted to learn different filters for different nodes in the graph, which has naturally happened in the deformable conv module. The difference is that in this model, the filter is learned based on the input node feature, while in deformable conv, the filter is learned globally across different locations.\n\nc) when looking close to Eq(5) and Eq(6), learning affinities is also not new. We have seen such strategy have been introduced in:\n\n[1] Graph Attention Networks. Petar et al. ICLR 2018\n[2] Graph R-CNN for Scene Graph Generation. Yang et al. ECCV 2018\n\nOverall, I think the proposed dynamic message passing strategy is not a brand-new techniques, which is more like a mixture of various components from other work.\n\n2. The overhead brought by the proposed model is still pretty high. Though the authors claimed that the proposed model has reduced much the FLOPs compared with non-local network, it is still much higher than other models like deformable conv. Also, the authors did not compare themselves with GCNet and CCNet on the computational complexity. \n\n3. Based on the above analysis, it is still not clear whether the improvements over other methods are due to the model design or the computational and parameter overhead introduced by the model. When we look close the Eq(5) and (6), and substitute Eq(6) into Eq(5), we can find the overall computation in Eq(5) become multi-hop computations over the node features. In this sense, I am curious whether increasing the number of  DGMN layers without using dynamic filters and affinities but different parameters at different layers can still achieve the same performance.\n\n4. Based on the above analysis, the authors should add at least one more experiments by decreasing the overhead introduced by the DGMN and compare it with the previous work. Also, if possible, make increase the parameters and computational complexity of baseline network so that it is comparable to the DGMN would be a strong experiment to show.\n\n[Summary]\n\nThis paper present a dynamic message passing networks for various vision tasks. the authors proposed to learn to positions for the grid nodes and the filters and affinities as well. The paper is well-written and clearly presented. The experimental results demonstrate the effectiveness of the proposed model on object detection, instance segmentation and semantic segmentation. However, as pointed above, I still think the novelty of the proposed model is limited and it is not very clear to me whether the improvement is due to the proposed model or the high computational complexity. Overall, I still think the paper is a good paper. I would like to give a weak accept above borderline. However, since it is not an option, I choose weak reject as the rating. I will be open to change my rating if the authors can address my above questions.\n\n"}