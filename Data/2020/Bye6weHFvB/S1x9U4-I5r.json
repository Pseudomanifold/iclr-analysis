{"experience_assessment": "I have read many papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper aims at learning a latent representation of images in the setting of sequential decision making. The representation are learned such that there exists a metric that correctly reflects the difference in reachability between points in the neighborhood of the current observation and the goal.\n\nI'm struggeling to understand the core approach of the paper. More specifically, while learning the local metric (Alg. 1) seems clear, I can not understand the details of Alg.2 (which btw. is never referenced in the text). The surrounding paragraph is not detailed enough. Why is \\Phi(x, x') denoted a global embedding? \\Phi has two inputs, shouldn't that be some sort of a metric? How is \"find n\" done? There is a lot of talk about embeddings, but they are actually not occuring in section 3. What is a 'plannable representation'?\n\nSome of the experiments compare to VAE and its learned embedding space. Shouldn't the comparision be to models that think about the Riemannian geometry of a VAE, e.g. \"Latent space oddity: on the curva-ture of deep generative models\". There are a several citations missing in that direction, going back to at least \"Metrics  for  probabilistic geometries\" by Tossi et al. in 2014. As it was also pointed out in a public comment, relevant citations related to \"Learning for planning\" seem to be missing, too. Finally, a wider set of experiments needs to demonstrate the method (again, considering the scope of the as-of-now-not-cited papers)."}