{"experience_assessment": "I have read many papers in this area.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper describes a method of training neural networks to be robust to a worse case mixture of a set of predefined example attributes. This is done with a loss in accuracy in the average case but improvements in the worse case. The proposed algorithm is relatively simple and convergence rates are also given for this new algorithm.\n\nBuilding neural networks that perform well in the face of group-level worse case test-set distributions is a very important problem particularly in areas such as health and safety-critical applications as past work points out. This paper shows good results in the worse case and additionally shows that the common technique of importance reweighting cannot arrive at the same solution. The convergence analyses also yield additional insight into this new algorithm. The paper is well written and relatively easy to understand with good details on the experimental setup. The algorithm has a downside in that the groups must be known a priori, is it possible for these groups to be learnt? Also, can using a hinge loss also improve robustness to the worse case examples?\n\nHowever, there are some unanswered questions in the paper. What is the effect on the training time of this algorithm? Is it just the time for an additional forward prop? What is the effect on the worse-case examples of weight decay on the Bert model? Even though it hurts the average performance does it improve the worse case at all? In the last line of algorithm 1 why is q_G used instead of q_g?\n\nOther comments:\nAt the bottom of P5: The ordering of 93.4% and 97.1% seem to be reversed.\nAbove eq. 5 , \\delta_g seems to be overloaded. In the paragraph, it first refers to the generalization gap and then later to a heuristic.\nTable 2: The drop in average accuracy for waterbirds does not seem 'small'.\nBottom of P8: 'background is more unique', it seems this is supposed to mean the background appears less often?\n"}