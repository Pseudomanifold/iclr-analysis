{"rating": "6: Weak Accept", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "The paper describes an approach that combines domain adversarial neural network with generative adversarial imitation learning. In the setup, each environment is dependent on some latent context variable (e.g. physics parameters) through which latent variable dependent policy and latent variable independent discriminators are learned. \n\nI don't think the exact same idea has appeared in existing literature. The authors justifies its connections and differences between third person imitation learning, but it seems that the proposed method bear some similarities to the NeurIPS19 papers below. \n\nhttps://arxiv.org/pdf/1909.09314.pdf\nhttps://drive.google.com/file/d/1urPE7J5tT8dzoBHSFvZKwNLsQieU706o/view\n\nThe following papers also assumed that GAIL-like methods in a meta learning setup, where environments depend on context. Perhaps the difference here is that the discriminator is also trained with a gradient reversal layer, so it encourages the discriminator to not use redundant state information. Also in this paper the source domain only contains demos from one env, which might highlight the importance of the gradient reversal layer.\n\n\nQuestions:\n\nIn \"dynamics learning\", it seems that the inference network learns is mostly the context variable c, wonder if it is better to use terms like \"latent variable inference\" to avoid confusion.\n\nWhat does the standard deviation mean in Figure 6? It seems a lot of them are even larger than the mean.\n\nThere is little explanation to the VAE-ADAIL experiments -- is it safe to assume most of the experiments require certain knowledge of the latent variable in order to be successful? Maybe some of the arguments about VAE can go to the appendix.\n\nWhy would in some cases UP-True performs much worse than ADAIL? In Ant it is even worse than PPO expert.\n\nHow would you adapt to unseen environments in ADAIL-pred? I don't see explanations in the text about how this is done. Essentially, how are samples obtained from the environment in order to perform posterior inference?\n"}