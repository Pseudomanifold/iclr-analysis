{"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The authors propose an approach for calibrated predictions under domain shift scenarios. The approach, that leverages (unlabeled) test samples allows for unsupervised post-processing calibration, even for off-the-shelf models for which the training data is not available. Experiments compare the proposed approach with existing calibration methods in shifted domains.\n\nEquation (5) is confusing. If I understand correctly, the authors are simply making the point that q(x,y=k) can be written in terms of q(x,y\\neq k) by weighting by the ratio of conditionals, which are available.\n\nSensitivity to noisy labels. The experiment is reasonable and the results are convincing, however, the authors do not justify why accurate (manual) labels on the target set are not feasible in many applications. The authors could point to a few examples for context.\n\nThe authors assume that q_s(y) = q_t(y), which seems restrictive in practice. Though it does not impact my opinion of the proposed approach, it seems narrow to think of a practical situation where the space of covariates is changing but the class composition remains unchanged. This is vaguely addressed in Section 6. Perhaps it can be elaborated further.\n\nI enjoyed reading the paper, the proposed reinterpretation of NLL in terms of a weighted average and its approximation based on weights that do not depend on the labels but the (assumed known) labels marginal is interesting and seems to yield good results."}