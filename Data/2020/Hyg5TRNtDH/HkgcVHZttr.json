{"rating": "3: Weak Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "The paper proposes an unsupervised calibration method in a domain adaptation setting. The approach is based on the well known temperature scaling and does not require labels for the calibration set. The problem of calibration under domain shift is an important problem in areas where uncertainty estimation is useful; the paper tackles this problem and relaxes the assumption of knowing the input distribution. The method does not rely on the labels in the calibration set but has a major limitation of knowing the task distribution which may not be true in many practical settings where uncertainty estimation is relevant (such as medical diagnostics).\n\nThis assumption may not be a negative point for the paper as any domain adaptation problem needs at least some minimal assumptions; however,  the limits of the proposed method should be studied with respect to this assumption. For instance, in the experiments how robust are the experiments with respect to the assumption of a known q(y)? In the practical applications of the method in medical domain and self driving cars, q(y) is only known up to some approximation; so understanding the robustness of the method w.r.t. to this assumption is critical in real applications. \n\nAlso with the recent attention to calibration and uncertainty estimation in DL; I believe the acceptance bar for papers in this area has risen. Unfortunately, most papers in this area rely on completely synthetic experiments which makes their impact limited. I understand that ground truth uncertainty may not be available in some of these domains; however, other indirect metrics such as missclassification detection can be used. There are also medical datasets available (e.g. Diabetic Retinopathy) that can be used for evaluation. \n\nTo summarize, the paper addresses an important problem of calibration under domain shift but it needs some more empirical work to show the real advantage and limitations of the proposed method in a practical setting."}