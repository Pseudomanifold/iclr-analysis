{"experience_assessment": "I have published in this field for several years.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "- This paper introduces a structured consistency loss for semantic segmentation under the semi-supervised learning paradigm. Specifically, authors propose to include this term to force consistency between the predictions of two networks (a teacher and a student). To evaluate their method, authors employ images from the cityscapes dataset. Results show that the proposed method achieves competitive results compared to state-of-the-art architectures.\n- Contributions are unclear. The only contribution seems to be the \u2018first study that employs semi-supervised learning and achieves state-of-the-art performance in semantic segmentation using the Cityscapes\u2019. First, this contribution is insufficient to be considered as a technical contribution. And second, I feel authors mislead the reader with this assertion. \n- The paper is poorly written with many senseless sentences and weird word compositions (e.g., \u2018our research designed the semi-supervised learning approach suitable for semantic segmentation\u2019 or \u2018In this study, we are aimed at bypassing the labeling cost problem with semi-supervised learning technique.\u2019 or \u2018It regularizes the inter-pixel relationships consistent, thereby allowing the network to learn more powerful generalization capabilities\u2019 just to give few examples). This makes the reading of this work particularly difficult, as well as the understanding on some parts.\n- Authors fail to compile relevant works, particularly in semi-supervised segmentation, leading to a very weak related work section. Particularly in semi-supervised segmentation, more than one hundred papers have been published since 2015 only in major conferences on vision (CVPR,ICCV,ECCV) and learning (ICLR, ICML, NeurIPS). None of them, however, are listed in the related work section. Authors should significantly improve this section.\n- Which is the difference with French et al. (2019) and Liu et al. (2019)? Both seem to be using CutMix for semantic segmentation.\n- Where the labeled images are used? Authors show that labeled images and their corresponding ground truth masks are employed in eq 1) and 2). Nevertheless, it is never explained in which moment these are employed. Are they used to pre-traine the student and teacher networks? Are they mixed with unsupervised images during training? Please clarify. \n- Please add reference for the cross entropy loss with boundary label relaxation.\n- Furthermore, this paper contains many grammatical errors.\n- Even though the idea is interesting, I am inclined to reject this paper because there are many unclear details, the related work is insufficient and the paper needs a thorough proof-reading in english. "}