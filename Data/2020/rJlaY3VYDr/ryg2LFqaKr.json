{"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "- Summary: This paper proposes to train an OOD detection model without OOD data, because OOD is hard to define a-priori, such that OOD observed during training is not guaranteed to be matched with OOD at test time. They propose a decomposed confidence strategy and modification on input preprocessing. They show the superiority of their method over the state-of-the-art methods, when OOD is not available.\n\n\n- Decision and supporting arguments:\nWeak reject.\n\n1. The analysis around `g` is confusing. After equation 5, they state that \"`g(x)` is shared among all classes like p(d_in|x).\" At this point, I expect that `g` is a confidence score, but at last they used `max_i h_i` for OOD detection, and the role of `g` turned out to be just a learnable temperature in softmax. Also, even the learning objective for `g` is not introduced. Also, it seems the authors tried to make some relationship between equation 4 and their method, but I couldn't find their correlation.\n\n2. Contribution is limited. To my understand, the main novelty in this paper is on the learnable temperature `g`, and the others are already explored in the literature. The proposed three similarity measures are used in prior works, i.e., inner-product in Hendrycks & Gimpel (2017), Euclidean distance in Lee et al. (2018b) (though they claimed that Mahalanobis distance is better), and Cosine similarity in Techapanurak & Okatani (2019).\nThe essential modification on input preprocessing strategy is simply removing OOD data from the validation set, and this is a natural setting as their proposal is to train an OOD detection model without OOD data.\n\n\n- Comments:\n1. How is `g` trained? What is the learning objective and how the ground truth value is assigned? Since the activation of `g` is sigmoid, a natural conjecture is that in-distribution and OOD would be labeled as 1 and 0 (or reversed). However, they said they do not train their model with any OOD, so it is hard to figure out the learning objective and the ground truth value for `g`.\n\n2. Why don't you compare with the GAN-based OOD generation (Lee et al., 2018a) and the adversarial attack-based validation (Lee et al., 2018b)? They do not require any OOD as well. In section 2.1, the authors set the hyperparameter `alpha_l` in the Mahalanobis method to be uniform because no OOD for validation is available, but actually Lee et al. (2018b) proposed the adversarial attack-based validation method to avoid the dependency on OOD.\n\n3. Notation is confusing. `f` is used for multiple parts: `f_i = h_i/g` in eq 5 and `h` is a function of `f^p`. Some notations like `w_g` and `b_g` are not defined.\n"}