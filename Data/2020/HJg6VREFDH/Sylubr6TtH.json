{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "In this paper, an inference WGAN model (iWGAN) is proposed that fuses autoencoders and WGANs. By working on both the prime and dual problems, the proposed iWGAN takes an objective that is in general the upper bound of WGAN. The generalization error bound of iWGAN is analysed and its probabilistic interpretation under maximum likelihood estimation is provided.  The proposed iWGAN model is validated on both synthetic and real (MNIST and CelebA) datasets. \n\nPros:\nThis paper not only proposed the iWGAN model, but also provided some theoretical analysis about the iWGAN, such as the generalization error bound and the probabilistic interpretation. \nThrough the experiment, it seems that the proposed iWGAN works.  Especially, on the synthetic dataset, iWGAN seems to  have less mode collapse than WGAN.\n\nCons:\nThe major concerns of this paper lie in its experiment.  \n(1)\tThere is no quantitative comparison between iWGAN and WGAN, especially on the two real image datasets.  There are only some visual examples of the results in either the main body of the text or the appendix. \n(2)\tThe proposed iWAN is only compared with WGAN.  There is no experimental comparison with other autoencoder GANs  in the literature,  although the paper stated that iWGAN has many advantages over other autoencoder GANs (in the abstract).\n\nIn addition to experiment, other concerns include:\n(1)\tThe proposed method needs to be better motivated, although it is interpreted under the framework of maximum likelihood estimation. For example, what is the advantage to optimize the proposed upper bound of WGAN over its original objective? In the experiment, it seems iWGAN has less mode collapse than WGAN based on the synthetic data. But there is no explanation or discussion about why iWGAN could enjoy this favourable property.\n(2)\tThe proposed framework is tightly based on WGAN. It is not clear whether it could be extended to other GANs, which limits the significance of the proposed work.\n\nDue to the above concerns, rating is recommended as \"3 Weak Reject.\"\n\nSuggestions:  The authors are encouraged to provide extensive comparison with other autoencoder GANs and WGAN, especially in quantitative way.  \n"}