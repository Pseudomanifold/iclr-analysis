{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "The paper studies the correlation between likelihood of flow-based generative models and image semantic information, and shows that even small perturbations, like a few pixel translations or noise applied to background, significantly affect models\u2019 likelihoods, which signals that these likelihood models cannot be used for out-of-distribution data detection. However, very similar observations were made in prior works [1] and [2]. In particular, the paper [2] showed that likelihood of PixelCNN is dominated by background pixels which makes the observations in section 4.2 (applying noise to background) unsurprising. The sensitivity of Glow model to even 1-2 pixel translations (section 4.1) and exploiting multi-scale structure of Glow (zeroing latent variables in section 4.3) are interesting, but I believe, not enough for a full paper. Thus, due to the limited novelty, I recommend a weak reject.\n\nOther questions and concerns:\n1. The author claim to introduce \u201csemantic-invariant transformation\u201d. I believe this can be called \u201cdata augmentation\u201d, why introduce a new term?\n2. The last bullet point in the introduction is not clearly written.\n3. Equation 1: variable u wasn\u2019t introduced. Paragraph after equation 4: please fix the comma.\n4. The clarity of figure / table captions can be improved, as well as their references in the main text.\n5. The section 4.4 is confusing. Which discriminative classifiers are considered? How are they trained? The Table 1 is not referenced in the main text and the results are not explained or discussed. \n6. The experiments are only performed on MNIST / FashionMNIST datasets. It would help to see experiments on other datasets, e.g. CIFAR-10, SVHN.\n7. Related work section can be elaborated: please, discuss how the observations made in the paper are different from / consistent with [1] and [2].\n\n\n[1] Nalisnick, Eric, et al. \"Do deep generative models know what they don't know?.\" arXiv preprint arXiv:1810.09136 (2018).\n[2] Ren, Jie, et al. \"Likelihood Ratios for Out-of-Distribution Detection.\" arXiv preprint arXiv:1906.02845 (2019).\n"}