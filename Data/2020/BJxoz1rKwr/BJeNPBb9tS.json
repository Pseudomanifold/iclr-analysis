{"rating": "3: Weak Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "Summary & Pros\n- This paper proposes a simple yet effective framework utilizing self-supervision in semi-supervised settings. When predicting self-supervision, this framework uses its conditional probability p(z|y,x) given a primary label y. This scheme can formulate the relationship between labels and self-supervision.\n- This paper also proposes two additional techniques for improving performance with (1) the average prediction across four rotated samples and (2) mixed samples.\n- The proposed framework achieves better performance than the prior work, S4L, and it is also comparable with SOTA method, Mix-Match.\n\nConcerns #1: The claims for the proposed method are not clear\n- On page 3, the authors claimed that the benefits of the proposed method come from three perspectives (1)-(3). I think the claims are not clear because p(z|x) does not depend on y, so it is hard to say that maximizing p(z|x) can encourage maximizing p(true y|x). For example, p(z|x) can be maximized even if p(true y|x) is small.\n- To verify the claims, experimental supports should be provided.\n\nConcerns #2: Why the semantic classifier p(y|x) in the auxiliary branches is required?\n- The authors said that the reason is self-supervision z is noisy compared to the ground-truth y. But this reason is not clear because the self-supervision is always assigned correctly.\n- On page 3, the authors said that the proposed method provides the gradient of p(y|x) while S4L does not. But if use the additional semantic classifier for p(y|x) in (1), the claim becomes not true.\n- Moreover, the semantic classifiers in main and auxiliary branches aim to model the same distribution p(y|x). Why separate branches are required for the exact same purpose?\n\nConcerns #3: Writing is not well-organized.\n- Overall, writing could be simplified and well-organized.\n- When constructing self-supervision, the input images are also modified, e.g., rotated. The notation x in p(z|x) and p(y|x) is confused, so using another notation such as \\hat{x} for the case could be better.\n- What are the exact training objectives? I think they should be stated explicitly in the main paper, not appendix, because it is important that which sample x is used for p(z|x) or p(y|x), especially in this semi-supervised setting.\n\nConcerns #4: Why Fine-tune is worse than Labeled-only?\n- The result in Table 2 is weird because there is no reason that pre-trained parameters are worse than random parameters. So evidence supporting the result should be provided.\n\nThe proposed method is simple and effective and provides meaningful gain, but verification and explanation seem to be not enough and writing could be improved. So I will increase the score if a strong rebuttal is given.\n"}