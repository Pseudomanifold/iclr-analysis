{"rating": "3: Weak Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper investigates an interesting problem of building a program execution engine with neural networks. The authors proposed a transformer-based model to learn basic subroutines, such as comparison, find min, and addition, and apply them in several standard algorithms, such as sorting and Dijkstra\u2019s.\n\nPros:\n1. The method achieves generalization towards longer sequences than the sequences in the training set in several algorithms.\n2. The method represents numbers in binary form and the visualization shows that it learns embeddings from fixed-range integer numbers in a well-structured manner.\n3. The learned NEE subroutines are tested in a variety of standard algorithms, such as multiple sorting algorithms and Dijkstra\u2019s shortest path algorithm. The experiments further demonstrate that several NEE subroutines can be composed together in complex algorithms.\n\nCons:\n1. NEE mostly focuses on learning low-level subroutines such as number comparison or addition. Therefore, it has to be used along with conventional subroutines, and cannot completely replace the full execution in complex algorithms, which have sophisticated control logic, such as if/else and for-loops. When the transformer model is used alone in the sorting task (Sec. 4.1), the performance degrades substantially as the sequence length gets longer.\n2. Although the method achieved some degree of strong generalization, it lacks a formal way to verify the correctness of the learned subroutines, as opposed to prior work on program synthesis (Cai et al. 2017) that can prove the generalization of their model with recursion. \n3. The method relies on detailed execution traces for supervised learning which can be costly to obtain.\n\nQuestions:\n1. Confusing sentence: \u201cCan we retain high attention resolution by restricting the model to only observe the first scenario repeatedly?\u201d Can you elaborate on what you meant here?\n2. From Figure 1, it seems that the model with dot product attention generalizes better in longer sequences than the one with all modifications. What\u2019s the reason?\n3. I would like to better understand the limitation of these learned NEE subroutines in long sequences. For instance, in Figure 8 and Figure 9, how would the model perform beyond the lengths of the sequences tested here? Would the performance maintain at 100% or decrease gradually as the sequences get even longer?\n4. I am curious to know how this method could be extended to support more complex number systems, such as float numbers, and more complex data structures beyond sequences, such as binary trees and priority queues. I\u2019d love to hear what the authors have to say about this.\n5. I'd also like to know if the number embeddings learn in different algorithms would exhibit different structures (by examining the visualization of number embeddings learned in different tasks).\n6. As NEE focuses on learning the basic subroutines while NPI aims to learn the high-level program executions, I think that it\u2019d be very interesting to see how these two can combine their complementary strengths to build a complete neural-based execution engine.\n\nTypos:\nSelect he node --> Select the node\n"}