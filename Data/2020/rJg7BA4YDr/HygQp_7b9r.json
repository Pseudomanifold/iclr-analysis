{"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "# Summary\n\nThis paper trains a network to mimic simple known algorithms in a way that guarantees that they generalize to\nout-of-distribution test instances. The network mimics the algorithms by running repeatedly in a loop where each\niteration of the loop runs a Transformer and outputs a mask that tells the next iteration the inputs to process. The\nsetup is tested on sorting, adding, and graph algorithms, and found to learn regular number representations that\nsupposedly aid generalization.\n\n# Review\n\nThis paper has an admirable and useful goal, but the way it is currently implemented and presented is not ready for\npublication at ICLR.\n\nMy main issue is with the training/testing setup and its presentation. The authors assume a certain structure of an\nalgorithm (for instance, the iterative structure of recursive selection sort), delegate one or more modules inside this\nstructure to be implemented by neural networks, and train them only.\nMost of the \"strong generalization\" is coming from the fact that the iterative structure is fixed. The work abstracts\nout the most complex parts of each algorithm. In Figure 3, for instance, the NN must learn to find the smallest element\namong the non-masked-out ones on the input, return it, and mask it out. This is a much simpler task than the whole\nsorting algorithm. Training the network to solve \"find_min\" != claiming that the network solves and strongly generalizes\non \"sort\".\n\nImportant training details are left unspecified. How is the data for training NEEs generated? For instance, for training\nthe network in Figure 3, do you trace the whole selection sort on a randomly generated list, and collect the\nintermediate input/output pairs for \"find_min\"? If so, it's absolutely unsurprising that the process also works for\nlonger lists -- see above. Are composable NEEs, like the three networks in Figure 7, trained jointly or separately? Do\nthey observe their own outputs that are fed into subsequent NEE networks, or are the previous outputs teacher-forced,\nor are they pre-trained? Many of these details need to be clarified precisely to make the experimental setup\nverifiable.\nSome important details are presented factually without any motivation. For example, why does Figure 5 use\nSHIFT and XOR? Why, in general, the next mask produced by a NEE is XORed with a previous one instead of replacing it?\n\nI liked the embedding visualizations, which clearly demonstrate structure in the latent space driven by (a) the\nbinary number representations, and (b) the addition task objective. In addition to regular ordering structure (needed to\nimplement addition), the latent space also clearly exhibits regularities inherent to the binary representation, such as\nthe shift by 64 in Figure 8a. While interesting, this only confirms the findings of Shi et al., albeit in a more pure\nexperimental setting.\n\nIn summary, the scope of experiments and presentation of results would need to be significantly improved in order for\nthis work to reach the quality bar of ICLR."}