{"rating": "8: Accept", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This work is clearly the work of a large team. the paper clearly defines what is being done. I have spent a lot of effort with MCTS. I can not find the corresponding allowance for stochastic jumps in the latent space long horizon learning. \n\nYou have the phrase \"allowing to imagine thousands of trajectories in parallel\". I would like some elaboration on this. I think you have ideas of what is happening in the latent space that I am not following. \n\nYou are heavy on the machinery and math. I find the learning in the latent space the important part and there are things like how much simulation is done in the latent learning not clearly spelled out. How does the effort compare to the 1E9 steps of the base line your refer to? \n\nYour team is highly competent your style is distinct. Now may be the time to move you to understanding what structures get learned in latent space, are the in fact compact, diverse?\n\nPerhaps there is room for memory/memories in the latent space? \n\nMassive effort, nice results. Now for learning on our part (the humans). "}