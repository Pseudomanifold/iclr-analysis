{"rating": "3: Weak Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "N/A", "review": "Review for \"Towards Scalable Imitation Learning For Multi-Agent Systems with Graph Neural Networks\".\n\nThe paper proposes a new time series model for learning a sequence of graphs. \n\nI vote to reject the paper for three reasons.\n\n1. Lack of significance. Algorithm 1 is essentially supervised learning of an autoregressive model with a GNN. The GNN definition is expanded out in the pseudocode, but seems to be completely standard. Moreover, Section 2.5 is also completely standard - you are using a sum of standard MSE losses. It should be much more concise. Also, there is typically no point scaling the loss by D if you use Adam (because the scaling they will eventually cancel out).\n\n2. Poor awareness of prior work. What you call \"scalability issue caused by poor extrapolation\" is normally called poor generalization. Improving generalization is an established problem in ML. You should cite some of that work. See [1] and follow the references.\n\n3. Poor experimental evaluation. Your experiments show that the competing GNN method (what you call Kipf's GNN) didn't converge in certain settings. Robust GNN implementations exist that converge for a wide range of reasonable graphs. You should have used one of them.\n\nAs things stand, because the criticisms concern the core of the submission, I have doubts the quality of the paper can be improved enough within the ICLR revision time to obtain an \"accept\" score. However, I wanted to encourage you not to give up. The building blocks that you have in the paper are very relevant and can be a basis for impactful work. You also write well (despite some minor issues). I hope these skills will help you make great submissions in the future!\n\nMinor points:\n1. I would not call what the paper is doing \"imitation learning\". Imitation learning normally means you have a controllable system and want to learn a policy from expert demonstrations. What this paper does is commonly referred to as learning an autoregressive time series model. \n2. Avoid colorful language. For example, the sentence: \"the apparent resemblance of the corrected distributions in the final output may inspire an inductive bias as part of training objective\" is unclear. \n\n[1] https://papers.nips.cc/paper/7176-exploring-generalization-in-deep-learning.pdf"}