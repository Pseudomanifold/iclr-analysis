{"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This work considers sequence prediction problems in a multi-agent system (MAS), which I think is different from imitation learning problems where agents try to mimic experts\u2019 behavior given histories or states. In that sense, I think the title of this work should be changed so that readers are not confused. \n\nThe main idea of this work is to use (1) graph neural networks (GNNs) to learn the abstract information among multiple agents, (2) use 1D convolution to extract historical features of each agent, (3) and minimize the MSE loss function between true and predicted states to make expected successor states of multiple agents more accurate. The experiments show training in a small number of agents can be generalized and transferred to the setting in which there is a large number of agents. \n\nAlthough the proposed algorithm is practically useful, I believe the submission is premature to be accepted at a conference due to (1) the lack of comparison with existing works on multi-agent (reinforcement and imitation) learning and (2) the lack of novelty (It seems that the proposed method simply combines existing neural networks and applies it to multi-agent behavior prediction.). There\u2019s a huge recent development on multi-agent RL and IL regarding the scalability of MARL (MF-MARL, https://arxiv.org/pdf/1802.05438.pdf), coordinated multi-agent imitation learning (https://arxiv.org/abs/1703.03121), multi-agent GAIL (https://arxiv.org/abs/1807.09936), etc, which should be considered as related literature. In addition to them, there\u2019s a paper on arXiv that uses GNN for MARL (https://arxiv.org/abs/1810.09202), which may be deeply related to this work as well. \n\nI\u2019ll definitely increase my score if I underestimate the quality of this work. "}