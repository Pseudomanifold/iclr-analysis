{"experience_assessment": "I do not know much about this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper is a mash-up of recent work on differentially private stochastic gradient descent (DPSGD) and the lottery ticket hypothesis. Differential privacy is a paradigm for ensuring that statistical models learned from a large dataset do not disclose any particulars of individual elements of that dataset. DPSGD is a technique that applies differential privacy ideas to models trained with stochastic gradient descent, where privacy is guaranteed by clipping and adding noise to gradients. On the other hand, the lottery ticket hypothesis is a method for finding sparse sub-networks contained in larger dense neural network models that are at least as accurate as the underlying dense model. The authors propose and demonstrate that by combining DPSGD with the lottery ticket hypothesis that they can train end-to-end differentially private models that outperform the DPSGD technique.\n\nI am up in the air about whether or not to accept this paper. I have trouble assessing the originality and significance of this work, the former since it seems to be a simple combination of two recent ideas, and the latter because I don't really have a context for how important the development of differentially-private optimization strategies are. I also didn't really find the experimental results to be that extensive, but I don't have a real sense of what state of the art is for differential privacy. Perhaps some of these issues could be mitigated by some additional exposition? I think one of my problems is that most of the paper is written to show that this new technique is superior to DPSGD, but I don't really have a good sense if either of them are sufficient as a practical solution of this problem.\n\nSome additional questions I had are as follows:\n\n1) One of the reasons given for combining the lottery ticket hypothesis with DPSGD is that DPSGD scales poorly as models get larger due to clipping by the norm of the gradient. Could you not compensate for this by scaling the norm by the number of parameters, or does that mess up the differential-privacy calculation?\n\n2) I don't understand how the winning ticket selection portion is differentially privacy. I understand that they use the exponential mechanism, but I would have assumed that the dataset needs to be varied in addition to the model. Is there an intuitive explanation for how privacy is achieved essentially just by varying the initialization and not actually adding noise to the data?\n\n3) Are there any datasets or methods where the effectiveness of the differential privacy technique could be directly assessed? For example, is there a way of testing whether the model is memorizing specific data elements, and then further showing that these differential privacy techniques mitigate this? This would be a nice check to have in addition to the plots of accuracy vs. privacy budget."}