{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper introduces a Self-Adversarial Learning (SAL) mechanism in GAN based text generation, aiming at tackling the problem of mode collapse and sparse rewards problem. Specifically, motivated by \u201cself-play\u201d mechanism in RL community, instead of using a binary classifier as discriminator in original GAN, SAL employs a comparative discriminator which is a pairwise classifier with three classes: \u201cbetter\u201d, \u201cworse\u201d and \u201cindistinguishable\u201d. The authors provide lots of experimental results and ablation study showing the efficiency of the proposed mechanism in comparison with previous GAN models.\n\nDecision: weak reject. \nThis paper is well motivated: clearly sparse rewards and mode collapse are two problems need to be solved in GAN based text generation, however, the following concerns prevent me from finding this paper acceptable in ICLR:\nThe \u201cself-play\u201d idea is widely used in RL. In RL, the comparison between policies can be determined directly by the game simulation results. In text generation, such comparison is more difficult to be judged. This paper appears to assume that the generated sentences are \u201cworse\u201d than the real samples, which is similar to the original definition of discriminator in GAN, and the generated sentences in earlier epochs are \u201cworse\u201d than that in later epochs, which needs further justified.\nAs a simple extension to GAN, I\u2019m not convinced that the problem of mode collapse could be solved by proposed mechanism. If the generator falls into a local minimum, a collapsed mode, the proposed mechanism will never pull the generator out of that. Moreover, what is the theoretical foundation of the proposed evaluation metric on quality-diversity trade-off, NLL_{gen} + NLL_{oracle}?\nThe setting of the important set of hyper-parameters, reward weights, is unclear in the paper. The reward weights directly influence the reward in training, thus should play an important role of model performance. More discussion about this should be provided.\nMoreover, in the paper, only comparison between proposed mechanism with GAN based models are shown. Comparison with more recent models like RelGAN should be provided. And comparison with other state-of-the-art text generation model should be discussed.\n\n\n\nFeedbacks: \nReferences regarding experimental results in table are incorrect. For example, the results in synthetic data should be in \u201cTable 2\u201d and COCO image caption dataset should be in \u201cTable 3\u201d. \nSome imprecise parts, for example, in Equation (5) and (6), it should be G_\\theta(Y_{1:t-1} and G_\\theta(y_t | Y_{1:t-1} .\nI\u2019m curious about what the performance would be like if the weakly supervision by regarding sentences generated in later training stage are \u201cbetter\u201d than the sentences generated in earlier training stage is removed in training comparative discriminator. This is different from the CAL model in the ablation study.\nWhat is the influence of different values of rewards weight? \nAlso about the rewards weight, in the description of Scheduled rewarding, the rewards weight is described to be linearly changed with training iteration, while in Appendix C.3, the rewards weight is described to be fixed. This is very confusing.\nA minor issue: for image captioning, a lot other metrics are widely used in measuring the model performance, e.g. CIDEr, SPICE and so on. Those metrics could be helpful for audience to understand how the model performs in comparison with other captioning models.\nAnother minor issue: for image captioning and WMT (conditional generation), the detailed model structures are not described in paper, which is not very friendly to audiences with relatively little knowledge in related areas.\n\n"}