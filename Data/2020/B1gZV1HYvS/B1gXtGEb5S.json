{"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "The authors propose a decentralized adversarial imitation learning algorithm with correlated policies, which recovers each agent\u2019s policy through approximating opponents action using opponent modeling. Extensive experimental results showed that the proposed framework, CoDAIL, better fits scenarios with correlated multi-agent policies.\n\nGenerally, the paper follows the idea of GAIL and MAGAIL. Differing from the previous works, the paper introduces \\epsilon-Nash equilibrium as the solution to multi-agent imitation learning in Markov games. It shows that using the concept of \\epsilon-Nash equilibrium as constraints is consistent and equivalent to adding the difference of the causal entropy of the expert policy and the causal entropy of a possible policy in RL procedure. It makes sense. \n\nBelow, I have a few concerns to the current status of the paper.\n\n1.\tThe authors propose \\epsilon-Nash equilibrium to model the convergent state in multi-agent scenarios, however, in section 3.1 the objective function of MA-RL (Equation 5) is still the discounted causal entropy of policy, the same as that of MA-GAIL paper. It is unclear how the \\epsilon-NE is considered in modeling MA-RL problem.\n\n2.\tRather than assuming conditional independence of actions from different agents, the authors considered that the joint policy as a correlated policy conditioned on state and all opponents\u2019 actions. With the new assumption, the paper re-defines the occupancy measure and introduces an approach to approximate the unobservable opponents\u2019 policies, in order to access opponents\u2019 actions. However, in the section 3.2 when discussing the opponents modeling, the paper did not clearly explain how the joint opponent function \\sigma^{(i)} is designed. The description \\sigma^{(i)} is confusing.\n\n3.\tTypos: in equation 14 \u201ci\u201d or \u201c-i\u201d; appendix algorithm 1 line 3 \u201cpi\u201d or \u201c\\pi\u201d. \n"}