{"experience_assessment": "I have published one or two papers in this area.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "Summary: This papers tackles the question of building an object-centric latent variable generative model of scenes that can sample novel scenes with coherent objects and relationships. To do this, the authors define a generative model, GENESIS, that uses an autoregressive prior over mask variables. The component variables are generated conditioned on these mask variables. The visual appearance of the objects are generated conditioned on the component variables. Inference is done sequentially by inferring some later object varaibles conditioned on others. Results show that the model adopts a consistent strategy in generating and inferring the scene components, first considering the background then the foreground objects. The authors apply GENESIS to three datasets with monochromatic objects and show that GENESIS qualitatively generates coherent scenes and infers coherent scene components.\n\nDecision: Accept. This work clearly addresses a problem beyond current object-centric modeling approaches such as IODINE and MONet, which is the problem of generating novel scenes.\n\nStrengths:\n- The paper is well written and executed.\n- The evaluation is thorough\n- The problem and solution are well motivated\n\nWeaknesses: \n- While the authors demonstrates that GENESIS is able to model static scenes, it is not clear how straightforward it is to extend GENESIS to modeling dynamics for the purpose of robotics and reinforcement learning (as stated in the authors' motivation). Whereas approaches such as IODINE or RNEM (van Steenkiste et al. 2018) treat the object latent that can be propagated through time, maintatining that the same latent models the same object may not be a guarantee for autoregressive approaches such as MONet or GENESIS that re-parse the scene at every frame. Object temporal consistency is especially important when considering tasks that have occlusion, which are important problems in robotics.\n- The results in Appendix D seem to suggest that GENESIS decomposes a scene mostly via color segmentation, as IODINE and MONet do. One concern is that such models that rely mainly on color segmentation are not applicable for real world robotics with various lighting conditions and textures because segmenting based on color may not provide coherent object representations. Would the authors be able to provide an empirical analysis of how GENESIS models a real-world scene, analogous to Figure 11 in the IODINE paper?\n\nVan Steenkiste, S., Chang, M., Greff, K., & Schmidhuber, J. (2018). Relational neural expectation maximization: Unsupervised discovery of objects and their interactions. arXiv preprint arXiv:1802.10353."}