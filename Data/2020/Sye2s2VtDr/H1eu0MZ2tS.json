{"rating": "3: Weak Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review": "In the paper, the authors proposed CrossGO, an algorithm for finding crossing features useful for prediction.\nIn CrossGO, one trains a neural network that captures feature crossing implicitly.\nThen, possible crossing features are estimated using the gradient-based saliency.\nThe idea here is that, if a feature has a crossing with some other features, its contribution in the saliency can vary across different inputs.\nThus, by looking at the variation of the saliency, one can find candidates features for feature crossing.\nCrossGO greedily selects candidate crossings based on the idea above.\nIn the last step, a simple logistic regression is trained using the candidate crossings, and the effective crossings are selected using a forward greedy feature selection.\n\nI found the paper well-written and the idea is easy to follow.\nMy concern, however, is the lack of Factorization Machines (FM) in the experiments.\nIn Introduction, the authors mention to the deep version of FM and stated \"(deep FMs are) not able to generate interpretable cross features\".\nBut, as the authors are aware of, non-deep FMs are able to handle feature crossings in a interpretable way.\nThus, it would be essential to adopt non-deep FMs as the baseline in the experiments.\nBecause the important baseline is missing, I found the results are not convincing enough to claim the effectiveness of the proposed method."}