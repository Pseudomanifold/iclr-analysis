{"rating": "3: Weak Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "\nThe paper presents a scheme to generate new features as cross-product\nof binary features to improve the performance of linear models while\nobtaining interpretable models. The candidate set of cross-features\ncan be exponential and is handled by the proposed scheme by utilizing\nthe gradient-based importances of the features in a (deep) neural\nnetwork. Features with large discrepancies in their local and global\ninterpretations are used as the seed set of candidate features for\ngenerating new cross-features, and the final step performs a feature\nselection to further reduce the final set of cross-features. The\nempirical evaluation demonstrates the utility of the proposed scheme\non 8 datasets. \n\nWhile the proposed scheme does present a way to improve the accuracy\nof interpretable models, I am currently recommending a reject for the\nfollowing reasons (given the higher standard recommended for papers\nover 8 pages):\n\n- While this paper does consider some baselines, it seems to be\n  missing some crucial baselines that address the same (or very\n  similar) problem. There are some papers [2,3] that learn boolean\n  conjunctions (that can be seen as cross-features) to generate\n  accurate interpretable models. Moreover, there are some search based\n  feature generation schemes [1,4] that significantly improve upon the\n  exhaustive feature generation scheme of Kanter & Veeramacheneni,\n  2015. This technique can easily be applicable in learning boolean\n  cross features with binary features. At the very least, it is important to \n  understand where this proposed scheme is positioned relative to the \n  aforementioned literature and why a comparison is not required.\n- It is very unintuitive (at least to me) to tie the candidate\n  generation scheme to a neural network especially given the\n  sensitivity of neural network training to different initializations\n  and other factors. For the same data and neural network, the local\n  vs. global discrepancies can change significantly, thereby changing\n  the candidate set of cross features. This can potentially make the\n  proposed feature generation scheme somewhat unstable, and the\n  interpretations from the subsequent models might not be as\n  interpretable as they seem. It would be good to understand what I am\n  missing here and why being tied to a neural network model is\n  essential and not an issue here. \n\n\nClarification:\n\n- Lines 8-10 in Algorithm 1 is not clearly explained.\n- The experiment to motivate Assumption 1 needs to be better\n  explained.\n\n\nMinor:\n\n- The notation in equation (1) needs to be clarified better.\n\n\n[1] Khurana, Udayan, et al. \"Cognito: Automated feature engineering\nfor supervised learning.\" 2016 IEEE 16th International Conference on\nData Mining Workshops (ICDMW). IEEE, 2016. \n[2] Dash, Sanjeeb, Oktay Gunluk, and Dennis Wei. \"Boolean decision\nrules via column generation.\" Advances in Neural Information\nProcessing Systems. 2018. \n[3] Wei, Dennis, et al. \"Generalized Linear Rule Models.\" Proceedings\nof the 36th International Conference on Machine Learning. 2019.\n[4] Khurana, Udayan, Horst Samulowitz, and Deepak Turaga. \"Feature\nengineering for predictive modeling using reinforcement learning.\"\nThirty-Second AAAI Conference on Artificial Intelligence. 2018. \n"}