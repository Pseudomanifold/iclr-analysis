{"experience_assessment": "I have published in this field for several years.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "Summary: This work proposes to use a combination of graph neural networks (GNNs) and proximal policy optimization (PPO) to train policies for generalized device placement in dataflow graphs. Essentially, (1) a GNN is used to learn representations of a dataflow graph (in an inductive manner), (2) a transformer is used to output a device placement action for each node in the graph, and (3) the entire system is trained end-to-end via PPO. Extensive experimental results show very impressive results compared to strong baselines.\n\nAssessment: Overall, this is a solid application paper. The authors GNNs, PPO, and Transformers in an effective, well-motivated, and sound manner. Moreover, the task is interesting and relevant. There is not significant methodological novelty, as the authors are essentially combining standard components in a straightforward way. That said, the results are strong and the paper is well-written, so it certainly has merits as an application paper. \n\nWill code be released? This is essential for reproducibility, as the paper does not contain sufficient technical details to allow for reproduction.\n\nReasons to accept:\n- Strong empirical results on an interesting application \n- Well-written paper\n- Thorough experiments\n\nReasons to reject:\n- Incremental methodological contribution\n- Likely difficult to reproduce"}