{"rating": "3: Weak Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper tries to propose a new method to stabilize the training procedure of GAN. To this end, they use adversarial samples of real data to train the discriminator, and claim that it is helpful to reduce the adversarial noise contained in the gradient. Although training GAN with adversarial samples of discriminator is somewhat novel, the method and experiments are not convincing. \nI do not recommend the acceptance based on the limited contribution of this paper. The following is a detailed evaluation. \n\n1. The paper uses vague description such as \u201cThis approach can improve the robustness of discriminator and reduce adversarial noise contained in gradient\u201d without convincing justification. Please give a formal description or notation of \u201cadversarial noise contained in gradient\u201d, and discuss how to remove the effect of \u201cadversarial noise\u201d in principle instead of extensively testing adversarial training of discriminator. \n\n2. The experiment is not convincing and the improvement is not significant. The author running adversarial training on CIFAR10 dataset with FGSM and the perturbation is tested from 0.2/255 ~ 4/255. The performance (FID score) is a bit sensitive to the amount of perturbation level. Moreover, this The improvement over DCGAN is quite limited given previous works such as WGAN-GP. Combined together, the result is not convincing (it seems to be a heavy tuning result rather than a principled solution)."}