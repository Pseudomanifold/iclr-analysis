{"rating": "3: Weak Reject", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "In this paper, a coarse-to-fine pyramidal scheme, along with learned attention/routing mechanism, is proposed to handle classification in large images, whereby the receptive field of attends to a much smaller part of the image than would be useful for classification. To overcome this problem, the authors propose a mechanism by which attention mechanisms are propagated from coarse to fine levels. A few experiments are provided to show the benefits of the proposed mechanism over convolutional network baselines, especially in situations where the input size is relatively large compared to the effective receptive field. The paper is written in a straightforward manner and is mostly easy to read. \n\nWhile the overall idea is interesting, the authors seem to have completely missed reference [1] from CVPR 2017, which provides a very similar set of ideas but in a more formal and potentially more powerful setting of multigrid networks, incorporating both multiscale and attention mechanisms. \n\nFurthermore the experiments on ImageNet have extremely weak baselines; if I understand correctly, the top-1 accuracy is not even 55% for the best model, which is a far cry from modern architectures and baselines. It is well known that results on toy models hardly translate to real-world networks, and this makes me wonder about how applicable the results of this paper would be for large scale ResNet networks. It would have been much more convincing if the authors would have taken modern baselines and then shown that using their top-down approach allows scaling to even larger images, for example. As it is, the largest image size considered is 256x256, which is exactly what can already be well handled by modern ResNet's. For these very weak empirical results, I feel that the paper is not yet ready.\n\nSome specific questions:\n\n1. What interpolation/downsampling algorithm was used to create the coarser resolutions? Is the performance sensitive to this algorithm?\n\n2. For Figure 4, please provide the details about the figures in the caption itself, to avoid needing to scroll back and forth between the text and the figure. I found Figure 4 quite confusing to parse. Similarly for Figure 6. Fixing these would be very helpful.\n\n[1] Multigrid Neural Architectures (http://openaccess.thecvf.com/content_cvpr_2017/papers/Ke_Multigrid_Neural_Architectures_CVPR_2017_paper.pdf)"}