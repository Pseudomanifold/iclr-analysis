{"rating": "6: Weak Accept", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review": "Notes: \n\n  -Goal is to learn autoencoders which can capture disconnected manifolds by employing multiple discrete charts.  \n\n  -For example in Figure 1, a Torus is shown, which can't be captured by a single chart (smooth mapping from euclidean space).  \n\n  -This motivating intuition makes sense, although I wonder to what extent a neural network can compensate for this by being relatively unsmooth.  \n\n  -The circle example in the introduction is illuminating and I enjoyed it.  \n\n  -It's somewhat subjective, but I feel that autoencoders are becoming less widely used, so the paper might have more impact if it had targeted models like ALI/BiGAN which do reconstruction but purely with adversarial objectives.  \n\n  -Two techniques are presented for handling how points are assigned to charts (4.1).  I'm a bit unclear on how this interacts with the notion that a single point can be covered by multiple charts.  \n\n  -The paper uses lipschitz regularization on the decoder.  Note that Spectral Normalization (Miyato 2018) could also be used here.  \n\n  -The illustration of the effect of lipschitz regularization in figure 4 is good.  \n\n  -For 5.2, I'd prefer the use of a dataset other than MNIST, since we don't strictly know that the digits require different charts (for example I'm pretty sure there's a smooth mapping between \"1\" and \"7\").  I'd prefer an example where literally different types of objects are combined which couldn't possibly be modeled by a single chart.  \n\nReview: Overall I felt like this paper gives a nice mathematical exposition on the relationship between charts, manifolds, and autoencoders.  I slightly lean for acceptance but am very borderline, especially as the results on \"real data\" are very weak.  "}