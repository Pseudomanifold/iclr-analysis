{"rating": "3: Weak Reject", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "## Summary of the Paper\n\nThis paper introduces a new architecture for autoencoders based on the\nconcept of *charts* from (differential) topology. Instead of learning a\nsingle latent representation, the paper proposes learning charts, which\nserve as local latent representations. Experiments demonstrate that the\nlocal representations perform favourably in terms of approximating  the\nunderlying manifold.\n\n## Summary of the Review\n\nThis is an interesting paper with an original idea. I appreciate the use\nof concepts from differential topology in deep learning and agree with\nthe paper that such a perspective is required to increase our\nunderstanding of complicated manifold data sets. However, I find the\nfollowing issues with the paper in its current form, which prevent me\nfrom endorsing it for acceptance:\n\n1. I have doubts about the technical correctness of the proposed\n   architecture; specifically, the relevance of the *initial* latent\n   representation, which employs a Euclidean space, is not analysed.\n\n2. The role of the number of charts, which needs to be specified\n   before-hand, is not analysed in an ablation study.\n\n3. The experiments do not showcase the *conceptual* improvements of the\n   proposed technique.\n\nI shall briefly comment on each of these points before discussing other\nimprovements.\n\nI want to point out that I really like the ideas presented in this\npaper and I think it has the potential to make a strong contribution but\nthe issues in their current form require substantial revisions and\nadditions.\n\n# Concern 1: Technical correctness\n\nThe paper claims at multiple places that the geometry of Euclidean space\nis 'trivial' or 'too simplistic' to meaningfully reflect the structure\nof the data. This claim is double-edged, though: first, there are\nmany methods that use autoencoders based on these spaces that exhibit\nsufficient reconstruction capabilities. Second, the proposed\narchitecture itself uses a Euclidean latent representation as its\ninitial encoder. The paper states that 'Ideally, this step preserves the\ntopology of the data [...]', but this is never analysed.\n\nI fully agree with the idea that charts are a suitable way to describe\ncomplicated manifolds, but the paper needs more precision when terms\nsuch as 'topology' and 'geometry' are being used. Likewise, I disagree\nwith referring to Euclidean space as 'trivial'. Again, other methods\ndemonstrate that the space captures high-level phenomena sufficiently\nwell for reconstruction purposes. At the very least, the paper should\nbe more precise here.\n\nMoreover, I would recommend experiments in which the dimensionality of\nthe initial encoder is discussed.\n\n# Concern 2: Number of charts\n\nSelecting the number of charts appears to me as a critical component of\nthe proposed method. While the appendix contains one experiment for\nMNIST with different numbers of charts, this concept needs to be fleshed\nout more. How do we know that we have a sufficient number of charts?\nSince in differential topology, the choice of chart should not matter,\nhow does it behave in these cases? Is there a way to detect that the\nnumber of charts must be increased?\n\nI could envision something like a simple 'step size' control procedure:\nif a quality measure indicates that there need to be more charts, double\nthe number of charts and re-run the training; if the number of charts\nis too big, halve it and re-run the training.\n\nI get the idea that increasing the number of charts will probably\ndecrease the reconstruction error, but this comes at the obvious expense\nof even more parameters. I thus recommend another set of experiments\nthat shows the influence of the number of charts, maybe even on the\nsynthetic data sets used in the paper.\n\n# Concern 3: Conceptual improvements\n\nWhile I enjoyed the didactic approach of the paper, which first\nintroduces simple test data sets to illustrate the concepts, my\nmain question is about the conceptual improvements that the charts\nprovide in the end.\n\nI see that the reconstruction error for MNIST goes down---but there are\nalso significantly more (!) parameters than in the comparison\narchitectures. The ideas of the sampling or interpolation experiments\ngo in the right direction, but in their present version, they are not\nentirely convincing. In fact, they even raised more questions for me: \n\n- Figure 6 depicts individual charts but their *covering* of the space\n  is highly non-uniform. The letter '0' is covered more often than the\n  letter '1', for example. How can this be compatible with the claim\n  that the novel architecture learns a suitable set of charts? I could\n  understand some overlaps, but there seems to be a clear difference\n  between the charts generated in the synthetic examples---which do\n  appear to be cover everything in a uniform manner---and the charts for\n  MNIST. This needs to be elucidated some more, in particular since the\n  paper writes that the charts 'cover [...] in a balanced and regular\n  way'.\n\n- The digit morphing example is not not entirely convincing to me. Is\n  this not something that I can do equally well with a VAE or generative\n  models in general? I am *not* disputing the claims of the paper here,\n  I am merely stating that *if* the new method is beneficial for this\n  sort of application, a more in-depth experiment is required.\n\nThus, while I would like to give the paper the benefit of the doubt, it\ndoes not show just *why* it is relevant to have a chart-based embedding.\nSome suggestions for a set of experiments:\n\n- Do charts help in separating the input space? I would hypothesise\n  that this is the case---it thus might be worthwhile to study\n  low-dimensional embeddings obtained based on each chart and 'stitch'\n  them together.\n\n- Do charts tell us something about the properties of a manifold? For\n  example, are certain charts 'easier' to embed than others? This could\n  be used to indicate different dimensions in a data set.\n\n## Experimental setup\n\nI have one major point of critique here, namely the way results are\npresented without any measures of tendency. Instead of showing a bar\nplot in Figure 7, I would suggest showing a Table with standard\ndeviations along multiple repetitions of the experiment. It is not clear\nfrom looking at this to what extent this results can be replicated.\n\nMoreover, a discussion of the number of parameters is required. To some\nextent, I find it not surprising that a better reconstruction error is\nachieved if more parameters are present.\n\nThis makes some of the claims in the paper hard to assess.\n\n## Technical clarity\n\nThe papers is generally written well and has a good expository style.\nHere are some cases where I find that clarity can be improved:\n\n- To add to what I wrote above: if charts are Euclidean as well, the\n  paper should elucidate why Euclidean charts do *not* suffer from being\n  too simplistic.\n\n- The discussion of homeomorphisms in the introduction is slightly\n  misleading; none of the functions learned later on is a homeomorphism\n  because of the latent space dimensions.\n\n- Homeomorphic mappings of manifolds into a Euclidean space are not\n  necessarily desirable---this is why the definition of a manifold uses\n  the concept of neighbourhoods. I think this should be rephrased in\n  a positive manner, as in: manifolds are complex, so we cannot expect\n  a *single* map to suffice...\n\n- The leading example of a torus embedding needs more details. Why is\n  the structure destroyed?\n\n- The introduction of 'topological features' on p. 2 is slightly abrupt.\n  It would be sufficient to explain by means of the figure that the\n  mapping obviously does not respect all properties.\n\n- p.2: paths become invariant to _what_ exactly?\n\n- p.2: what is the 'topological class'?\n\n- p.2: would LLE not be a good precursor to the method proposed in this\n  paper?\n\n- p.2: is this paper to be seen as an implementation of Chen et al.  (2019)?\n  This should be made more clear.\n\n- p.3: the concept of intrinsic dimension slightly varies in literature.\n  I would propose mentioning the homeomorphism of every chart to some\n  $d$-dimensional space, and state that if this exists, one calls the\n  manifold $d$-dimensional.\n\n- p.3: the circle example could be explained in more detail for readers\n  unfamiliar with the concepts.\n\n- p.4: the chart prediction module requires a brief explanation at the\n  point when it is first introduced (1 sentence is sufficient). The\n  method plus architecture is presented but the details come very late;\n  I would prefer some intuition here\n\n- p.4: $N$ needs to be defined earlier\n\n- p.4: how is the dimension of latent spaces chosen? Please also refer\n  to my comments on the experiments above.\n\n- p.5: Section 4.1 again mixes 'topological' and 'geometrical' concepts;\n  suddenly, the concept of curvature crops up---this needs to be\n  explained better!\n\n- p.5: Distances can always be measured in connected subsets of\n  real-valued spaces; whether the set is open or closed does not change\n  the fact that a centre exists. Am I misunderstanding this?\n\n- p.5: I like the 'partition of unity' approach, but to me, this reads\n  like a convex combination of predictions. Am I misreading this? If\n  not, I would suggest to rephrase this.\n\n- p.5/6: the goals of the new method need to be stated more clearly; the\n  paper needs to explain better to what extent *reconstruction error* is\n  affected by charts (it does not seem to be, as I outlined above)---and\n  this again raises the question of which quality measure the new method\n  *can* preserve.\n\n- p.6: the definition of the Lipschitz constant could be more precise;\n  please specify the requirements $f$ has to satisfy\n\n- Eq. 4 needs more details for me: it seems as if the weights appear\n  twice as a kind of 'decay term' (in the second part, I see the sum\n  but the product appears in both terms). This should be stated more\n  clearly.\n\n- p.6: the pre-training needs more details; how crucial is this step?\n\n- p.6: what does the 'orientation' imply? It is not defined except in the\n  appendix.\n\n- p.6: the jump from the illustrative examples to the non-synthetic ones\n  is large; the uniform sampling of the latent space does not scale to\n  higher dimensions, for example. The paper should comment on this if\n  possible.\n\n- In general, I would recommend giving the employed models more\n  'speaking' names. I found it hard to keep track of all of them and had\n  to refer to the appendix constantly.\n\n- For Figure 4, please show the full space, together will all charts\n\n- p.7: please give some ideas (see above) for how to use the covering of\n  the points in practice; I like that the object can be reconstructed\n  with a proper set of charts, but the paper could make the necessity\n  of the technique much more obvious by choosing stronger examples.\n\n- p.7: the object arguably *also* has a complex geometry, not only\n  complex topology. This should be mentioned.\n\n- p.8: the discussion of MNIST is slightly incorrect; as outlined above,\n  many digits appear to be generated by multiple charts, while some,\n  such as `1` do not appear on more than one chart.\n\n- The metrics in Section 5.3 should be introduced earlier, maybe at the\n  expense of some exposition in the introduction or the simpler\n  examples; it is not good style to have to refer to the appendix to\n  understand a core experiment of a paper.\n\n- p.8: I do not understand the term 'wholly pyramid'.\n\n- p.11: the decoder should map to $x_i$, if I am not mistaken\n\n- p.11: I would suggest a more consistent terminology to describe the\n  models. The prediction function is replicated multiple times, for\n  example, so why not introduce a shorthand notation for this?\n\n- p.12: '\\cup' and '\\cap' need to be switched: the *intersection* of\n  domains needs to be empty, not their *union*\n\n- p.13: to what extent are the 'faithfulness' and 'coverage' established\n  metrics? It seems that they are developed for this paper, so I would\n  explain them in the main text and also make clear why they are\n  desirable metrics---else, the metrics could be criticised as being\n  fine-tuned for the proposed method.\n\n  For example, if *coverage* can measure the phenomenon of *mode\n  collapse*, this needs to be demonstrated.\n\n## Minor comments\n\nSome typos:\n\n- low dimensional --> low-dimensional\n- eigen-functions --> eigenfunctions\n- considers manifold point --> considers a manifold point\n- paring subnetwork --> pairing subnetwork\n- paramterized --> parametrized\n- preformed --> performed [occurs multiple times]\n- chats --> charts\n- Lipshitz --> Lipschitz (in Figure 4)\n- evalutation --> evaluation\n- seciton --> section"}