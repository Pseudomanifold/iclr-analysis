{"experience_assessment": "I have read many papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "<Paper summary>\nThe authors proposed a novel method for positive-unlabeled learning. In the proposed method, adversarial training is adopted to extract positive samples from unlabeled data. In the experiments, the proposed method achieves better performance compared with state-of-the-art methods. \n\n<Review summary>\nAlthough the idea to utilize adversarial training for PU learning is interesting, the proposed method is not sufficiently validated in theory. In addition, the manuscript is hard to follow due to confusing notations and lack of figures. I vote for rejection.\n\n<Details>\n* Strength\n + The main idea is simple and interesting.\n + The proposed method performs well in the experiments.\n\n* Weakness and concerns\n - Confusing notations and lack of figures.\n  -- Lack of mathematical definition of C and D.\n  -- The argument of P^p and that of P^u are different (x^p and x^u), which implies that those distributions are defined at different space (but actually same).\n  -- Shared index ``i\" for positive and unlabeled data in Eq. (3).\n  -- The notation with ``hat\" often imply the empirically estimated (or approximated) value in the field of ML. \n  -- No figures about the proposed method. Specifically, it is hard to understand the relationship between C and D. \n\n - Since Eq. (3) looks totally different from Eq. (2), why Eq. (3) is reasonable remains unclear. \n  -- About I: first, P^{pu} cannot be calculated, because it requires unavailable labels of x^u. If you treat unlabeled data as negative, it should not be called ``ground-truth,\" and the term I cannot help D correctly recognize positive samples. Second, the positive samples are almost ignored in this term, because the number of positive data should be substantially small in a common setting of PU learning. \n  -- About II: the authors explain the role of this term by min-max game between C and D during optimization, but the most important point here is what will happen when we obtain the optimal C and D after the optimization. What property or behavior do the optimal C and D have? \n\n - What do the authors want to claim with Proposition 1? The right-hand side of Eq. (5) cannot be easily calculated due to the density ratio between P^p and P^u. There is no explanation about what f and eps mean. What ``optimal\" means is also ambiguous. \n\n\n* Minor concerns that do not have an impact on the score\n - Although the problem setting is quite different, the idea of this paper is partially similar to the importance weighting technique adopted in some recent domain adaptation methods [R1, R2]. Do you have any comment on that?\n\n[R1] ``Reweighted adversarial adaptation network for unsupervised domain adaptation,\" CVPR2018 \n[R2] ``Importance weighted adversarial nets for partial domain adaptation,\" CVPR2018\n\n"}