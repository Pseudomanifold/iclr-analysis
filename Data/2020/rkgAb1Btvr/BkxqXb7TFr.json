{"experience_assessment": "I do not know much about this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "I'm not an expert in this area but I do find this paper interesting. Though the name \"Fourier networks\" is a bit arbitrary because the proposed approach also applies to multi-layer networks where only the last hidden layer has the proposed change.\n\nThe extrapolation problem of ReLU networks is an interesting point. I don't know previous works that point out this for out-of-distribution detection but it's worth figuring out if this observation has been made in the adversarial robustness community.\n\nI do have several concerns, summarized below:\n* On page 3 the fourier transform is motivated by that RBF networks \"do not generalize as well as ReLU networks\". I doubt if there is any evidence for this argument.\n* I have some issue understanding proposition 1: what is w_i'? Only w_i is mentioned before.\n* The \"Fourier network\" is not defined explicitly in the paper, which makes it hard to understand the architecture/algorithm details. If I understand it correctly, it is only about changing the activation function of the last hidden layer and large initialization, with everything else the same as the ReLU networks?\n* How does the magic number \"\\sigma_1 = 0.75\" and \"\\sigma_2 = 0.0002\" come from? Did you search it by looking at the test performance? Is the performance sensitive w.r.t. the two parameters?\n\nI'm willing to increase my score if the authors addressed my concerns.\n\n"}