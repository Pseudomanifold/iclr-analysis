{"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper introduces a parameterized approach to generate adversarial samples by balancing the speed-distortion trade-off. The method first tries to reach the boundary of classes in the classifier space, then walks on the classifier manifold to find adversarial samples that make the classifier to fail in prediction while minimizing the level of distortion in the sample. Having a limited number of iterations, the method reduces the fluctuations around the boundary and paves the classification manifold.\n\nThe idea is novel, interesting and well-formulated, while the intuition could be better explained. The paper is a good read, has an adequate amount of literature review, and the results are supporting the claims of the paper: lower distortion while having comparable accuracy, the use of generated samples in fortifying the classifier, and keeping distortion to a reasonable level (qualitative results in appendix). However, one of the claims is to trade the distortion level to speed that needs verifying in the main manuscript, therefore, it is suggested that the section B.1 moves to the main manuscript and discussed more thoroughly. Also the effect of other parameters on this trade-off (such as the number of iterations K).\n\nIt is also interesting to discuss how the algorithm performs in classes that are linearly separable on a toy dataset."}