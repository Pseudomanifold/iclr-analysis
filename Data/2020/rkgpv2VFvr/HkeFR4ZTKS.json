{"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper provides a theoretical justification for the benefit of multi-task deep RL (MTRL) with shared representations. By extending prior work (Farahmand (2011) and Maurer et al. (2016)), the authors demonstrate that the bound of MTRL can be improved if the cost of learning the shared representation at each AVI iteration can be reduced, which is mitigated as we increase the number of tasks. The author also empirically verify their theoretical results in a tabular Q-Fitted Iteration domain and also in challenging RL domains such as Mujoco. The results show that MTRL with shared representation can outperform their single task counterparts to some degree.\n\nOverall this paper adapts the theory shown in Farahmand (2011) and Maurer et al. (2016) to the setting of MTRL and demonstrates the effectiveness of using shared layers, which seems intuitive. While the theory seems a bit incremental, it\u2019s the first paper that theoretically validates the benefits of sharing knowledge, which is a contribution to the MTRL field. I would recommend a weak accept, though I have a few concerns on experimental results, and hope that the authors can clarify them during rebuttal.\n\nSpecifically, as the authors have noted, there is a wide range of prior works [1,2,3] that have empirically demonstrated the effectiveness of utilizing shared representations in MTRL. While the authors claim that the goal of the experiments is to show that MTRL with shared layers can outperform its sing task counterparts and thus they ignore other MTRL approaches. I believe that is not the main argument of the paper. The authors should provide empirical evidence on the claim that with an increasing number of tasks in MTRL, the error bound should improve and the performance of MTRL should also boost. Besides, I find the comparison where single-task training is initialized with shared representation a bit confusing. Training would definitely be improved when it\u2019s initialized with some related pretrained features. Maybe the authors should compare this to some other methods such as initializing with single-task representation or even representation learned from training different tasks.\n\n[1] M. Hessel, H. Soyer, L. Espeholt, W. Czarnecki,S. Schmitt, and H. van Hasselt. Multi-task deep reinforcement learning with popart.arXiv preprintarXiv:1809.04474, 2018.\n[2] Teh, Y.W., Bapst, V., Czarnecki, W.M., Quan, J., Kirkpatrick, J., Hadsell, R.,Heess, N., Pascanu, R.: Distral: Robust multitask reinforcement learning. In: Ad-vances in Neural Information Processing Systems 30: Annual Conference on Neu-ral Information Processing Systems 2017 (2017)\n[3] Wulfmeier, M., Abdolmaleki, A., Hafner, R., Springenberg, J. T., Neunert, M., Hertweck, T., ... & Riedmiller, M. (2019). Regularized Hierarchical Policies for Compositional Transfer in Robotics. arXiv preprint arXiv:1906.11228."}