{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "title": "Official Blind Review #4", "review": "This paper proposed an aggregation algorithm (DARN) for the multi-source domain adaptation problem which is highly useful in real-world applications.\nThe proposed method is based on the theoretical extension of the single-source domain discrepancy measure proposed by Mansour et al. 2009 to the multi-source setting.\nThis paper also showed the effectiveness of the proposed method on some real-world datasets.\n\nStrengths\nThe paper introduces new technical insights to understand their bound, e.g. effective sample size.\nThe paper proposed the way to estimate coefficient, optimal \\alpha, with theoretical justification, and I think this is the biggest contribution of this paper and is interesting.\nThe proposed method is also able to be used in the regression task since it is based on the disc which can be estimated in the regression task.\n\nWeakness\nThe main theorem of this paper is an extension of existing methods, so the novelty of theoretical analysis is somewhat limited.\nA naive approach to estimate coefficient with single-source domain discrepancy measures such as [1]Mansour (2009), [2,3] Ben-David(2007, 2010), [4] Kuroki et al (2019), and W1-distance is not considered.\nExperimental results itself are fine but not complete.\n  - Although disc can be easily estimated in the regression task (differently from d_A distance which is a special case of disc), there are no experimental results of the regression task even in the synthetic data.\n  - It would be also better to show the coefficient of existing methods that have no theoretical justification.\n  - It would be better to compare with a naive approach that uses domain discrepancy between each source and target as (fixed) coefficient since this approach such as Mansour (2009), Ben-David(2007, 2010) and Kuroki et al (2019) which explicitly consider the hypothesis class has theoretical justification in the form of generalization error bound in the target domain.\n\nOverall, I like the approach of the proposed method, especially tuning coefficient during training procedure although novelty in the theoretical analysis is somewhat limited.\nSo this work has to be supported with more detailed experimental results to express the potential of this approach fully.\nFor this reason, I think it is okay but not good enough at this time.\n\n[1] Yishay Mansour, Mehryar Mohri, and Afshin Rostamizadeh. Domain adaptation: Learning bounds and\nalgorithms. In COLT, 2009.\n[2] Shai Ben-David, John Blitzer, Koby Crammer, and Fernando Pereira. Analysis of representations for\ndomain adaptation. In NeurIPS, 2007.\n[3] Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and Jennifer Wortman\nVaughan. A theory of learning from different domains. Machine Learning, 2010.\n[4] Seiichi Kuroki, Nontawat Charoenphakdee, Han Bao, Junya Honda, Issei Sato, and Masashi Sugiyama.\nUnsupervised domain adaptation based on source-guided discrepancy. In AAAI, 2019.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory."}