{"experience_assessment": "I do not know much about this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The authors approach the problem of representing knowledge graphs from a top-down perspective, in which they argue for certain fundamental desiderata for hyper-relations (composition, inversion) followed by properties that define a mathematical group.\n\nI found the paper extremely difficult to follow. As defined in Eq. 1, knowledge graph embeddings are a model family with a choice of domain for the entity and relation, and a choice of how that relation operates on a head entity. This means one can devise arbitrary properties and restrictions on that family. It's not clear to me what motivates selecting a (abelian) group, where inversion, closure, identity, associativity, and commutativity are demanded to be properties of knowledge graph embedding models. This seems more a definition of what models they consider, rather than a novel insight about knowledge graph embedding models itself (the authors claim \"we proved for the first time the emergence of a group definition in the KG representation learning\", which seems hard to wrap one head's around).\n\nGiven this overarching family of models, the authors proceed to identify existing models as certain choices of that family.  I see little use in inventing this abstraction as the authors do not show any practical insights, or interesting theoretical analysis that comes from this higher-level abstraction."}