{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "Review: This paper focuses on generating adversarial perturbation in semantic space. The main contribution of this paper is to propose a general method to generate semantic adversarial examples by using advances in differential rendering and inverse graphics. \n\nPros:\n1. Generally, the presentation is clear and easy to follow.\n2. A general way to transform any pixel-attack algorithm to its \u201csemantic version\u201d is novel.\n\nCons:\n1. There are already a lot of ways to make adversarial examples even semantic adversarial examples. It\u2019s not enough to just propose a new way to make adversarial examples. I think this paper would be more compelling if proposed SAEs have some special property (e.g, easy to take effect in the real world or stronger robustness against defense strategy).\n2. In section 5.3, the authors show that data augmentation using SAEs increase the robustness to SAEs, but pixel perturbation AEs do not. This result is of little value. It is obvious that data augmentation using SAEs can increase more robustness to SAEs or pixel-perturbation AEs can increase more robustness to pixel-perturbation AEs. The authors are suggested to compare changes in general robustness caused by two types of data augmentations. For example, compare minimum adversarial distortion."}