{"rating": "3: Weak Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This paper proposes to generate \"semantic adversarial examples\" (SAEs) by applying small perturbations in the semantic space, by contrast to more standard adversarial examples that apply perturbations to the image intensities. The concept of SAE has already  been considered in a few papers (where for example the color distribution of the images are changed). \n\nWhat the paper proposes is to consider small perturbations of the parameters of a scene. For example, a car can be slighted rotated in 3D, or its color changed, without changing its 2D bounding box. If the perturbation is differentiable, and with a differentiable rendering, it is possible to generate SAEs with optimization algorithms that generalize algorithms developed for \"classical\" adversarial examples (FGSM and PGD).\nIn practice the perturbations are performed by using the method from Yao et al. \"3D-Aware Scene Manipulation via Inverse Graphics\" (NIPS'18).\n\nThe paper shows that their SAEs disturbed an object detection method (SqueezeDet), and that training SqueezeDet with SAEs improves its robustness to their SAEs.\n\nI found the paper interesting, however I am not convinced by the general concept:\n* While the method from Yao et al is supposed to work on real images, it requires to detect and estimate the pose and the shape of 3D objects, which is still challenging to do on real images. This is probably why the paper considers only synthetic images (VKITTI), to be able to generate a large number of SAEs.  \n\n* The generated images are also valid images, in the sense that for a slightly different scene, they would have been generated by the image renderer used for VKITTI. It sounds more like what the authors have is a method that can generate scenes to improve the performance of an object detector when trained on synthetic images, rather than a method  to be more robust to malicious attacks. This is very interesting, however the paper is not branded toward this  application."}