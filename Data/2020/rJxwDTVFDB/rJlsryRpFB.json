{"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "Authors consider dropout as MAP for conditional model and consider different types of averaging to obtain predictive distribution p(y|x, theta) during inference stage. The paper proposes power mean family and shows that well-known types of MC averaging (arithmetic and geometric) are particular cases of proposed family. Authors show that power mean family objective is lower-bounded by the original dropout lower-bound. Therefore it is consistent to use original dropout on the training stage and do any kind of averaging from power mean family during inference stage.\n\nConcerns:\n1) In general, paper is hard to follow and main motivation of the accomplished work is not clearly stated in the paper.\n2) One of the most confusing things about this paper is the analysis of the lower bound tightness. The authors state that the quality of fit for models in the power mean family depends on the Jensen gap ln(E[L]) - E[ln(L)] where L = p(y|x, w). This gap reflects the difference between the training objective and the objective which is used at the evaluation stage. From this perspective the expectation for the second term E[ln(L)] (which corresponds to the training objective and is the same in all settings) is fixed because we change the dropout scheme only in the inference. Therefore, the Eq. 10 for the gap from this paper is misleading. From this equality the authors derive that reducing the variance leads to decreasing the gap. However, from the Bayes inference it is known that the zero gap between the training objective and the one at evaluation will be reached when we use expectation with respect to the true posterior distribution on the model weights given training data. The authors however claim that the gap is zero when deterministic dropout (that is weight scaling rule) is used. This would be true if we used the same deterministic objective during training stage (that would correspond to no dropout). But we use expectation wrt non-degenerate noise distribution during training and at evaluation stage we take expectation wrt degenerate distribution (i.e. apply deterministic mode). Since the distributions are different we cannot conclude that the gap is zero. Moreover it can be even negative. Hence the statement about zero gap and justification of deterministic mode seems to be wrong. \n3) Experiments results are also hard to follow. In Tables 2, 3, 4 the differences in metric values are insignificant and there are no error bars. From such empirical results it is difficult to draw any conclusions. \n\nOverall, the motivation of the paper is not clear, the analysis for the lower bound tightness and following conclusions are misguided and experiments results are unconvincing. Therefore, I would suggest rejecting the current version."}