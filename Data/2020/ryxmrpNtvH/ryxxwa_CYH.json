{"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper studies weight sharing in neural architecture search (NAS). It constructs a mini search space with 64 possible choices, and performs various comparisons and studies in an exhaustive way. Some of the observations are quite interesting, exploring the limitations of weight sharing.\n\nMy biggest concern is the limited search space. Unlike other NAS works that usually have search space size > 10^10, this paper focuses on a very small search space (64 options in total). Because the search space is so small, a small change in any search option might cause a big difference for the sampled model, which possibly lead to some of the instability observed in this paper (such as observation 3 in Section 3.2 and the implication \"training a child model can easily perturb the rank of the previous mini-batch in section 4.1). However, this might not be true if the search space is big, where changing a few search options may not affect the supernet significantly.\n\nIt would be great if the authors can perform similar study on a larger search space. If evaluation for large search space is difficult, you may consider some pre-defined accuracy lookup tables (such as NAS-Bench-101: https://arxiv.org/abs/1902.09635).\n"}