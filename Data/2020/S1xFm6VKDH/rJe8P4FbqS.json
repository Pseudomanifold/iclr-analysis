{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review": "The authors describe MMN meta module network hybrid approach to visual reasoning combing the neural module network with explicit multi-hop hand crafted reasoning. The proposed method parses the input into functional program using a recipe encoder, resulting in instance modules, after which a teacher-student framework is used to exploit scene graphs to provide guidelines for instantiated modules for the student to follow. The authors leverage the prior work from Hudson and Manning, Dong and Lapata and , Vawani et. al. The authors describe the method in visual diagrams and supporting experiments on GQA data set, comparing against state of the art, detailed impact of attention, teacher network (module) and bootstrap, culminating with results on error analysis on difference functions and the ability to cope with unseen functions.\n\nThe improvement points for the paper are\n1. The results in Table 1 are not the best throughout after discounting the MCAN/NMN/NSM (for e.g. BAN and LGCN are better in one each), the authors didn't discussed this\n2. The authors mention that the results in NSM are hard to compare as it uses well-tuned external scene graph generation model, what if the authors employed a similar model in their setting for scene graph generation \n3. The method  uses teacher/student network for module supervision but it's training/setup is left undescribed in results section (table 1)\n4. the guideline in table 2 needs definition \n5. For the described functions in figure 9, how the arguments are chosen (from multiple possibilities) and once a single argument is chosen, how the execution graph is obtained needs some explanation. If a parser is employed what are the details? and then the additional coverage in results\n"}