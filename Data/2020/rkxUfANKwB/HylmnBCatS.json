{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper presents a VAE-based method to predict molecular properties as well as to design a novel molecular architecture.\nThe method employs as a basic input the SMILES representation of molecules which are not well defined in terms of the representation, though.\nTo tackle the issue, the authors formulate the method based on (1) multiple inputs of SMILES strings, (2) the character-wise feature fusion across those multiple strings and (3) network training by multiple output targets of SMILES strings different from the input ones.\nAs a result, the method provides the fixed-length latent representation which is robust against the variations of the SMILES representation and is useful for predicting the molecular properties and optimizing the molecular design.\nThe experimental results on the tasks of the property prediction and molecular optimization using the benchmark datasets demonstrate the effectiveness of the proposed method in comparison with the others.\n\nThough this paper provides some contributions to the field of molecular graph representation, it contains flaws in presentation, lacking details of technical contents; thus, the paper is regarded as \"borderline\". I would like the authors to properly provide the details in the following points.\n\n* This paper lacks some important technical contents, making it hard to understand. \n- What is the actual form of the property predictor used in p(\\rho|z). And, in the first place of the paper, it would be better to explain what kind of and how many properties of the molecular are considered.\n- How is the decoder constructed and trained? Though the authors state that a single-layer LSTM is employed as the decoder, there is no clear description how to cope with the multiple outputs (decoder targets) in training the LSTM.\n- What does \\theta in p_\\theta(z) mean? In the VAE, p(z) works as a simple prior on z.\n- The description, especially in Sec. 3 for the proposed method, is rather poorly presented by using less amount of math. At least, the authors should first depict the overall architecture of the method through clarifying the above-mentioned technical points.\n- It is unclear how to apply the proposed method to the semi-supervised learning framework? Is it re-formulated in the SS-VAE [a] framework?\n- The comparison experiments seem to be inconsistent. The proposed method is compared with different methods in different datasets/tasks. Toward fair comparison, it should be evaluated in comparison with some baselines including such as JT-VAE consistently.\n\n[a] Kingma, D. P.; Mohamed, S.; Rezende, D. J.; Welling, M. Semi-Supervised Learning with Deep Generative Models. Proceedings of the 28th Annual Conference on Neural Information Processing Systems. 2014; pp 3581\u20133589.\n\n* The authors cope with the fluctuations regarding the SMILES representation by means of RNN. There, however, are some approaches to canonicalize the SMILES representation itself such as by canonical SMILES. The authors have to mention those other approaches and discuss the superiority of the method over them; hopefully the proposed method should be compared with the naive one simply combining VAE [Kang&Cho18] and canonical SMILES representation. And to further understand the difficulty in SMILES variations, it would be better to show the averaged cardinality of SMILES representation per molecular.\n\n\nMinor comment:\n* In aggregating the RNN features for each character in SMILES strings, it might be possible to incorporate some structural knowledge into the process; for example, \"C\"s in benzene share the identical feature representation through fusing all those features."}