{"experience_assessment": "I do not know much about this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review": "The paper tackles the challenging problem of transfer learning and few shot learning in RL setting and provides some theoretical guarantees for the downstream task coverage. \n\nThe paper structure can be further improved by adding a background subsection on successor representation (SR) in RL; SR is not a very well known representation in RL and a brief subsection on that can help the reader in understanding the motivation behind using it. In terms of related work ,another work which can also be mentioned (although not directly related) is \u201cDARLA: Improving Zero-Shot Transfer in Reinforcement Learning\u201d which also uses disentangled representations for zero-shot transfer learning. The paper also needs to be more clear in terms of contributions; it seems that there is a significant overlap between this work and (Barreto et al., 2017, 2018); some clarification would be helpful here. \n\nIn terms of empirical results; the authors can also compare with other transfer learning methods in deep RL such as Hansen 2019 or Nair 2018 or explain why these are not reasonable baselines. Also the results for DIAYN are a bit surprising to me since in all the experiments the performance of the method is underwhelming; this is especially surprising because in the original DIAYN paper the method performed well in reasonably complex tasks. Can you provide an intuition on why DIAYN performs poorly even in the agent tasks. "}