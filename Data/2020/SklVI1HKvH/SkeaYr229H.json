{"rating": "3: Weak Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #4", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review": "The paper deals with a task of learning latent representations for 3D point clouds by introducing a series of particular point cloud decoders. The advantage of the proposed architectures is their ability of producing variable-size output 3D point cloud. While the work on point-based architectures is relevant to the current agenda in the vision community, the novelty of this paper is somewhat limited, as the proposed architecture is constrained to one class (PointNets) only, while the decoding network could just as easily be used with other encoders (e.g., DGCNN [1]). \n\n\nMajor comments:\n\nOne major shortcoming of the paper is its very limited experimental evaluation, that does not really allow to judge whether the proposed decoder architecture brings the real utility for most problems. For instance, authors only provide results for two distinct experiments: building an auto-encoder and understanding how each architecture uses noise. Much more tasks, such as shape denoising, upsampling, completion, or retrieval could have been explored, too. Only one (simple) dataset is used, i.e. ModelNet, whereas more complex datasets (e.g., ShapeNet, ABC, or datasets related to human shapes) could have been considered.\n\nI wonder why authors didn't compare to (or even cite) [1], which seems to be one of the earliest papers in the area. \n\nOther possible research questions are as follows. What is the effect of the proposed decoder networks on the learned latent representations in the entire architecture? Will the interpolatory and semantic properties of the learned latent spaces be preserved when using the autoencoders? \n\nHaving said that, I believe the paper cannot be accepted in the present form, however, I would change my decision, should more experiments validating the architecture be provided. \n\n\nMinor comments:\n\n* in definition of a point cloud, both n and N are used to indicate its size\n\n\n[1] Wang, Y., Sun, Y., Liu, Z., Sarma, S. E., Bronstein, M. M., & Solomon, J. M. (2019). Dynamic graph cnn for learning on point clouds. ACM Transactions on Graphics (TOG), 38(5), 146.\n[2] Achlioptas, P., Diamanti, O., Mitliagkas, I., & Guibas, L. (2018, July). Learning Representations and Generative Models for 3D Point Clouds. In International Conference on Machine Learning (pp. 40-49)."}