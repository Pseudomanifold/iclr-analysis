{"rating": "3: Weak Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "In this paper, the author derived a tight ell_1, which is not the symmetric norm, robustness certificates under isotropic Laplace distributions. Experimentally, the authors showed that the deep networks smoothed \nby Laplace distributions yield the state-of-the-art certified robustness in ell_1 norm on the CIFAR-10 \nand ImageNet. To find the ell_1 certificate, the authors first identified the tight robustness certificate, for attacking the model in one particular direction, say the first direction. To show that any other perturbation directions cannot lead to a worse result, the authors convert the d dimensional likelihood function into a one-dimensional function, and the authors used relaxation for different perturbations and show that the worst-case result is bounded by the previously identified direction.  However, I have the following concerns about this work:\n\n1. Theoretically, the authors only showed the certificate is tight for binary classification. I would suggest\nthe author change their claim in the abstract.\n\n2. What is M on page 3 which is used without definition after definition 1?\n\n3. Can you give a concrete continuous probability distribution that leads to the scenario in Fig.~3?\n\n4. Can you extend the analysis to a multi-class classification scenario?\n\n5. Besides randomized smoothing on the input images, recently Wang et al showed that randomize the deep nets can\nalso improve the deep nets and they gave it a nice theoretical interpretation. Here is the reference: Bao Wang, Binjie Yuan, Zuoqiang Shi, Stanley J. Osher. ResNets Ensemble via the Feynman-Kac Formalism to Improve Natural and Robust Accuracies, arXiv:1811.10745, NeurIPS, 2019\n\nOverall, since this work is a straightforward integration of some existing work, I think this\npaper lack novelty. Please address the above questions in rebuttal."}