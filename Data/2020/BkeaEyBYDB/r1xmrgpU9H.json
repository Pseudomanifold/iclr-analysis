{"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The main contribution of this paper is to notice the connection between Federated Averaging (FedAvg) and Model Agnostic Meta Learning algorithms (MAML). Authors also consider an algorithm that first trains with FedAvg and then continues training using Reptile.\n\nPros:\n\nInterpretation of FedAvg as a meta-learning algorithm is interesting.\n\nCons:\n\nVery limited methodological contribution. Proposed algorithm is essentially two existing algorithms applied one after another.\n\nExperiments are not conducted rigorously enough. There are many arbitrary hyperparameter choices which may bias the conclusions made in the paper. Statement \"We tried SGD with a range of other learning rates, and in all cases we observed this value to work the best.\" is alarming suggesting that authors tried a variation of settings observing test data performance and reported a few selected runs. Although \"each experiment was repeated 9 times with random initialization\", the train/test split of the clients was fixed. Randomizing over client train/test split could help to improve the reliability of the results.\n\nEMNIST-62 is the only dataset analyzed in some detail. This dataset has drastically varying P(y|x) across clients, i.e. some people write zeros as some others write 'o's. This suggests that it is very hard to train a good global model and personalization is necessary. However this doesn't mean that Shakespeare dataset \"does not provide any interesting insights\". Perhaps, it is indeed more interesting and challenging, demanding more advanced methodology.\n\nIn Figure 1, number of communication rounds may be impractical for FL (considering also addition 200 Reptile rounds). On Shakespeare, FedAvg paper reports 54% accuracy achieved in under 50 communication rounds in one of the settings. There are also recent works on improving communication efficiency that were not discussed or studied for personalization quality, e.g. FedProx from \"Federated Optimization in Heterogeneous Networks\" and PFNM from \"Bayesian Nonparametric Federated Learning of Neural Networks\".\n\nQuestions about Figure 2 experiments:\n1. Fine-tuning requires 200 extra epochs over the initially trained model. What's the initial model accuracy when FedAvg is further trained with Adam optimizer for 200 extra communication rounds?\n2. The personalized test accuracy with FedAvg and Reptile fine-tuning reaches the same value in 10 update epochs, even when Reptile fine-tuning gets 200 extra initial training epochs. Does Reptile fine-tuning provide additional benefits to the initial model as compared to running FedAvg for more number of epochs?"}