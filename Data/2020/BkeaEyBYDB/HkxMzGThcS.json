{"rating": "3: Weak Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #4", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper studies the application of techniques from meta-learning (a method\nto train a single model which can then be easily adjusted to perform well on\nmultiple tasks) to federated learning (the task of distributed training of\nmodels on distributed datasets).  The paper notes that standard meta-learning\nalgorithms are similar to standard federated learning algorithms, and uses\nthis perspective to produce a merged method and evaluate it empirically.\n\nPros.\n+ The motivation of the paper is clear and indeed these methods seems similar,\n and meta-learning can help with federated learning.\n\nCons.\n- The resulting method appears somewhat underdeveloped; it is simply to run\n some amount of federated learning and then some amount of meta-learning,\n whereas the first parts of the paper led me to believe that a single\n simultaneous merge of the methods is the way to go.  The paper does not\n report any fine-grained evaluation of various such choices, thus I don't know\n why they did that they did, and thus do not find their choices compelling.\n- The Reptile method is already presented in the original paper with\n a distributed counterpart, so why not just run that?  I am not convinced that\n some more minor modification of Reptile could not already do well on this\n paper.\n- The empirical evaluation is not very extensive, so I am also not convinced\n there, and in particular I need convincing of this type to believe that\n regular reptile is beaten by FedAvg+reptile.\n\nMinor comments.\nPage 1, second paragraph, the word \"outperform\".  I'm not sure what the\nperformance measure is; in federated learning, we care about many things, for\ninstance privacy, keeping the work on the distributed clients low, etc.\nPage 2, the \"three objectives\".  I feel meta-learning is doing all three too.\nPage 3, Algorithm 1.  I realize space is a concern, but this was hard to read.\nPage 4, Algorithm 2.  \"relatively larger\" is vague."}