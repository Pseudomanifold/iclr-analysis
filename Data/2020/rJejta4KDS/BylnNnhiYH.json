{"rating": "3: Weak Reject", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This paper proposes distillation attacks to generate transferable targeted adversarial examples. The technique itself is pretty simple: instead of only using the raw logits L(x) to compute the cross entropy loss for optimization, they also use the distilled logits L(x)/T to generate adversarial examples. Their evaluation setup largely follows the style of Liu et al., but they construct a different subset of ILSVRC validation set, and some of the model architectures in their ensemble are different from Liu et al. Their results show that by including the distilled logits when computing the gradient, the generated adversarial examples can transfer better among different models using both single-model and ensemble-based attacks.\n\nI think their proposed attack is interesting due to its simplicity and effectiveness. However, I would like to see clarification of some evaluation details, as well as more experiments to compare with Liu et al.:\n\n1. To assess the effectiveness of targeted attacks, it is important to ensure that the semantic meaning of target label is far from the ground truth label. Some of the 1000 ImageNet labels have very similar meanings to each other, thus different choices of the target label would dramatically affect the difficulty of the attacks. In Liu et al., they manually inspect the image-target pairs to ensure that the target label is very different from the ground truth in its meaning. To enable a fair comparison, it would be helpful to provide results on the same image-target pairs constructed by Liu et al., which could be found in the public repo linked in their paper.\n\n2. For ensemble attacks, is including both the raw and the distilled logits crucial in obtaining a good performance? What is the performance of including distilled logits only? How do different values of \\lambda_1 and \\lambda_2 in (8) affect the attack performance?\n\n3. Could you visualize some generated adversarial examples, so that we can view the qualitative results?\n\n4. In general this paper lacks empirical analysis on why distillation helps improve the transferability. Some more discussion would be helpful."}