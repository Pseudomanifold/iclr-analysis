{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This work explores the problem of WSL -- in particular, learning to segment with only global labels. The contributions are mainly two-folded. (1) An novel design of regularization terms that promotes the identification of relevant and irrelevant regions for global classification. (2) An recursive erasing algorithm to predict those two types of regions. \n\nPros:\n1. The writing is clear\n2. The literature review seems thorough\n3. Segmentation results provide ample evidence\n\nCons:\n1. The global classification results are not convincing enough to claim \"significant improvements in terms of image-level classification\", as stated in the paper, according to the experiments.\n2. There's a missing link between \"false positive reduction\" claims and the proposed algorithm. The design of the entropy-based loss terms does not seem to directly address this, but covers both false positive and false negative scenarios. Equ (10) used in Algorithm 1 (in the appendix) seems to explicitly reduce false negatives with as it iteratively adds relevant regions that are missed with a max operation.\n3. Using multiple iteration for the mask prediction model seems to experimentally perform better. Without any theoretical analysis, it is however not clear why this is the case at least intuitively. Each step depends on the previous one and could be facing the problem of error accumulation over time (e.g., at the first step, the relevant regions could already been erased). It is hard to imagine how the mask model can produce a better output with simple global classification objectives.\n4. Section 2 is thorough but not entirely clear on the difference between the proposed methods and existing ones. For instance, (1) the following claims are not clear: \"... but places more emphasis on mining consistent regions, and being performed on the fly during backpropagation...\". What is \"consistency\"? What is \"on the fly\"? (2) \"... provide automatic mechanism to stop erasing over samples independently from each other...\" What is the automatic mechanism? What does \"samples independently\" mean? (3) \"...To avoid such issues, we detach the upscaling operation...\" If the upscaling op is not parameterized by the model, what is its formulation?\n5. DICE and F1 score seem to be computed with a threshold of 0.5. Is that an optimal choice? To make the evaluation independent of the threshold, one could use the continuous version of DICE instead.\n6. With small datasets, one would expect to see confidence interval/standard error on the results table, with multiple runs of the same experiments, for instance."}