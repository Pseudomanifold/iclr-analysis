{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper proposes a deep neural network for weakly-supervised pointwise localization. The authors formulate it using conditional entropy that separates relevant and irrelevant regions for classification, which is different from typical attention maps that are prune to false positive. The architecture consists of a localizer and a classifier, where the localizer is designed to separate relevant and irrelevant regions (in a CAM-style) guided by the conditional entropy loss. Experimental results show good results on three benchmark datasets including one medical and two natural datasets.\n\nThe proposed formulation and architecture is interesting in the sense that it explicitly models foreground and background separation. But, I have serious concerns about the positioning of this paper and the experimental evaluation as follows. \n\n1) Weakly-supervised point-wise localization? \nThe problem this paper tackles, called weakly-supervised point-wise localization in this paper, actually appears to be the problem of weakly-supervised semantic segmentation; the proposed loss and architecture are specifically designed to separate the foreground from the background. While this paper cites many of weakly-supervised semantic segmentation, the authors do not name their method as one of them, which looks strange to me. I think the title, introduction, and related work need to be revised more explicitly referring to weakly-supervised segmentation.  \n\n2) Experimental comparison\nThe authors compare their methods mostly to visual attention (or explanation) methods, e.g., CAM variants, avoiding direct comparison to recent weakly-supervised segmentation methods. And, the motivation for choosing their particular dataset and evaluation metrics is also unclear. If they want dataset with \"both image and pixel-level labels\", then the standard benchmarks for semantic segmentation, such as PASCAL VOC or COCO would be a natural choice.  Otherwise, if the authors want to present their work as visual attention or explanation methods such as Grad-CAM, then they should have evaluated it in the corresponding evaluation benchmarks (e.g., using pointing game). I recommend the authors evaluate their method on standard semantic segmentation benchmarks. \n"}