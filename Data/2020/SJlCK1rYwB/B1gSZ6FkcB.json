{"experience_assessment": "I have published in this field for several years.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "The paper essentially explores variants of reweighing training samples based on how much they are captured by a bias model (i.e. hypothesis only in NLI). The most effective method, product-of-experts, involves ensemble based training of a bias only model and a full model (i.e. for SNLI, bias = hypothesis only, full = hypothesis+premise).  At test time, the bias model is removed and only the full model is applied. The ideas are simple and largely effective, given that a bias model can be formulated / is known ahead of time. \n\nThe paper has significant overlap with Clark et al. @ EMNLP 2019 ( https://arxiv.org/abs/1909.03683 ) and He et al. (  https://arxiv.org/abs/1908.10763. )  I am unsure what the ICLR policy is on concurrent submission, but this work does expand somewhat on that work, experimentally. If this ICLR submission doesn't fall within the grace period I would likely reduce my score. \n\nThat being said, this work does have a set of experiments different than those produced in concurrent work, showing results on SNLI hard and FEVER. Furthermore, the paper presents a debiased focal loss, which, while not as effective as ensemble based training, is an interesting baseline to consider.  \n\nOverall, the work is good and in an interesting direction, caveat being that several other concurrent works @ EMNLP exist exploring exactly the same idea. \n"}