{"rating": "1: Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This manuscript introduces a general framework to deal with bias(es) in the datasets. The authors propose a bias-only model designed to capture biases in the data. The authors claim that performance of the bias only branch influences the overall cross-entropy loss which leads to learning bias-free models. \nThe paper is on a very interesting topic, but it lacks proper methodological motivation, discussion, and backing up of the claims. Furthermore, the experiments only show accuracy results, while one expects to see a set of experiments demonstrating how the bias was actually removed from the target learned model. \n\nThere are some major concerns on this paper: \n-\tThe proposed methods all operate on the last loss component on how to combine the loss of the bias branch and the one coming from the actual model. The authors hypothetically mention that with this combination the model will learn to remove the bias-contaminated features from the model side because the bias branch already has them. This is very hypothetical and there is no guarantee to it. There is no regularization to make the model branch avoid the bias-contaminated features. There is absolutely no theoretical nor any experimental studies on this issue in the paper. Models are pretty much prone to cheating. They will cheat if they can. If there is a bias in the dataset, the model will capture it and cheat, even if it leads to redundant information coming from the bias side. \n-\tThe second important shortcoming of the paper is lack of proper experiments to back up the claims in the paper. Experiments only show simple accuracy results with our without bias. But the authors keep claiming that their model learns to remove the bias. If that is the case, correlation analysis between the features learned from the model branch and bias terms/variables is missing. Also, there is no direct comparison on how each of the three proposed losses differ from each other in removing the effects of the bias. \n-\tThe authors show in the experiments that their proposed model is better than the hypothesis-only model. This can only be attributed to the fact that info from the premise and in general the added meta-data help the learning framework to learn better features as it is regularized better (and constrained more). This does not mean that the bias is removed from them. There is no discussion or experiments on this issue. \n\nMinor:\n-\tThe proposed models are all similar in terms of modifying the final loss function of L_C, how the outputs of B and M models are ensembled. It may not be a good idea to keep claiming that several different methods are proposed in this paper for dealing with bias. Nature of all methods is the same.  \n-\tFigure 1 that is the introduced in the introduction and referred to ever after is not clear and self-contained. One cannot understand it until they read until the end of the method section. \n-\tThere is no theoretical analysis or discussion on why the proposed loss functions should be able to remove bias!\n"}