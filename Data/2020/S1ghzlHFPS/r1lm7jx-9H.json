{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "Review for Temporal Modeling via Logical Specification of Factorial\nLSTMs\n\nThis paper addresses a key problem in machine learning: how to control\nthe inductive bias of a model in an interpretable way.  The paper\ncontributes a Datalog-based language that allows a human to hand-code\nstructural assumptions (typically based on domain knowledge) that are\nautomatically translated into sparsity patterns in the parameter\nmatrices of an ML model (in this case, a neural Hawkes process,\nalthough the idea would [probably] generalize to other cases).  The\nlanguage plus structured-neural-Hawkes process is demonstrated on a\nfew very small problems, with mixed results.\n\nThis paper is borderline.  However, I tend to favor rejection because\nwhile the ideas are very interesting (and potentially impactful),\nvalidation of the claims is weak.\n\nContributions:\n\nOn the positive side:\n\nA Datalog interface to specifying structural zeros in parameter\nmatrices is a good idea.  The language is natural, and the high-level\nmapping from structure and objects to low-level parameters seems\nreasonable and potentially useful.\n\nThe method makes it easier to specify an inductive bias.  This is a\nstep in the right direction; but at its heart, this paper does not do\nanything that couldn't have been done by hand - it only makes it\neasier.\n\nThe method is potentially more interpretable than other attempts at\ncontrolling inductive bias (for example, simple weight regularizaion),\nbut see below for why this might be a red herring.\n\nThe paper is very nicely written.  It's clear that a lot of attention\nto detail went into writing it.  Well done.\n\nWeaknesses:\n\nThere are a few major points to criticize about this paper.\n\nFirst, there is no clear learning or prediction benefit.  The results\nare mixed: while it appears that the SHP learns faster than the\nunstructured HP, they appear to be asymptoting at the same point.\nThis is perhaps to be expected, as the structural zeros introduced by\nthe corresponding Datalog program effectively reduce the parameter\ncount, but the shape of the learning curves is unchanged.\n\n(Also: please include error bars in Fig. 2(a1) and 2(a2))\n\nThe proper comparison would probably be to a low-rank parameter\nmatrix, where the parameter count is similarly reduced, but in an\nunstructured way.  That would allow us to disentangle \"parameter count\nreduction\" from \"inductive bias\", which is currently not done in the\npaper. \n\nThe results in Figure 3c are mixed - it appears that SHP is only\nbetter in 1/4 of the cases; in all other cases, the error bars seem to\nindicate that there is no predictive power.\n\nFinally, I am concerned that the method may give a false sense of\nexplainability to the model - why it is true that a highly structured,\nsymbolic language is being used to craft an inductive bias, there is\nno \"symbol grounding\".  That is, there is no guarantee that the neural\npart of the learning algorithm will use the parameters in the way the\nhuman intended it to, because the parameters are ultimately\ndisconnected from the symbols.\n"}