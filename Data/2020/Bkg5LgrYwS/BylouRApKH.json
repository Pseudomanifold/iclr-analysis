{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "*Summary \n\nThe paper describes a new end-to-end imitation learning method combining language, vision, and motion.\nA neural network architecture called Multimodal Policy Network is proposed. That can extract internal representations from language and vision to condition the generated motions. \nIt enables an end-user to influence a robot's policy through verbal communication.\nThe experiments demonstrate the generalization performance of the method. That can generate behaviors towards different goals depending on different sentences. \n\n*Decision and supporting arguments\n\nI think the paper is just below the borderline. The reason is as follows.\n\nThe concern is about evaluation. They demonstrated the method could work, and the robot can move to appropriate goals. However, there is no comparative methods in the experiment.\nRelated to this point, the problem was not identified in the Introduction.\nThe authors might assume that introducing language into behavioral cloning itself is qualitatively new work. However, such a study has a long history. \nFor example, please refer to Tani's pioneering works.\nSugita, Yuuya, and Jun Tani. \"Learning semantic combinatoriality from the interaction between linguistic and behavioral processes.\" Adaptive behavior 13.1 (2005): 33-52.\n\nThe author should specify a current challenge or problem in pre-existing studies about imitation learning with language input, clarify their claim, and give empirical support for the claim.   \n"}