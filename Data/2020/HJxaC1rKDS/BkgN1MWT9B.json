{"rating": "3: Weak Reject", "experience_assessment": "I do not know much about this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "The authors propose to tackle imbalance classification  using re-sampling methods. The idea is to generate adversarial examples of a model trained on the imbalanced dataset, in the least frequent classes.\n\nTo the best of my understanding the rational behind this is that models usually overfit the least frequent class. Hence adversarial examples in the minority class would help to train a new model that generalize better.\n\nQ1. If a model is trained to perform well on the class-imbalanced dataset and is robust to adversarial attacks / does not overfit the minority classes, what would happen?\n\nMy decision is weak reject for the following reasons.\n\nWhile the idea seems appealing, intuitive ideas on why such a methodology should work. Moreover rather than trying to give more understanding on why such a methodology works, the experiments only illustrate that the propose algorithm outperform the state of the art. While such positive results are always welcome, it is also useful to propose experiments to gain a better understanding on the performances/limits of an algorithm.\n\nAlso, the proposed algorithm depends on some hyper-parameters that are never empirically nor theoretically studied.\n\nSuggestions\n-----------------\nwhile it is nice to report standard deviations, the authors could increase the number of runs to make the differences more significant and eventually provide a statistical test. "}