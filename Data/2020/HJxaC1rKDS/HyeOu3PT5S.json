{"rating": "3: Weak Reject", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This manuscript proposes an over-sampling method for dealing with the imbalanced classification and long-trailed problems. The authors refer to their work as Advserarial Minority Over-sampling (AMO). \n\nThe interesting aspect of this paper is that it explores adversarial perturbation (possibly of majority class) as a means of over-sampling for the minority class. The findings suggest that it could improve imbalanced learning. However, there are several major issues with the paper in its current form:\n-\tThere is a recent publication with almost the same topic in ICCV 2019 that also explores using adversarial minority over sampling frameworks (published on arxiv on Apr 3, 2019 https://arxiv.org/pdf/1903.09730.pdf). Although that one is a bit different methodologically, the authors have not mentioned it, compare with it, nor discussed it. It is not clear where the current manuscript stands in comparison with the ICCV 2019 paper. \n-\tGiven the above paper, the novelties of the proposed technique become marginal. \n-\tAnother major issue with the paper is its methodological limitations. As the authors have also mentioned, it looks a bit like learning to classify the adversarial examples. It seems like this is a very effective method if we want to classify a majority (normal) class versus a minority (anomaly) class. Because when the model generates adversarial examples for any specific class the adversarial examples may cover all space of the samples minus the samples of that (normal) class. Therefore, the model does not learn the geometry of the minority class (as opposed to many state-of-the-art long-trailed classification models) and only learns the majority class. This is not itself a positive characteristic. \n-\tThe authors have not provided any theoretical discussions/guarantees why adversarial examples should be a good means of learning the imbalanced distributions. Everything in the paper seems to be experimental and heuristic. \n-\tThe accuracy metric provided by the authors is a bit misleading. For these cases of long-trailed classification models, Average Class Specific Accuracy and Geometric Mean (analogous to F1-score) are the most relevant ones to report, especially because experiments are conducted on multi-class settings. \n-\tThe results in Table 2 show a highly imbalanced classification rate between majority and minority classes. This means that neither the proposed method nor the baselines could solve the problem. The differences between the proposed method and the baselines do not seem to be statistically significant. So, what is the purpose of this experiment!? \n"}