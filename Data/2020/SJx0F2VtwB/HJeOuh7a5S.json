{"rating": "3: Weak Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "The authors study the problem of conversational QA, proposing SDNet, a neural architecture based on RNNs, several levels/types of attention (as with many QA models), and a novel module for incorporating the contextualized embeddings of BERT. Specifically, as in DrQA+PGNet, previous dialogue turns are prepended to the current question and passed into an encoding layer than includes static word embeddings (GloVe) and pre-trained contextualized embeddings. The resulting representation is passed to an integration layer based on RNNs with self-attention on the context/question representations and inter-attention between then. Finally, the output layers relies on a bilinear projection to compute the probability of candidate answer spans. [Obviously, there are technical details (that are described fairly well in, and is the bulk of, the paper)]. Experiments are conducted on CoQA, showing improvements over FlowQA (and other baselines), presumably the state-of-the-art when this paper was written. Ablation studies show that the specific method of incorporating BERT (weighted sum per-layer) and incorporating dialogue history are important in achieving the stated performance.\n\nGiven when this work was completed (and the paper written), it was ostensibly the state-of-the-art at the time. However, this is ~9 months from when this paper was submitted \u2014 so some of the impact of the empirical results have been attenuating in publishing. When written, the most significant novel contribution was likely the method used for incorporating BERT and combining different embeddings. However, given new contextualized embeddings developed since then, many works incorporating contextualized embeddings with several different strategies, and now knowing that ~1.5% isn\u2019t that large of a jump on this dataset makes this contribution seem more marginal than when published. I am fairly certain that this could have been revisited between the original SDNet submission and now (and likely improving performance). Beyond this, the other neural components were fairly standard at the time of development and now are standard procedure \u2014 such that this doesn\u2019t seem very novel at this point. While it is somewhat understandable that the performance isn\u2019t state-of-the-art at the time of submission, it is likely necessary to contextualize this work within more recently developed work. Secondly, I would expect the authors to also evaluate their method on QuAC and complete a more thorough error analysis. Unfortunately, at this point, this paper has likely already had some impact, but seems to have missed its (time-sensitive) window for getting into a top-flight conference without continuing to innovate and be near the state-of-the-art at the time of submission and be appropriate situated. Thus, I recommend rejecting from ICLR as the paper simply reads like a resubmission that has missed its time (even if it is a nice paper in many regards).\n"}