{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "SUMMARY: Perform unsupervised/self-supervised image-to-label and label-to-image translation on the Viper dataset\n\nCLAIMS:\n- Perform self-supervised training\n- Have consistency in long-term style and short-term content\n\nLIT REVIEW: Sufficient literature review for the task at hand.\n\nDECISION: Good work, but paper needs a lot of improvement\n\nThe work done and effort put to get good results seem worthwhile. The idea is simple enough, but slightly hacky, in the sense that they use cycle-consistency in style domain (as is done with images in a lot of literature), but improve upon RecycleGAN by adding a recurrent neural network to consume multiple frames instead of just one. In addition, possibly to improve the representation learnt, they combine with an interpolation loss, which is another common idea in video literature. It seems like there needs to be a more coherent idea to string the work together. If it is a pure combination of different methods to make the results work, the authors can mention so.\n\nThe writing is not clear, and it seems hasty. A lot more time could have been spent on making the story clearer, having a better explanation of the method. The method seems to be explained in parts in the introduction and in later sections. It would be better to explain it fully in one section instead of in parts.\n\nIt is also not clear that there are two tasks being tackled - interpolation and translation - to achieve the overall objective, I had to realize it myself as I was reading. There is no clear explanation provided as to why interpolation is being done if the overall task is translation. It could be that interpolation is an excellent task to discover good content in videos in a self-supervised manner, but it is not mentioned anywhere in the paper.\n\nSufficient experiments have been done to prove that their method works better than previous methods, on the Viper dataset on translation between images and their semantic segmentation labels. However, the claims of being long-term consistent in style is not explicitly shown in a quantitative manner, it is only perhaps shown qualitatively. First of all, it is not clear what the authors mean when they say \"long-term\": how many frames is the threshold between short-term and long-term according to the authors? Since the translation task is conditioned on style, it need not be that the new style is \"consistent\" in the long term, it is simply conditioned upon. It is one way of tackling \"long-term consistency\", but not very satisfactory.\n\nThere are several mistakes in the content of the paper. The math used is very weak and unnecessary, In my opinion it is alright not to have detailed math, but it is not good to express it badly. The conditional formulations are very wrong, I would advise the authors to recheck the expressions.\n\nUnfortunately, it is not possible to verify how good the method is until:\n1) examples of the videos are shown, and not just images. This could be done by making a website and uploading example videos.\n2) the code is released.\n"}