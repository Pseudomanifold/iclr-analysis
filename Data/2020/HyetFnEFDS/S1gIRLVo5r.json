{"rating": "3: Weak Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #4", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "I. Summary of the paper\n\nThis paper describes a principled strategy for searching for the most\nsuitable neural network architecture out of a particular class of\narchitectures. Specifically, the problem is framed as an optimisation\nproblem over a set of directed acyclic graphs (DAGs) that correspond to\npotential network architectures. By optimising the edge weights of this\nrepresentation, a suitable architecture can be generated.\nIn addition to the aforementioned optimisation scheme, the paper also\npresents a regularisation that results in *sparse* networks, i.e.\nnetworks with a smaller number of edges. Multiple experiments on\n'tuning' existing architectures on several data sets conclude the paper.\n\nII. Summary of the review\n\nThis paper discusses a highly relevant subject, namely how to select\nneural network architectures in a principled manner. While the presented\nwork already goes into a good direction, I cannot give it my endorsement\nfor acceptance because of the following reasons:\n\n  - The paper is lacking clarity: concepts could be explained somewhat\n    better, and the paper is suffering from language/grammar issues that\n    make it harder to understand the contents.\n\n  - Lack of experimental or theoretical depth: the proposed method is\n    presented as-is; no theoretical analysis of its behaviour is\n    performed; while this is not necessarily a problem, as there are\n    several empirical experiments, the experimental section is not\n    sufficiently detailed: for example, no limitations of the method are\n    being discussed and the presented results are not state-of-the-art\n    accuracies.\n\nNevertheless, I want to point out that this paper has the potential to\nbecome an important contribution to the community; it is absolutely\nclear that more principled approaches are required to select network\narchitectures.\n\nIn the following, I will comment on the individual aspects in more\ndetail.\n\nIII. Detailed comments (clarity)\n\n- The abstract could be improved in terms of its logical flow. Instead\n  of trying to introduce new terminology (macro/micro etc.) here, the\n  abstract should rather state directly that this paper frames network\n  architecture selection as an optimisation problem over DAGs.\n\n- The use of topology is slightly non-standard here. What is the meaning\n  behind the 'macro' and 'micro' operations? This should be explained\n  somewhat better.\n\n- Figure 1 should be extended to show an example of how the depicted\n  graphs are described through the terminology mentioned in the paper.\n  For example, individual edges or nodes could be highlighted and\n  referred to in the text to make the 'mapping' clearer.\n\n- I do not understand how operations such as *addition* are represented\n  in the DAG. Ideally, this should also be elucidated by a figure.\n\n- When discussing 'intervals' of residual connections, I am assuming\n  that the paper refers to how many layers are skipped? If so, this\n  should be mentioned and defined explicitly.\n\n- The term 'searching space' should be replaced by 'search space', as\n  the latter is more standard usage.\n\n- I do not understand why the optimisation of the topology can decrease\n  the computational burden, as claimed on p. 2. The optimisation process\n  still has to be performed, just like the training of the network,\n  correct? Am I misunderstanding this?\n\n- The caption of Figure 2 could be extended; does a single node type\n  mean that the complete network only consists of nodes of that type?\n  Moreover, accuracies/errors should be shown in addition to the loss\n  curves.\n\n- The term 'dense connection' is vague; I think the paper should use\n  'densely-connected graph' here.\n\n- The sentence 'Among these nodes, [...]' refers to the *whole* network,\n  and not to the way the output tensor $\\mathbf{x}_i$ is processed. Am I\n  understanding this correctly?\n\n- I do not understand the initial sentences in Section 2.2; what is the\n  meaning of 'cell' in this case?\n\n- The term 'topological structures' should be renamed to '(sub)graphs'\n  in order to improve clarity.\n\n- I do not understand the comment on sparsity in Section 2.4. How are\n  'moderate sparsity' and Figure 2 connected?\n\n- In the algorithm, I would use 'Sparsity Type' instead of 'Sparse Type'\n  to refer to the parameter.\n\n- What does 'Complete' (without $\\mathbf{\\alpha}$) mean in Table 3?\n\n- The footnote below Table 3 is not referenced anywhere in the text or\n  in the table.\n\n- In Figure 3, are the adjacency matrices consistent? What happens if\n  the training process is repeated? It would be highly interesting to\n  show 'averaged' matrices over multiple runs.\n\nIV. Detailed comments (experiments & theory)\n\n- A theoretical analysis of the proposed method would be interesting.\n  Does the optimisation always converge? Are minima unique? What is the\n  computational complexity?\n\n  At least some of these aspects should be discussed.\n\n- The limitations of the proposed method are not explained. For example,\n  what is the meaning of the sentence on p. 2 about 'excluding the\n  influence of the mixture of different layers/nodes'?\n\n  It is my understanding that the proposed method can only change the\n  *connections* between blocks of a network, but not the type of layers.\n  Is this correct? If so, it would be a major limitation that should be\n  mentioned explicitly.\n\n- Another limitation that is not discussed is the scaling to very deep\n  networks. How problematic is it to model all potential connections in\n  such a network? Are there limits to the current optimisation scheme?\n  This needs to be assessed in the experimental section.\n\n- For all experimental tables, standard deviations and means should be\n  provided. This is necessary in order to assess the stability of the\n  proposed method, because there are multiple sources of stochasticity:\n  one arising from the optimisation procedure, the other one arising\n  from the training of the network itself.\n\n- The results reported for the experiments are somewhat behind the\n  state-of-the-art in terms of accuracy values. This should be stated\n  more clearly; I assume that it is caused by limitations of the\n  proposed method, which prohibit an application to very recent\n  architectures. Is this correct? If so, it should at least be\n  mentioned.\n\n- The claim that nodes at the start of a topological ordering contribute\n  more to specific stages needs to be (empirically) proven.\n\nV. Style issues\n\nThe paper is not easy to read because of several non-standard phrases or\nexpressions.\n\n- The phrase 'in topology' is often added to a sentence where it does\n  not entirely make sense. For example, '[The] architecture can be\n  expressed as a directed acyclic graph (DAG) in topology'. I do not\n  see the necessity of adding 'in topology' here. There are other places\n  at well from which I would remove this phrase.\n\n- 'effective networks' --> 'effective network architectures'\n\n- 'largely affects' --> 'largely affect'\n\n- 'Motivated by which' --> 'Motivated by this'\n\n- 'innovative method' --> 'method' (or 'novel method')\n\n- 'as a complete graph, through' --> 'as a complete graph, and through'\n\n- 'auxiliary sparsity constraint' --> 'an auxiliary sparsity constraint'\n\n- 'named as TopoNet' --> 'called TopoNet'\n\n- 'At initial periods' --> 'Previously' (I am not sure I understand\n  this correctly)\n\n- 'red signs' --> 'red arrows'\n\n- 'for its topology' --> 'in terms of its topology' (?)\n\n- 'both combining' --> 'both a combination' (?)\n\n- 'number of interval' --> 'number of intervals'\n\n- 'straight connected' --> 'directly connected'\n\n- 'conduct transformation' --> 'performs a transformation'\n\n- What is the meaning of the phrase 'These may cover the influence\n  [...]'? Is this a reference to limitations of existing networks?\n\n- 'opted from' --> 'chosen from'\n\n- 'Following two simple design rules' --> 'We follow two simple design\n  rules'\n\n- '1000-dimension' --> '$1000$-dimensional'\n\n- 'We raise two ways' --> 'We describe two ways'\n\n- 'consited' --> 'consisted' / 'consists'\n\n- 'deepen the depth' --> 'increase the depth'\n\n- 'origin' --> 'original'\n\n- 'promotions' --> 'improvements'\n\n- 'can make more profit' --> 'can be useful to improve performance' (I\n  am guessing this from the context)\n\n- 'sparseness on representation' --> 'sparsity'\n\n- 'Adaptive one' --> 'The adaptive one'\n\n- 'At the fore' --> 'At the beginning/start'\n\n- I do not understand the sentence about the 'free lunch'. Does it refer\n  to the fact that some connections can still be removed from the\n  network without decreasing accuracy?\n\n- 'less computation costs' --> 'lower computation costs'\n\n- 'shortcut offers' --> 'shortcuts offer'\n\n- 'benefits optimization' --> 'benefit optimization'\n\n- 'feasible way to the optimization' --> 'feasible way for the optimization'\n\n- Some references in the bibliography are not capitalised consistently"}