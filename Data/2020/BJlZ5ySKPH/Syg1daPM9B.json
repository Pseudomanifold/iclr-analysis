{"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "Summarize what the paper claims to do/contribute.\n* The paper proposes a new image-to-image GAN-based translator that uses attention and a new normalization that learns a proper ratio between instance and layer normalization. Experiments benchmark the new method against multiple prior ones, and on a number of dataset pairs.\n\nClearly state your decision (accept or reject) with one or two key reasons for this choice.\nWeak Accept\n\n* The paper was well-written and the method and contributions are clearly explained.\n* There is clear novelty in this paper, even if slightly limited. However, the newly proposed normalization seems to work quite well.\n* The results look good, however it is hard to compare methods quantitatively with only few samples. (Nothing that the authors could have done: there are many samples in the supplementary material and results seem consistent.) Qualitative measures like FID and KID should be taken with a grain of salt also. It is a big plus that a user study was conducted! (However, details of how these subjects were selected would be useful)"}