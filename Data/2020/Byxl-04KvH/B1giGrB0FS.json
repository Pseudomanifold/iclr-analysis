{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper presents a hierarchical learning approach that trains neural network classifiers on a known hierarchy of labels.  The experiments show that the approach makes a network more robust to distortion compared to standard end-to-end learning.  The approach in this paper and its formalization of the task are interesting, but the significance of the techniques is somewhat unclear and the experiments could be more thorough in terms of the baselines and data sets considered.\n\nFrom the related work section, the relationship between this paper and the previous work is somewhat complicated -- it is hard for a reader not deeply familiar with these previous works to understand the unique contribution made in the submission, and assess why it is significant.  For example, in the last paragraph of that section, many of the distinctions drawn between the submitted work and previous methods seem minor (including a confidence measure for a certain prediction, for example) or seemingly subjective (about whether an operation with a previous method was \u201cnatural\u201d or could be done \u201ctransparently\u201d).  Making crisper, less ambiguous distinctions between this work and previous work would help.\n\nLikewise, the experimental results here do not compare against any of the hierarchical learning approaches discussed in the related work section.  The results show that the paper\u2019s approach is more robust to distortion compared to standard end-to-end learning.  However, I was unclear on why it was not appropriate to compare against the other hierarchical learning methods from previous work.  Also, if the claim is improved robustness, I feel that evaluating against adversarial training (Madry et al., ICLR 2017) or similar approaches is necessary to understand the practical relevance of these improvements.\n\nFinally, experiments that consider larger hierarchies (here, the number of target classes tends to be small, CIFAR-10 and MNIST each have ten classes, meaning the hierarchies are not very rich) would help illustrate the potential power of the techniques.\n\nMinor\nI didn\u2019t understand the following statement, and given that it\u2019s a fairly bold claim I would rephrase it or explain it better in the paper body rather than referring the reader to the appendix:\n\u201cA standard DNN unknowingly uses low quality data also to train higher layers, even if there is no high level information in the data.\u201d\n\nI don\u2019t understand what the right arrow operator on the top of page 5 means.  From earlier statements it seems that I(f_i(X), Y_i) -> I(X, Y_i) means that the left quantity is approximately equal to the right.  But I\u2019m not sure why to use an arrow for that rather than an \\approx symbol.  The arrow would seem to imply that the left approaches the right in the limit, but if that is what you mean you should tell us in the limit of what.  Later the arrow is used to represent links in a Markov chain, adding further confusion for me.\n\nI think it would be helpful if before Equation 1, you mentioned this holds for strictly nested Y_i\u2019s (since earlier in the paper, Y_i referred to more general things).\n \nI assume the ECE is computed over held-out validation data (i.e., not training data)?  The paper should say this.\n\nPage 7: lineal -> linear"}