{"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper proposes a quasi-multitask learning (Q-MTL) for supervised learning. The network architecture in Q-MTL borrows the idea of multi-task neural networks by sharing the latent representation among different classifiers which are designed for a single task.\n\nWhat is the difference among multiple classifiers for the single task? Can they become identical? The rationale behind Q-MTL is unclear to me. Authors need to conduct more analyses to show why Q-MTL is superior to supervised learning.\n\nAuthors claim that Q-MTL is equivalent to performing some regularization. However, I did not see any analysis on this aspect.\n\nIn experiments, the performance of Q-MTL is not so good when compared with ensemble learning."}