{"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "This paper proposes a model that learns to disentangle visual scene into objects (slots), and simultaneously learns a dynamics model to capture how these objects interact with each other.  The authors demonstrated that the proposed model has the potentials to discover objects without supervision, and also enables an exploration strategy that maximizes the number of objects changed in the agents' trajectories.\n\nThis paper is for sure studying an important problem. The approach presented in the manuscript makes intuitive sense. The experimental results are reasonable but can be strengthened. However, I was shocked that the authors seem to be unaware of the abundant related work in this area (see below). I'd like to see the authors' responses regarding the missing related work. As of now, my recommendation is a clear reject.\n\nAs the authors mentioned, objects play a key role in human perception, and the problem of discovering objects from visual input is for sure an important problem. I commend the authors for pursuing research in this direction.\n\nThe experimental evaluations are however a little limited: it's restricted to games, where the visual appearance of objects is almost identical. In those cases, it'd be hard to access how the model may generalize to real-world data, where object appearances and texture can be complex. There are also no comparisons with published, SOTA methods.\n\nThe major problem of this manuscript, to me, is its ignorance of related work and, therefore, overclaiming at a few places. Most importantly, I suggest the authors cite, discuss, and ideally compare with many related works from Josh Tenenbaum's group and Sergey Levine's group. A few papers listed below, in particular [A] and [B], also formulated the problem in a similar fashion, where they decompose the scene into object-centric representations and learn the interactions among objects. [B] and [C] also explored how the model can be used in an RL setting. Further, [D] studied learning an object-oriented dynamics predictor in a similar context as presented in this paper. \n\nThe sparse effects have also been explored by Xia et al. [E]. Similarly, the work has built upon object-centric representations. I, therefore, wonder how the proposed method compares with all those published papers, both at the conceptual level and at the experimental level.\n\n[A] Wu et al. Learning to See Physics via Visual De-animation. NeurIPS 2017\n[B] Janner et al. Reasoning About Physical Interactions with Object-Oriented Prediction and Planning. ICLR 2019\n[C] Co-Reyes et al. Discovering, Predicting, and Planning with Objects. ICML 2019 Workshop, https://sites.google.com/view/dpppo/\n[D] Zhu et al. Object-Oriented Dynamics Predictor. NeurIPS 2018\n[E] Xia et al. Learning sparse relational transition models. ICLR 2019\n"}