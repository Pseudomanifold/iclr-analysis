{"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "\n[Summary]\nThis paper proposes and studies the \u201clocal elasticity\u201d, a quantitative measure for the ability of neural networks to only locally change its prediction (around x) after a stochastic gradient step at x. The paper verifies experimentally that nonlinear neural nets are locally elastic through showing that an elasticity-motivated similarity score can perform clustering well.\n\n[Pros]\nThe notion of local elasticity is interesting and has the potential of opening up lots of further directions. The way I understand it is to relate to memorization (as the authors have indeed discussed) --- I think \u201clocal elasticity\u201d can be viewed as some sort of \u201clocal memorization ability\u201d, in that the NN is able to change its prediction only in a small neighborhood of x---without affecting predictions at other remote x\u2019s---after one SGD step on x. Conceptually this is something not covered by the existing narratives in deep learning theory, yet the phenomenon itself is quite convincing and could provide a new perspective into lots of things.\n\n[Cons]\nIt feels like the experimental results in the present paper is a rather indirect evidence for the local elasticity -- that the similarity score coming from the elasticity works well for a downstream clustering task. Could there be some more direct evidence about the local elasticity? How would the elasticity compare on different architectures? In the present form the experiments perhaps at most says that the similarity score makes sense, not yet that a fully quantitative characterization of the local elasticity.\n\nI\u2019m also a little bit concerned about the fairness of the clustering experiment, in that the elasticity-motivated clustering algorithm utilizes an auxiliary dataset whereas simple baselines such as K-means and PCA K-means are not able to use that. Is there a way of modifying the K-means and PCA K-means so that they can also use this auxiliary dataset while still giving a sensible algorithm for the primary 2-class clustering task?\n"}