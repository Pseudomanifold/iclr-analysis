{"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper describes work on Parallel Neural Text-To-Speech.  \n\nThere are a number of efforts in this direction going on simultaneously.  FastSpeech is one that was noted in public comment.  I have seen other work under submission as well.  I don't believe this undermines the fundamentals of the work, but it will color claims of being \"first\" by each submission.\n\nWaveVAE is an interesting approach to a parallel neural vocoding.  However it performs works than the IAF distilled ClariNet parallel vocoder with the same amount of parameters.  It is not clear what advantages WaveVAE has over ClariNet.\n\nMore problematic, ParaNet is described as providing a speedup over Deep Voice while maintaining quality.  However, this claim is somewhat misleading.  The maintained quality is only achieved when using an autoregressive wavenet vocoder.  It appears as though the inference speed up is only measured on the feature to mel conversion, while the wall-clock inference time is (likely) dominated by wavenet inference (a notoriously computationally intensive process).  When evaluated with parallel vocoders (ClariNet, WaveVAE or WaveGlow) ParaNet performs quite poorly when compared to Deep Voice 3. (This is especially true when using WaveGlow -- the best performing vocoder for DV3 MOS=3.96, ParaNet MOS=3.21).  While there are fewer attention errors (cf. Table 2) this doesn't seem to impact MOS to a great degree.\n\nAttention Distillation is somewhat equivalent to using an external alignment or duration model as is done in classical TTS.  Requiring this external resource somewhat undermines the claim of being an \"end-to-end\" TTS system.  It is worth comparing attention distillation to, say, training a traditional alignment model based on forced alignment and feeding the target durations as a conditioning feature along with the text.  This is what ParallelWaveNet (https://arxiv.org/pdf/1711.10433.pdf) does.  From that perspective it is not clear why ParaNet+neural vocoder should be considered as \"more parallel\" than ParallelWaveNet or other IAF vocoding approaches paired with a traditional front end."}