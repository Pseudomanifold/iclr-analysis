{"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper proposes a measure of difficulty for datasets. Prior work in this space has often utilized certain indicators like the overlap of samples across different classes etc. [A] While this work defines a model-agnostic error as the measure of difficulty, which should encompass all possible indicators of error. Then, the paper provides a lower bound on this error which can be estimated using neural network [B]\n\nI am inclined to accept (weak) this paper for the following reasons:\n1. The paper extends Fano's inequality for the case of real-valued vectors and discrete labels, under the assumption of smoothness of the estimators.\n2. The proposed approach for difficulty measure estimation is simple and clear and primarily based on [B].\n3. The estimates seem to correlate well with the errors of state of the art models, particularly on sentiment and text classification dataset. On the image datasets, it is still reasonably well correlated.\n\nSome suggestions for improvement:\n1. Add prior work on measuring data complexity to the references, e.g. [A, C] etc. and add some details contrasting prior work with this paper\n2. It would also be good to see some correlation numbers like Pearson correlation etc. between DIME and SOTA errors.\n\n[A] Spectral Metric for Dataset Complexity Assessment, CVPR 2019\n[B] Mutual Information Neural Estimation, ICML 2018\n[C] Complexity Measures of Supervised Classification Problems, PAMI 2002"}