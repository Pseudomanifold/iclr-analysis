{"rating": "8: Accept", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "Main Contribution:\n\nThis paper is trying to bridge the gap between CNN and the human  visual system by proposing a metric  (angular visual distance) and validate that this metric is correlated to the human visual hardness and this metric has a stronger relation  compared to the softmax score which has been viewed as a metric measuring the hardness of images in CNNs. Furthermore, this paper proposed a reasonable explanation for this observation, i.e., the norm is possibly not correlated to the human visual hardness and validate through the experiment. Finally, this paper shows that this metric is also useful  in other applications. \n\nInnovative Part:\n\nThe metric proposed in this paper is based on an interesting and also innovative observation that  samples in each class will concentrate in a convex cone in the embedding space (e.g., shown in Figure 1) and the norm has no information on the visual hardness. I like this observation since several existing theoretical results have similar implications although in far simpler settings. For example, [1] shows that for LINEAR model with logistic loss, gradient descent converges to the maximum margin classifier while the norm (corresponding to ||x||_2 in this paper) diverges to infinity with log(T) rate.  If we are looking into the Figure 1, we will see that ten convex cones almost form an equal partition of  the two-dimensional space and this indicates that the classifier is very similar to the classifier with the maximum margin in the angular space (NOT in the Euclidean space). The observation is quite intuitive and has strong theoretical foundation, which is the main reason that I vote for the acceptance of this paper. \n\nDrawbacks:\n\nThis paper also have several drawbacks but I do believe they can be addressed very easily. \n\n1. The introduction is not well-written, especially the second paragraph. I strongly recommend modifying the introduction. \n\nFor the first three sentences of the second paragraph, do you mean that CNNs are constructed based on some properties of the human visual systems and thus they should have had some connections but they actually fundamentally differ in practice? Otherwise, if these two are fundamentally different with each other, what is the point of showing some connections between them? \n\nFor the sentence \"we use this dataset to verify our hypothesis\", what is the hypothesis? Do you mean the hypothesis that human visual hardness should have had connections to the classifying hardness for CNNs?\n\n For the sentence \"Given a CNN, we propose a novel score function that has strong correlation with human visual hardness\", I am not sure whether the word \"strong\" can be used here. \n\n2. In table 1, I am not sure whether the author should assume that all audiences have some background on z-score, although I can understand it. I would also encourage the authors to use other correlation metrics with more intuitive explanations (e.g., correlation coefficients). \n\n3. For the experiment, I would like to recommend authors adding the following experiments.\n\n3.1) Show that on other datasets (e.g., CIFAR 10, 100), AVH converges fast to a plateau while the norm constantly diverges to infinity. \n3.2) Introducing several other measurements to show the correlation. \n3.3) I also would like to see similar results in Table 1 for different models. \n\n\n\n\n\n\n[1] Soudry, Daniel, et al. \"The implicit bias of gradient descent on separable data.\" The Journal of Machine Learning Research 19.1 (2018): 2822-2878."}