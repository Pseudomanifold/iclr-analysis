{"rating": "1: Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "The paper considers the problem of generating a high-resolution image from a low-resolution one. The paper introduces the Grey Level Co-occurrence Matrix Method (GLCM) for evaluating the performance of super-resolution techniques and as an auxiliary loss function for training neural networks to perform well for super-resolution. The GLCM was originally introduced in a 1973 paper and has been used in a few papers in the computer vision community. The paper trains and validates a super-resolution GAN (SRGAN)  and a super-resolution CNN (SRCNN) on the DeepRock-SR dataset. Specifically, for the SRGAN, the paper uses the EDSRGAN network trained on loss function particular to the paper: The loss function consists of the addition of the L1 pixel-wise loss plus the VGG19 perceptual objective plus the proposed GLCM loss.\nThe paper finds that SRCNN outperforms SRGAN in terms of the PSNR metric, but SRGAN performs better in terms of the spatial texture similarity.  \nNext, the paper shows that when trained with the mean L1-GMCM loss function, SRGAN performs best.\n\nIn summary, the paper proposes to use the GMCM loss for training and evaluation of the super-resolution methods. However, this metric is well known in the computer-vision community along with many others. Also, the idea to use this metric in training is only evaluated for one network (albeit a very sensible one) and only for one dataset (the DeepRock one). Since the novelty provided by the paper is small, I cannot recommend the acceptance of the paper."}