{"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper proposes a new loss function for performing principal component analysis (PCA) using linear autoencoders (LAEs). With this new loss function, the decoder weights of LAEs can eventually converge to the exact ordered unnormalized eigenvectors of the sample covariance matrix. The main contribution is to add the identifiability of principal components in PCA using LAEs and. Two empirical experiments were done to show the effectiveness of proposed loss function on one synthetic dataset and the MNIST dataset. \nOverall, this paper provides a nontrivial contribution for performing principal component analysis (PCA) using linear autoencoders (LAEs), with this new novel loss function. This paper is well presented.\nThere are some issues to be addressed:\n1. The output matrix is constrained to be the same size of the input, which is scarcely seen in practical applications.\n2. Literature on (denoising) auto-encoder can be reviewed more thoroughly.\n3. Comparison with state-of-the-art auto-encoder can be provided to demonstrate the effectiveness of the proposed algorithm.\n4. It is better to explain the meaning of each variable when it first appears, e.g., , the projection matrices A and B, and Variable A* in theorem 2.\n5. In the experiment part, in both the Synthetic Data or MNIST, the size of each data set is relatively small. It's better to add experimental results on big data sets with larger dimension.\n6. In order to better show the effectiveness of the new loss function, you can add some comparative test for different choice of compressed dimension p.\n7. There are some typos, such as \u2018faila\u2019 in the second line of the second paragraph in the INTRODUCTION. \n"}