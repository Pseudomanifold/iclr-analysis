{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This paper presents two main contributions. A modification to an existing synonym based adversarial attack algorithm for text based classification models, and a Synonym Encoding Method which aims to increase a language model's robustness to adversarial attacks. \n\nThe paper is well written and easy to follow and the results are thorough.  It falls prey to a pervasive issue with the adversarial literature however. The defense which they propose, namely ensuring that synonyms share the same encoding, reduces the test accuracy of the model. It has been shown that models which under-perform on the test set often have slightly higher adversarial robustness, and so in order to insure that their defense (instead of simply the lower test accuracy) is responsible for the improved robustness, a standard network should be trained to a similar test performance, and then the robustness of this under trained model should be presented.  This would greatly strengthen the work.  \n\nIdeally however they can find a version of their defense which does not impede the test set accuracy. As is argued by Gilmer et al (Motivating the Rules of the Game for Adversarial Example Research, 2018), Robustness should not come at the expense of test accuracy, given that the test set is the only known distribution that the network will be tested on.\n\nthe paper also presents an improved synonym based attack which is conceptually unrelated to the defense which they propose.  This is an important contribution of the work. And it is strengthened by the human evaluation study they present.  \n\nOverall i think this paper is a borderline case. It is clearly written and has worthwhile contributions, but it could be improved if they tested a similarly performing standard network on the adversarial attacks. And it would be greatly improved if they were able to find an implementation of their defense that did not hinder the test performance."}