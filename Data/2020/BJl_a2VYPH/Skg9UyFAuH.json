{"rating": "6: Weak Accept", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "Summary:\n\nThe paper propose a novel adversarial attack and defense method for NLP models. The defense method proposes to smooth out the feature space such that features within an epsilon distance to the current features has the same output.\n\nComments\n\n1. The paper is clear written and well motivated.\n\n2. It virtual adversarial training methods in  Miyato, T., Dai, A. M., & Goodfellow, I. (2016). Adversarial training methods for semi-supervised text classification. arXiv preprint arXiv:1605.07725 seems to be related. Virtual adversarial training proposes virtual adversarial samples by adding adversarial samples from adding epsilon noise in the feature space. it would be nice to have a comparison to this.\n\n3. It seems to assume that words within a certain distance to the true x is a synonym. I am if there exist such words that are not synonyms and if there is a way of evaluating what are the percentage of words that are. Since this would obviously effect both the defense and the attack methods.\n\n4. I am curious if smoothing out the output spaces (right before the softmax for example) would have a similar effect and  if the authors could compare to this method.\n\n5. It would be interesting to see more results on other commonly used QA systems such as the SQuAD and MS MARCO dataset. Especially MS MARCO since it requires a generative answer (rather than just classification).\n\nMinor comments:\n\n1. S_m on page 2 was used without being defined. I think it is meant to be the loss for the model output, but would be nice to define it before using it.\n\n"}