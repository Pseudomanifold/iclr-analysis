{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "\nThis paper proposes the unknown-aware deep neural network (UDN), which can be used to discover out-of-distribution samples for neural network classifiers. Its main idea is to introduce PR subnets to model the product relationship instead of the dot product of regular networks, then it can avoid over-fitting. Experimental results demonstrate that UDN can discover unknown samples more precisely than several baselines.\n\nThe problem of learning with out-of-distribution samples is important for real-world applications. The results provided in this paper seem positive. However, I think the main idea is not well explained, and the experiments provided are not sufficient. It\u2019s not clear why introducing this PR subnet forest can help the model avoid overfitting, and why this structure is more beneficial than other simple ensemble structures. I think it\u2019s more helpful to provide additional insights or theoretical analysis. As for the experiments, the contents of images in CIFAR, SVHN, and MNIST are completely different, so under the given setting, the unknown samples are easy to detect. It\u2019s more practical and convincing to split categories in each dataset into two parts to simulate unknowns.\nBelow are some detailed comments:\n-      Can you compare the performance of UDN with Bayesian neural networks, since BNNs are also popular methods to model uncertainty?\n-      How does the hyper-parameters for PR subnets affect the results? \n"}