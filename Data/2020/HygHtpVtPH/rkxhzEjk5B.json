{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "This paper proposes a denoising auto-encoder where the input image is corrupted by adding noises to its Laplacian pyramid representation. Then a DAE is trained to predict the original data and learn a good representation of the data. By corrupting the Laplacian representation, which is multi-scale, the corruption of the image is not local and thus more robust representations are learned.\n\nI personally like this idea. However, it seems a simple extension of the classical DAE. \n\n1. Is it possible to generalize this idea to other representations of the images such as wavelets or sift, or the representations learned by other neural networks? It seems that you can add corruptions to any image representations as long as you can reconstruct the image from the representation. Here, you can reconstruct from  Laplacian pyramid representation.\n\n2. As an empirical work, the experiments in this work is rather small-scale, using only CIFAR10 and MNIST. That seems far from sufficient. "}