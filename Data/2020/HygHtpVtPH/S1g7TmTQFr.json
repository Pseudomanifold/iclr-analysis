{"rating": "6: Weak Accept", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "Denoising auto-encoder (DAE)  is a representation learning framework proposes in [1], which uses noisy input to reconstruct the clean \u201crepaired\u201d input. In the conventional DAE, the noise is directly added to the input space. This paper introduces a novel type of noise, which corrupts the Laplacian pyramid representation, and uses it to train a DAE. The effect of the proposed perturbation is to allow larger scale and semantically meaningful corruption, which may help to learn more transferable representation. Several experiments are conducted showing the effectiveness of the method\n1) On MNIST, LapDAE provides better reconstruction images\n2) On Cifar-10, LapDAE provides better image retrieval results\n3) On Imagenet, combining with the transformation technique in [2], LapDAE achieve state-of-the-art result\n4) On Pascal VOC,  combining with the transformation technique, LapDAE achieve state-of-the-art result on transfer learning\nOverall, I find the idea natural and simple (simplicity of an approach is a good quality to me). At the same time, I also find the contribution a bit limited. The following are further comments and questions.\n\n* From the experiments, standard DAE are harder to train comparing to the proposed LapDAE. In my opinion, this suggests that the local noise are harder to remove comparing to the Laplacian noise. It would be interesting to perform the following experiment to further understand the difference between DAE and LapDAE: train a DAE and LapDAE then \na) Apply LapDAE to reconstruct an image where the random noise is added on the input space (as the standard DAE setting).\nb) Apply DAE to reconstruct an image where the noise is added to the Laplacian pyramid representation.\n\n* How does the corrupted set C been selected? Moreover, how does the selected layer in the Laplacian pyramid effects the performance? For example, is there a difference in terms of performance of the model when training on LPS4 versus LPS8?\n\n* The transformation technique seems to be very helpful for the performance, is it possible to combine it with other benchmark methods like RotNet or Counting?\n\n[1]  Vincent et al. 2010, Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion \n[2] Zhang et al. 2019, AET vs. AED: Unsupervised Representation Learning by Auto-Encoding Transformations rather than Data"}