{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "This paper provides a novel approach to learning useful representations with deep learning models. They formulate an entirely unsupervised framework based off autoencoders to accomplish this task. Their data differs from previous works by upsampling a noise-corrupted downsampling of the original inputs. The autoencoder is then trained to reconstruct the original image from this new data. Their experiments demonstrate that using this Laplacian pyramid scheme to generate noisy data leads to an autoencoder that learns better representations compared to a standard DAE. \nOverall, the work in this paper has the potential to be a contribution to ICLR but lacks experimental completeness and clarity. Moreover, the main contribution is a better denoising autoencoder, but in the grand scheme of representation learning, it is unclear how broad of a contribution this is. I would be willing to change my score, upon addressing the following details:\n\u2022\tAs mentioned above, the results as presented provide a better DAE. The paper would be much stronger if it also provided comparisons to more recent models in representation learning closer to state of the art. For instance, they choose BiGAN as a model for comparison, but these were developed over three years ago and are now outdated in favor of better GAN models.\n\u2022\tThe paper would be further strengthened with additional experiments of their representations being qualitatively better than previous models. Their example of image retrieval via nearest neighbor is quite limited when compared to the wealth of tasks GAN models can accomplish.\n\u2022\tIn general, when presenting qualitative results (Figures 3,4, and 5), additional examples should be put into supplementary materials so as to demonstrate the paper did not cherry pick.\n\u2022\tThe presentation of the quantitative results is peculiar. The paper chooses to combine their Laplacian DAE with the AET framework. As such, all the results tables should include numbers for AET alone and the conventional DAE with AET.\n\u2022\tLastly, the paper needs a revision for ease of readability, as there are a significant number of grammatical errors that make it hard to read at times. \nWhile the transfer learning experiments seem incomplete to me, that is not my area of expertise and I cannot judge how convincing that setup is as well as other reviewers. \n"}