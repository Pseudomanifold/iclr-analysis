{"experience_assessment": "I have read many papers in this area.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "In this paper, a framework for building group CNN with an arbitrary Lie group G is proposed. Generally, such a group CNN consists of 3 types of layers: a lifting layer which lifts a 2D image to a 3D data (G-image) whose domain is G; a group correlation layer which computes a 3D G-image from a 3D G-image; and a projection layer from a 3D G-image to a 2D image. To implement the convolutions in the lifting layer and group correlation layer which are defined in the continuous setting, the B-Spline basis functions are applied to expand the convolution kernels. Experimental results on tumor clarification and landmark localization show the superiority over CNN.\n\nAdvantages:\n1. A flexible framework for group convolutional neural network is proposed with strong theoretical support in Theorem 1.\n2. Familiar properties of convolutions from classical CNN design (like localized, atrous, and deformable convolutions) can also be implemented in G-CNN using specified B-Spline basis functions.\n3. In comparison with standard CNN, the effectiveness of the B-Spline-based G-CNN is validated through experiments on two typical data sets. \n\nWeakness:\n1. [Readability] For readers who are not familiar with Lie groups, this paper is very hard to follow. \n(1)\tFor Theorem 1, the authors are suggested to give some illustrative explanation. Besides, what is \u201cStab_G\u201d? \n(2)\tThe architecture of G-CNN, i.e., the 3 types of layers, are directly given in Eqs. (5)-(7) without examples, illustrative examinations, or visual illustrations.\n(3)\tFig. 1 can be modified for better readability. \n \n2. [Experiments] The proposed G-CNN has some similarities with data augmentation (like rotation, scaling) based CNN. Then, how better can the G-CNN perform than CNN with data augmentation? More experiments on this point are suggested, and relevant theoretical explanations will be appreciated.  \n\n3. [Implementation] Considering the complicated mathematics in this paper, I am afraid that implementation of the proposed G-CNN is also very hard. It would be better for the authors to discuss the implementation. In my mind, if the implementation is not so hard, then the formulation of G-CNN can also be simplified for better readability. \n"}