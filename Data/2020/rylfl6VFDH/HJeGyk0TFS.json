{"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper proposes a new way of training variational dropout which is adaptive to input samples due to the proposed sparsity-inducing beta-Bernoulli prior. The authors provide a good motivation for their model, introduce beta-Bernoulli and dependant beta-Bernoulli prior and propose the method in the variational inference framework. \n\nConcerns:\n1) The main concern relates to the significance of benefits from the input dependency property. From the Tables 1, 2 we can see that BB is comparable with DBB and the latter is not uniformly better than the former in terms of error, xFLOPs and memory. This similarity in the performance is more significant for LeNet5-Caffe network, for CIFAR-10 and CIFAR-100 datasets. Is the overhead of DBB worth the benefits it gives? \n2) The second question is about the memory consumption of DBB. The authors use two stage pruning scheme for DBB: at first, they prune DBB using the beta-Bernoulli dropout, then prune the network for each input individually. It means that DBB should keep all weights after the first stage, in other words the memory consumption of DBB is the same as BB. Some clarifications about this concern are necessary. \n\nOverall, the paper proposes interesting and well-motivated method for training sparse networks. Although, there are concerns about the DBB extension I would recommend considering this paper for acceptance. \n"}