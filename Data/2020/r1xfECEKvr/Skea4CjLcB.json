{"experience_assessment": "I do not know much about this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "I am not an expert in the field of model uncertainty\n\nSummary / contributions:\nThis paper discusses the important problem of model uncertainty in the output of ML models developed for clinical applications. The authors illustrate the underlying concepts using RNNs which are popular in the medical ML literature by applying these to two datasets. They argue that Bayesian RNNs with Bayesian embeddings should be the models of choice in such settings as they explicitly allow the expression of uncertainty whereby obtaining confidence intervals etc is easy. The other advantage is the fewer number of parameters that need to be stored to get such statistics.\n\nNovelty:\n-- Some of the ideas presented are standard or well-known properties to most ML practitioners. For instance, the relationship between mean and variance in Fig 2 or the uncertainty in predictions / optimal decisions in Fig 3. Is the point of the paper to make it more obvious?\n-- It is certainly the case that medicine practioners are not as aware of these issues, but to reach that audience this paper would do better in a venue that caters to that community. However, the paper needs to address the concerns first so as to not confuse that community\n-- The Bayesian RNN models being discussed are not novel either and their properties have been discussed in the corresponding papers (probably not in such detail and with examples).\n-- What is the value of the Bernoulli distribution? Isn't the single output from a well calibrated model is enough to give the same information.\n\nWriting:\nThe paper is very well written and has good figures and examples to explain the ideas. The one area that can be improved is the contributions section.\n\n\nResults:\n-- The authors do not discuss the related issue of model calibration in much detail. It is unclear what additional information we are gaining from the author's perspective of model uncertainty. A well calibrated model as well as other ways of obtaining confidence intervals (via hypothesis tests) would serve just as well.\n-- Are the conclusions derived on the specific datasets general?\n-- The results showing group-level biases are not very helpful and come across as anecdotal. These can be derived from most other models too."}