{"rating": "3: Weak Reject", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "Overall:\nIIUC, the main contribution of this paper is to take previous work on training GANs with\nmultiple generators and add a learned assignment of z -> G_i, so that we have\nG(z) = \\sum_i NP(G_i | z) * G_i(z)\nwhere NP is this learned assignment.\n\nI think that technically this idea is new,\nbut there is important related work [1] that (IMO)\n  - does essentially the same thing\n  - better experimentally validates the thing they do\n  - was published in last ICLR.\n\nI also have a number of issues with the experimental design: see my detailed comments below.\nFinally, the technique seems like it can't easily scale up to larger GANs or data sets \nbecause it requires instantiating many copies of the generator in memory?\n\nFor these reasons, I lean somewhat strongly toward rejection.\n\n\nDetailed comments on draft:\n\nIt's worth noting that conditional GANs also sample from multiple disconnected `manifolds'.\nI guess the value of adding your technique is that it can work without labels?\n\n> Our approach differs significantly from those previously\nstrange sentence.\n\n>  By dividing up the space into four slices...\nI don't get this part. \nIf you fed all the slices to a single generator you could\ngenerate four `disconnected manifolds' with just 1 generator, no?\n\n> , multiple-discriminator mixture in (Arora et al., 2017)\nNit: you don't need the parens there, IMO.\n\n> our model learns to model the data over the full collection of generators in each minibatch\nGiven that modern GAN techniques (e.g. bigGAN), this is going to have some pretty unpleasant\nperformance characteristics, right?\nEach generator has to be instantiated in memory all the time.\n\n> LGAN\nNit: surely, given the state of the GAN literature, this name has been used before.\n\n\n> We compare our NPGAN\u2019s ability to model this distribution to\nThe following baseline seems like it would be much simpler and get the job done:\nTrain a GAN on a prior that's a mixture of like 100 gaussians or whatever. \nThen it seems like it could learn to assign 70, 50, and 30 of those modes\nto each one of the gaussians in your underlying data?\nI guess I haven't tried this myself, but it seems like a more fair comparison.\nThe way the current experiment is set up, you know a priori that your model\nis the only one that can work.\n\nOverall, I don't really understand why it's necessary to have multiple generators.\nIf I want the prior my generator `sees' to be disconnected, can't I just\npass samples from the prior through a standard relu network?\nSurely a relu network can learn to separate one mode into two, and so forth.\nBut once you do that, you've essentially got [1].\n\n> We next demonstrate\nWould be nice to have a new subesection here.\n\nI think your single-generator baseline in Fig 2 and 3 is unrealistically bad.\nSee fig 3 of [2], in which it looks bad but not nearly as bad as you've shown it.\nI think this points to another issue with the experimental design.\nIf the generator is a big enough relu network, it ought to be able to automatically\ngenerate `disconnected bits', but it has to be big enough, and you've compared a\ngenerator with N parameters to 2 and 3 generators with N parameters each.\nMoreover, your learned noise prior has some extra number of parameters (I don't see\nwhere you described these but I may be missing it).\n\n> A single generator is unable to model this non-disconnected data.\nAgain, I have a feeling that this is because of the small generator you use.\nI'm pretty sure that a motivated person could get a normal GAN to model the\ndistribution in fig 5 reasonably well.\n\n> The other models can only work if the precise optimal number of generators is known a\npriori.\nIsn't this not true for the method that throws out redundant generators?\n\nThe experiments described in 4.3 and 4.4 are pretty contrived.\nIt's ok to have some contrived experiments, but it seems like all experiments\non which you were able to provide evidence that your technique was helpful are contrived.\nIt also seems like the baselines you used are not obviously the right choice for these\nexperiments?\n\nRe: your CIFAR experiments:\nI think this supports my earlier claim that the extra parameters and bells and whistles\nin modern GAN techniques *already implicitly do what your method is proposing to do*.\nI think a lot of people miss this point when writing papers about GANs.\nWhen people request comparisons against more modern techniques,\nthey're not (merely) being difficult: \nthey want to know if the technique you propose \"stacks\" with other techniques,\nin the sense that your method is doing something that wasn't already being done implicitly\nby the old methods.\n\nReferences:\n[1] On Self Modulation for Generative Adversarial Networks (https://arxiv.org/abs/1810.01365)\n[2] Discriminator Rejection Sampling (https://arxiv.org/pdf/1810.06758.pdf)\n"}