{"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "[Summary]\nThis paper proposes a new method for overcoming catastrophic forgetting in continual learning, based on distribution-based regularization using the sliced Cramer distance, i.e. Sliced Cramer Preservation (SCP). Unlike previous work on catastrophic forgetting, this paper tackles unsupervised learning scenarios as well as supervised learning. They evaluate the proposed SCP on permutated MNIST, sequential learning in autoencoder task, and sequential learning for segmentation. \n\n[Pros]\n- This paper tackles unsupervised learning scenarios beyond the classification on benchmark datasets.\n- This paper employes sliced Cramer distance with theoretical justification.\n- The analysis on EwC and MAS in terms of geometric view\n- Experimental results look promising.\n\n[Cons]  \n- Even if MAS[1] describes the details on synaptic concept and Hebbian rule, many readers might be not familiar with synaptic or neuro-science terms. So, in prelimiary session, more explanation can help readers to understand.\n- In addition to permute-MNIST, it is required to be evaluated on more conventional tasks such as MNIST->SVHN or CIFAR-10, 100 datasets. Also, more recent work should be compared such as IMM [2] and PGMA [3] for supervised learning scenarios.\n- All graph result figures can be improved for enhancing legibility. In Figure 6, In particular, the subtitle of Summer case confuses me.\n \n[1] Aljundi et al. Memory Aware Synapses: Learning what (not) to forget, ECCV 2018.\n[2] Lee et al. Overcoming Catastrophic Forgetting by Incremental Moment Matching, NIPS 2017.\n[3] Hu et al. Overcoming Catastrophic Forgetting for Continual Learning via Model Adaptation, ICLR 2019."}