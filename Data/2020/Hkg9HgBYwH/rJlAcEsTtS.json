{"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "## summary\nIn this paper, the author extends the standard music Transformer into a conditional version: two encoders are evolved, one for encoding the performance and the other is used for encoding the melody. The output representation has to be similar to the input. The authors conduct experiments on the MAESTRO dataset and an internal, 10,000+ hour dataset of piano performances to verify the proposed algorithm.\n\n## Novelty \nThe application is interesting, but the novelty of the architecture itself is limited. Multiple encoder structure has been widely investigated in machine translation.\n\n## Questions\n1.\tIn section 4.2, how do you use the $\\mathcal{Y}$? Since it is defined but never used. What does the $p()$ and $q()$ mean ? You mentioned that \u201cWe omit the usual first term in the MMD loss \u2026\u201d but if so, why do you introduce this term to evaluation metric?\n2.\tBy checking the music Transformer, in Table 3, it is not surprising to see that the proposed method outperforms the corresponding baselines, because no conditional information is used. \n3.     It is better to give some mathematical definition of music generation with specific style. I am not working on music generation but I list two CV related papers about conditional image translation, which mathematically describes \"an image with specific style\".\n4.\tConsidering that this is an unsupervised setting that two styles are transformed, can cycle-consistency be implemented as a baseline? The following two papers are about conditional unsupervised image-to-image translation, which build a cycle-consistency loss during the feedback and might help improve the performances.\n\n\n## Reference\n[ref1] Multimodal Unsupervised Image-to-Image Translation, ECCV\u201918\n[ref2] Conditional image-to-image translation, CVPR\u201918\n"}