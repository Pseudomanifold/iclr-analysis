{"experience_assessment": "I do not know much about this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review": "This paper proposes using a neural network to perform the two-sample test to distinguish if two distributions are different from each other.\n\nThe idea is not very different from the discriminator network used in GANs where a classifier learns to distinguish between two distributions. The threshold is computed using the permutation test, and I wonder how the logit test compares to a simple permutation test.\n\nThe authors show that the logit method has high power when the distributions are different. How do the results look if the distributions are the same, and yet the classifier is trained with (fake) 0-1 labels. Would the net logit method do a better job in predicting that the two distributions are the same as compared to other methods?"}