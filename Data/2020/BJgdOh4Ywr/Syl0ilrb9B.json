{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The idea of the paper is to learn a distance function between observed and the agent\u2019s behaviors. Once they have the distance function, they can learn the agent\u2019s policy efficiently given a single demonstration of each task. In their formulation, the distance function and the policy are jointly learned.\u00a0\n\nThe idea is reasonable and the performance outperforms baselines like GAIL and VAE. However, the paper is not-well written with many relevant equations defined in the supplementary material. The unsupervised data labeling part seems Adhoc with many details in the supplementary material. I wonder if the process stable or not. How many lower than the average performance of the proposed method as shown in F.g 4 are caused by unsupervised data labeling?\n\nIn Fig. 4b, the manual performance is very strong once converged.\u00a0Although the proposed method initially reaches high reward,\u00a0after twice many iterations the manual performance even outperforms the proposed method on average many times. Hence, I am not very convinced about the proposed method will be the best-picked method in practice.\n\nOverall, I think the idea is good. But the paper is poorly written and I concern the most about the stability of the unsupervised data labeling process. The experimental results are also not super convincing. Hence, I recommend for weak rejection."}