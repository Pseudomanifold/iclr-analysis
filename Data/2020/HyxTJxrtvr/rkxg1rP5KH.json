{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "Summary\nThe paper presents a method to learn an embedding space for each pixel in a video that indicates the instance id of the objects. They also propose an auxiliary loss based on depth prediction to improve performance. This can be used to both segment and track objects in videos.\n\nStrengths\n1) The proposed approach is simple and general and handles the problem of occluding objects in videos. \n2) Their causal convolution architecture will be useful for other problems in videos.\n3) The authors perform a number of ablations to investigate how much each part of their solution contributes to the final performance.\n4) The paper is well-written and well-motivated.\n\nWeaknesses\n1) Comparisons to other video instance segmentation methods [1,2,3] are missing. The only comparison is done with a single-frame instance embedding method. \n2) The authors propose to predict depth as an auxiliary task. However, they do not use the predicted depth at test time. This is a missed opportunity. Difference in depth might help in identifying instances. Also, it might be worthwhile to investigate if instance segmentation is helping depth prediction.\n3) Experiments have been conducted on only one dataset. \n\n\nReferences\n[1] \"Video Instance Segmentation\" Linjie Yang and Yuchen Fan.\n[2] \"MaskRNN: Instance Level Video Object Segmentation\" Yuan-Ting Hu, Jia-Bin Huang, and Alexander G. Schwing.\n[3] \"SAIL-VOS: Semantic Amodal Instance Level Video Object Segmentation \u2013 A Synthetic Dataset and Baselines\" Yuan-Ting Hu, Hong-Shuo Chen, Kexin Hui, Jia-Bin Huang, Alexander Schwing.\n\n"}