{"rating": "3: Weak Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "\nPaper summary:\n\nThe paper proposes a method to predict the future trajectory of a ball (or a set of balls) given the first few frames of the trajectory and a set of experience runs in the same environment. The model first learns to convert the set of images to a set of corresponding heatmaps that encode the location of the ball. Then, a recurrent network generates the future states given the first few locations and the output of a network that learns abstract information from the experience runs. The network is trained using reconstruction and perceptual similarity loss.\n\nPaper strengths:\n\nIt is interesting that the model is able to learn from a set of experience runs. Learning abstractions from a set of experience runs is an interesting direction.\n\nPaper weaknesses:\n\nThe paper has two main problems. (1) The model and the experiments are designed for a very simplistic scenario. I do not think that machinery is really needed to perform prediction in this simple setting. (2) The paper needs major re-rewriting. Some of the main parts of the paper are not clear. Please refer to the comments below for more details.\n\n- It is unclear how the initialization function (Equation 4) is learned. It is very unlikely that the auto-encoder produces a heatmap of the object locations only based on the reconstruction loss that it receives at the end. This should be clarified.\n\n- Equation 2 is very confusing. Is \\phi-hat a function of experience I(E) or I_{0:T}(R). It seems \\phi-hat produces an image that is compared with I(R), but it doesn't seem that M produces an image.\n\n- The proposed machinery is overkill for the very simple experimental setup. A nearest neighbor baseline would probably perform as well. We can extract a set of frames in the experience runs that are closest to the first few frames using some simple distance functions. Then, we can predict the future movements by copying the rest of the trajectory from the experience run.\n\n- The only part that seems unsupervised is the location of the ball, which can be easily obtained by image subtraction in this simple setting. What else is unsupervised in the proposed approach?\n\n- The beginning of section 3.2 mentions w, but there is no mention of it afterwards.\n\n- Why does the backprop for sixty 64x64 images require 12Gb of memory? It would be good to explain that.\n\n- Regarding the evaluation, how does it know which prediction corresponds to the which groundtruth to compute the distance that is mentioned? The prediction can correspond to any of the balls since there is no explicit notion of object in the model.\n\nDue to the issues mentioned above, especially extremely simple experimental setup and lack of clarity, I chose \"Weak Reject\". \n\n"}