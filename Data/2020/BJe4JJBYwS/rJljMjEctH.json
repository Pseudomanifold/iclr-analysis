{"rating": "6: Weak Accept", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "The paper proposes a new method for image-to-image translation. The problem of most existing methods is that they are good in translating style  (e.g from photo to Van Gogh) but do not allow for significant changes in shape (e.g. from zebra to giraffe). The authors address this by performing the translation in a cascaded fashion starting from a semantic (deep) level (fifth layer of VGG). The underlying idea is that translating at this more semantic level puts less spatial constraints on the final resulting images (making translations from zebra to giraffe possible). After the fifth layer is translated other layers are translated conditioned on the previous translation results. \n\nThe method is compared to other translation methods including DRIT, MUNIT, GANimorph. Both visually and quantitatively as measured by FID. The results of the proposed method are superior. No comparison to TransGaGa is provided (but I could not find code for this method).\n\nMy recommendation is borderline accept. The proposed method is simple. The experimental results are limited but show both visually and quantitatively superior results. Especially FID scores are much better. I think the paper could be improved in explaining the conceptual novelty of the paper (especially with respect to GANimorph and TransGaGa).\n\n1. I like the idea of applying the cycle consistency to the deeper layers rather than at the pixel level. Are there other methods which  do this ? It could be highlighted more as part of the contribution.\n2. An ablation study should be added (in FID scores). I would like to see the necessity of the cascade (which is in the title) confirmed: results for only translating a single layer (3,4, or 5)  should be compared to translating 3,4,5 together as in proposed method. \n3. Would it be possible to not use pretrained feature from VGG-19 ? This might also be a limitation. In principle, I guess you could train everything end-to-end, or is this impractical because of the feature inversion. \n4.The authors could add some text on the lack of diversity for the translations in the limitation section. I understand there is no diversity and the translation is deterministic. \n \nIn general, I think the paper clearly explains what it does, and it also shows cases that it performs better than state-of-the-art. The paper could be much improved in its analysis of the reasons for its better performance, analyzing key aspects of its design like cycle GAN on features, pretrained VGG features and the use of cascaded generation of the final image. \n"}