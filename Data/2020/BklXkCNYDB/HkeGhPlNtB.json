{"rating": "3: Weak Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "The authors present a framework to implement graph neural networks training\nefficiently ---an inherently sparse task--- using \"custom dense hardware\", here\nTensor Processing Units (TPUs V2). The key steps are: (1) reordering the labels\nto reduce the bandwidth of the adjacency matrix, (2) (Sometimes approximate)\nDecomposition using block matrices for efficient storage and computations, and\n(3) memory layout optimization. They evaluate their framework on the VarMisuse\ndataset and compare the performance against a GPU implementation running on\nNvidia Tesla V100. In the best configuration, they were able to reach 78% test\naccuracy in 13 minutes vs 19h for the baseline.\n\nThe paper is well structured and thorough. I was able to understand the\nchallenges and the solutions proposed, even without prior knowledge in the\narchitecture this work focuses on. I think it is sufficiently detailed to enable\nan independent implementation without referring to the authors source code.\n\nHowever, I feel that it might lack novelty. Indeed, as described in the Related\nWork section, each component of the pipeline is well known and used very\nfrequently in the HPC community. Sometimes, knowing how arrange common\nprimitives is very powerful, and looking at the results of the experimental\nsection, this is enough to improve performance by almost two orders of\nmagnitude. However, I think it might be more due to some intrinsic properties of\nthe dataset than the method itself. As made clear by the title of section 5.1,\nit is the data itself that has low bandwidth. If we consider a dataset that does\nnot satisfy this requirement, stage (1) has no effect, and it is impossible to\nperform the decomposition done in (2). In that situation, the contributions of\nthis paper would be nullified.  It would be perfectly reasonable to think that\nmost datasets have low bandwidth, but this not a claim that made the authors.\nThis work would be considerably more impactful if it measured the bandwidth of\nmore well recognized datasets. My small exposition to these problem does not\nallow me to make any meaningful suggestion.\n\nFinally, I am puzzled by the \"dense hardware\"/GPU distinction. From my\nexperience, GPU devices *are* designed for and extremely efficient at dense linear\nalgebra. Sparse operations are historically performed on CPUs. While they are\npossible on GPUs, they are usually much slower. For example CUSparse, the sparse\nmatrices library, part of NVidia CUDA toolkit, was only introduced in its\nversion 4. It's a clear indication that sparse operations are not a strength of\nGPUs. According to my experience writing GPU code, I feel that this approach\nwould actually perform extremely well on GPUs as it does on TPUs. I think it is\nthus important to compare this framework on GPUs too. Since these\noptimizations are not TPU specific and have not been applied in the GPU based\nGNN libraries referenced in this paper reinforce my concerns that they are\nproblem-specific.\n\nEven though the performance gains demonstrated are sizeable, the fact the\napproach does not seem TPU specific and is potentially problem specific makes me\nlean towards rejection.\n"}