{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This paper proposes a channel pruning approach based one-shot neural architecture search (NAS). Unlike other NAS works that mostly search for operations/connections and topologies, this paper focuses on pruning channels for a fixed network.\n\nIn general, the idea of channel pruning has been extensively studied in previous works, and the channel pruning search algorithm is very similar previous one-shot NAS framework. The results on CIFAR-10 are reasonably good, but the results on ImageNet are not competitive to other NAS works.\n\nHere are some more comments:\n\n1. This paper is more like a new automated pruning technique rather than a new NAS technique. Therefore, I recommend the authors compare this technique with other pruning techniques, such as NetAdapt (https://arxiv.org/abs/1804.03230 ) and AMC (https://arxiv.org/abs/1802.03494).\n\n2. The baseline model described in Figure 1 is quite limited. It would be helpful if the authors can also apply this pruning technique to other types of models (such as NASNet-A/MNASNet-92 from your Table 3,  or mobilenets used in NetAdapt/AMC papers).\n\n3. Section 2.2 and Algorithm 1 is difficult to follow. It is not clear how Taylor expansion is carried out, and how saliency vector S is used. I recommend the authors expanding Algorithm 1 to include more details.\n\n4. Figure 2(b) shows random pruning leads to better results than no-pruning. This is kind of counter-intuitive, could you give more details about your settings and explanation?\n\n5. There are some minor errors: (1) Figure 1 [y1, y2] should be [z1, z2], and [y3, y4] should be [z3, z4];  (2) At the end of section 2.1, the number of weights in node 1 should be reduced by 4/8 instead of 3/8.\n"}