{"rating": "3: Weak Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "The paper proposed a scheme to detect the presence of anomalous inputs, such as samples designed adversarially for deep learning tasks, that is based on a \"subset scanning\" approach to detect anomalous activations in the deep learning network. The paper is considering a very interesting problem and provides the suitable application of an approach previously developed for pattern detection. The approach is motivated by p-value statistics of the activation patterns in the deep learning network under the \"null hypothesis\" of a non-anomalous input.\n\nMy rating is \"weak reject\" because the explanation of the subset scanning approach is not clear. The paper describes two functionals F and G that are defined over subsets of the data and activations. Section 2.2 mentions a method that maximizes F over data and activation subsets by maximizing F over the data subsets under a fixed activation subset and vice versa, and iterating over these two. The section also discusses the function G that measures the priority of an image, but does not describe how the priority is known to provide an optimal solution for the former optimization over F. Another function with the same name is defined to measure the priority of an activation node, and again it is not clear why this will provide an optimal solution for the latter optimization. It would have been helpful to establish (or at least instantiate) the optimality results for this approach; only a citation is provided.\n\nThe applicability of the approach is limited to the requirement that multiple adversarial samples be present for accurate detection. It would appear that other approaches to anomaly detection do not require this condition, particularly if they are designed to operate on individual samples. Furthermore, the requirement for the \"same system\" to design the anomalous samples limits the applicability of the anomaly detection approach to cases like the single adversarial design detection setting studied here.\n\nSome questions for the authors:\nIs there a reason why the figures (Fig. 2) show results only for a single class?\nIs there a reason why no other anomaly detection algorithms for the activation patterns were used in comparisons? How about other adversarial noise detection algorithms?\nIs there intuition behind the difference in performance when all target classes vs. a single target class is used? Does this mean that a multi-class adversary generation would be too diverse for the proposed approach to detect it effectively?\n\nMinor comments\n\"Weird together\" - is too informal, and it's not clear why this phrasing is needed. Consider replacing or explaining.\nTypos \"anomlaous\" multiple times."}