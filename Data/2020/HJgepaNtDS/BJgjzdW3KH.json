{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper defines a set of learnable basis functions and a joint learning algorithm to estimate them. It is based on the premise that the common learning approach in time-series is to first represent them in some spectral domain; thus, the main problem is to define and estimate the basis functions. However, this premise is not accurate and many learning algorithms operate just in the actual time domain (even in speech).\n\nThe paper advocates for a special group of strictly increasing transformations of the basis functions. While in Section 3.2 the authors do explain the connections to the time-warping operation, they never explicitly justify why such a group is interesting. At least, it is not clear why they are not interested in a semi-group of (non-strictly) increasing functions, which is more flexible and used in DTW.\n\nThe authors implement the more general group using piece-wise linear functions, which makes enforcing the strictly increasing property easier. This idea is nice, however I am concerned with speed of such transformations in practice. Unfortunately the authors do not report runtime numbers in the experiments.\n\nWhile the paper has verbose and wordy writing, it also spends a major part of the paper describing the common knowledge about group theory and wavelets. Instead, some crucial design decisions are not well-justified. For example, the description of the constraints in cLGT suddenly appears.\n\nThere are several major problems in the experiments. First, the results in Tables 1 and 2 do not seem to be statistically significant and Table 3 does not have the intervals. Second, the Haptics dataset is too small. Also, choosing a single dataset from the UCR sets only sends the message that this dataset is one of the few datasets on which the algorithm has worked better.\nOverall, the key message out of the experiments is that if you project the data to a parameterized basis set and constrain the parameters, you will get better generalization, which is not very novel. \n\nOther than improving the experiments, the authors can significantly improve the writing by decreasing the emphasis on the background knowledge and elaborating more on the new proposed ideas."}