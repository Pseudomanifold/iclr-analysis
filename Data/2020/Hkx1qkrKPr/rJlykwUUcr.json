{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper studied the problem of \"deep\" GCNs where the goal is to develop training methods that can make GCN becomes deeper while maintaining good test accuracy.  The authors proposed a new method called \"DropEdge\", where they randomly drop out the edges of the input graphs and demonstrate in experiments that this technique can indeed boost up the testing accuracy of deep GCN compared to other baselines. \n\nThis paper is clearly well-written and the authors conducted a comprehensive study on deep GCNs. I also like the discussion in sec 4.3 where the authors explicitly clarify what are the difference between DropEdge, Dropout and DropNode, as the other two are the methods that will pop up during reading this paper. The extensive experiment results also show that for deeper GCNs, DropEdge always win over other baselines (see Tab 1) despite most of them are marginal except the backbone being GraphSAGE on Citeseer. Can you explain why this is the case? Why other backbones seem to have similar performance  even with DropEdge (i.e. most of the accuracy increase are less than 3 %). \n\nQuestion:\n1.  When looking at Tab 1, it looks like most of the time, 2-layers networks are already the best (or close to the best) and are clearly better than 32 layers. Therefore, this makes me wonder: why do we need deeper networks at all if the shallow networks can already achieve a good (almost best) performance and it is also much similar and efficient in training? Can you please clarify why do we care to train a deeper network at all under this scenario? Are there any reasons that we would like to use deeper network as opposed to shallower networks?\n\n2. It is less clear to me regarding this sentence: \"DropEdge either retards the convergence speed of over-smoothing or relieves the information loss caused by it\" \n\nOverall, I think this paper presents an interesting study on making deeper GCNs comparable to shallow network performance, but since the the boosted performance doesn't really outperform most of the 2-layer networks,  I would like to hear the justification of why we need the deeper networks for this node classification task. "}