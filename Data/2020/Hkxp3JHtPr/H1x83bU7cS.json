{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper proposes two variational methods for training VAEs for SSAD (Semi-supervised Anomaly Detection). Experiments on benchmarking datasets show improvements over state-of-the-art SSAD methods.\n\nIn generally, the paper is well written. But I have some concerns.\n\n1. Some of the results have not yet been obtained.\n\n2. Missing some relevant references.\nIn addition to VAEs, there is another class of deep generative models - random fields (a.k.a. energy-based models, EBMs), which have been applied to anomaly detection (AD) recently. Particularly, the unsupervised AD results on MNIST and CIFAR-10 from [2] are much better than the proposed methods (MML-VAE, DP-VAE).\nThough semi-supervised AD is interesting, good performances on unsupervised AD can be a baseline indicator of the effectiveness of the AD models. The authors should add comments and comparisons.\n\n[1] S. Zhai, Y. Cheng, W. Lu, and Z. Zhang, \u201cDeep structured energy based models for anomaly detection,\u201d ICML, 2016.\n[2] Y. Song, Z. Ou. \"Learning Neural Random Fields with Inclusive Auxiliary Generators,\" arxiv 1806.00271, 2018.\n\n3. \u201cFor all of the experiments, our methods use an ensemble of size K = 5.\u201d\nAre other methods also tested by using an ensemble?"}