{"experience_assessment": "I do not know much about this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "In this paper, the authors reformulate the RNN training objective to explicitly learn the state vectors, and propose an algorithm called Fixed Point Propagation (FPP Algorithm 1). The authors motivate the derivation of FPP in Section 3, provide some theoretical convergence results in Section 4, and demonstrate experiment results in Section 5.\n\nIn general, this paper is interesting and well written. The experiment results in Section 5 seem to be very strong. However, I am not familiar with the relevant literature, thus, I am not sure if the authors have compared with the strongest baselines in this field. \n\nI think the paper suffers from the following limitations:\n\n1) Theorem 1 shows that the FPP algorithm converges to a stationary point. However, this result seems to be too weak. Can we say something about the stationary point? Is it a local minimum under some conditions?\n\n2) In the experiments, the authors choose \\lambda=1. My understanding is that \\lambda is a key meta-parameter of FPP. Please do a better job in justifying this choice."}