{"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper develop a path-based encoding scheme to featurize the neural architectures that are used to train the neural network model, and design a NAS algorithm that performs Bayesian optimization using a neural network model. The experiments show the priority of the proposed method.\n\nIn general, this paper is easy to follow, but the contribution is limited. The author did not give a clear explanation of why does this method work. There are several problems that exist in the paper:\n\n1.\tThe paper introduced a path-based encoding scheme, which seems have nothing different from enumerating all possible paths. Any additional operations should be clarified in the paper.\n2.\tThe method retains new architectures with high UCB value. However, the author did not prove that a higher UCB value leads to a better architecture. Eq.(1) trained several different networks to predict the accuracy. However, when using early stop stragegy, the intermediate accuracy is not convincing, and the new architecture selected based on UCB may not perform well when training with full epochs. If early stop is not used, there is no need  to predict the accuracy with different networks.\n3.\tIn my opinion, Algorithm 1 is a simplified traditional Evolutionary Algorithm, which only have mutation operation and do not have selection and crossover operation, and has limited novelty.\n\n"}