{"experience_assessment": "I have published in this field for several years.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "This submission belongs to the field of uncertainty estimation in neural networks. In particular, this submission described several approaches for measuring uncertainty in an arbitrary neural networks. These approaches are (i) input distortion through a simple set of transformations, (ii) distortion of mapping between input and output using noise added to intermediate layers (iii) distortion of mapping between input and output using the same masking approach as the one employed in dropout. Some of these approaches can be applied to white-box models only and grey-box models only. All of these approaches can be used with black-box models. \n\nAll the ideas described in this work have been published before, the novel aspect the authors are claiming is the absence of distortions in training. I find the content to be very light, the technical description adequate and the experimental validation limited. The presentation of this work has a number of issues:\n\n1) I do not believe what you are doing should be directly called uncertainty. I believe what you are doing is a perturbation analysis where you are using a measure of perturbation stability to assess uncertainty. \n\n2) I believe you are not referencing properly a large body of literature clearly indicating poor uncertainty estimates that arise from the use of MC-dropout. The same applies to ensembles. \n\n3) The technical content is very light and limited to a very specific configuration. You should have considered input distortions for speech, text, image and other types of data. \n\n4) Given how light the technical content is, I expected to see a very solid experimental part focused on comparison of your 3 approaches to published work. Unfortunately, this is not the case. The large bulk of experimental results shows the performance of the proposed approaches at almost every possible settings. Though I appreciate thoroughness, I would rather see the best configuration compared to the best published numbers on most commonly used tasks in the area. "}