{"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "The authors proposed a meta-learning based black-box adversarial attack method to reduce the number of queries. Their proposed meta attacker is trained via a meta-learning approach, and it could utilize historical query information and fast adapted to different target models. The authors conduct experiments in three datasets, and the results show that their proposed meta attacker is more efficient than other black-box attack methods. \n\nStrong points of this paper:\n1) novelty. The paper combines meta-learning and black-box attack and develops a deep convolutional model (meta attacker) to predict the gradients of another DNN model. Most of the other query-efficient attack methods focus on utilizing estimated gradients, while this paper focuses on predicting accurate gradients. That makes this paper novel. \n2) The results are good. The proposed method could attain comparable l2 norm and attack success rate with much fewer queries. And the analysis in experiments is interesting. The generalizability experiment of the meta-attacker(meta transfer) shows that gradients in different models and different datasets have some similar patterns. \n\nWeak points of this paper:\n1) The authors could investigate more in the theoretical part. For example, the authors could gives the theoretical support of why a convolutional network could stimulate other networks' gradient. \n2) The deploy of the meta-attacker is not as easy as other black-box attack methods. It would not be practical if we need to meta training the attacker before we use it. \n\nQuestions:\n1) Is it hard to meta training the meta-attacker? How long will it take for training? \n2) Is it necessary to finetune the meta attacker in algorithm 2 every m iteration? How to determine the \"m\"?\n3) Could the proposed meta-attacker embedded with other optimized black-box attack methods? \n\nOverall, this paper is well-structured, novel, and ideas are well motivated. The query-efficient black-box attack problem is practical and meaningful. I would encourage the authors to release their codes. Last, I would recommend acceptance for this paper. \n\n"}