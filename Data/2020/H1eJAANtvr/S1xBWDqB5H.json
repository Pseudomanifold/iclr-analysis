{"experience_assessment": "I do not know much about this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper proposes to address the problem of spatio-temporal forecasting in urban data, in a way that can accommodate regions with highly distinct characteristics.\n\nOn the spatial side, they make use of Graph Attention Networks (GAT), a very recent technique for spatial feature extraction using graph attention as a form of reweighting. The authors modify the GAT to accommodate a masking that allows for selection. For some parameter K, a collection of K GATs is then combined with the masking used so that only one of them can be active at any given time. This architecture (called MGAAT) then encourages a form of clustering,\nwith each cluster associated with a single GAT. This modification one of the two essential contributions of the paper.\nAlthough the description is not easy to follow, it does appear to have the potential to encourage clustering as claimed by the authors.\n\nOn the temporal side, the autoencoder-based Transformer architecture of Vaswani et al is imposed on top of the MGAAT architecture. Very few details are given in the main paper - as it stands now, without the hints on Transformer that appear only in the supplement, the overall workings of the paper cannot be easily understood. No insight is given as to how the overall architecture solves the main motivating problem for this paper.\n\nFor their experimentation, the authors compare against a good number of competing methods. However, three of them - DCRNN, GeoMAN, and ASTGCN - use important elements of the authors' own design, namely attention-based  models and encoder-decoder architectures (GeoMan uses both). However, the authors fail to differentiate their design from these approaches.\n\nOverall, the machinery is rather complex, underexplained, and undermotivated. The paper has major omissions and other serious presentational issues that make it very difficult to follow. The authors do not take care to point out which parts of their design are original and which are borrowed - it took much sleuthing to determine that the MGAAT differs from the GAT only in its introduction of a masking factor. As someone not previously familiar with GATs and atrous graph attention (as I suspect most of the audience would be), I found the paper very difficult going. A total overhaul of the paper would be needed in order to properly explain and motivate this work. \n\nOverall, in its current state (not least due to presentational issues) the paper appears to be significantly below the acceptance threshold.\n"}