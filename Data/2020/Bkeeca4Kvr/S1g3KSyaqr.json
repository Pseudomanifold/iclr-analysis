{"rating": "6: Weak Accept", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper introduces few-shot learning for graph classification. The authors propose a pre-training->fine-tuning approach to handle graph classes unseen at training time (and in only a few shots at test time).\n\nAt a high level, and to my understanding, their method a priori generates the ingredients for a graph of graphs, a \"super-graph\", in two steps: first, it discovers a prototype graph for each graph class in the dataset, then it clusters the prototype graphs into a set of super-classes by k-NN. Both of these operations rely on the spectral distance between graphs, defined in this work using the spectrum of a graph's normalized Laplacian matrix and the pth Wasserstein distance between probability measures. The intuition is that the super-graph built from these ingredients helps model latent relations between graph classes; these relations can be used at test time to improve classification of unseen graph classes.\n\nDuring (pre-)training, the model builds super-graphs on each batch of data. It uses super-graph information in two ways: an auxiliary classification head (an MLP called C^sup) is trained to map graph embeddings to their corresponding super-class labels, and the super-graph itself, whose nodes are embeddings for individual graphs in the batch, passes through a graph attention network (GAT) that outputs a base class for each graph -- this is the classification head C^GAT. The graph embeddings themselves come from a feature extractor F_\u03b8 implemented as a graph isomorphism network (GIN).\n\nDuring the fine-tuning stage the model adapts to and classifies graphs from classes unseen during training. Here the parameters of the feature extractor GIN and the C^sup MLP are frozen. C^sup outputs a set of super-class labels that are used to construct a super-graph, which in turn feeds into C^GAT, which in turn yields labels for the test graphs. C^GAT (but not the GIN or C^sup) fine-tunes on a small number q of labelled examples of each novel test class. The full model is evaluated on unlabelled examples from the novel test classes. This process assumes that the novel test graph classes belong to the same set of super classes as the training graph classes, a point that is, unfortunately, not discussed.\n\nThere's a lot to digest in this paper, on both the technical and architectural sides. There are graphs of graphs (super-graphs) and different GNN variants operating on both, with the output of one graph network, the feature extracting GIN, feeding into another, the GAT classifier. Understanding all of these pieces and how they fit together is challenging for the reader: I got lost somewhat in the Classifier description in Section 4, while Section 3 defines many things and gives some math that might be extraneous. It is also not immediately obvious that fine-tuning takes place on the set G_N and testing on the set G_U. Overall, though, the paper became clear to me with time and I found the overall presentation to be good. Some additional figures that depict the super-graph construction and clustering would be useful.\n\nThe construction and use of the super-graph structure to model relations between graph classes is interesting and novel to me, though it relies on well-established techniques (Wasserstein barycenters, Lloyd's algorithm for k-NN). The architecture itself, which combines GINs and GATs, is also novel to me; a downside is that it is highly complex.\n\nExperiments were undertaken on two datasets and seem fairly thorough, with variance established on a high number of seeds (high in the deep learning literature). They demonstrate that the proposed method makes significant improvements over baselines. The baselines are somewhat limited because, as the authors state, \"there do not exist any standard state-of-the-art methods for few-shot graph classification\". However, I do not think the authors should be penalized for trying something new. On the other hand, given the novelty of the task, it would be nice to see an investigation/discussion of how few-shot graph learning differs from few-shot image learning (where there has been much more work).\n\nI found the ablation and sensitivity studies illuminating, and I was pleased to see that the authors do support their claim that the super-graphs improve class separation over the feature extractor embeddings -- the GIN-k-NN baseline results provide evidence of this.\n\nOne place where I lack confidence in the results: I am not very familiar with the datasets used (TRIANGLES and Letter-High) nor how standard they are in the graph-learning literature. The authors do not even describe in the paper what the graph classes in these datasets actually are or represent, which would be good to know.\n\nOverall, I think the paper is worth seeing and discussing at the conference, although it could be improved in various ways.\n\nMinor errors:\n- there appears to be bracket imbalance in eq.6\n- \"Lloyd's\" is misspelled a few times\n\nReviewer's note: I have significant experience in few-shot learning but not in graph neural networks."}