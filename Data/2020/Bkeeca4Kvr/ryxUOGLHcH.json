{"experience_assessment": "I do not know much about this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper proposed a few-shot graph classification algorithm based on graph neural networks. The learning is based on a large set of base class labeled graphs and a small set of novel class labeled graphs. The goal is to learn a classification algorithm over the novel class based on the sample from the base class and novel class. The learning process constitutes of the following steps. First, the base class is classified into K super classes based on the spectral embedding of the graph (onto distributions over the corresponding graph spectrum) and the k-means algorithm with the Wasserstein metric. Second, for each super class, the classification is done through a feature extractor and a classifier. In the training of the feature extractor and classifier, the author introduces a super-graph with each node representing a super class. Finally, in the fine-tuning stage, the feature extractor is fixed, and the classifier is trained based on the novel class.\n\nThis work seems to be the first attempt to adopt the few-shot learning in graph classification tasks. The architecture is novel, and the classification of graph based on spectral embedding together with the Wasserstein metric is novel to me.\n\nI vote for rejecting this submission for the following concerns. \n\n1. The classification of base class into super classes seems questionable to me. In the meta-learning language, the author attempts to learn a good representation of graphs based on different graph classification tasks generated by a task distribution. In terms of graph classification, the task distribution is supported on the joint distributions (G, Y). Hence, to characterize different tasks, as far as I am concerned, the classification should take both the graph G and the label Y into consideration, instead of solely the graph.\n \n2. Though seemingly very important to the architecture, the purpose of constructing the super-graph g^{sup} in the training of C^{CAT} seems to be unclear to me.  I would appreciate it if the author could provide more explanation on the introduction of the super-graph in training.\n"}