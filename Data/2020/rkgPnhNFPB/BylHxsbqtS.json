{"rating": "6: Weak Accept", "experience_assessment": "I do not know much about this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review": "The authors generalize Gaussian random vectors to a broader class of \"concentrated\" vectors which they use as their primary tool for analysis of the latent representations learned by GANs. They show that the spectral behavior (i.e. spectra and leading eigenspaces) of the Gram matrix computed over GAN representations is the same as those produced by a high dimensional Gaussian Mixture Models (GMMs). Furthermore, they show that the \"sufficient statistics\" (i.e. measures of information encoded in the latent representations) for GANs depend only on their first and second moments. Thus, for data that follows Gaussian mixture patterns, GANs and GMMs behave identically. The authors also show that common neural network operations (linear/convolutional layers, pooling, batch normalization, ReLU activations) are Lipschitz transformations, where the Lipschitz constants can be bounded using spectral normalization (this is borrowed from previous work). They also provide some empirical analysis to verify their theoretical findings.\n\nOverall, the paper is well organized and the theoretical results are both compelling and thorough. The experimental results also follow nicely from the theory. Admittedly, this reviewer is not well versed enough in this area of mathematics to provide thorough critical insight about the derivations and proofs. However, the notation is clear and the general arguments appear to be sound. The authors' theoretical results are significant, and provide a much needed step forward in formalizing and understanding deep generative models."}