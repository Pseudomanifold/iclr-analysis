{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This manuscript studies mutual-information estimation, in particular variational lower bounds, and focuses on reducing their sample complexity. The first contribution is based on adapting the MINE energy-based MI estimator family to out-of-sample testing. MINE involves fitting a very flexible parametric form of the distribution, such as a neural network, to the data to derive a mutual information lower bound. The present work separates the data fitting from the mutual information evaluation to decrease sample complexity, the argument being that the function class is no longer a limiting factor to sample complexity of the mutual information estimation. The second contribution uses meta learning to decrease the sample complexity required to fit the neural network, creating a family of tasks derived from the data with data transformation that do not modify the mutual information. The approaches are demonstrated on synthetic data as well as fMRI data, to detect significant inter-subject dependencies in time-series of neural responses.\n\nThere are some very interesting and strong contributions of this manuscript. However, I worry that one of the central theoretical arguments does not seem correct to me. Indeed, the manuscript introduces sample complexity results to justify the benefits of the out-of-sample procedure (th 1), but it seems to me that these give an incomplete picture. Th 1 gives the number of validation samples required to bound error between the mutual information estimate at finite samples and asymptotically for a function T parametrized by \\tilda{theta}. This control is of a very different nature from the control established by MIME which controls the error to the actual best possible variational bound. In other terms, the control of th 1 does not control the estimation error of T. This is the reason why it is independent from the function class. The total error in estimating the mutual information must take this error in account, and not only the validation error. Hence the theoretical sample complexities contributed are not comparable to those of MIME.\n\nThe meta-learning estimator seems to involve a significant implementation complexity, for instance heuristic switchs between estimation approaches. The danger is that could hard to make reliable in a wide set of applications. It would be more convincing to see more experiments. Along this direction, it is problematic that, in the synthetic examples, the relative  performance of methods changes significantly from experiment to experiment and there does not seem to be a simple way to control that. On the other hand, the MIME-f-ES tends to have a reasonably good failure mode.\n\nI would have been interested in \"false detection\" experiments: comparing estimator in a variety of problems where the mutual information is zero, but for different marginal distribution. This is particularly important when the application is to test for independence, as in the fMRI experiments.\n\nFor hyper-parameter search (using hyperopt), the manuscript should make it explicit what metric is optimized. Is it the data fit of the neural networks? With what specific measure?\n\nWith regards to the fMRI experiments, good baselines are missing: DEMINE is compared to Pearson correlation. Additionally, CNNs are not a particularly good architecture for fMRI, as fMRI is not locally translation invariant (see Ayd\u00f6re ICML 2019 for instance). Finally, it seems that the goal here is to test for independence. In such a situation, there are better strategies for higher-order tests of independence than estimating mutual information, in particular estimator that give a control p-value.\n\nMinor comments: \n\nAlg 1 seems a fairly generic neural-network fitting algorithm. In its current state, I am not sure that it adds a lot to the manuscript.\n\nThere are many acronyms that are never defined: MINE, TCPC"}