{"rating": "1: Reject", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #4", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review": "The authors propose a procedure for improving neural mutual information estimates, via a combination of data augmentation and cross validation. They then use these estimates in hypothesis testing, on low dimensional toy datasets and on high dimensional real-world fMRI data.\n\nThe improved training procedures for MI estimation are of interest, however the hypothesis testing parts of the paper could still be improved.\n\nIn hypothesis testing, it is important to verify that the test has the correct level (false positive rate). This is all the more essential when the estimate has required optimisation over parameters. It is not clear from the presentation that this has been confirmed.\n\nThere are a number of prior approaches to testing for multivariate statistical dependence in the machine learning and statistics literature (including a 2017 paper which uses mutual information). A small selection is given below, although a literature search will reveal many more papers. In the absence of citation or comparison with any of the prior work on multivariate statistical dependence testing, the current submission is not suitable for publication. \n\n\nIn statistics:\n---------------\n\nhttps://arxiv.org/abs/1711.06642\nNonparametric independence testing via mutual information\nThomas B. Berrett, Richard J. Samworth\n2017\n\n\nMeasuring and testing dependence by correlation of distances\nG\u00e1bor J. Sz\u00e9kely, Maria L. Rizzo, and Nail K. Bakirov\nAnn. Statist.\nVolume 35, Number 6 (2007), 2769-2794.\n\n\nLarge-scale kernel methods for independence testing\nQinyi ZhangEmail Sarah Filippi, Arthur Gretton, Dino Sejdinovic\nStatistics and Computing\nJanuary 2018, Volume 28, Issue 1, pp 113\u2013130| Cite as\n\n\n\nIn machine learning:\n---------------------\n\nMultivariate tests of association based on univariate tests\nHeller, Ruth and Heller, Yair\nAdvances in Neural Information Processing Systems 29\n2016\n\nA Kernel Statistical Test of Independence\nGretton, Arthur and Fukumizu, Kenji and Choon H. Teo and Song, Le and Sch\\\"{o}lkopf, Bernhard and Alex J. Smola\nAdvances in Neural Information Processing Systems 20\n2008\nhttp://papers.nips.cc/paper/3201-a-kernel-statistical-test-of-independence.pdf\n\nhttp://proceedings.mlr.press/v70/jitkrittum17a/jitkrittum17a.pdf\nAn Adaptive Test of Independence with Analytic Kernel Embeddings\nWittawat Jitkrittum, Zolt\u00e1n Szab\u00f3, Arthur Gretton ; ICML 2017, PMLR 70:1742-1751\n\nTime dependence\n----------------\n\nIt is also the case that if the variables have time dependence, then appropriate corrections must be made for the test threshold, to avoid excessive false positives. Does the fMRI data exhibit time dependence?  For the case of multivariate statistical dependence testing, such corrections are described e.g. in:\n\nhttps://papers.nips.cc/paper/5452-a-wild-bootstrap-for-degenerate-kernel-tests.pdf\nA Wild Bootstrap for Degenerate Kernel Tests\nKacper Chwialkowski, Dino Sejdinovic, Arthur Gretton\nNeurIPS 2014\n\n"}