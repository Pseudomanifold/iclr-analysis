{"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #4", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review": "This paper investigates the possibility of using hypermodels in improving the exploration of bandit problems. By using SGD for training the hypermodel parameters, this paper introduces a computationally efficient alternative to ensemble methods. The idea of the paper is novel and interesting; however, I do have several concerns, mainly from numerical experiments that I would like the authors to address those in the rebuttal.\n\n1) My first and the most important concern is that the numerical experiments do not evaluate different aspects of the method. There are numerous ways to check the sensitivity of your method for the choice of hyperparameters that I think could be added to the appendix. In addition to testing various values for $\\sigma_p$, $\\sigma_w$, and $\\nu_0$, I think that multiple experiments are missing:\n    i) larger neural network\n    ii) I was expecting to see what would happen without additive prior. It could be one of the baselines in Figure 3. Even though (Osband et al., 2018) discuss the effect of this extension, but the use of this model is not numerically justified. \n    iii) How the experiments are sensitive to the noise of the output variable? What will happen if you do not add noise?\n\nThere are also other experiments possible such as testing on a real scenario that would significantly improve the presentation of the work. This is not a requirement though.\n\n2) I didn't get what is the purpose of the last term in the loss function defined in Section 2.1. Why you are looking preferring $\\nu$ to be close to $\\nu_0$? \n\n3) P4, \"it is natural to consider linear hypermodels in which parameters a and B are linearly constrained.\" This sentence needs to be clarified. I didn't comprehend how you are dealing with large neural network issues.\n\n4) In Section 6, I was expecting to see a simulation showing a comparison of linear hypermodel with hypernetworks. \n\n\nMinor:\n* On P2, \"informatino-directed\" -> \"informatino-directed\"\n* In the second paragraph of Section 2.1, it is mentioned that a hypermodel involves perturbing data. My understanding is that what is meant here by perturbing data is to add some noise to X. However, in the later formulae, there is no such thing as perturbing data. You could say that since our numerical experiments didn't show any improvement using data perturbation, we didn't include it in our notations. Please remove the confusion.\n* very minor, but I would suggest using a different notation for $a$ in Sections 2.1 and 2.3 to remove any possible confusion. \n* I think that the summation in computing the variance of IDS should be over $\\tilde{Z}_{x^*}$.\n\n"}