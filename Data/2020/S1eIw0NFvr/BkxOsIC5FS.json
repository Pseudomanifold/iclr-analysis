{"rating": "3: Weak Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper study how the pruning impacts the images/classes and observes which images/classes do not generalize in the pruned networks under ResNet-50 with ImageNet dataset. The authors first observe whether there exist classes exhibiting higher/lower accuracy in pruned networks compared to unpruned ones. Then, the authors define images (PIE) that generate inconsistent predictions for unpruned/pruned networks and observe the properties of PIE (e.g., whether corrupted, contains multiple labels, etc.). In particular, PIE images could be considered as `hard examples\u2019 since even the unpruned networks misclassify them w.h.p. The authors also verify the properties of PIE and conclude the paper.\n\nOverall, I think the paper contains some interesting observations but not enough for publication yet, due to the following reasons. First, it is well known that hard (noisy or corrupted) images are harder to be correctly classified in networks of smaller model power (Hendrycks & Dietterich, 2019). That is, results in Figure 4 and Figure 5 are not very surprising. Moreover, there is no further discussion on the hypothesis test after presenting Table 1 and Figure 3. \n\nThe paper is generally well written even it contains few typos and inconsistent presentations (e.g., legends in images are inconsistent. Both underbar and space are mixed.)\n"}