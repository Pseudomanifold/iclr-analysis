{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "By extending prototypical networks, this paper proposes a probabilistic model, i.e., stochastic prototype embedding, that treats embeddings as random variables. The model is very straightforward and easy to understand. The authors make a few assumptions to simplify the problem. For example, the distance between every instance $z_i$ of class $y$ and the class embedding $\\rho_y$ follows a Gaussian distribution, and the a softmax prediction for a query embedding also follows a Gaussian distribution. Combining these, the authors give the class posterior for the query. Since the class posterior involves an integral, the paper employs a naive samplying and an intersection sampling. The intersection sampling seems a bit interesting in the sense that the sampler focuses on the intersection of the input distribution and the class distribution and it is more sample-efficient.\n\nIn general, I think this probabilistic approach is very natural and simple, which is definitely one of the advantages. Compared to the deterministic approach, i.e., prototypical networks, one biggest advantage I can think of is that it will be more robust while dealing with noisy training set (many outliers exist). However, such probabilistic formulation does not seem to be new in terms of visual recognition, although it may be new in few-shot learning.\n\nI also have a few concerns. One of my biggest concerns is the experiment. The experiments conducted in the paper are toy-ish. I can see that the proposed method indeed shows some gains over the prototypical networks on some toy tasks, but one can not really tell whether this approach really works for more realistic settings. For few-shot learning, I believe the authors should try to run experiments on Mini-ImageNet or CUB. A good experimental example to follow is [A Closer Look at Few-shot Classification, ICLR 2019]. It should be easy to run your model in their settings, since they have oper-sourced code."}