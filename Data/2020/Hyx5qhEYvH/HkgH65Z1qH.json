{"experience_assessment": "I do not know much about this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper proposes a brain-inspired recurrent neural network architecture, named Recurrent Leaky Integrate-and-Fire (RLIF). Computationally, the model is designed to mimic how biological neurons behave, e.g. producing binary values. The hope is that this will allow such computational models to be easily implemented on neuromorphic chips and the solution will be more energy-efficient. On neuromorphic MNIST and CIFAR, the proposed model achieves higher classification accuracy than other listed methods. On ROGUE, a text summarization benchmark, the proposed model achieves competitive performance. \n\nI am leaning towards rejecting this paper. The main advantage of the proposed computational model was not supported by evidence in the paper. The presented evidence only suggests that the computational model has the capacity for learning to solve real-world tasks to a degree that is on par with other existing computational models. But what supposedly distinguishes the proposed one from the rest, i.e. being more hardware-friendly and energy-efficient, was not demonstrated. "}