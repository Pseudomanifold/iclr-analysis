{"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This paper attempts to improve multi-agent RL by introducing a new algorithm, scholastic actor-critic. The paper evaluates their method on three multi-agent benchmarks, including the coin game, cooperative treasure collection, and MAgent.\n\nOn the whole, I found the paper difficult to understand. It was hard for me to parse what the proposed method was actually doing, and what was the motivation behind it. As far as I can tell, the paper introduces a new critic that randomly assigns agents into groups and then computes a Q value on based on the \u2018average contributions\u2019 of the agents in the group (making a \u2018super agent\u2019). It\u2019s not clear to me how these contributions are aggregated, as well as which agent\u2019s observation is used as input (there\u2019s only 1 \u2018o\u2019). There is also a gamma value that is introduced in section 3.2.2 without explanation. Section 3.2.3 talks mostly about how the authors construct their baseline for the advantage function. I don\u2019t see how any of these results in the \u2018actors being able to communicate more efficiently during training\u2019.   \n\nIn terms of results, the proposed method doesn\u2019t seem to perform much better than the baselines (it performs worse than at least 1 baseline when there\u2019s fewer than 64 agents, slightly better with 64 and 128 agents). There\u2019s also no error bars to indicate whether the slight improvement with 64 and more agents is significant.\n\nOverall, I do not recommend acceptance in the paper\u2019s current form. I\u2019d encourage the authors to re-write the paper to make the main contribution clearer, including checking for grammatical and spelling errors, and to improve the experimental results with a smaller number of agents. \n\n\nOther comments:\n-\tWhy the name \u2018scholastic actor critic\u2019? \n-\tI don\u2019t see how the MAgent environment is an iterated prisoner\u2019s dilemma, as claimed in section 4.1\n-\t\u201cThen other agents\u2019 contributions could be formulated as 15.\u201d -> not sure what this means\n"}