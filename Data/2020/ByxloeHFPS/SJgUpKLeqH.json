{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper studies the theoretical aspects of HRL. It provides theoretical analysis for the complexity of Deep HRL. The idea is to exploit a given action hierarchy, and known state decomposition, the fact that the high-level state space shares similar low-level structures. The final result is an exponential improvement of HRL to flat RL. \n\nOverall, the paper pursues an ambitious goal that analyses the complexity of Deep HRL. The writing is not easy to follow. I some questions and concerns as follows\n\n- I wonder why the state space must be defined in a product form? If a standard RL is used, then it could be applied directly to the state space ($S_L$) on that primitive actions operate. Hence L-1 state spaces will be discarded? I don't see why a flat RL must estimate policies for states at all levels. It looks like many later derivations based on the assumption of factored state spaces and factored transitions on different levels. In the case of factored representation, the authors should make clear assumptions and find a better way to describe the overall algorithm.\n\n- Section 3.2: the authors use time index for Q and V, does that mean all analysis is for non-stationary MDPs? This is not the assumption in Jaksch et al. (2010) and this paper. The description in this section is very confusing and contains a lot of imprecise definitions\ne.g. should H = \\prod {i=1} H_i?? is h =(h_1,...h_L) not in [1,H]? what is the definition of the immediate next lexicographical tuple? etc. The definition of \\sigma is also unclear and hard to understand.\n\n- The analysis in Section 4. and Algorithm 1 are not for Deep HRL as said in Abstract and Introduction. The analysis is based on PAC-MDP learning for models at each action level. This paper's contributions might be clearer if the authors made clearer assumptions, e.g. on action hierarchy, abstract state space structures etc..\n\n"}