{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "In this work, the authors propose a network pruning method to learn a pruned network during training. Specifically, they add a pruning mask for each layer and induce a sparisity loss on the mask variables during training. The pruned network is obtained by applying the learned mask to the networks.\n\nThe paper seems to be well contained. However, my assessment of this paper is weak reject. I am mainly concerned with the novelty of this method. Also i think some more evaluation is needed to fully understand the effectiveness of this method. My questions are summarized as follows:\n\nQ1: In the methods part, the authors said that \u201cPrevious pruning approaches often prune Conv filters with their successive Batch Normalization layer unchanged.\u201d Can the authors give some reference here as to which pruning approaches?\n\nQ2: Did the authors compare the proposed approach to training the pruned networks from scratch as done in [1]? Also can the authors analyze the sparsity patterns of the pruned networks as done in section G in the appendix of [1]?\n\nQ3: What is the difference of your approach to [2]? They seem to be very similar. I think it is necessary to add some discussion in the related work. Is there any experimental results for comparison with [2]?\n\n[1] Rethinking the Value of Network Pruning. Liu et al. ICLR 2019\n[2] AutoPruner: An End-to-End Trainable Filter Pruning Method for Efficient Deep Model Inference. Luo et al. Arxiv, 2018."}