{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "In this paper, the authors present a method, Learning to Control (LTC), that enables a reinforcement learning agent to learn to read and write external memory. They follow the intuition that human has two degrees of plasticity for memory, which leads to the dense-sparse memory design in this paper. The proposed method can be applied to a few-shot setting. \n\nwriting: The writing is ok. Readers can obtain the essence by a reasonable amount of guessing. \n\n\nStrength: Although memory augmented neural networks and reinforcement learning are both well-known, the proposed method combined them in a novel way.  The presented approach outperforms two baselines on the stanford dialogue dataset. \n\nWeakness: There is no ablation study for the proposed method to fully understand why the proposed method is superior. The authors use REINFORCE as the RL algorithm which is no longer useful in most of the complex RL tasks. More advanced RL algorithms are encouraged to be tried. The proposed title is \"Learning to Control\",   which I don't see where the control part is. It seems the LTC only refers to the REINFORCE agent. The experiments are very minimal which did not provide enough information to distinguish the proposed method from other methods. \n\nOverall, the general direction is promising. However, the paper is not yet fully finished. I believe the authors need major changes to the experiments section as well as the method description section. Hence, I cannot recommend this paper to acceptance.\n\nminor: \nexel -> excel \nFigure 1 needs more clarification."}