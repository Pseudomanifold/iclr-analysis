{"experience_assessment": "I have read many papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "\nThe paper proposes a memory network architecture with a sparse memory. Each memory entry contains a key (vector) and a value (class label). The memory is addressed using a policy pi_theta, which selects a single memory entry to be updated at each time step. The policy pi_theta is trained using policy gradient with the reward being the increase in the policy's certainty (measured as entopy). The model is evaluated on an online NER task that mimics the meta-learning setting of http://proceedings.mlr.press/v48/santoro16.html. In that work, the examples are provided in episodes. The labels are renamed at the beginning of each episode (to prevent fitting to the labels). The model has to predict the label of each example in sequence, and the correct label is given after each prediction.\n\nThe paper suffers from the following issues:\n\n- The method in the paper is very similar to the existing discrete addressing scheme (https://www.mitpressjournals.org/doi/full/10.1162/neco_a_01060), which naturally also uses RL for training. \n\n- The method description is either incomplete or incorrect. The task label does not seem to influence the loss function at training time. The current training loss only encourages the entropy to reduce, so unless the LSTM is pre-trained, there is no guarantee that the key s will address the right memory entry. Please correct me if I am mistaken here.\n\n- The writing is unclear. Task descriptions and notations are not properly set up. The experiment section does not explain the details of the experiments, leaving the reader to look at Santoro et al., 2016 for context. Even then, some statements in the experiment section are confusing. For instance, the numbers of classes in the description (5 and 20) do not match the number of NER classes (8).\n\n- The task used in the paper is non-standard. The paper could have used meta-learning tasks from previous papers, including the ones in Santoro et al., 2016.\n\nOther comments:\n\n- The citations should be written as \"xxx (author, year)\" and not \"xxx, author (year)\".\n- The paper could benefit from proofreading."}