{"rating": "8: Accept", "experience_assessment": "I do not know much about this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #4", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper proposes a novel method to solve the sequential signal reconstruction problem. The method is based on the deep unfolding methods and incorporates the reweighting mechanism. Additionally, they derive the generalization error bound and show how their over-parameterized reweighting RNNs ensure good generalization. Lastly, the experiments on the task of video sequence reconstruction suggest the superior performance of the proposed method.\n\nI recommend the paper to be accepted for mainly two reasons. First, they derive a tighter generalization bound for deep RNNs; Second, the experiment results align with the theory and show the continuous improvements when increasing the depth of RNNs.\n\nQuestions:\n1. How is the computation complexity of the proposed method when compared with other methods? Will the reweighting l1-l1 norm significantly increase the computation time?\n2. The experiments show that increasing the depth and/or width of the networks yields better performance, however, is there a boundary for such performance gain? For example, if the depth continues increasing, will the proposed method suffer the similar problem as other methods (performance does not improve or even degrade)?\n3. As the MOVING MNIST dataset is from a relatively simple and special domain, is it possible to reproduce the similar performance gain on other more realistic datasets?\n4. Are there any known limitations of the proposed method?"}