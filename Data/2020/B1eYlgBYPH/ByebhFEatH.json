{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "\nStrength:\nThis paper proposes a new reweighted-RNN by unfolding a reweighted L1-L1 minimization problem. It develops an iterative algorithm to solve the reweighted L1-L1 minimization problem, where the soft-thresholding functions can be adaptively learned. This paper provides the generalization error bound for deep RNNs and shows that the proposed reweighted-RNN has a lower generalization error bound. In addition, the paper shows that the proposed algorithm can be applied to video-frame reconstruction and achieves favorable results against state-of-the-art methods. The paper is well organized, and the motivation is clear. \n\nWeakness:\nThe effectiveness of the reweighted L1-L1 minimization method should be better explained and evaluated. It is not clear why the reweighted L1-L1 regularization is better than the L1-L1 regularization. In addition, the experimental evaluation does not support this claim well. The authors should compare the baseline method which uses the  L1-L1 regularization in their framework instead of directly comparing the proposed algorithm with [Le et al., 2019] as there exist differences in the algorithm design. This is an important baseline. \n\nAs claimed by the authors, the proposed reweighted-RNN has different sets of {W_l;U_l} for each hidden layer. This will definitively increase the model size when the depth increases. The authors should clarify whether the performance gains due to the only use of large model parameters. \n\nOverall, this paper proposes an effective reweighted-RNN model based on the solver of a reweighted L1-L1 minimization. Theoretical analysis and experimental results are provided. I would be willing to increase the score if these problems are solved in the authors\u2019 response. \n"}