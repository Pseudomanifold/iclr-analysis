{"experience_assessment": "I have read many papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #4", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "The paper proposes a method to estimate the similarity of sentence embedders called N2O with the goal to better inform embedder choice in downstream applications. For two embedders A and B, N2O samples sentences called queries from a corpus, uses A and B to compute embeddings for each sentence, determines the k nearest neighbors (= other sentences from the corpus) for each sentence, and computes the overlap of the resulting sets of neighbors. Nearest neighbors are computed with Cosine similarity.\n\nThe paper should be rejected, mainly because the proposed method is not appropriate to inform embedder choices as claimed by the paper.\n\nI doubt that the results from this paper can be used to make better embedder choices. The paper measures which embedders are similar in a specific way, but this does not tell us much about the performance in downstream tasks. Only based on the N2O measure, no informed decision can be made which embedder will perform well on a given task. Hence, the approach is not well motivated. Evaluation metrics such as the GLUE benchmark or SentEval provide much more information what we can expect from specific embedders. Hence, I think the results in the paper are only interesting to very few readers. Furthermore, the paper uses Cosine similarity to compute the similarity between embedders. However, embeddings are often not used directly, but used as input for a model (e.g. a neural network), which learns to predict something based on the embeddings. Hence, two embedders which are similar according to N2O may perform differently in downstream tasks.\n\nTo improve the paper, I recommend to test whether the N2O similarity correlates well with downstream performance. Concretely, the paper should clearly answer the question whether we can predict the downstream performance of an embedder A given its N2O similarity to an embedder B and the downstream performance of B. Furthermore, I recommend to also use other metrics to compute the distances between embeddings, and not only Cosine similarity. Th robustness and relevance of the findings is much higher if the findings are consistent across many different metrics. Instead of computing the overlap of the neighbors for different values of k, the paper could also use ranking measures to estimate the similarity of embedders. Furthermore, I think this paper fits much better to a conference focused on natural language processing. \n\nQuestions:\n1. The paper claims that N2O can be used to inform embedder choices. Based on the main results in Figure 3, how can this help to decide which embedder to use for my task at hand?"}