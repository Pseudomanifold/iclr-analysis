{"experience_assessment": "I have published in this field for several years.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "This paper couples self-organizing maps with convolutional neural networks for integrating genomic data. The authors are clear in terms of the methodology and they show that the method has excellent performance. The idea is clever, use the SOM to generate an image (the pairwise distance embeddings), then feed this embedding of distances or the distance map as an image into a CNN. The problem I have with this paper is the authors are proposing an embedding or feature space for deep neural networks. It is really confusing to me why there is no discussion of variational autoencoders or embedding algorithms like t-SNE as a comparison point. The lack of touch on the vast literature of learning features and embeddings from words, letters, music, or other non-obviously numeric signals was problematic."}