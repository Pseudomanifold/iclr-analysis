{"rating": "6: Weak Accept", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #4", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "The paper suggests learning decision trees to learn policies that can be verified efficiently. The decision trees are learnt by imitation learning (DAGGER) and are guided by a DNN policy (called the oracle) and its Q-function. The paper is an extension of VIPER to mixture of Experts.\n\nThe paper does two contributions:\n- the modification of Viper to learn a mixture of decision tree policies that better mimics the DRL agent, and\n- the fact that the model based on Mixture of Experts is still interpretable.\n\nForm my understanding, it is known that mixture of experts can be more accurate than a single decision tree. I'm unsure about the importance of verifying experimentally that it is also the case in the context of DAGGER. Could you please expand on why using a mixture of experts in the context of DAGGER is challenging? I think that would be an important addition to the paper. That being said, the experimental results are of interest as they bring interpretability and verifiable RL to more challenging environments.\n\nMinor comments:\n- The notation \"EM\" that appears in the fourth paragraph of the introduction is not defined previously.\n- There a few typos: e.g., \"there do not exist\"\n- How many seeds are used for the \"average results (e.g. Appendix E)?"}