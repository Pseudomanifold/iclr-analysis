{"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "\n\nStrengths: \n- The paper enhances the beam search approach to generate explanations for answers to visual questions. The explanations are further used for verifying the yes/no answers.\n- The paper constructs a VCBS algorithm with novelties in allowing soft constrains of the generated beams. Since I have not worked on the constrained beam search before, thus it is hard for me to measure the novelty of this method.\n- The results of VQA 2.0 is pretty good. The accuracy of the Yes/No questions almost achieves the SotA systems. \n\n\nWeakness:\n- I have a question about the NLI system. Since the NLI is a three-way classifier where the answers would be \"Entail\", \"Contradictory\", and \"Neutral\".  What would the system do when the relationship is \"Neutral\"? For now, I think that it just give an answer of \"no\" but I am not sure whether it is correct.  For example, in Fig. 3, it shows an explanation (premise) of \"something (not the vegetable) on a plate\" and the hypo is \"there are vegetables on the plate\". Since the hypo is not necessary to contradict the premise, the relationship should be neutral. It does not directly provide evidence of the answer.\n\nComments:\n- Since more data are involved in training the explanation system, the proposed methods are not fairly compared with the BAN method. It would be better to mention this detail in the paper. \n\n"}