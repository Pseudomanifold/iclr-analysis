{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper proposes a meta label correction approach for learning with noisy labels. They view the label correction procedure as a meta-process and then train a supervised model to fit the corrected labels generated by the meta-model. Some experiments and comparisons with SOTA are given, together with an ablation study.\n\nPros:\n-This paper made an interesting contribution to use a meta-model for label correction and then train a supervised main model using the correction labels via a bi-level optimization problem.\n\nCons:\n-The problem setting is a bit unclear to me. Weakly supervised learning and learning with noisy labels seem to be mixed up in this paper. Weakly supervised learning aims to learn from weak supervision, i.e., incomplete/ inexact/ inaccurate supervision (see more details in \u201cA brief introduction to weakly supervised learning, National Science Review, 2018\u201d), which is a more general concept. This paper only discussed learning from inaccurate supervision, thus stating learning with weak supervision may be a bit confusing.\n\n-In the introduction part, the authors reviewed two lines of prior works: re-weighting training instances and label correction. The literature review seems to be insufficient since there is another important research line that uses the sample selection bias trick. See \u201cJiang, L., Zhou, Z., Leung, T., Li, L., and Fei-Fei, L. Mentornet: Learning data-driven curriculum for very deep neural networks on corrupted labels. In ICML, 2018\u201d and \u201cHan, B., Yao, Q., Yu, X., Niu, G., Xu, M., Hu, W., Tsang, I., and Sugiyama, M. Co-teaching: Robust training of deep neural networks with extremely noisy labels. In NeurIPS, 2018\u201d.\n\n-The strategy proposed in Sec 3.1 to convert a classifier to a label correction network seems a little suspicious to me. Can any further explanation or theoretical intuitions be given on how the hyperparameter lambda works? This would be very useful and make the paper more convincing.\n\nOverall the paper proposed an interesting idea to deal with noisy labels in a meta label correction way, but some unclear parts need to be clarified and improved.\n\nFurther details:\n-Sec 2.2: there is a small mistake of the citation.\n\n-Sec 3.3: using a k-step look ahead SGD update as an estimate to the optimal model is good to me. But here k is set to 1500 and then decreased to 500, it seems to be too large and inefficient since the paper L2R also uses a similar trick for optimization and they only use k=1. How about the computation time?\n\n-In the experiments, MLC seems to be inferior in the UNIF case when using very small clean data and slightly outperforms baseline methods when using larger clean data. So how many clean data are used in tuning the baseline methods, since for L2R they only used 1000 clean data for all the experiments, and for Forward and GLC, they are also sensitive to the number of clean data used."}