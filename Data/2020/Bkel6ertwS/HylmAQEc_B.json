{"rating": "1: Reject", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "The authors compared a bidirectional LSTM to traditional machine learning models for genomic contact prediction. Although the paper presents an interesting application of ML, I vote for rejection since i)  the paper is similar to previously published works and lacks methodological novelty, ii) the description about the data and methods is not written clearly enough, and iii) the evaluation needs to be strengthened by additional baseline models and evaluation metrics.\n\nMajor comments\n=============\n1. As pointed out by Maria Anna Rapsomaniki, the paper is similar to previously published papers, which are not cited.\n\n2. It is unclear which features were used as inputs. How were the features that are described in section 3.1 represented? Are these binary values or the mean of the Hi-C signal over the genomic region? What does 20kb mean? How were genomic segments of different chromosomes treated?\n\n3. The motivation of using a biLSTM in section 4.3 is unclear. What has the choice of a biLSTM to do with the fact that DNA is double stranded? The DNA is not used as input to the model and genomic contacts can be formed between non-adjacent segments. Please compare recurrent models to non-recurrent models such as fully connected or convolutional networks.\n\n4. The authors used the weighted MSE as evaluation metric, which was used as training loss of the biLSTM, but it is unclear if the same loss was used for linear and gradient boosting regression. To understand if the performance differences are due to the loss function or model architecture, the authors should use the same loss function for training all models, and use additional evaluation metrics such as the MSE and R^2 score.\n\n5. The authors used linear regression weights to quantify feature importance (figure 4). It is unclear if the biLSTM assigned the same importance to features. To quantify the importance of features learned by the biLSTM, the authors could consider correlating the activations of LSTM units with input features, and also analyze if importances depend on the position of features.\n\n6. Which hyper-parameters of the biLSTM and baseline method did the authors tune and how?\n\n7. The authors should compare the described weighted MSE to the mean squared logarithmic error loss, which is commonly used for penalizing large errors less.\n\n8. Why did the authors use the activation of the center LSTM hidden state instead of concatenating the last hidden state of the forward and reverse LSTM? By using the center hidden state, half of the forward and reverse LSTM activations are ignored."}