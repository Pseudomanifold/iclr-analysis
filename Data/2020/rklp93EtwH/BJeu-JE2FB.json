{"rating": "8: Accept", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper proposed a knowledge-based meta-learning framework, called ARML(Automated Relational Metal-Learning) that automatically extracts cross-task relations and constructs a meta-knowledge graph. ARML wanted to solve the task heterogeneity problem in meta-learning through knowledge graph learning using graph neural networks. To do this, the authors introduced a framework consisting of (1) finding a prototype-based relational structure, (2) constructing a meta-knowledge graph, and (3) adapting the task-specific knowledge. Experimental results show that the proposed algorithm outperforms other competitive algorithms in few-shot learning tasks, which is justified by experimentally showing that the learned meta-knowledge graph has a meaningful interpretation.\n\nThe paper was well-motivated and well-written, which made it very interesting to read. Looking at the task heterogeneity problem of meta-learning as a knowledge graph learning problem is the most important contribution of this paper. Since then, the framework's proposal to learn it as a graph neural network is a very natural extension, which can greatly increase the performance of existing few-shot learning tasks.\n\nThe question here is whether the meta-learning method for finding relational structures through knowledge graphs is the first one proposed in this paper. The paper \"Few-shot learning with graph neural networks, ICLR-2018\" performed the few-shot learning task with very similar motivation. What is the difference compared to this paper?\n\nAnd as mentioned in the paper, HSML is the closest study to ARML in that it considers high-level relations between cross-tasks. The reviewer is very curious about the qualitative comparison of the high-level structures found by the two algorithms, and I confident that this comparison will enrich the paper."}