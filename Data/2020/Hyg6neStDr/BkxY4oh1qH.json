{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "The paper proposes a post-processing recipe for gender-neutralizing word embeddings.\nThe proposed method is a combination of existing Debias Algorithm (Bolukbasi et al, 2016) and all-but-the-top model (Mu and Viswanath, 2018). The former tries to identify gender component and eliminate the effect of that and the latter tries to reduce the effect of frequencies in the quality of embedding. The proposed method, Double-hard Debias tries to reduce gender bias from embedding, in a way that embeddings remain effective.\n\nThe paper is readable and addresses an important question.  However, the method proposed is incremental, missing extensive technical or intuitive exploration of its effect and has limited  experimental evaluation. \n- Debiasing experiments are limited and the task in Section 4.1 seems a  toy task  to me.\n- Showing neighborhood of problematic words, before and after the preprocessing is useful to see.\n- The performance of the processed embeddings in downstream NLP tasks could be reported.  \n\nDecision: I vote for a weak reject."}