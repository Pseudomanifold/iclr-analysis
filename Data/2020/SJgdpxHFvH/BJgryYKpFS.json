{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper examines the performance of MAML, FOMAML, and Reptile gradient based meta-learning algorithms on the task of semantic image segmentation. The paper proposes to do black box optimization (successive halving) on the hyperparameters of the inner loop of the gradient meta-learners for improved performance. The paper proposes some modification on the segmentation model architecture (no ablation study presented). Finally, it is shown that pre-training using meta-learning on similar segmentation tasks works better then just using ImageNet based model pre-training.\n\nIn its current form I suggest to reject the paper and urge the authors to improve it according to the following points:\n\n1. In parts (specifically the intro and some other earlier parts) the paper is very well written, but the later parts, the description of the model modifications (did you consider to add an architecture diagram?), the details of the experiments, the punch-line of the theory development that has been attempted, etc are not very clear and hard to follow. I suggest the authors to improve the readability of these parts, add some helpful / motivating diagrams and examples (perhaps some qualitative results too?), state more clearly what is used for meta-training? how it is made sure that meta-testing is done on a separate set of categories? (I did not see this split in the Appendix) and etc\n\n2. My main concern is novelty. As it stands, the current novelty proposition is: black-box optimization of LR and number of iterations in MAML style meta learning (hardly novel), architecture modifications (no ablation study if these help or not), small improvement on FSS-1000 5-shot test (what about other shots? still not sure about the splits), and showing meta-training on similar tasks is better then not doing it (that is using ImageNet pre-trained backbone for init) - again hardly a novel insight. For the last point, saying that meta-learned model was initialized from scratch does not cut it, as it was meta-trained on massive data that is more related to the test tasks then the ImageNet.\n\nI suggest the authors to mainly focus on 2, although making the writing clearer and better is also very important for a high quality paper."}