{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "Summary - The paper first makes the observation that training algorithms and architectures for meta-learning have become increasingly specific to the few-shot set of tasks. Following this, the authors first investigate if it\u2019s possible to learn good initializations for dense structured prediction tasks such as segmentation (across arbitrary amounts of available input data). Concretely, the claimed contributions of the paper include -- (1) extension and analysis of first order MAML like approaches to image segmentation; (2) using a formalized notion of the generalization error of episodic meta-learning approaches to decrease error on unseen tasks; (3) doing this via a novel neural network parametrically efficient segmentation architecture and (4) empirically comparing meta-learned initializations with ImageNet pre-trained initializations with increasing training set sizes.\n\nStrengths\n\n- Apart from the flaws mentioned under weaknesses, the paper is generally easy to follow. While it\u2019s somewhat hard to understand the motivations and the concrete contributions made by the paper, sections are more-or-less well-written.\nUsing the proposed hyper-parameter search scheme over first-order MAML approaches demonstrates improvements over not baselines which do not use the same and baselines which do not involve meta-learning.\n\nWeaknesses\n\nThe paper has some major weaknesses that affect the clarity of the points being conveyed in several sections. These weaknesses form the basis of my rating and addressing these would not only help in adjusting the same but would also help in improving the current version of the paper significantly. Highlighting these below:\n\n- The paper claims to make several contributions but it\u2019s hard to concretely understand them in several sections. For instance, the abstract mentions -- \u2018\u2019A natural question that \u2026.. human level performance in both.\u201d The statement is slightly unclear to me -- is the intended sentiment the fact that the goal should be to develop a single algorithm that works well for both few-shot and many-shot settings? If so, why should that be the case? Essentially, what is the limiting factor being identified that restricts few-shot approaches from performing well in many-shot settings? Maybe the statement could be framed better but in it\u2019s current form it\u2019s unclear what is being conveyed. When this is mentioned again in the introductory section, it is followed by a statement indicating that meta-learning an initialization is one solution. Why is this surprising? Maybe I\u2019m mis-understanding the motivation behind the claim. Could the authors clarify this? \n\n- Similarly, it\u2019s unclear what question (3) in the introduction is trying to address. Which \u201cdata\u201d (training / testing set of tasks) is the fixed update policy not conditioned on? Could the authors clarify this?\n\n- The description of the single update hyper-parameter optimization (UHO) is hard to understand in Sec. 4. -- specifically the text surrounding eqns (5) and (6). The transition from Eqn (5) -> Eqn (6) is unclear. Could the authors clarify this clearly? This section is further referred to in subsequent sections as a supporting basis for some of the obtained results (specifically, the last para on page 6)\n\nReasons for rating\n\nI found certain sections of the paper particularly hard to understand and interpret. I would encourage the authors to address these more clearly in the responses. The highlighted strengths and weaknesses of my rating and addressing those clearly would help in improving my current rating of the paper.\n"}