{"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This paper explores a very interesting idea: can a model learn what variables are and how to use them? Unfortunately, the paper doesn't seem quite ready: the model description was very hard to follow and it's not clear the approach has found a compelling use case.\n\nI read the paper carefully three times, and try as I might, I simply can't get my head around the entire architecture. The modeling section jumps straight into a series of definitions, without trying to build intuition or provide a worked example. There is an example in Figure 2, but it isn't really explained and I didn't find it helpful. Unification seems to be implemented as a form of attention (or self-attention) where the model can control the degree to which a symbol acts as variable. But the relationship between soft unification and attention isn't really spelled out -- what's the same, what's different? Ultimately it's not clear to me what the model is attending over during soft unification.\n\nThere are various other aspects of the paper that aren't clear:\n- strong vs. weak supervision\n- comparison models DMN and IMA are not introduced at all, and include no references\n- the logical reasoning experiment is not clearly described\n- there is only a cursory conclusion\n\nI am not sure the model has found a compelling use case. On bAbi with weak supervision, the model is worse than the comparison models. It only slightly beats out memory networks with strong supervision. For logical reasoning, it's not clear what it is compared against or if the comparison is fair. The clearest win over standard networks is on the simple synthetic experiments.\n\nFinally, the authors mention the paper has a cognitive science motivation, in that \"Humans learn what variables are and how to use then at a young age\" or that \"symbolic thought with variables is learned...\", taking a strong \"nurture\" stance on the origin of variables. But variables could very well be innate and simply early emerging. Any discussion of the origin of variables in the mind requires more nuance.\n\nI am excited about this research direction, and it could ultimately be a very nice contribution as the work matures. I don't think the paper is ready in its current form.\n"}