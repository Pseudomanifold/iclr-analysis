{"rating": "3: Weak Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "I Summary\n\nThe authors present a method that computes a saliency map after each scale block of a CNN and combines them according to the weights of the prior layers in a final saliency map. The paper gives two main contributions: SMOE, which captures the informativeness of the corresponding layers of the scale block and LOVI, a heatmap based on HSV, giving information of the region of interest according to the corresponding scale blocks. The method is interesting as it does not require multiple backward passes such as other gradient-based method and thus prove to be more time-efficient.\n\nII Comments\n1. Content\nOverall the paper is very interesting, but it is not always clear what the contributions are.The authors refer to \"scale\" in CNNs, this could be described a little as to explain what are scale blocks in a CNN, before introducing the terminology.\nThe proposed method \"LOVI\" is promising and I like the use of HSV for the different components. However, it is hard to read, especially when alpha-blended with a grayscale version of the original image.\n- The introduction doesn't clearly state what are the contributions of the method, an example of possible applications would be appreciated (the following about robotic for example but with more details)\n- 3.1 I really enjoy the fact that different datasets are used for their different properties (foreground, background, sparsity), this is a nice touch\nFigure 4 results are a little underwhelming, SMOE's scores are very close to the other methods\n- 3.2 The authors refer to Smoothgrad squared method, it is indeed a good process to refine saliency maps, however why it is used could be detailed, just as the parameters chosen for its implementation.\n- 4. The authors claim their implementation is \"approximately x times faster\" but there is no quantitative proof of it, which seems to be one of the selling-point of the paper (or at least one of the best results)\n\n2. Writing\nThose typos do not impact the review score, I hope it can help the authors to gain more clarity in their writing.\n- Abstract: \"it is also quantitatively similar or better in accuracy\" -> shouldn't it be \"and\" instead of \"or\"?\n- Intro\n\"a gradient saliency map by trying to back-propagate a signal from one end of the network and project it onto the image plane\" not well articulated, \"by trying to back-propagate\" -> \"by back-propagating\" (the claims seems weak otherwise)\n\"is running a fishing expedition post hoc\" ;)\n\"An XAI tool which is too expensive will slow down training\" Computationally expensive?\n- 2.1\n\"The resemblance to conditional entropy should be apparent\" -> is apparent \n\"we might say it is\" -> it is (don't weaken your claims)\n\"we simple apply\" -> we simply\n- 3.1\n\"if the results appeared terrible\" -> terrible is too strong/not adapted. What is a bad result and why?\nafter eq 7 \" the second method is in information\" -> an information\n -3.2\n\"which locations are most salient correctly\" -> word missing?\n- Figure 5: \"Higher accuracy values are better results for it\" -> yield better results\n\nThe phrasing with\"one\" as in \"if one would like to etc\" is used a lot through the paper, it can be a little redundant at times.\n\nIII Conclusion\nThe paper is interesting, however, one of the major contributions seems to be the speed of the method but no quantitative results have been reported. I would really appreciate seeing some experiments over it. Overall the results of the obtained maps are not very convincing compared to existing methods. I believe the writing of the paper could be wrapped around the speed of the method and in which context it would be important (robotic, medical?).  The conclusion and discussion are short and could be filled a little more (some captions could be shortened in order to give more space)."}