{"rating": "6: Weak Accept", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "N/A", "review": "The paper proposes a new loss function which adds to the training objective another term that pulls the current parameters of a neural network further away from the parameters at a previous time step.\nIntuitively, this aims to push the current parameters further to the local optimum.\nOn a variety of benchmarks, optimizing the proposed loss function achieves better results than just optimizing the training loss.\n\nThe paper is well written and easy to follow.  However, I am not entirely convinced about the intuition of the proposed method and I think further investigation are necessary.\nWhile the method is simple and general, it also seems to be rather heuristic and requires carefully chosen hyperparameters.\nHaving said that, the empirical evidence shows that the proposed loss function consistently improves performance.\nThe following details should be addressed further:\n\n- I am a bit confused by the definition of the loss function. In Equation 1 it seems that the term on the left represents the training objective. If that is correct than Equation 2 second case contains the training objective twice?\n\n- F in Section 3 after Equation 2 is not properly defined\n\n- Could it happen that the proposed loss function leads to divergence, for example if the parameter from a previous time step theta^Tp is close to the optimum theta_star?\n\n- What is the motivation to use the L1 norm? How does this choice affect convergence compared to let's L2 norm?\n\n- Section 4.1 typo in first paragraph: K instead of \\kappa\n\n- Section 4.1 the results would be more convincing if all networks were trained multiple times with a different random initialization and Table 1 would include the mean and std.\n\n- Why is no warm-up period used for the GAN experiments?\n\n- Section 4.3: why is \\kappa increase by 1% for the speech recognition experiments where as by 2% for all other experiments?\n\n- I suggest to increase the line width of all figures since they are somewhat hard to identify on a print version.\n\n- Why is the momentum set to 0.5 for SGD in the ablation study? Most frameworks use a default value of 0.9.\n\n- I would like to see the affect of the warm-up period to the performance in the ablation study.\n\n- How does the choice of learning rate schedule, such as for example cosine annealing, affect the loss function?"}