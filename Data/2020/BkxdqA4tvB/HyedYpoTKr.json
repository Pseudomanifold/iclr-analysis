{"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "In this paper, the authors consider the problem of learning model parameters of a switching nonlinear dynamical system from a dataset. They propose a new variational inference algorithm for this model-learning problem that marginalizes all discrete random variables in the model using the forward-backward algorithm and, in so doing, converts the model to one with a differentiable density, so that the gradient of the variational objective can be estimated with the low-variance reparameterization estimator. The authors also point out an issue in choosing a variational objective; the standard ELBO objective is not suitable for their learning problem, because it leads to a model that does not use discrete random variables meaningfully. To overcome this issue, they suggest a new improved objective and a learning procedure, which encourage the learned model to use discrete variables for capturing different modes of dynamics. The proposed variational inference algorithm was applied to three datasets, and in all these cases, it showed promising results.\n\nI found the main idea and technique of the paper simple and nice. I am reasonably positive about the paper. The main text of the paper is written well, but the experimental result section seems to be rushed and needs to be polished slightly. I gave weak accept, but if the authors give a convincing answer for my question below, I may raise my score.\n\nI presume that the objective L(theta,phi) in (11) is optimized by a version of gradient ascent. Here is my question related to this:\n\n[Q] Why is H(O) in p5 differentiable with respect to theta and phi? \n\nI am asking this question because the distribution O is defined in terms of arg max, which is not a differentiable operator. Furthermore, the definition of O uses p(s_t|z,x), which uses the model parameters theta. Oh, by the way, I think that the definitions of H and L_CE should include the expectation with respect to q_theta(z|x). \n\nSome minor comments are added below.\n\n* formula (1), p2: p(x1|s1) should be replaced by p(x1|z1)p(z1|s1)\n\n* p3: There are no sub-figures labeled with (a) and (b) in Figure 2. I suggest to put (a) and (b) in front of the captions of the two diagrams in Figure 2. A similar comment applies to Figure 3, because the main text refers to something called Figure 3(a) and Figure 3(b). Also, the paper uses fig. 2(b) sometimes, and Figure 2(b) in other times. Using one convention consistently might help some readers.\n\n* p3: Cat(s_t | S(f_s(...)) ===> Cat(s_t | S(f_s(...)))\n\n* p3: SDLS ===> SLDS\n\n* p3: log p(x) <= L(...) ===> log p(x) >= L(...) \n\n* p4: I found the phrase \"so they need to perform multiple forward-backward (FB) passes\" vague. The algorithm in the paper uses FB twice, and \"multiple\" in the quoted phrase might mean 2, 3 or more. This makes it less clear whether the algorithm has any benefit over the existing approaches.\n\n* p6: This measures compliments ===> This measure complements\n\n* p6: within some small temporal around ... where noted ===> within some range around ... as noted\n\n* p6: are is constant ===> are constant\n\n* p6: The ground truth discrete states ===> The ground truth discrete state\n\n* p7: The resulting of ===> The result of "}