{"rating": "6: Weak Accept", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review": "The paper argues for the use of attractive networks (AN) for the tasks that involve learning from noisy data. Attractor networks are recurrent in nature and use energy minimization dynamics. As motivation, the authors point to studies that give evidence for the usefulness of recurrence for visual tasks. The experiments presented show that the proposed model produces better quality images than a VAE based baseline.\n\nThe main contribution of the paper appears to the scaling of the AN based architectures to large-capacity models. The authors describe several components that are aimed at improving the gradient flow information and training stability. Firstly, a procedure to constraint the convolutional filters as required for ANs is described which allows CNNs based architectures to be used. An energy-based loss function is also described.\n\nTo tackle the vanishing/exploding gradients during training the authors propose to use leaky sigmoid activation. This is applied at the pre and post-convergence stage. How critical is the leaky sigmoid? Ablation studies for the activation choice and the loss choice need to be analyzed in more detail. \n\nThe authors should make clear the novel contributions, it can be a bit hard to extract this from the descriptions of these components. The point that the proposed model achieves state of the art results for associative memory models needs to elaborate in the text. CD-VAE seems like a weak baseline for the denoising task presented. \n\nIt will be useful to get more insights into the learning dynamics of CBAN and the ablated versions apart from the denoising performance. \n\nMinor:\n\nCBAN is defined in the text. \n\nIt might be easier to follow the main body by providing all the details of a couple of tasks/datasets in the main body and moving other tasks such as super-resolution to the appendix."}