{"experience_assessment": "I do not know much about this area.", "rating": "3: Weak Reject", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "title": "Official Blind Review #1", "review": "This paper presents an attractor network (AN) approach for pattern interpretation and completion. The authors propose a convolutional bipartite architecture consisting of visible (input and output) and hidden layers with weight constraints and squared and energy-based losses. To prevent vanishing/exploding gradients, temporal-difference method and leaky sigmoid activation function are exploited. Training is done by stochastic gradient descent. In experimental validation, the proposed model is able to reconstruct missing pixels in the images for bar task and supervised MNIST. And, in OMNIGLOT and CIFAR-10 experiments, the proposed approach outperforms its variants, and in super-resolution results, it outperforms the baselines. \n\nThe approach looks interesting but the motivation of using AN might not be well justified in the current presentation. Interpretation was emphasized in the paper, but it was not clear to me what induce interpretability in the model and how to interpret experimental results. Also, even though the proposed approach shows promising results in experiments, there were no baseline or only its variants as the baseline, except super-resolution task. \n\n\nDetailed comments:\nDo you have any explanation why \\lambda =1 in TD(\\lambda) works best among others?\nIt was not clear to me how the proposed approach uses recurrent networks. \nIn supervised MNIST experiments, it was claimed that it achieved the state-of-the-art results. But figure 8 might not be enough to justify the claim and could you provide more evidence? \n\n\nI am not quite familiar with this area and my understanding might be limited. But, to the best of my judgement, this paper has an interesting idea but is not yet ready to be published in ICLR. \n\n", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}