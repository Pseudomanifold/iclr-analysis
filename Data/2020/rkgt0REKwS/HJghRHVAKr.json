{"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper tackles the problem of learning with noisy labels and proposes a novel cost function that integrates the idea of curriculum learning with the robustness of 0/1 loss. The resulting cost function is theoretically justified and experimentally validated. \n\nPros:\n(1) The proposed cost function is novel in its design, especially the aspect of curriculum learning with a computationally efficient implementation, as in Algorithm 1.\n(2) The new cost function could be treated as a simple-to-implement add-on to make learning more robust to noisy labels. \n(3) The introduction is well formulated and organized with focused motivation.\n\nCons:\n(1) Equ. 9 requires more explanation of the intuition of using a combination of conventional surrogate loss and 0/1 loss, and furthermore the role of the index indicator in balancing the above two parts.\n(2) Curriculum learning focuses on easy example followed by hard ones. Yet noisy examples are mixed with difficult ones in your formulation of sample selection mechanism (index indicator). The pruned examples are therefore more likely to have a high proportion of hard examples, which is undesirable. To illustrates the effectiveness of the proposed algorithm against such scenarios , one would like to see experiments on more difficult datasets such as Tiny-ImageNet. \n(3) It is not clear if the quantitative results in Table 2 and 3 are produced with the pre-defined \\epsilon beforehand or with grid search as done in Table 4. Knowing \\epsilon would render comparison unfair for baselines.\n \nOther remarks:\n(1) E(u) threshold parameter changes from \u201cn\u201d in equation 11 to \u201cC\u201d in equation 13 (probably considering equation 9). In Equ 13, C is given as \"n+0/1 loss\", its transition to the other alternative forms in Equ 18 is not fully explained. \n(2) The purpose of proposition 1 is unclear and may be at least shortened.\n(3) Should have used some uncertainty metric instead.\n(4) Incremental improvement over SOTA. SOTA was actually better in some cases."}