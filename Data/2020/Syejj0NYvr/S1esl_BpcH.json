{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "title": "Official Blind Review #2", "review": "The paper proposes adversarial interpolation training, which perturbs the images and labels simultaneously. The perturbed image $\\tilde x$ is around $x$ and interpolated towards another image $x'$ while the corresponding $\\tilde y = (1-\\epsilon_y)y +\\epsilon_y\\frac{1-y'}{C-1}$ is near $y$ but away from $y'$. The distance of interpolating images is L2 distance in the feature space and that for labels is L2 distance in the label space. The paper provides an interpretation of the proposed approach from the perspective of robust and non-robust features. Thorough experiments on different types of attacks and different datasets are performed. Although the results are impressive, I still have some concerns on the method itself:\n\n1. The method seems like a combination of manifold mixup [1] and adversarial training. The interpolation in the feature space is not a new idea and has been explored in Manifold Mixup [1]. The method resembles manifold mixup if we focus on $x$ because $\\tilde x$ and $\\tilde y$ both retain the original image and target $(x, y)$. The \"adversarial\" interpolation part is from $(x', y')$ in the sense that $\\tilde y$ is away from $y'$.\n\n2. The paper lacks a theoretical explanation, which makes it less convincing how it works so well.\n\n3. I noticed several papers with similar ideas, e.g. [2,3,4]. Could you please discuss the connections with them? I also suggest adding related work on semi-supervised learning in the paper (see [4] for examples). It would be better to compare with Manifold Mixup [1], UAT [4] in the experiments.\n\n\nMinor:\n\nPage 5, \" further break the correlation between $\\delta$ and $y'$\", what is $\\delta$ here? I did not find the definition above the sentence. The notation is directly used without any explanation in advance.\n\n\nReferences\n[1] Manifold Mixup: Better Representations by Interpolating Hidden States, ICML 2019\n[2] MixUp as Directional Adversarial Training\n[3] On Adversarial Mixup Resynthesis, NeurIPS 2019\n[4] Are Labels Required for Improving Adversarial Robustness?, NeurIPS 2019\n", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory."}