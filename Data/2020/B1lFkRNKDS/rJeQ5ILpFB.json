{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "Different from the attention module that modulates feature maps by incorporating the global context, this paper uses the global context to modulate the weights of convolutional layers and help CNNs capture more discriminative features. To validate its effectiveness, the author conducted a series of experiments on image classification, action recognition, and machine translation.\n\nThis idea is quite straightforward and the experimental results also show it will achieve high performance with fewer parameters compared to the feature maps modulating way. I am wondering are there any intuitive explanations why the weights modulating way is better than the feature modulating way? Or can we combine both the two way and achieve higher performance on large-scale datasets? I would appreciate it if there are some related discussions and experiments.\n\nMy major concerns are the experimental settings. For the action recognition, a lot of papers will test on Charades and Kinetics. The Something-Something dataset may be used primarily for visual understanding tasks. Of course, it is ok that we test the action recognition performance on the Something-Something dataset. But if there is only one video dataset used to report scores, I think the Charades and Kinetics is a better choice. For the machine translation, papers will mainly compare on the wmt en-de, including the cited papers. They reported the scores on both wmt and iwslt. Since the cifar-10 is very small where ablation studies performed, are the results in the table averaged over multiple training runs? And if so, how many? \n\nAlso, I notice the specific module designing is very similar to the module proposed in the Squeeze-Excitation Network. They will both first fuse the spatial information and then fuse information between different channels. The difference is the size of the final weight map, where the size in this paper is equal to the size of convolutional layers, and the size in SENet is 1."}