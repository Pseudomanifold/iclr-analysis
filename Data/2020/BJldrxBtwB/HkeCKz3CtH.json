{"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper tries to understand and tackle what they call the anomalous generalization of GANs. They first show that GANs suffer from instability because of sample insufficiency, they show experimentally that when decreasing the batch-size on both a toy dataset and CelebA that the training become unstable and the performance drops, leading to the generation of outliers, they also show theoretically in a simplified setting that small batch-size can lead to instability. They then show that the anomalous generalization can also come from the discriminator not being able to discriminate pixel-wise combination of the real samples. They show on some toy dataset and CelebA that some of the generated samples are a pixel-wise combination of two training examples and that those combination can fool the discriminator, they also show provide a theorem confirming this observation. Finally they provide two methods to mitigate the previous issues: 1) They propose to add a loss term for the discriminator and force it to also learn to discriminate pixel-wise combinations of images. 2) They propose to remove the most realistic generated samples from the mini-batch and replace them with less realistic samples\n\nOverall I find the observations of the paper interesting and worth investigating. However I find the paper a bit weak especially about sample efficiency. Indeed the instability of GANs and how it relates to batch-size as already been studied, and the theoretical results provided are quite limited. Furthermore I'm not convinced by the proposed trick to fix that issue.\nThus I'm in favour of rejecting this paper.\n\nMain argument:\n- I think the results in section 3.3 should be put into context and mention related work. First of all this bilinear example as already been studied in the literature, in the full-batch and stochastic setting. In full batch it was already known that simultaneous gradient descent doesn't converge see for example [1]. In the stochastic setting it was also studied and an algorithm was proposed to fix that see [2]. I think this related work and other need to be mentioned in this section and the results need to be contrasted with existing results. In the current state it's not clear if this theorems bring anything novel.\n- I have also some concerns about section 4.3. At the beginning of training, it's clear that it's probably easy for the discriminator to classify real samples with a large margin, but as the training progress it becomes harder and harder for the discriminator to classify real samples so it's not clear to me that assumption 2 would hold. Can you discuss it ? it would be interesting to actually check experimentally how that assumption holds.\n- I'm also not convinced by the Sample Correction trick proposed.\n- PCR really seems to improve the performance, it would be nice to run all the methods with several seeds and also show the standard deviation.\n- Why is SC only computed on a really small subset of CelebA and CIFAR10 ? why not try on the full dataset ? It makes the conclusion not very convincing. \n\n\nMinor comment:\n- Figure 1 (right): what are the axis ? in particular does the axis represent the number of training iterations ? If so what is number of generated samples used to compute the proportion of correct generated samples. Also you don't measure if there is any trade-off between quality and mode dropping. Could you measure the number of different samples that are generated to have some measure of mode dropping ?\n- For the toy task how do you count the number of rectangles ?\n- Can you define what does DIF stands for and how it is computed ?\n\nReferences:\n[1] Gidel, G., et al. \"A variational inequality perspective on generative adversarial networks.\" arXiv (2018).\n[2] Chavdarova, T., et al. \"Reducing noise in gan training with variance reduced extragradient.\" arXiv (2019)."}