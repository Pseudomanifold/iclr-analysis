{"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "*** Summary\n\nThis work proposes to use an augmented RNN model to address the incremental domain adaptation problem. In particular, it designs the progressive memory bank approach which expands the memory capacity by adding parameters every time a new task comes in. The RNN retrieves knowledge from the memory bank via key-value attention. A proof in a highly simplified case is given in addition to empirical results showing that expanding the memory bank is better than expanding the RNN states.\n\n*** Strengths\n\n1. Section 3 is well-written. The methods and motivations are illustrated clearly.\n\n2. Comprehensive experiments are conducted. Supportive results for the arguments presented in Section 3 are therefore demonstrated.\n\n\n*** Weaknesses\n\n1. Regarding Table 2., multiple runs of different sources and targets would be helpful to better understand the effectiveness of the proposed methods in the 2-domain set-up.\n\n2. The choice of key-value memory bank is not intuitive. A comparison between this memory and the traditional attention can help demonstrate the validity of this choice."}