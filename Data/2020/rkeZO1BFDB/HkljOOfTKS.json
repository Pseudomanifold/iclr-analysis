{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "\n\nPAPER SUMMARY\nVision-and-language navigation (VLN) requires an agent to take actions in realistic environments with an understanding of human language. Recently proposed dataset, Room-to-Room (R2R), is captured from real indoor environments but only English instructions are provided.  In this paper, it proposes a task of XL-VLN (Cross-Lingual Vision-and-Language Navigation). A navigational dataset with the Chinese language is collected to support learn instructions of multiple languages.  Based on this dataset, this paper studies two different learning setups (i.e., zero-shot learning and transfer learning) while the meta-learner and domain adaption methods are used. It shows that all these methods improve the baseline neural agent models.\n\n\nPROS\n1. Multiple Languages in VLN datasets.\nI really agree that studying a single-language dataset would limit the view of VLN research.  Moreover, mature VLN systems would be deployed to multiple countries with different languages in real life. I am glad to see that a new dataset with another language and its preliminary results are provided in this paper.\n\n2. Zero-shot learning setup. \nI appreciate the methods in solving zero-shot learning, which develops symmetric encoders for the two languages. Instead of using a translator to get additional training/test data, the instructions of two languages are feed into the model \nSimultaneously. This approach in enabling zero-shot learning of multiple languages looks novel to me. \n\n2. Well-written.\nThe paper is well-written that I easily get the idea of the paper.\n\n\nCONS\n1. Chinese is the only language.\nAlthough the task is appealing, the novelty of this dataset is moderate since only one extra language is collected. Thus, zero-shot/knowledge-transfer methods developed for this dataset might overfit the specific language pair (i.e., Chinese-English). Only one extra language also disallows the existence of \"validation set\", where the methods are developed/tuned on a specific language pair and tested on an unseen language pair. Overall, the dataset gives a chance to study the VLN task beyond English, but it is far below a \"cross-lingual\" VLN dataset as it claims in the title.\n\n2. The contribution of each component is not solid proved.\nI calculated the contribution (to the unseen results) of each component based on the numbers in the paper:\n\nUnseen                           Accu  SPL\n---------------------------------------------\nBaseline:                        23.2   18.0\n+ Two Language:         +1.0    +1.4\n+ Meta Leaner:             +1.2    +0.6\n+ Txt2img:                     -0.6     +0.5\n+ Domain Adversarial: ???      ??? (I did not find the exact numbers in the paper)\n\nIt seems that each component contributes around 1% to the final model and the overall improvement is around 2%. Based on previous results on English R2R,  around 2% improvement w.r.t the baseline might not be significant enough to show the validity. To show the significance, I prefer to see the stddev of the models of different runs and a bootstrapping test (https://en.wikipedia.org/wiki/Bootstrapping_(statistics)). For now, I am not sure whether the proposed methods \n\n3. Might need more experiments.\nIn Table 1, train w/ MT is trained on ZH MT and test on ZH. An alternative approach is naturally applicable here: trained on EN and test on EN MT. However, I did not locate this result. By the way, the results in Table 4 and Table 5 are indispensable to me, which show the actual contribution of each component. Is there any reason to put them in the Appendix instead of Table 1 (i.e., ablation studies)?\nThe models seem only takes the egocentric view as input where most of the current VLN systems are built on the panoramic views. The paper would be better if the experiments on panoramic views are conducted.\n\n\nTECHNICAL CONSIDERATIONS\n1.  In Eqn. (6), the paper mentions that the ReLU could be used as an activation before L_2 norm. It seems that the loss would have a plain minimum 0 if the outputs of  (W h) are all (or mostly) negative. Thus, the ReLU activation seems not to be effective from intuition. Is there any explanation or any references that take this formula? \n\n2. The adversarial domain adaptation in Sec. 4.3 might need some clarification. Suppose the NMT system translates the source domain S to MT target domain T' and target domain T to MT target domain S'.  As mentioned at the beginning of Sec. 4.3., this method tries to align the distribution of S and T' in training, while domains S' and T are used in testing. Aligning S and T' does not naturally guarantee the match of S' and T. Thus, I prefer to see more explanation here.  \n\n3.  What is the difference between the meta-leaner in this paper and the gated-mechanism? Specifically, the gated mechanism uses a learned gate to control the information. It could be scalar (as in this paper or in attention mechanism) or a vector (as in LSTM). To me, meta-learner seems to be too broad and misleading. \n\n4. The notation of the dataset \\{ (E, p_1, x_{1:N}, G \\}^|D'| is a little bit confused to me. Is there any reference material that use the superscript to annotate the cardinality? \n\n\nTYPO\n1. In Eqn. (5), it might be softmax( FC( h_t ) ) instead of softmax( h_t ).\n\n\n"}