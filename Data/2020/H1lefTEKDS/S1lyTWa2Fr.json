{"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This paper presents a systematic empirical evaluation of model-based RL algorithms on (mostly) continuous control environments from OpenAI Gym, with comparison to popular model-free algorithms. It identifies three challenges for model-based RL, learning the dynamics, selecting the planning horizon, and applying early termination to guide learning.\n\nA systematic comparison of model-based RL algorithms is missing from the literature, and I believe that this paper does a fairly thorough job of providing such a comparison. A wide range of algorithms are selected, and the environments are representative of those commonly used in the literature. The first two challenges identified have been recognized in the literature. For example, Vemula et al. (2019) [1] discuss the planning horizon in random search RL algorithms.\n\nHowever, I would like to see some results on the policy search algorithms such as PILCO in Section 4.5, even if they are on the simpler environments. Currently they are not represented in Table 4. \n\nMinor comment:\n1. There are several instances where the writing should be clarified, e.g. acronyms are not explained before they are used. For example, it would be helpful to the reader to define GT-CEM and GT-RS in Section 3, especially as Table 1 (page 6) comes before the text discussing those two algorithms (page 7). \n2. Table 1 is a bit difficult to parse. Maybe it could be split up, or some algorithms/environments deferred to the appendix.\n\n[1] Vemula, Anirudh, Wen Sun, and J. Bagnell. \"Contrasting Exploration in Parameter and Action Space: A Zeroth-Order Optimization Perspective.\" The 22nd International Conference on Artificial Intelligence and Statistics. 2019.\n"}