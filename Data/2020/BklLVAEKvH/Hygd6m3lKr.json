{"rating": "3: Weak Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper proposes a new clustering method, called CNC, which is composed of two-step procedures.\nIt first embeds an input dataset into a d-dimensional space, followed by performing relaxed normalized cut to detect clusters.\nAlthough the contribution of introducing a new relaxed formulation of the normalized cut is interesting, I have the following concerns regarding with the clarity, significance, and evaluation of the proposed method.\n\n- The paper is not clearly written at many points and the quality of presentation is not high, which also deteriorates the significance of the paper.\n    In particular, the optimization process for clustering discussed in Section 4.1 is not clearly presented.\n    Although the objection function, which is the expectation of the Ncut, is introduced in Equation (6), how to solve it is not presented.\n    Since this is the key step for CNC, it should be carefully discussed.\n- In the embedding step, how to choose the dimensionality d?\n    This is not even reported in experiments.\n- Empirical evaluation is not thorough and important evaluation is missing.\n    * First, the contribution of embedding is not evaluated.\n      The performance between CNC with the proposed embedding and without it should be compared.\n      Moreover, the sensitivity of the performance with respect to changes in d should be examined.\n    * A number of resulting scores are missing; in particular, CNC is compared to only SpectralNet for CIFAR-10 and CIFAR-100 under NMI.\n      It would be more convincing if the NMI for other methods are also reported.\n- Parameter sensitivity is not evaluated, while there are a number of parameters in the proposed method as reported in Section 5.7.\n    Since parameter tuning is fundamentally difficult in the unsupervised setting, parameter sensitivity is crucial.\n    Also how to choose such parameters is not clear.\n\nMinor comments:\n- In Algorithm 1, line 1, \"X \\in R^n\" -> \"X \\subseteq R^m\"?\n- In Algorithm 1, the dimensionality \"m\" of data points and the batch size \"m\" are the same. Is it correct?\n- At the first line in Section 4.1: \"for each data point\" -> \"For each data point\"\n- P.4, L.-4: \"nreast-neighbor\" -> \"nearest-neighbor\"\n"}