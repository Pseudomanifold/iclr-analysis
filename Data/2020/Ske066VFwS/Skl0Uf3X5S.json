{"experience_assessment": "I do not know much about this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper addresses the problem of inferring dynamical systems from observations. It aims at calcium imaging data, but in fact only tests its proposed methods on two synthesized data sets.\n\nI am not really familiar with neuroscience, and found the the paper relatively clearly written, and interesting. The model seems to work, for the synthetic data. I appreciate the confluence of neuroscience and machine learning.\n\nI rate the paper Weak Reject, for two main reasons.\n\nFirst, the paper is, although readable on a high level, not accessible in detail to readers who are unfamiliar with VLAEs, like myself. I feel to be a good fit for a conference with a broad range of topics, some effort should be made to keep papers, at least to some degree, readable by the broad audience. Otherwise, a narrow conference, e.g. on calcium imaging, might be a better venue.\n\nSecond, the paper title promises \"an application to calcium imaging data\", but that application is not actually presented. I understand the two synthetic data sets are meant to assess the viability of the model for the task, but the title calls for an actual application to real data.\n\nSome more feedback:\n\nThere are a few things not immediately clear (which may or may not have to do with VLAEs). E.g. why does the model contain both an inference network and a generative network?\n\nThe conclusion had a few grammar errors, please grammar-check it."}