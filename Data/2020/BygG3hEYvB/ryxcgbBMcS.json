{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper proposes two measures of information discarding during forward propagation of a neural network. The paper presents how to calculate the two measures, compare them with alternatives, and demonstrate their values in different networks and different tasks. \n\nThe paper is in general well written. However, first, the proposed measures do not seem to be well motivated--what is the essential purpose of having the measures? Second, although the intuition is clear, the proposed methods do not seem be well justified. As the authors pointed out, the proposed measures are related to the mutual information I(F;X), where F is the considered inner representation. Why are the proposed measures superior to alternatives? Why are they better than the information bottleneck one (in the extreme case, to make it task-independent, one may drop the term involving Y)? Furthermore, on the technical side, the raw input as well as the reconstructed input is highly non-iid (independent and identically distributed), so is it sensible to calculate the total entropy H(X_c) as the sum of the individual ones for the pixels (in equation 2, for example) at all? Third, the authors tried to justify that the proposed measures are consistent and faithful in Section 4, but I failed to see if from the panels in Figure 1. What is the exact definition of coherency here? "}