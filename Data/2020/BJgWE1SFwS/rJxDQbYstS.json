{"rating": "3: Weak Reject", "experience_assessment": "I do not know much about this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper presents an approach for choice modeling that leverages neural network features in a continuous-time Markov Chain whose stationary distribution represents the choice distribution. Nonlinear features can be computed for both alternatives and individuals, and the resulting model beats all baselines in terms of log-likelihood and accuracy on an airline itinerary choice prediction task.\n\nOverall, this paper presented a simple but effective approach for using neural networks in the PCMC class of models. The experimental section is too limited, with results on only one dataset and no comparison of different architectural choices for how to incorporate neural networks into PCMC models, or analysis pointing toward what the features are learning that allows them to improve over earlier approaches. The text was also confusing in a number of places (possibly due to my lack of knowledge in choice modeling), and there\u2019s no discussion of related work incorporating neural networks into ranking-based models.\n\nComments:\n* Knowing nothing about choice modeling, I found the introduction hard to follow with lots of jargon that may be inaccessible to the broader ML community. It may be useful to specify the set of desired properties for these models up front, and then highlight how the different existing models do or don\u2019t satisfy these properties (e.g. uniform expansion, regularity, efficiency,  framing effects, etc.)\n* How is the proposed approach \u201camortized inference\u201d? \n* What\u2019s the triangle notation in P(a |> c) ?\n* It\u2019d be useful to say more as to why contractability/uniform expansion are useful components of a choice model.\n* \u201cAdditive smoothing at the cost of some efficacy\u201d - efficacy in what sense? Expressivity? Or worse performance? The same smoothing technique (minimum of epsilon) seems to be used in this approach.\n* Theorem 1 and proof do not consider some of the architectural choices of PCMC-Net (e.g. cartesian product layers, does d_a have to go to infinity?)\n* Contractability: why is this property desirable if you don\u2019t take advantage of it computationally?\n* Why is SGD + dropout training stable but the original MLE problem not?\n* Comparison to baselines using low-rank or other simple parameterizations of Q?\n* Table 1 should be moved to supplement\n* \u201cUsual rule of thumb\u201d -> cite something here? Not familiar with this\n* What is the impact of \\epsilon and dropout probability on model performance? From proofs I had expected \\epsilon tiny (1e-9) but you use 0.5\n* Would be useful to show how model performs on smaller dataset to gain intuition"}