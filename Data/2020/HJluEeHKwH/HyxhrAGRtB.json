{"experience_assessment": "I do not know much about this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "This paper proposes a differentiable variant of the Cross-Entropy method and shows its use for a continuous control task.   \n- It introduces 4 hyper-parameters and it is not clear how robust the method is to these. \n- Although the idea is interesting, I think the paper needs a more rigorous experimental comparison with previous work and other methods.\nDetailed review below:\n- The abstract should mention clearly that the proposed method allows you to differentiate through argmin operation and can be used for end to end learning. Similarly, please reframe parts of the introduction to make it more accessible to a general reader. For example, in the introduction,  \"approximation adds significant definition and structure to an otherwise...\". This statement requires more context to make it useful. Similarly, \"smooth top-k operation\" is not clear. \n- Is there a way to guarantee that the solution found by (D)CEM is a reasonable approximation to the argmin. For unrolled gradient descent, this can be done by looking at the gradient wrt x. \n- It might be more useful to explain CEM before the related work section or just moving the related work to the end. \n- Section 3: If the paper is about CEM, please give some motivation and details rather than just citing De Boer, 2005. \n- There is a notation clash between \\pi for the sort and policy later in the paper. Similarly, \"t\" is for both for the iterations of CEM and the time-stamp in the control problem. \n- I don't understand how Proposition 1 adds to the paper. This is a standard thing. Similarly for Proposition 3. \n- Isn't there an easier way to make the top-k operation soft - by sampling without replacement proportional to the probabilities? Please justify this design decision. Similarly, how is the temperature \\tau chosen in practice?\n- Please explain the paragraph: \"Equation 4 is a convex optimization layer and... GPU-amenable..\" Isn't this critical to the overall scalability of this method?\n- - How are the hyper-parameters for CEM  chosen - the function g(.), the value of k, \\tau, T chosen in practice. If the criticism of GD is that it overfits to the hyper-parameters - learning rate and the number of steps, why isn't this a problem with (D)CEM.  \n- Section 4: Since you're comparing against unrolled GD, please formally state what the method is. \n- Section 4.2: How is the structure of Z decided, that is how do you fix the space for searching for the policy in the Z space? \n- There are other methods that auto-encode the policy u_1:H to search the space. How does the proposed method compare to these methods? This is important to disentangle the effect of GD vs CEM and that of just searching in a more tractable space of policies. \n- Section 5.1: How is the number of optimizer steps (=10) decided? Also, how is the learning rate for GD picked. Is the performance of unrolled GD worse for all values of \\eta, even after a grid-search over the learning rates?\n- For Section 5.2, please compare to baselines mentioned in the paper. Also, there needs to be an ablation/robustness study for the DCEM method. \n\n\n\n\n"}