{"rating": "6: Weak Accept", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This work improves upon the current state of applying neuroevolution to solve RL tasks, by using a modular \"world models\" architecture. While the original work used backpropagation to train the three different components on different tasks, later work used neuroevolution to train the entire architecture for final performance; however, the latter work was unable to demonstrate success on the more challenging task used in the original work. Given that the architecture has a heterogenous pipeline, the authors propose, and empirically show (over a set of seeds), that allowing extra time for components to adapt to other, more recently-changed components, enables neuroevolution to solve the second task. I would give this paper an accept, as this insight, along with a novel algorithm, could aid further work in neuroevolution but also more generally the optimisation of modular NNs.\n\nThe ablations are an important part of this work, and it would be good to study these further. The random age objective performing well does indeed indicate that diversity preservation plays a role in the better performance in DIP, but the fact that protecting the upstream controller does improve performance slightly makes me question if this effect has been properly decoupled. This ablation will reset the age 1/2 the time DIP does, reducing diversity/increasing selection pressure, and so another appropriate ablation is to see the effects of protecting MDN-RNN and controller innovations (with the VAE being the most downstream component)."}