{"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "I'm somewhat out of area for this review: I study relational models, but have little experience with computer vision in general and object tracking in particular. \n\n--------------------\n\nThis paper presents an extension to HART [Kosiorek 2017] to track multiple objects. It builds on a simple baseline: run multiple HART models in parallel, each tracking one of the objects. They extend this by adding a relational reasoning module to allow interaction between the parallel models. The relational reasoning module uses Lee et al. (2019)'s self-attention block (similar to Vaswani et al. 2017). They find that the simple baseline is surprisingly effective, but that MOHART (their model) improves performance in environments with stochastic interactions and crowded settings which tend to be more noisy.\n\nThe novelty is somewhat limited: they're plugging together two existing approaches (HART and SAB) to allow for interaction, but I am recommending acceptance because I found the experiments surprising (as a negative result) - they show that independent HART models are a strong baseline for tracking in settings that involve interactions, but that are nevertheless solvable without knowledge about the state of other objects. For the synthetic experiments, I would have expected the fact there are repulsive forces between the objects would have been sufficient for the relational module to be helpful. The paper also provides further evidence of the usefulness of non-local networks for these sorts of problems."}