{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper tackles the problem of catastrophic forgetting when data is organized in a large number of batches of data (tasks) that are sequentially made available. To avoid catastrophic forgetting, the authors learn a VAE that generates the training data (both inputs and labels) and retrain it using samples from the new task combined with samples generated from the VAE trained in the previous tasks (generative replay). In this way, there's no need to store all past data and even the first learned batch keeps being refreshed and should not be forgotten.\n\nI like that this paper uses a single global probabilistic model instead of separate discriminative and generative ones. Unfortunately, there are several things that left me unconvinced about this paper:\n\n1) Presentation of the paper\n\n- Variables x, y, z are introduced and talked about without explanation. The graphical model or factorization assumptions are not even mentioned until after the loss has been defined. A normal flow is to first describe the model and what the involved variables mean, and then talk about what the loss for learning it should be, not the other way around.\n\n- Text contradicting the equation: \"In order to balance the individual loss terms, we normalize according to dimensions and weight the KL divergence with a constant of 0.1\". But equation (2) shows a loss with no weighting. I'm assuming the text is correct, but then a beta should be added to the equation in front of the KL divergence.\n\n- Tables and figures are inconveniently far from where they are referenced in the text.\n\n2) Theoretical inconsistencies\n\nAlthough the system might work overall, two things seem to be technically incorrect:\n\n- The decoder and classifier are expected to approximate the distribution of training data according to the authors (for valid generative replay). This is not true in a beta-VAE. The weighting of the KL that the authors introduce is going to bias the learned generator towards the high probability regions. This is not a sound mechanism to achieve an as-faithful-as-possible (limited by the expressiveness of the encoder-decoder architectures) approximation to the training data.\n\n- A Weibull distribution is used to model the same data, again, in a different way. I.e., there are two different probabilistic models modeling the same data in inconsistent ways and one or the other is used depending on the part of the system. (As an example, q(z) could be arbitrarily multimodal as far as the encoder is concerned, but the Weibull seems to force one mode per class. But regardless of this, both models are inconsistent.)\n\n- Similarly, the proposed rejection sampling scheme of OCDVAE is not consistent with the theory of VAEs and it's a post-hoc tweak that is not theoretically expected to provide a pdf of data with lower KL divergence to the true data pdf.\n\n3) Experiments\n\nFinally, the experimental results do not look very compelling, it seems to be overall worse than the baselines in the two image datasets and slightly better in the audio dataset, so it's unclear that this approach is superior."}