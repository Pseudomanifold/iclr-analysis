{"rating": "3: Weak Reject", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "N/A", "review": "This paper proposes a GAN-based approach for high-resolution image enhancement. The contributions are of this work are mainly on a few network architectural designs of the generator and discriminator, and an improved loss function. Some qualitative and quantitative results are presented to demonstrate the effectiveness of the propose method. However, the overall novelty is incremental and experimental results are not solid.\n\nPros:\n\n+ Improved performance on benchmark dataset\n\nOriginality: The novelty of this work is limited. All proposed modules (additive and multiplicative connection, two-stream of low- and high-frequency inputs, and AdaSWGAN), as authors cited in the paper, are directly borrowed from previous work. The AdaSWGAN looks like a simple combination of AdaWGAN and SWGAN. While no one has integrated those in one framework for image enhancement before, I do not find principled designs or intuitions from authors on why those modules work well for this specific task.\n\nQuality: The image enhancement is formed as a one-to-one mapping in this work. However, for a given low-quality input, there can be multiple possibilities for the enhanced output. While there are already a few im2im translation that work on multi-modal, the authors need to take this into account when formulating the problem. Regarding the experiments, it is better to compare with more methods such as CLHE, NPEA, and FLLF, as did in [Chen et al., 2018].\n\nSignificance: The task of image enhancement is still a challenging problem, due to less paired data and the difficulty of disentangling different aesthetic factors. In addition, it is a one-to-many problem. While this work does not concern those topics, except for the performance improvement in Table 1, its significance is greatly reduced.\n"}