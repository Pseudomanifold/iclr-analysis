{"experience_assessment": "I have read many papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "The authors present an empirical study to evaluate the performance of CNN-based object classifiers for situations in which the object of interest is very small relative to the size of the image. Two artificial datasets, based on MNIST and histopathological images are introduced to conduct the experiments. Through empirical evaluation the authors conclude that the size of the dataset required for generalization increases rapidly with the inverse of the O2I ratio, that higher capacity models generalize better, and that accounting for the model's receptive field is key.\n\nThe contributions of the study are limited: i) The artificial datasets generate images that are small and O2Is that are big for the applications of interest, e.g., gigapixels images in digital pathology (see Figure 1). ii) The dataset based on MNIST is perhaps too artificial (too structured), once one compares their results relative to nCAMELYON. iii) The authors only consider ResNet-50. iv) The authors do not consider multi-instance learning pooling functions, e.g., noisy or, noisy and or attention. v) The authors do not consider performance as a function of the positive instances in the image (number occurrences of 3 in the proposed nMNIST). vi) There is no methodological contribution."}