{"experience_assessment": "I have read many papers in this area.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper studies the causes of the empirically poor performance in deep structures that plagues existing GNNs, and identify the suspended animation problem as the main issue. In analogy to the Residual CNN network, a residual graph network is proposed to address such issue. Moreover, the underlying Markov chain property such as stationary distribution is theoretically analyzed, the so-called suspended animation limit is defined and its upper and lower bounds are established. Empirical experiments are relatived short and less sufficient, with comparisons on there datasets: Cora, Citeseer, and Pubmed. It would be more convincing to present its performance on a more diverse range of datasets.  Note the results on Citeseer is inferior to existing method. It is helpful to clearly explain why  this could be the case.\n"}