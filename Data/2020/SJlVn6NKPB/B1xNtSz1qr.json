{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "The paper proposes an approach for representation learning on remote sensing data/satellite imagery inspired by recent unsupervised contrastive multiview representation learning methods (CPC, DIM, CMC). The method relies on the InfoNCE objective to contrast two different views of the data obtained by randomly cropping image patches, color jittering, channel dropping etc. The proposed method is compared to an ImageNet pretrained network in a classification task based on OpenStreetMap (OSM) features and show to outperform the ImageNet pretrained classifier. \n\nThe paper is well-written and the method is clearly explained. To my knowledge there is little prior work on unsupervised/self-supervised learning on remote sensing/satellite data and this data suits the contrastive/multiview framework very well. In that regard I appreciate the direction explored by the paper.\n\nHere are some questions and concerns:\n\n- I think the paper is lacking some important details, for example how are the unsupervised and ImageNet-pretrained representations transferred? Fine-tuning, or learning a classifier on top of the frozen representation? In the case of fine-tuning, the ImageNet baseline could be extended to more channels.\n\n- As an additional baseline, how does a network trained from scratch on the available labeled training data perform?\n\n- The authors evaluate on a single data set, that seems to not have been used previously. To make the evaluation more solid it would be good to compare on other data sets, for example on EuroSAT [1], and with other, possibly supervised classification methods, see, e.g., [1, 2].\n\n- Did you do ablations on augmentations used? For example, is zeroing out channels more effective than copying other channels instead?\n\n- Both forward and backward prediction losses are used, but it seems that the loss is symmetric. Does adding the backward prediction loss really help?\n\nOverall, I like the direction the paper is exploring, but I think it would greatly benefit from adding detail on the outlined aspects and extending the evaluation.\n\n\n[1] Helber P, Bischke B, Dengel A, Borth D. Eurosat: A novel dataset and deep learning benchmark for land use and land cover classification. IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing. 2019 Jun 14;12(7):2217-26.\n[2] Kussul N, Lavreniuk M, Skakun S, Shelestov A. Deep learning classification of land cover and crop types using remote sensing data. IEEE Geoscience and Remote Sensing Letters. 2017 Mar 31;14(5):778-82.\n"}