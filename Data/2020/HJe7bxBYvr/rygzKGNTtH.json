{"experience_assessment": "I have read many papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "N/A", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review": "This paper proposes to use learned transition models to do two separate things: (i) avoid unsafe states and (ii) allow an alternative channel for task reward specification. The idea is to create a comprehensive connectivity graph of the states in the environment. Once done, an agent can avoid unsafe states by avoiding states that are unconnected to a specified safe state. A practitioner might also specify safe/unsafe states as an additional source of information about the reward.\n\nThis paper suffers from poor and loose writing, incomplete specification of its experiments, unrealistic assumptions during evaluation (Sec 5.3 \"we create the graph using rollouts from the actual environment\" to avoid errors from learning a transition model). \n\nThe paper does not address basic concerns with its approach: how is the model to be learned at all, if it is to be comprehensive in the way that is necessary for the connectivity graph (which this paper calls an \"imaginative module\")? The authors say this is done through multiple agents performing random actions in the environment, in which case, isn't this extremely unsafe training time by the paper's own definition of safe exploration? \n\nFurther, creating a complete connectivity graph is unrealistic even for fully known transition models in most reasonably complex settings, such as, say, Go or Chess. \n\nIf the transition model is fully known as in the car racing setting, why not directly use that to plan and solve the game?\n\nExperiments show fewer \"unsafe\" states for the paper's approach compared to a method that has no way to know that those states are unsafe. How is this a reasonable validation, especially when the transition model is fully known? Also, this is an insufficient metric by itself as it says nothing about whether the method actually performed well at the task."}