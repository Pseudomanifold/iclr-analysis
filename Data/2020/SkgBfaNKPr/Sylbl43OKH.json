{"rating": "1: Reject", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "## Summary of the Paper\n\nThis paper studies changes in topology of two-class neural networks.\nSpecifically, the *Betti numbers*, a measure of topological complexity,\nare monitored during the training process for different architectures\nand different activation functions. Results are collected in large\nempirical study and three main observations are stated:\n\n1. Topological changes are robust across repetitions of the training.\n2. Smooth activation functions slow down the topological changes.\n3. Initial layers contribute less to topological changes than deeper ones.\n\n## Summary of the Review\n\nThis is a highly interesting paper and I enjoyed reading about this\ntopic. However, two issues prevent me from accepting this paper in its\ncurrent form:\n\n1. It is unclear how the stated observations generalise beyond the\n   simple data sets and architectures that are used in the paper.\n\n2. I have some concerns about the technical correctness of the\n   complexity calculations in the paper.\n\nMoreover, there are some errors in the description of key concepts in\nthe paper. Given that the claims in this paper are relatively\nlarge and somewhat vague---for example the claim that initial layers are\nresponsible for geometric changes, while deeper layers are responsible\nfor topological changes---I suggest revising this paper.\n\nDespite my verdict, I want to stress that I very much like this line of\nresearch and this type of analysis. This has the potential to become an\nextremely strong contribution.\n\nIn the following, I will comment on the afore-mentioned issues and some\nminor ones.\n\n# Issue 1: Generalisation\n\nAll experiments in this paper are performed for extremely simple\narchitectures and simple data sets. Nonetheless, the paper appears to\nmake very general claims about, for example, the simplification of\ntopology. While the last experiment briefly deals with MNIST, the setup\ndoes not go into sufficient details here. Moreover, as the data set is\nsubjected to a transformation before (which is apparently required for\ncomputational purposes), this experiment does not exactly deal with the\nsame input manifold as before, making the observations into a stretch.\n\nI would suggest experiments on other FCN architectures here and at least\none other (image) data set. The employed architecture also seems\nrelatively sparse (10 layers, of 10 neurons each); is the predictive\nperformance of this network for a binary classification task\nsufficiently good?\n\nTo add to this: I am perfectly aware that any paper with empirical\nobservations has to start somewhere; I would be perfectly fine with\nseeing experiments dealing with small FCN architectures on a few\nwell-selected data sets only. But in this case, the claims of the paper\nneed to be slightly rephrased---right now, there is large 'leap of\nfaith' from the performed experiments to the generality of the claims.\n\nThis should be fixed not only by rewriting but also by considering\na more detailed setup. For example: do the observations hold for *other*\nbinary problems on MNIST? Are there certain data sets to which the\nobservations do not apply?\n\n# Issue 2: Technical correctness\n\nThe use of Betti numbers as complexity measures is well-known in\nalgebraic topology. In this case, we are dealing with *samples*,\nthough, that are not necessarily as well behaved as a simplicial\ncomplex of a known object: Betti numbers of real-world data sets\nare known to be notoriously unstable; persistent homology exists\nfor this reason.\n\nWhile the paper describes their usage in the appendix, I see some\npotential issues with the algorithm:\n\n- Why is no *witness complex* used for the point clouds? If\n  computational issues are a concern, I would suggest first\n  to try this algorithm, whose stability is known.\n\n- The construction of the Vietoris--Rips complex strikes me as slightly\n  ad-hoc. Is there a reason for not using a standard construction first,\n  i.e. Euclidean distance + scale parameter?\n\n  I am raising this point because the complex construction is *the*\n  crucial step in homology approximation---which is essentially what is\n  happening here.\n\n  I am worried that the approximation is not stable enough, and I would\n  recommend rather looking at persistence barcodes and use something\n  like *total persistence*; ('Diffusion Runs Low on Persistence Fast,\n  Chen & Edelsbrunner, 2011).\n\n  In fact, all experiments in this paper are also explainable by\n  noticing that the Vietoris--Rips complex, if sufficiently many\n  connections exist, simply describes the full $d$-dimensional simplex,\n  which has trivial topology, i.e. Betti numbers 1,0,0,...,1. Depending\n  on the algorithm used, simplices in the top dimension might not be\n  used to increase the highest Betti number, leading to the described\n  profile of 1,0,0,...,0. This needs to be carefully check and analysed\n  in order to make it clear that the results are to be trusted!\n\n  Another issue with this setup is that the Betti numbers that are\n  *possible* to be reported also typically depend on the filtration that\n  is used in the complex. It appears that an integer-based filtration\n  based on the number of edges is used. Does the paper employ the scale\n  values to decide what the Betti numbers are? The provided explanation\n  does not make this sufficiently clear to me.\n\n  At the very least, I would recommend explaining the choices in\n  filtration and distance in more detail. In particular the $k$\n  parameter of the KNN graph used to calculate geodesic distances needs\n  to be explained more---how stable is this choice? Does it affect the\n  results in any way? Why is the 'ordinary' distance filtration,\n  potentially with scale factors to ensure comparability between layers,\n  not sufficient?\n\n- To add to the points above: what if the topological changes during\n  training happen at different scales? The way the Vietoris--Rips\n  complex is constructed, this cannot be detected.\n\n- In Figure 13, the *reduction algorithm* is not explained in\n  a sufficient amount of detail. Which one is used to ensure that the\n  topology does not change?\n\n# Clarity\n\nThe paper is lacking clarity at several places and uses erroneous\ndescription of some concepts:\n\n- while homeomorphic maps preserve topology, the statement in the\n  abstract only holds if the network is sufficiently wide to encompass\n  the intrinsic dimension of the manifold. Or am I misunderstanding this\n  sentence? It seems to rule out a lot of architectures---in particular\n  any architecture with a small bottleneck; even the MNIST reduction\n  from 50D to 10D technically does *not* qualify as a homeomorphism any\n  more---unless the concept of intrinsic dimensionality is invoked, in\n  which case more details are required. \n\n- I slightly disagree with muddling the terms 'topology' and 'shape'.\n  Technically, topological information is coordinate-free and only\n  defined up to homotopy. For the sake of precision, I would suggest\n  using only topology here.\n\n- The Betti numbers provided in many examples are wrong. The standard\n  torus has Betti numbers (1,2,1), while the solid torus is $S^1 \\times\n  D^2$, i.e. the product of a circle and a disk. But the disk is\n  homotopy equivalent to a point, which means that the solid torus has\n  Betti numbers (1,1,0), _not_ (1,2,0) as claimed multiple times in the\n  paper. This strikes me as somewhat worrisome, to be honest, because\n  the Betti numbers are an essential concept to understand the rest\n  of the paper.\n\n- The terms 'geometric' vs. 'topological' are used without defining what\n  is meant by 'geometry'. To my understanding, the geometry cannot be\n  measured by Betti numbers alone. The claim that initial layers thus\n  perform geometrical changes needs to be defended somewhat better.\n\n- The digression of floating point precision strikes me as a somewhat\n  unnecessary tangent; I understand that homeomorphism are restricted,\n  but even if all activation functions are homeomorphisms, the network\n  architecture *itself* could account for topological changes---or am\n  I misunderstanding something here? Is the claim about homeomorphism to\n  be taken in terms of each individual neuron's value?\n\n  Nevertheless, I like the discussion from a technical point of view.\n\n- The formulation 'is far from a homeomorphism' strikes me as slightly\n  odd; I would rephrase that; the paper is not discussing homotopies,\n  after all.\n\n- The sentence 'We posit that...' on p. 3 is hard to understand---why\n  does it invalidate the approximation point of view? The paper is\n  *only* looking at the topology, but neglecting the geometry of the\n  data entirely. It could very well be that topology---or at least Betti\n  numbers---is too coarse to describe the changes in the network.\n\n- Dimension is a topological invariant, but it should be made clear if\n  one is talking about *intrinsic* or *ambient* dimension. The whole\n  idea of the manifold hypothesis is that the intrinsic dimension is\n  low.\n\n- A dense + uniform sampling does not necessarily guarantee that Betti\n  numbers can be recovered correctly (p. 4); more details are required,\n  maybe a brief link to a section in the appendix\n\n- On p. 5, the Betti numbers for the filled torus are wrong (see above);\n  they should be (1,1,0). Likewise, the Betti numbers for the genus two\n  surface are wrong; they should be (1,4,1).\n\n- The claim about the $\\epsilon$ scale for the Vietoris--Rips complex is\n  factually correct, but the statement is misleading insofar as the\n  paper only extracts the complex at a single threshold, whereas\n  persistent homology integrates the multi-scale aspect of real-world\n  data sets.\n\n- I do not understand the choice of showing *half* a standard deviation\n  in the plots. Is it not customary to show the mean plus/minus one\n  standard deviation?\n\n- Why is the variance between different runs in Figure 6 so high?\n\n- In Figure 7, the $y$-axis should be scaled to be the same for all\n  plots in order to make the comparison easier\n\n- In Table 1, multiple $\\epsilon$ values are already shown; why not show\n  persistence barcodes?\n\n- On p. 17, homeomorphism should be replaced by homomorphism\n\n- On p. 17, boundary operators are not required to satisfy Eq. 4, but\n  rather Eq. 4 is the *fundamental lemma* of simplicial homology.\n  I would suggest rewriting this in terms of the standard boundary\n  operator as it will simplify the exposition.\n\n# Related work\n\nSome related work on topology and deep neural networks is missing.\nI would suggest citing:\n\n- On Characterizing the Capacity of Neural Networks using Algebraic Topology, https://arxiv.org/abs/1802.04443\n- Neural Persistence: A Complexity Measure for Deep Neural Networks\n  Using Algebraic Topology, https://openreview.net/forum?id=ByxkijC5FQ\n\nMoreover, there is a lot of ongoing research with respect to the\ninformation bottleneck principle that should be at least briefly\nmentioned. Here is a good starting point:\n\n- Deep Learning and the Information Bottleneck Principle, https://arxiv.org/abs/1503.02406\n\n# Minor style issues\n\nThe paper is well-written for the most part. Here are some minor style\nissues that I found:\n\n- '\\citep' should be used; the citations are currently intermingled with\n  the text\n\n- 'on training set' --> 'on a training set'\n\n- The union of $M_a$ and $M_b$ is supposed to be disjoint; the paper\n  could employ a disjoint operator here to make this more explicit;\n  I would recommend '\\cupdot'.\n\n- 'reduction is computation' --> 'reduction in computation'\n\n- 'it is a routine to verify' --> 'it is a routine proof'\n\n- 'take quotient' --> 'take the quotient'"}