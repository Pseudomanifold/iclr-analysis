{"rating": "1: Reject", "experience_assessment": "I do not know much about this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This paper proposes a new way of scheduling the learning rate in optimization algorithms such as SGD. It is a stand-alone, parameter-free approach that optimistically doubles the learning rate at every loss improvement between two epochs, until the loss increases too much or diverges, in which case the learning rate is divided by two.\nThis approach is theoretically proven to converge and to follow an optimal scheduling strategy.\nIn addition, the authors experimentally tested their approach on two image classification tasks, showing that the proposed algorithm yields similar to baseline results.\n\nI am rejecting this paper because it seems to motivate things with non-related facts, experiments are not robust and thorough enough, and there is no conclusion (not even in the appendix).\n\n- The most important thing in this paper to me is the fact that \"adversarial training\" is used to motivate this approach a lot. it is mentioned 14 times across the paper: 3 times in the abstract alone. Yet there is no explanation of what it is, and how is it different from \"natural training\" as mentioned in the paper. I suggest the authors either to clearly explain the difference between the two and explain why their approach may help in one setting or the other; or to simply remove the mentions of \"adversarial training\" if it is not important to the approach.\n- to better motivate the approach, I would suggest the authors include different tasks, rather than different training settings. For instance by having one image classification task (keep one of the two current ones) and one text classification or even generation task. This would show that the proposed approach generalizes well to other network architectures.\n\n- The second concern I have is about the experiments. If increasing the learning rate like the proposed approach is making training to convergence faster, then why are the experiments only measuring test set accuracy and not also runtime to convergence?\n- Overall, the experiments are not complete and thorough enough: some table values are missing, the set of adversarial training experiments on CIFAR100 are not reported, and some experiments diverged with the ADAM optimizer. Less than 20% accuracy on a 10-class image classification task seems very far from optimal.\n\n- Eventually, I strongly suggest the authors submit a better closing statement than \"We use cross entropy loss in all cases.\" (especially after having read this same sentence earlier in section 5.1 of the paper). No conclusion is added to the paper, not even in the appendix.\n\nBelow are a few minor points not taken into account in the scoring but that could make the paper slightly better:\n- Section 1, paragraph #1, first sentence: a few citations here would be nice.\n- typo on the first line of page 3: \"5The pseudocode ...\"\n- typo in the 2sn paragraph of section 4: \"... the convergence is the fast*est* since the step sizes ...\"\n- typos in the first line of the second paragraph of section 4.1: \"Assuming that *the* loss surface is smooth, *the* loss will continue...\"\n- page 6: \"At this time, p=2^{n-1} at this time.\"\n- Section 5.1, paragraph 2, first sentence: \"... with dropout and with both dropout and cutout, ...\"\n"}