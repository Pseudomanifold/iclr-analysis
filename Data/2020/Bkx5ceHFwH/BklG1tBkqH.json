{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This paper studies the role of auxiliary semantic supervision for visual navigation tasks. The paper proposes auxiliary losses of the form or predicting the room the agent is currently in, the rooms around the agent, and the next room that the agent should go to. The paper applies these ideas in context of the RoomNav task in realistic indoor scenes. The paper also proposes a self-supervised imitation learning that  is used to improve the model in novel previously unseen environments.\n\nStrengths:\n1. The paper tackles an important problem in a good and realistic experimental setup.\n\nShortcomings:\n1. Contributions are weak. Paper proposes use of auxiliary losses as a way to include semantic information into the policies (and use of self-supervised imitation learning). The idea is straight-forward, but would still make for a good paper is it was evaluated thoroughly and was found to work very well. I am not sure if this is the case either:\na. Improvements are typically small and conclusions are different when looking at different metrics. Some of the proposed losses seem to be hurtful (ex CS_RS)\nb. Ablations have been conducted on the test set. They should be done on a held out validation set and the best model should be evaluated on the test set against baseline (and other methods as applicable). Given the small improvements and that ablations are being done on the test set itself, I am not sure if we can conclude that the method works better than the baseline.\nc. Lack of any comparison to past work. I can think of at least 2 papers which have tackled semantic goals on similar datasets before [A,B]. Some of them also have code and experimental setups available, so comparisons should be attempted.\n\nThus, in my view the paper has limited technical depth, weak experimental evaluation and inconclusive results.\n\n\n[A] Bayesian Relational Memory for Semantic Visual Navigation (ICCV 2019)\nYi Wu, Yuxin Wu, Aviv Tamar, Stuart Russell, Georgia Gkioxari, Yuandong Tian\n\n[B] Cognitive Mapping and Planning for Visual Navigation\nSaurabh Gupta, James Davidson, Sergey Levine, Rahul Sukthankar, Jitendra Malik\nComputer Vision and Pattern Recognition (CVPR), 2017"}