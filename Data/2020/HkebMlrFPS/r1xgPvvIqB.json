{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #5", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This paper introduces a novel method for training a neural model to generate multi-facet embeddings, given a word, phrase, or sentence. The model is trained in an unsupervised setting based on surrounding words. The method is evaluated on several unsupervised tasks: phrase similarity, sentence similarity, hypernym detection, and extractive summarization.\n\nThe method for learning multi-facet embeddings could be an interesting contribution. However, the necessity of multi-facet embeddings does not seem sufficiently motivated, and the experimental results do not seem to clearly validate their use, relative to single-facet embeddings. The motivations given in the introduction for multi-facet embeddings are:\n1. words can have many senses\nHowever, the experiments do not assess this proposed limitation of single-facet embeddings. Also, it seems recent approaches to generate contextualized word or sub-word embeddings may be sufficient to resolve word sense ambiguity.\n2. Sentences and phrases can have many topics\nHowever, the best performance on phrase similarity tasks is achieved using K=1, i.e. a single-facet embedding.\n3. multi-facet embeddings can capture asymmetric relations like hypernymy\nHowever, the best performance is also achieved using K=1.\n\nGiven that best results for multiple tasks are achieved in the K=1 case, it would seem the proposed method reduces to be quite similar to the original word2vec formulation.\n\nThe paper evaluated the proposed embeddings on a range of tasks, and achieves favorable comparisons to baselines. However, the results are weakened by the fact that most of the tasks seem to lack strong published results to compare with (with an exception for summarization, which compares with, but under-performs Zheng & Lapata 2019). In some other cases, more recent baselines seem to be omitted:\nSection 3.1 - For BiRD, it seems there are stronger baselines in Table 4 of Asaadi et al. 2019?\nTable 4 - There do not seem to be comparisons with other recent work on hypernym detection, such as Le et al. 2019?\n\nThe experimental setup also does not really offer a fair comparison with BERT or similar approaches for generating contextualized language representations, where the learned representations are intended to be fine-tuned on the task of interest. The proposed multi-facet embeddings are not evaluated on target tasks of interest where fine-tuning data is available. This is one limitation of considering only the unsupervised setting, but the limitations of the BERT comparisons are also noted by the authors.\n\nThe writing seemed relatively clear overall, however in section 2.3 the model architecture, and its motivation, are a bit hard to follow. It seems unconventional to refer to the model as using a Transformer decoder, if not training the decoder with masked self-attention and not decoding auto-regressively. This would seemingly be more clearly described as a second Transformer encoder, with an additional attention sub-layer attending to the output of the first Transformer encoder? It may also be helpful to better motivate this modeling decision, if other architectures were not evaluated. There are many possible functions mapping phrases to a set of K vectors. For example, could a single Transformer encoder be used? Is it important to model interactions between the K vectors before the final output layer?\n\nOverall, it is an interesting question whether multi-facet embeddings are a better representation for words, phrases, and/or sentences than commonly used single-facet embeddings. The method proposed is novel, and achieves strong results on a wide range of unsupervised tasks. However, the core claim is weakened by the single-facet version of the proposed method performing best on multiple tasks, and several tasks lacking comparisons with strong previously published baselines. \n\nThe paper could be improved by clarifying the core contribution in the context of the best results being achieved using the K=1 variant of the method, and by comparing across tasks with more previously published results.\n"}