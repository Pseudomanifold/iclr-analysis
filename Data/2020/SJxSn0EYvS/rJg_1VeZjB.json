{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "title": "Official Blind Review #4", "review": "The paper proposes an end-to-end solution to accurately perform multi-person pose estimation. Existing approaches can be characterised as being either 'bottom-up' (parts localisation then person localisation) or 'top-down' (the opposite direction). In particular, existing techniques in the bottom-up regime use greedy heuristics to refine the predictions, which makes the overall optimisation process unclear. The proposed technique performs both parts jointly through the proposal of an end-to-end differentiable model (a CNN-LSTM on top of an image's extracted features) to perform multi-person pose estimation.\n\n- I found the paper quite difficult to follow in some parts. For instance, it disrupts the flow of the paper by having related works / lit review while describing the model (you should put this in a separate section). It would have also been nice to have more equations complementing the text.\n- Many of your citations need to be in parentheses (i.e. use \\citep).\n- Figure 3 should be moved up to be closer to the text which explains the training procedure, right now it's too far down.\n- You should also show LSTM2 in the figure, or have it in its own figure\n- If the final output of the LSTM are the confidence maps for each person, you should make this clear in the diagram, e.g. drawing arrows from each of the z time steps (since each of the z time steps corresponds to heat map predictions for one person).\n- Refer to Algorithm 1 in the text. What is this algorithm referring to? LSTM2?\n- Center table captions\n- I am confused about how LSTM1 and LSTM2 interact. When I first read the paper I thought that the LSTM in Figure 3 was 'LSTM1' and that you were replacing this by an 'LSTM2'.\n- It says in the training procedure that \\tilde{z} poses are predicted (or more technically, 2x that amount +1 because of the refinement loop). This to me implies that \\tilde{z} can change for each input over the course of training. You also have a fully-connected network which predicts the ground truth stopping vector p (whose length is determined by max(z,\\tilde{z}+1) and therefore appears to be of variable length), but because this is a fully-connected network how can p be variable length? It doesn't seem clear from the writing. Perhaps I can suggest how I would have implemented this:\n- Run the LSTM for T=z+1 iterations, where z is the ground truth number of people in the image. The input to the LSTM at each iteration is simply the input x from the AE concatenated with the output heat map from previous timestep (like LSTM2). The output at each iteration t will be a tuple (\\tilde{H}_t, \\tilde{p}_t}), where \\tilde{p}_t \\in [0,1] is the probability that we halt the LSTM. For iterations 1..z, the GT value for \\tilde{p}_t will be 0 and for iteration z+1 it will be 1. This would not require a refinement network nor a separate network to estimate stopping probabilities.\n- I find the ordering issue to be an interesting problem. Unfortunately, as you have mentioned in Section 3.1.2, it still requires one to define permutations of the poses during training. Perhaps future work could somehow utilize permutation-invariant modules (e.g. DeepSets).", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A"}