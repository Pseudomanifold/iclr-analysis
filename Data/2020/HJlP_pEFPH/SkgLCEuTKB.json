{"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This work proposes a framework for real world super resolution, which includes two networks: high-to-low and low-to-high. With high-to-low network, a general mobile super resolution dataset is proposed. According to the proposed framework and dataset, promising results are achieved for realistic image super-resolution.\n\n[Strengths]\n- This paper is well-written and easy to follow.\n- A new dataset is proposed for real world image super-resolution task.\n\n[Weaknesses]\n- The novelty of this work is relatively limited. The idea to use a high-to-low network to model distribution of real-world low resolution images has already been investigated in several works, like Bulat et al. (2018) and Zhao et al. (2018). However, no comparisons are conducted with these two works. Besides, the network structures are very similar to SRGAN and ESRGAN, which again shows little novelty.\n\n- The authors claimed the recent SOTA optical based method from Zhang et al. (2019) suffers from many problems. However, no direct comparisons are conducted to verify their viewpoints, and it's difficult to distinguish which one is better.\n\n- Is there any visualization for the distributions of real work noisy images and the learned low resolution images? Besieds, since only one mobile device is used to capture the images, why does the proposed method generalize well on other mobile phones? Any distribution illustrations?"}