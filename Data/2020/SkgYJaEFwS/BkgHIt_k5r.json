{"experience_assessment": "I have published in this field for several years.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The authors claim to have obtained a pac-bayes bound on generalization error of unseen tasks. They then propose a learning algorithm that empirically seems to be performing well and making better-calibrated predictions.\n\nThe experimental results seem promising. However, the theorem statement seems trivial (see detailed comments below). Also, the abstract and introduction overstates the contributions. Therefore, I cannot recommend acceptance at this point. If the authors derive some non-trivial theoretical results, I would be happy to change my decision. \n\nDETAILED COMMENTS.\n\nIn the introduction, the authors highlight two problems that exist in current meta-learning approaches. One of the problems that the authors mention and claim to have addressed in this paper is that most of the state-of-the-art algorithms come with no generalization guarantees. However, I do not see how the proposed algorithm comes with any sort of guarantees. I would be grateful if the authors could justify and explain.\n\nQuestions about Theorem 2:\nIs the population for each task assumed to be finite? Throughout the paper, I only see the loss evaluated on draws from the validation or training set, and the risk term (expected loss) never appears. In which case, how can there even be a generalization bound proved? Is the paper about transduction? If so, that has to be made clear in the abstract, introduction and the rest of the paper.\n\\mathcal{Y}_i^v is a validation set (of labels). What does the first expectation in Eq. (1,4 and others) mean? Can I replace it with an average over \\mathcal{Y}_i^v \u2018s?\nI cannot see how the first term in Equation (5) ( \\hat \\mathcal{L}_i^v ) is different from  the term stated in Equation (4) ( \\mathcal{L}_i^v ). If it is the same, than Corollary 1 seems to be trivial. Obviously, if one has two non-negative terms A and B, then A<=A+B. I do not see how a PAC-Bayes bound is needed there at all.\nSimilarly, Thm (2) has a trivial equivalent.\nLet\u2019s assume that Theorem (2) holds and perhaps there are some typos that make it trivial. Why is it interesting? It is bounding the cross entropy loss on the validation set (so it has nothing to do with generalization, maybe at best transductive bounds if there is some kind of mistake on the right hand side) in terms of quantities that depend on the same validation set. Where does the training set appear? How about expected loss?\n\nRemark 1. I don\u2019t think that McAllister 1999 has results on unbounded loss functions, and definitely not in Section 5 (conclusions). Germain et al. 2016 (PAC-Bayes meets bayesian inference) does.\n\nThe quality of the work could be improved if all of the assumptions and approximations were stated clearly and numbered. \n\nWhy the approximation in Equation (12) is reasonable? What are the conditions under which the approximation is good? What if the model is misspecified (which it is)? \u201cWe expect under this modelling approach, the discriminator model is approximately correctly-specified.\u201d - I see no reason to expect that. \n"}