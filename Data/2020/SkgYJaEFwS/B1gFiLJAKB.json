{"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper derives a novel meta-learning algorithm that uses the PAC-Bayes framework. Starting from the generalization error bound of vanilla theoretical PAC-Bayes results in single tasks, the authors extend it to the few-shot learning setting. Compared to the amortized Meta-Learner, the authors propose a more expressive way that implicitly models the shared prior and task-specific posteriors. Moreover, they use MAML algorithms to meta-learn the parameters of the discriminator. Experimental results demonstrate that the proposed method is competitive for the state-of-the-art.\n\nOverall, this paper is well written and easy to follow. The proposed method avoids estimating the correct weighting factor of KL divergence and has better representability than variational function-based algorithms, which might be significant to the community. In particular, the proposed method has a strong theoretical guarantee. One limitation is that the experimental results have no obvious improvement than existing methods. \n\nThough I'm not familiar with this research area, I think it is a good submission."}