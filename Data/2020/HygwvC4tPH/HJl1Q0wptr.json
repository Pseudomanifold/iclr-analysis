{"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper describes a new way of learning context dependent entity representations that are capable of encoding fine-grained entity types. This is realised by matching entities to all their contexts and thereby encoding all their properties.\nThe contribution is RELIC, a table of entity representations that are learned given the above objective. This table, RELIC, can be used in various tasks like entity typing, entity linking and question answering. Given a corpus of entities and their respective contexts, the probability of an entity occurring under its context is maximised (additionally, the probability is minimised for negative samples). The data is taken from a Wikipedia dump. Without adding further information, the RELIC table can directly be used for entity linking.\nIn the entity linking task, RELIC achieves a lower precision at two benchmarks (CoNLL-Aida, TAC-KBP 2010) than other approaches. This can be tackled by fine-tuning the RELIC table, which is done with the training set from the CoNLL-Aida task. With fine-tuning, comparable results are achieved.\nFor entity typing, RELIC embeddings of entities are used as input for a 2-layer FF network, which then outputs which types belong to the entity. The FIGMENT and TypeNet datasets are used as benchmark here and it is shown that the RELIC based approach outperforms the other approaches.\nRELIC is also used for a category completion task, where a category is represented by a centroid of three randomly sampled entities belonging to it. The entities from RELIC are then ranked with the dot-product with the centroid. Two tasks are used to measure the performance here: the TypeNet completion task and a Wikipedia-based task. Compared to embeddings of a 2017 approach, the RELIC embeddings perform better. \nFinally, a QA task is performed using RELIC. Here, the questions are modelled as contexts and the entity which is closest in terms of cosine similarity is taken as answer. The performance is below the upper bound from 2018, but better than a classifier system from 2017.\n\nOverall, the paper is well structured and manages to show that RELIC is a versatile tool on which various tasks can be performed. The technical details are well covered and the evaluation is done in a detailed way.\nThe contribution of the paper is mostly in the definition of context-entity pairs as input to a transformer model and in empirical evaluations. I specifically found the findings in 5.3 interesting. The technological contribution is rather limited.\n\nMinor comments: At page 3, chapter 3.1 there is a word duplication [\u2026]to correctly match match[\u2026] that should be corrected. Additionally, on page 5 it should be mentioned that the values in table 1 are precision values."}