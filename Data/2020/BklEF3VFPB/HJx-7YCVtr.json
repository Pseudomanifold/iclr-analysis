{"rating": "3: Weak Reject", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper proposed a new method for unsupervised domain adaptation. Different from a conventional domain classifier based adaptation, they propose to utilize the loss of autoencoder to extract domain-invariant features. They trained reconstruction network to reconstruct source examples well whereas making reconstruction loss of the target examples large with some margin. Their goal is to stabilize the training of adversarial training for domain adaptation, incorporate pixel-level information, and give interpretable learned feature space. They performed experiments on digits datasets and WiFi Gesture Recognition datasets. Through experiments, they have shown that their method shows better performance than baseline methods and their method is not parameter-sensitive, is stable and provides interpretable adaptation results. \n\nI think their method is interesting and motivation is important. However, their experimental results are not convincing enough. \nFirst, they did not compare their method with recent state-of-the-art methods.  For example, there are classifier's discrepancy based adversarial learning method, Saito, Kuniaki, et al. \"Maximum classifier discrepancy for unsupervised domain adaptation.\". In addition, they did not compare with \"A dirt-t approach to unsupervised domain\nadaptation\", which they cited in the paper. I think their method is for stable and interpretable adversarial learning. So, it does not have to outperform other methods in accuracy. However, they need to show some superiority over these representative adversarial methods. \nSecond, their experiment is only on digits and WIFI datasets. Is the method effective for object recognition datasets, such as Office or OfficeHome? This is an important question to be addressed because the two datasets are benchmark domain adaptation dataset and the behavior on this dataset will show how this method is applicable to various datasets. I would say that the method does not have to outperform state-of-the art methods for these datasets, but they need to show how the method works on this dataset with respect to stability and interpretability. \n\nIn addition, this method seems to have clear connection with \"Zhao, Junbo, Michael Mathieu, and Yann LeCun. \"Energy-based generative adversarial network.\" arXiv preprint arXiv:1609.03126 (2016)\". They need to add this paper to a reference  and explain some connections. \n\nTo sum up, due to the two questions listed above, I think this paper is marginally below the acceptance threshold. Please respond to the questions.\n "}