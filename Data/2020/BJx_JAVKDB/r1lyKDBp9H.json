{"rating": "1: Reject", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "Summary:\nThe authors present a study on 5 remote sensing datasets where in-domain representation learning is studied and various methods to train and transfer knowledge between them are assessed. In addition, the authors aim to release these 5 datasets with appropriate training and test conditions to the public.\nAn interesting point of the paper is that ImageNet representations are used to either pretrain, finetune or train networks on each dataset and to transfer that performance to each other dataset. The performance of ImageNet is highly competitive int his context, demonstrating the quality of its features.\nThe paper is not proposing technical novelties of any kind throughout.\n\nComments:\n-pixel real estate and resolution makes it unclear which dataset is bigger, though the authors attempt to discuss this. The 'winning' dataset (in terms of its usefulness for transfer) seems to have the highest resolution and image size, which may easily be the reason that models can better be trained here.\n- Some of the tasks the authors attempt might best be attempted with different models. For example, not every remote sensing task is about classification of a patch. In some cases, segmentation into types of areas would be more appropriate. As such, the basic premise of the paper that the 5 tasks are similar and can be treated as one benchmarkable object seems quite brittle. A better approach seems to surely be to treat each problem with a more tailored approach?\nAdding the right inductive biases into each problem may also help mitigate the lack of specific domain data when aiming for high performance in each domain.\n- The authors miss a chance to consider this an exercise to perform a version of multitask learning for many of their experiments of similar structure, i.e. aerial images. In many cases satellite images will require similar RGB features. Why should we not use knowledge from all  datasets to get the best features? I was looking forward to seeing a discussion on this topic but unfortunately did not find it.\n\nDecision:\nOverall, this paper handles an interesting collection of data, but does not add much interesting novelty to the field of representation learning and fails to leverage some opportunities in those datasets to do sth. interesting (i.e. better transfer and/or better models). \nI also find the approach to tackle all 5 datasets and all problems in each dataset as a similar problem too simplistic. Remote sensing data, as many real-world datasets, is a wonderful playground for rich modeling ideas and inductive biases to make things work with less data or particularly structured data. \nIt is commendable to prepare the datasets for publication and the basic results the authors show make for good first baselines here, but ultimately do not meet the bar for novelty or scientific insights.\nThe paper might be a stronger fit for a targeted workshop on its topic."}