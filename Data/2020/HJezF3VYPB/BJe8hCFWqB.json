{"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper introduces an unsupervised federated domain adaptation (UFDA) problem and proposes a new model called Federated Adversarial Domain Adaptation (FADA) to transfer the knowledge learned from distributed source domains to an unlabeled target domain. This paper uses a dynamic attention mechanism by leveraging the gap statistics to transfer distributed source knowledge. This paper also proposes a method to disentangle the domain-invariant features from domain-specific features, using adversarial training. Moreover, a theoretical generalization bound for UFDA is derived. An extensive empirical evaluation is performed on UFDA vision and linguistic benchmarks.\n\nThis paper should be rejected because the total pipeline seems ad-hoc except for optimizing the weight of the source domain in the attention mechanism. Although the derivation of generalization bound for FDA in Sec.3 is excellent, it only demonstrates the importance of the weight $\\alpha$. This result is trivial if we assume to have the same source domain as the target and utterly unrelated source domain to the target domain. It seems that proving why minimizing the gap statistics contributes to FADA is more essential in the dynamic attention mechanism. Because representation disentanglement has no relation with the derived theory, it would be better to clarify whether this method is original or not.\n\nIn the UFDA setting, the reviewer has doubts about whether it is realistic that the source node has a rich labeled data assuming our smartphones. Also, the assumption that the system cannot access the source data but must access all source feature seems a significant limitation in terms of privacy issues and communication cost between the target node and the source nodes.\n\nIt is unclear what is the final target classifier. If the target can access the teaching signal (e.g., labels or tags) in the source domains, it would be better to mention whether this situation violates the assumption the authors raised or not.\n\nMinor comments\n1) What is T(p, q, \\theta) in the section of Representation Disentanglement?\n\n2) What is C_s in eq.6? C_{s_i}?\n\n3) In Fig.3, it is not proper to discuss the size of intra-class variance by just looking at the figures because the t-SNE is a non-linear mapping. It is better to show quantitative scores, such as the value of the Fisher criterion."}