{"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "The authors developed a novel quantization technique that yields layer-wise different mixed-precision quantization. To do so, they alternatively update the pre-trained weights and the quantizer, which they call cursor. The following two features distinguish this paper: using two precision values around the cursor's value (instead of the closest one) and regularizing the parameter size using a new loss function. Because the whole process is differentiable, the appropriate precision to each layer can be found fast. Thanks to these efforts, this method balances the compression rate and accuracy well on CIFAR-10 and ImageNet.\n\nUnfortunately, the details of these two features are hardly supported in conceptual, theoretical, and experimental manners. \n(1) The reviewer guesses that \"parameter size after quantization in one layer\" in equation 3 is related to \"layer_size\" in equation 8. However, the relationship is unclear and cannot convince the reviewer that the newly proposed loss (equation 3) is differentiable. Also, equation 7 ($f=d_1*(Conv(X, W_1)+d_2*Conv(X*W_2))$) is difficult to make the reviewer understand why and how this method works.\n(2) The preliminary experiment in section 4.1 seems to claim that a single cursor leads a network to local minima, by only showing training loss. The reviewer thinks that the authors need to show validation loss as well to claim the failure of the single cursor.\n\n\nThe followings are minor comments.\n* To the best of the reviewer's knowledge, the term \"cursor\" is the authors' original one. Therefore, the authors need to write its definition.\n * The mathematical notations in this paper are confusing. (1) Each face has different meanings. For example, $max$ means $m \\times a \\times x$, rather than the max operator $\\max$. (2) operator * is used in arbitral as both unitary and binary without any comments or definitions.\n* The reference is required to be format and cited correctly. For example, [He et al. 2015] is accepted to CVPR 2016 but is not mentioned. \n* The authors claim that \"comprehensive experiments\" are done. However, the authors' proposal is experimented only on CIFAR-10 and ImageNet with MobileNet V2 and ResNet-18, while DNAS, for example, is verified on more variety of data and networks, plus object detection tasks. The reviewer thinks that the method proposed in this paper requires more comprehensive experiments.\n"}