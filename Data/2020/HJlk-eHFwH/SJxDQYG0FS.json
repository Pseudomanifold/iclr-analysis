{"experience_assessment": "I have read many papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper presents a voice conversion approach using GANs based on adaptive instance normalization (AdaIN).  The authors give the mathematical formulation of the problem and provide the implementation of the so-called AdaGAN. Experiments are carried out on VCTK and the proposed AdaGAN is compared with StarGAN.  The idea is ok and the concept of using AdaIN for efficient voice conversion is also good.  But the paper has a lot of issues both technically and grammatically, which makes the paper hard to follow.\n\n1. On writing\nThere are glaring grammar errors in numerous places. e.g.\n  -- \"Although, there are few GAN-based systems that produced state-of-the-art results for non-parallel VC. Among these algorithms, even fewer can be applied for many-to-many VC task. At last, there is the only system available for zero-shot VC proposed by Qian et al. (2019).\"   This is hard to parse.\n -- \"helps generator to make ...\"  -> \"helps the generator make ...\"\n --  \"let assume\" -> \"Let's assume\" \n --  \"We know that the idea of transitivity as a way to regularize structured data has a long history.\"   what does it mean?\n --  \"the generator of AdaGAN is consists of Encoder and Decoder.\"  -> \"consist of\"\n -- \"After training of AdaGAN for large number of iteration of $\\tau$ , where theoretically $\\tau \\rightarrow \\infty$.\" where is the second half of the sentence?\n\n2.  On math notation\n The math notation is messy and there are lots of inaccuracies.  e.g.\n  --  $X_{i} \\in p_{X}(\\cdot|Z_{i},U_{i})$ should be $X_{i} \\sim p_{X}(\\cdot|Z_{i},U_{i})$\n  --  \"generate the distribution denoted by $\\hat{X}_{Z_{1}\\rightarrow Z_{2}}$\"  -> why  $\\hat{X}_{Z_{1}\\rightarrow Z_{2}}$ becomes a distribution? \n  --  \"$p_{N}(\\cdot|Z_{1},U_{1})$, $p_{N}(\\cdot|Z_{2},U_{1})$\" in Eq.14,  $N$ should be replaced by the random variable.\n  --  $S'_{X}$ and $S'_{Y}$ should be $S_{X'}$ and $S_{Y'}$ in line 15 in the algorithm\n\n3. On technical details:\n -- In Fig.1 (b), why is there only one input to the discriminator?  How do you inject the adversarial samples and how do you generate adversarial samples? \n-- In section 4.4, \"in encoder and decoder all layers are Linear layers\".  Are you referring to fully-connected layers? Linear layers are usually referred to those with linear activation functions.  \n-- The experiments are claimed to be zero-shot, but 3-5s of speech is required.  can you explain? \n\nAlthough the samples sound OK, given its current form, the paper needs significant re-work. "}