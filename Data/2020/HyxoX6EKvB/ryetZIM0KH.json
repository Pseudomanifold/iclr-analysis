{"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "Summary: This paper proposes a method for binary word attribute transfer based on reflection. It applies a single reflection-based mapping that relates the locations of two vectors in a Euclidean space by a hyperplane, and results in an identity mapping when it is applied twice. It's sort of like roundtrip-translation, but for word vector attributes. The paper also proposes a pretty smart idea: the mirror functions are parameterized to take advantage of the fact that inversions differ, even for the \"same\" word attributes. \n\nI am giving the paper a weak accept, because I think idea is really fun, and definitely has legs. I like the idea for this paper quite a bit, it really got me thinking, but I think it isn't quite structured how I would like. Unfortunately, as it is, it also feels a bit spare in terms of contributions. I would like much more discussion/analysis of the parameterizations (and their parameters), or treatment of more binary-attribute linguistic analogy types (antonymy, scalar terms), or both! Another thing that could be added is comparisons across types of word vectors (word2vec alone is a bit narrow). Any of those things would have justified a strong accept. \n\nSuggestions: \n- As I was reading, I was not at all convinced by the \"idealness\" of your transfer function in 4.1 (maybe change it from \"ideal\" to \"idealized\"). \"Ideal\" assumes that there will be pairs sharing a stable attribute. But, often \"gendered\" words don't come in pairs, and \"gender\" is far from a stable attribute. To be more specific, despite your Fig 3a: \"actress\" may be feminine, but \"actor\" is clearly neutral (anyone can be described as an \"actor\" but only women can be described as \"actress\" in most cases); thus \"actress\" is the gendered one. We can go ahead and pair \"actress\" with \"actor\"---they do share a morphological relationship after all---but \"actor\" isn't as obvious a masculine counterpart as \"king\" is for \"queen\". How would you square this with phi(queen)=king and phi(king)=queen, where the identity of counterparts is clearer? Do we ideally want the same invertible method here for both actor-actress and queen-king (I think I don't, hence the function is not \"ideal\"). I wouldn't be surprised if the same situation arises in other analogies. This is, I think, why you brought up parameterization. But you miss the opportunity to clearly motivate why we need to parameterize! You should include more motivation and lay the linguistic facts out in a clearer way that incorporates examples like the one I gave, and preferably before S4.1.\n-The total number of words you chose to use is pretty small, which you acknowledge. I would've loved to see a few more phenomena, perhaps antonymy, part-whole, morphological reinflection (e.g., a generalization of your sing-pl set, datasets exist for past-tense at least), etc. \n-it would have been neat to compare word2vec to other types of vector embeddings, maybe contextualized? They are what everyone's using right now (this suggestion didn't factor heavily into my rating though). Also the framing in your introduction made me think this is where you were going (you started with discussing vectors, as opposed to just jumping in on binary word attribute transfer. I think the paper could just jump right in with binary word attribute transfer, and skip the basic vectors paragraph).\n-I would've liked more discussion of your parameterized mirrors, since that was the neatest/prettiest part, in my opinion. (maybe I missed something, but how did you decide on how many z to use? or did every pair get its own? Do your zs for each attribute correlate at all? you could use something straightforward like CCA to check, would be neat.)\n\nSmall Notes/Musings:\n-on p.1 \"(PMI (citation...\" with nested parentheses is not easy to read, I prefer \"(PMI; citation)\".\n- It is fine to operate on the assumption that gender is binary for now, but you should acknowledge that binary gender is an assumption (and a socially problematic one), that isn't real.\n-in 5.5, I'm not impressed by \"When non-attribute word the was given, Ref(v the) became 'the' without knowledge that the has no gender attribute\", because \"the\" is the most frequent word in English, perhaps show that it works with rare, non-gendered words instead. Incidentally, does it know syntactic category? Because that might be a neat thing to check.\n-what do you think about trinary attributes (cold, warm, hot)? It would be a cool extension.\n"}