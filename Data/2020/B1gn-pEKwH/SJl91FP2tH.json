{"rating": "1: Reject", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "The authors present a model for time series which are represented as discrete events in continuous time and describe methods for doing parameter inference, future event prediction and entropy rate estimation for such processes. Their model is based on models for Bayesian Structure prediction where they add the temporal dimension in a rigorous way while solving several technical challenges in the interim. The writing style is lucid and the illustrations are helpful and high quality. \n\nHowever, the paper and the technical challenges which the authors faced have been extensively studied in the closely related field of (marked) temporal point process modeling, which also models processes with discrete events in continuous time. Hence, the claim \"When it comes to continuous time, discrete-event predictors, far less has been done\" is mildly erroneous. The literature in that field has provided several ways of handling the technical challenges which authors have tried to overcome. For example, excellent predictor for the next event as well as time has been proposed by Du. et. al. (2016), Mei and Eisner (2017) and, very recently, by T\u00fcrkmen et. al (2019), among many many others. Also, probability model (i.e. \\phi_s(t)) of the next event time can be represented using intensity functions \\lambda(t). However, if the authors require an explicit likelihood function, Normalized Flows with re-parametrization, can provide that too (see Kobyzev (2019) for a review of recent work in the area). This while being a Neural Network based approach well-weathered models and does not require numerical integration. Without placing this work in context of these works, it is very difficult to judge the contributions of the paper well.\n\nThen there are a few unanswered questions about the model:\n\n 1. In the Background, where the authors describe the generative process, does the emitted symbol also depend on the dwell time \\tau (like Mei and Eisner, 2017), or is the distribution of the dwell time and the next symbol independent given the state (like Du et. al)?\n 2. Similarly, during entropy calculation, while breaking the entropy term from (9) to (10), shouldn't there be a dependence of the discrete symbols on the continuous dwell times of the prior step?\n 3. We need significantly more information about the training used for the LSTM/RNN models to be able to judge whether the performance of the methods is comparable or not. These could be provided in a supplementary material, if they do not fit within the main text.\n\n\nSome other ways of improving the paper:\n - The reference style changes frequently in the paper and is mutually inconsistent.\n - The \\pi in Eqn. (3) is not formally defined. If it is the initial state probability, then should it be dependent on the model \\Mcal and parameters \\theta?\n - The illustrations, though useful, are too large and use up space.\n - Though the task of determining the entropy is indeed intellectually satisfying, it would very much help motivate the reader if there were some applications which the authors could allude to.\n\n\nCitations:\n - Aalen, Odd, Ornulf Borgan, and Hakon Gjessing. Survival and event history analysis: a process point of view. Springer Science & Business Media, 2008.\n - Du, Nan, et al. \"Recurrent marked temporal point processes: Embedding event history to vector.\" Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 2016.\n - Mei, Hongyuan, and Jason M. Eisner. \"The neural hawkes process: A neurally self-modulating multivariate point process.\" Advances in Neural Information Processing Systems. 2017.\n - T\u00fcrkmen, Ali Caner, Yuyang Wang, and Alexander J. Smola. \"FastPoint: Scalable Deep Point Processes.\"\n - Kobyzev, Ivan, Simon Prince, and Marcus A. Brubaker. \"Normalizing flows: Introduction and ideas.\" arXiv preprint arXiv:1908.09257 (2019).\n"}