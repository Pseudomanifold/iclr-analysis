{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "Summary\n\nThe authors propose a new pooling layer, LaPool, for hierarchical graph representation learning (Ying et al., 2019) by clustering nodes around centroids that are selected based on \"signal intensity variation\". The signal intensity variation of node x is defined as sum_{y in HOP(x, h)} ||x - y||  where HOP(x, h) is the set of nodes reachable from x within h hops. Once top k maximizers are selected as centroids (k can be predetermined or dynamically chosen), a sparse cluster assignment distribution is computed for each node using sparsemax (Laha et al., 2018), and the affinity matrix and the node embeddings are coarsened as in Ying et al. (2019). The authors show that LaPool can improve performance in various graph-related tasks over baselines and generate interpretable clusters. \n\n\nStrengths\n\n- Explicit centroid selection based on signal intensity variation seems like an intuitive idea worth investigating. \n\n- LaPool seems to be empirically effective, in particular outperforming Graph U-Net which is probably the most relevant baseline (also k-max pooling for hierarchical graph representation learning). But I'm not an expert on the considered tasks, so I cannot judge how significant these results are. \n\n\nWeaknesses: \n\n- The paper has issues with clarity. There seem to be many sloppy notations as well as unclear (possibly wrong) arguments.\n\n1. Isn't equation (1) true for unnormalized graph Laplacian (D - A), not normalized? \n\n2. In the proof of Theorem 1, why is it that C C' X = X (i.e., X is in range(C))? This is a crucial step that I'm not sure why is true. I might be missing something, but it's not clear to me in the current version. \n\n3. Sloppy notations. What do \"A^h\", \"||L X||_{R^d}\", \"top_k(V|L S)\" mean in equation (4)? I can infer their meaning, but do I have to? This also interferes with my other confusions: back to question #1, is it true that S = ||L X||_{R^d}? \n\n4. Is the number of clusters fixed or dynamic for these experiments? Figure 2 seems to be dynamic based on the main text, but I cannot tell if it's the case for other experiments. Based on the provided code, it seems the default number of clusters is always 10% of the number of nodes.\n\n- The paper doesn't do a good job of contextualizing itself. Graph U-Net seems to be the most relevant previous work, but there's no discussion of how this work relates and why it's better. For instance, is it the case that Graph U-Net is not interpretable because there's no explicit clustering? It'd be much clearer to spell out such differences. \n\n- It's unclear why certain design choices are made and why they're better. For instance, is swapping entropy minimization with sparsemax necessarily better? I understand not every design decision should be (or needs to be) justified, but it's helpful if it is to understand what helps and what doesn't.\n\n\nSummary\n\nThe core idea of the paper, clustering nodes based on signal intensity for hierarchical graph representation learning, is interesting and seems to be useful in practice, but the paper has issues with clarity and the rest of the framework is a bit limited in novelty (DiffPool + sparsemax + GIN)."}