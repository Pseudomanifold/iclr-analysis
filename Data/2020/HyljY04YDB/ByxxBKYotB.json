{"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "title": "Official Blind Review #1", "review": "This paper proposes a graph down-sampling component named LaPool. It uses the graph signal to dynamically select some \"important\" centroids and learn a sparse assignment matrix for clustering the remaining nodes.\n\nThis paper should be rejected due to the following reasons.\n\n1. Strange new results compared with its previous version\n\nThe paper has a previous arxiv version. While the method does not change, the performance in this current submission has dramatic change compared with previous version: the proposed model seems much improved, while some important baselines (that outperform the proposed model) only have 50% of it previous performance in this submission.\n\nFor example, for Table 1 in the current version, the proposed model reached almost perfect scores in both F1 and AUC. However in previous version for the same setting and experiment (in Table 2 and 3 of its arxiv version), the performance are much lower especially the Structural alert prediction results.  Their previous results, which show the model does not perform better than DiffPool .\n\nFor the structural alert prediction results on DiffPool, below I copied and pasted the results from the arxiv version\n                                  \n\nTable 3: Structural alert prediction results \n------------------------------------------------------------------------------------------------------------\n                                             Tox21                   |               ChEMBL\n                       F1-macro F1-micro ROC-AUC F1-macro F1-micro ROC-AUC\n------------------------------------------------------------------------------------------------------------\nGIN                     78.9        68.3             72.6           93.6         76.7          59.2\nDiffPool              79.2        68.0             75.6           94.5        83.3          59.3\nGraph U-net      71.1        47.6             67.9           92.9        68.1          59.3\nLaPooldistance 80.6        74.2             73.5           95.2        81.3          59.5\nLaPoolunreg     81.3        72.8             74.1           94.1        75.8          58.9\nLaPool3hop       79.1        71.6             74.8           93.8        75.0          59.1\n------------------------------------------------------------------------------------------------------------\nOne example: \n(1) in the ICLR version, The F1 score for DiffPool is only 48.638 \u00b1 9.916 on ChEMBL data (about 50% of its previous level) but F1 for the proposed method is improved. Why is that? \n(2) same as baseline  Graph U-net , the ICLR version reports F1 37.585 \u00b1 2.978, why is that?\n(3) same as GIN, in the ICLR version, F1 is only 31.759 \u00b1 3.728, less than 50% of its previous level in arxiv version.\n\nThe author needs to justify this dramatic change.\n\n2. Although LaPool can dynamically select centroids, for a dense graph such as a complete graph, only one centroid will remain there since there is only one node which has larger signal variation than all its neighbors, as shown in Eq. 4. This consequently hurts the model performance on more dense graphs. That may be why in Table 2, on dense data \"DD\", LaPool performs much worse than baseline DiffPool. Also on another dense data \"FRANKENSTEIN\", LaPool does not performs significantly better than DiffPool.\n \n\n3, the evaluation of interpretability is not convincing. This paper considers  \"interpretability as the degree to which a human (in this context, a medicinal chemist) can understand the cause of the model\u2019s decision\". Therefore, the conclusion that this model is more interpretable is based on only one person's subjective judgement.  Even so, from the scores the model does not outperform baseline \"GIN\" that much.\n", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}