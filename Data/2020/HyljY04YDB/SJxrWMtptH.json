{"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "The paper introduces a new pooling approach \"Laplacian pooling\" for graph neural networks, which the authors claim is able to better preserve information about the local structure, and to provide interpretability.  Namely, the pooling approach is based on finding centroids (nodes having high signal variation compared to their neighbors, via graph-Laplacian) and assigning other nodes to be \"followers\" based on a soft-attention mechanism. The authors add these new pooling layers to existing GNN architectures and show improved performance on problems of classification and generative modeling of molecular graphs. The paper also extends CNN interpretability techniques (integrated gradients) to GNNs.\n\nI am borderline on the paper -- I'll give a weak accept rating for now. The proposed Laplacian-pooling ideas could be interesting, and the results encouraging -- but I found the mathematical motivation to be not very convincing, and has various (mostly correctable issues). The paper can be viewed as more of an engineering effort, which attempts to find practical tricks aimed at modeling molecular structures. What I like about the paper is that the authors make an earnest attempt to model the domain (biochemistry) -- for example they realize that a graph formalism for molecular structures is rather simplistic, and misses many important details -- such as different types of bonds (which require different types of edges). The authors also realize that typical neighborhood smoothing (diffusion) that makes sense for say spatial or social network graphs may not make sense for molecular graphs, where specific substructures (e.g. presence of a benzene ring) may be highly indicative for some classification tasks. The paper also contains a collection of interesting practical heuristics and observations (mainly in appendix) to help train GNN models for classification and generative modeling -- which researchers in the field may find valuable. I am not sure if the idea of coarsening (via hierarchical pooling) can be meaningfully applied to a wide-variety of natural molecules - but it does seem to make sense for some organic molecules -- e.g. protein chains. \n\nDetailed comments: \n1. The paper makes an analogy between band-pass filtering and the proposed approach. In my opinion the analogy is rather weak -- while it may carry over to spatial graphs (e.g. grid graphs) but may not apply to more complex graphs -- e.g. graphs where each node is at most a few hops away from any other node. It's not clear in what sense (3) corresponds to high-pass filtering. Can you show that it's somehow related to filtering-out the large (low-pass) eigenvalues of the graph-laplacian?\n\n2. There is a typo in equation (1) -- equality of the quadratic form f'L f requires an unnormalized definition of the graph laplacian D - A, instead of I - D^{-1} A. \n\n3. Notation in equation (3) -- is unclear and undefined.  What is ||L X||_{R^d} ? is that a norm (giving a scalar), or concatenation?  What is Top_k(V | L*S) -- the readers have to guess. You may be relying on notation from existing papers -- but still need to set up notation to be self-consistent. Subtle comment: \"signal intensity variation\" sounds like the variation of signal intensity -- e.g. something like difference of signal norms. Perhaps intensity of signal variation is a better term.  Sparsemax is also undefined. What is A^h -- the h-hop adjacency matrix? \n\n4. I do not understand what do you mean by \"information preservation\" after pooling -- and I did not understand the importance of the \"structure-aware feature content\" definition, and the value of theorem 1.  Matrix C in the derivation is undefined. \n"}