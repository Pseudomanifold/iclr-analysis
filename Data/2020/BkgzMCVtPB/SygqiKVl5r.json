{"experience_assessment": "I have read many papers in this area.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review": "# Summary\nThe authors investigate an attack-defense problem in which an attacker attempts to pass authentication by generating a faked input, while an authenticator attempts to detect the fraud. They formulate this problem as a zero-sum game and reveal the closed form of the optimal strategies. Furthermore, they reveal a more insightful closed form of the optimal strategies in the Gaussian case. This result clarifies the relationship between the success rate of the attacker and the numbers of the source, registration, and leaked observations. The analysis for the Gaussian case also gives an interesting insight that the optimal attacker\u2019s strategy is to generate fake inputs so that its sufficient statistics are matched to that of the leaked observations. Based on this insight, the authors propose a new learning algorithm for the authenticator and demonstrate by some empirical evaluations that the proposed algorithm is robust against the faked input.\n\n# Detailed comments\nThis is an interesting and well-written paper. I recommend acceptance of this paper.\nThe authors investigate an attack of generating a faked input for passing the authenticator under which the attacker can only observe partial information about the source input. This is an interesting point of view and allows us to analyze a more practical situation. Furthermore, based on the theoretical analyses, they reveal an interesting insight of the optimal attacker\u2019s strategy that the optimal strategy generates a faked input so that its sufficient statistics are matched to that of the leaked observations. This insight introduces the new robust learning algorithm which outperforms the existing robust learning algorithm demonstrated as in the empirical evaluations.\nSome minor refinements would improve the paper:\n- \\bar{x} and \\bar{a} in Theorem 4.2 should be clearly defined.\n- It seems to me that the authors use the term \u201cML attacker\u201d to denote some different attacking algorithms."}