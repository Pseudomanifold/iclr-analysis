{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper proposes a new loss for training models that predict where events occur in a sequence when the training sequence has noisy labels. The central idea is to smooth the label sequence and prediction sequence and compare these rather than to force the model to treat all errors as equally serious.\n\nThe proposed problem seems sensible, and the method is a reasonable approach. The evaluations are carried out on a variety of different tasks (piano onset detection, drum detection, smoking detection, video action segmentation).\n\nSuggestions\n* While the authors do bring up lots of related work on learning from noisy labels, the insights from that work, and its relationship to this proposed technique could be more productively explored\n* The connections between the assumptions of the evaluation metric and the motivation for the smoothing methodology could be more productively elucidated\n* The task explored in this paper, and the task-specific problem, should be described more generally since ICLR has a generalist readership. For instance, the paper gets off on a rather strange footing discussing large data (indeed, but evident to the vast majority of ICLR readers), but little is said in terms of the specifics of the temporal localisation problem except via citations to other papers. In particular, the task set up, the problem posed by label misalignment could be described elegantly right in the introduction with a carefully designed figure. In section 2, the description is hard to follow, the mathematical notation is vague and hard to parse. For instance, the label sequence Y, is d-dimensional- the meaning of d should be clarified. Calling it \u201cdiscretised\u201d is also a bit strange, for most readers- it\u2019s a label sequence.\n\nThe evaluation objective needs to be clarified, at least qualitatively; ideally in the introduction. Introducing a new objective is meaningful not only in light of noisy labels (always a problem), but in light of how the evaluation is carried out.\n\n"}