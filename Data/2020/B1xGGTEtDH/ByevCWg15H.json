{"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "N/A", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "    - This paper complement of the fundamental Universal approximation theorem variants\n    - Based of the Register model, that the authors seem to have developed themselves from the scratch, elegant, although non-obvious\n    - Proof is straightforward, although the pictural description can be enhanced. In reality the width neurons are unfolded horizontally in the n+m+1 layer\n    - As of now, single-point continuous function does not seem to have been proven to be sufficient to build universal single-layer approximator networks in the 1999 paper. \nIt is unclear how the authors prove that part of their theorems.\n    - The third part of the paper relies on Stone-Weierstrass theorem and a manipulations around the concept of \"enhanced neurons\", carefully constrcutred to fit in the n+m+1 and n+m+2 budgets\n    - However, the proof of relaxing the Polynomial functional constraint in Theorem 4.8 is not entirely clear. While it seems to be a two-staged proof (convergence for non-linear function x^2, then convergence of a class of polynomial functions to x^2), it is unclear how the $\\rho_h$ neurons can be assembled with the registry neuron budget from the initial polynomial function.\n    - Although inspired by prior work, the author's contribution is novel, original and important.\n   \nOverall, I find this paper highly useful, elegant and, to the extent of my knowledge and understanding, properly proved. My main suggestions to the authors are with regards to the clarification of the proof of the Theorem 4.8.  after which I could increase my score.\n"}