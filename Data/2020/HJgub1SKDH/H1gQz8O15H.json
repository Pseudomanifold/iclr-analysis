{"experience_assessment": "I do not know much about this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "The paper analyzes collections of deep neural network classifiers on different dataset: the only constraint is that the different models are trained on the same classification problem.\nTheir similarity is based on the accuracy performance on both the training and test sets.\nThe paper shows that the accuracy and pattern of classification are similar across the different models. In other words, most data points in both the training and test sets are classified correctly by all the networks, or by none at all.\n\n\nThe paper is well-written, and the motivation is clear. However, multiple papers in the literature already exist about the importance of initialization, and the difference in generalization for different local minima obtained by neural networks.\n\n\nMy vote is borderline reject for the following reasons:\n- Although the paper has some interesting insights, the whole interpretation of the model is based on the two evaluation metrics introduced in Section 2. These two evaluation metrics measure how much different models agree for the prediction of examples, and allow to measure the \"easiness\" of examples. The \"easiness\" of examples was already studied in curriculum learning. The paper could be improved by using other qualitative evaluation metrics.\n- The paper studies the consensus of models for different types of architecture/datasets/optimizers (all the compared models share the architecture/datasets/optimizers). However, all the models also seem to share the same type of inialization: according to Section 2, all the neural networks have the same type of initialization (Xavier initialization in the first paragraph).\nDoes using different types of initialization also have an impact? Maybe different types of initialization wouldn't lead to the same conclusions.\n- The paper seems to consider only the agreements on the training and test sets, what about the validation set?\n- the \"examples which are easy for linear networks are for the most part also easy for non-linear networks, but not vice versa. Thus, the non-linear networks classify correctly most of the examples that are classified by the linear networks\". This result is related to curriculum learning: although curriculum learning does not explicitly consider linear models, it considers simpler models that are easier/more efficient to train.\n- \"Curiously, the deeper the network is and the more non-linearities it has, and even though the model has more learning parameters, the progress of learning in different network instances becomes more similar to each other. Un-intuitively, this suggests that in a sense the number of degrees of freedom in the learning process is reduced, and that there are fewer ways to learn the data\". Isn't this observation related to the choice of activation functions? For what kinds of activation functions did you observe that phenomenon?\n- The results about the \"out of sample test sets\" seem straightforward. Test examples from a different distribution are more likely to meet less consensus since the neural networks are trained for the distribution of the training set.\n- Before deep learning became popular, most machine learning models (e.g. SVMs) were interested in convex optimization to avoid this kind of phenomenon: even if linear problems were trained with SGD, the model that was learned was close to a global minimum of the (convex) optimization problem, and the performance of the models was robust to their initialization. In Section 4.2, a NN is trained with linear activation and average pooling, which makes the optimization problem convex if the loss is convex. This part of the paper is related to the argument of most ML research from the 2010s (that obtained a solution close to the global minimum), just like the part where SVMs are learned.\n- I did not understand the KNN classification part which usually does not learn parameters and should then not depend on initialization. How are the conclusions drawn for KNN classification?\n\n\n\n"}