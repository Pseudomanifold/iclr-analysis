{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "This paper proposes a framework to unfold the safeguarded Krasnosel\u2019ski\u02d8\u0131-Mann (SKM) method for the learn to optimization (L2O) schemes. First, SKM is proposed in Algorithm 1 with convergence guarantee established in Theorem 3.1 and Corollary 3.1. Then, SKM is unfolded and executed with a neural network summarized in Algorithm 2. Experiments on the Lasso and nonnegative least squares show the efficiency of the proposed method as well as the effectiveness of safeguarding compared to traditional L2O methods.   \n\nAdvantages:\n1. A general framework that encompasses all L2O algorithms for use by practitioners on any convex optimization problem.\n2. It seems that the convergence analysis of Krasnosel\u2019ski\u02d8\u0131-Mann equipped with safegarding is established for the first time. \n\nWeakness:\nThe idea of reimplementing an iterative algorithm in a deep architecture is not new, and the combination of safegarding with KM has already been analyzed [1,2].  Moreover, the experiments are not convincing. \n1. Safegarding is the key point of this paper, but the authors did not review related works on safegarding. Please show the relationships of SKM with prior works and comment on the novelty of the analysis in this paper. \n[1] Themelis, Andreas, and Panagiotis Patrinos. \"SuperMann: a superlinearly convergent algorithm for finding fixed points of nonexpansive operators.\" IEEE Transactions on Automatic Control (2019).\n[2] Sopasakis, Pantelis, et al. \"A primal-dual line search method and applications in image processing.\" 2017 25th European Signal Processing Conference (EUSIPCO). IEEE, 2017.\n\n2. All the 3 experiments are conducted on synthetic datasets which is not convincing enough to show the efficiency and effectiveness of LSKM. It is suggested to carry out experiments on real-world datasets like [3,4] with state-of-the-art methods. \n[3] Sun, Jian, Huibin Li, and Zongben Xu. \"Deep ADMM-Net for compressive sensing MRI.\" Advances in neural information processing systems. 2016.\n[4] Metzler, Chris, Ali Mousavi, and Richard Baraniuk. \"Learned D-AMP: Principled neural network based compressive image recovery.\" Advances in Neural Information Processing Systems. 2017.\n\n3. The are too many errors in references, for examples:\n(3.1) What is \"In S. Bengio, H.Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett (eds.), Advances in Neural Information Processing Systems 31\"? This error appears multiple times. \n(3.2) Show complete information of reference \"Liu et al. (2019a)\".\n"}