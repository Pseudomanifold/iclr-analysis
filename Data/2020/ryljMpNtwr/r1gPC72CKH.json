{"experience_assessment": "I do not know much about this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This paper presents a benchmark for measuring robustness to input image corruption in object detection settings. The paper proposes a benchmark for this task, and proposes a simple data augmentation technique for this task.\n\nStrengths\n1. Understanding the robustness properties of existing vision models is an important problem.\n2. The paper establishes a sensible protocol for the benchmark, where methods are tested upon image perturbations that are not used for training the model.\n3. I like the proposed simple data augmentation procedure and the experimental finding that data augmentation with such a procedure leads to models that are robust to held-out, previously unseen perturbations.\n\nShortcomings:\n1. While the paper proposes a sensible experimental protocol, certain questions remain:\na) Are the set of test time perturbations exhaustive and representative of the perturbations in the real world? The paper doesn't talk about this, or provides any experimental data to establish this. The paper derives them from an earlier paper called \"Benchmarking neural network robustness to common corruptions and perturbations\", and thus I am not even sure if the proposed set of perturbations should be viewed as a contribution of the current paper.\nb) While the paper itself follows good practice by not training on perturbations that are considered at test time, unfortunately, it does not define a clear protocol or characterization as to how future researchers should use the benchmark. I believe setting up such a protocol is going to be difficult and is worthy of more thought and consideration, absence of this weakens the paper, as it leaves the door open for flawed future research.\n\n2. Missing comparisons: Proposed method is interesting, but I wonder if there were a more standard evaluation to test the efficiency of the method, perhaps something like testing if representations learned using such data augmentations were more robust to adversarial perturbations? Or perhaps, comparison against other methods that exist in literature for related tasks, such as methods that study how to make networks robust to adversarial perturbations?\n\nBecause of the aforementioned reasons, I don't view the benchmarking part of the paper as a solid contribution. Similarly, the proposed method is simple and intuitive (which is good), but it will help if there were more comparisons to set the paper in context of related work."}