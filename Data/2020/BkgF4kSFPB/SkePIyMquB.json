{"rating": "1: Reject", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "The paper presents a method for learning agents to solve visual planning, in particular to navigate to a desired goal position in a maze, with a learned topological map, i.e. a graph, where nodes correspond to positions in the maze and edges correspond accessibility (reachability in a certain number of steps). The work extends previous work (semi parametric topological memory, ref. [22]) in several ways. It claims to address a shortcoming of [22], namely the fact that the graph is calculated offline from random rollouts, by using a conditional variational auto-encoder to predict a set of observed images which could lie between the current position and the goal position, and, most importantly from a context image which describes the layout of the environment. These predicted images are then arranged in a graph through a connectivity predictor, which is trained from rollouts through a contrastive loss. Training is performed on multiple environments, and the context vector provides enough information for this connectivity network to generalize to unseen environments.  At test time, the agent navigates using a planner and a policy. The planner calculates the shortest path on a graph where edges are connectivity probabilities, and the policy is an inverse model trained on the output of the planner.\n\nWhile the idea of a topological memory with dynamic graph creation is certainly interesting, the work is unfortunately not well enough executed and the paper structured written in a way which makes it up to impossible to grasp what has been really done, as much information is missing which would be required for understanding. \n\nAs a first example, we are never really told what the observations are, which the agent sees. The different figures of the paper show very small images with a 2D maze from a bird\u2019s eye view consisting of a walls arranged in a single connected component (mostly 1 to 3 strokes) in red color and an agent shown as a position indicated as a green dot. Are these the observed images? In absence of any other information, this is what we need to assume, and then this problem is fully observable and does not seem to be very challenging. Given the figures, even a handcrafted algorithm should be able to calculate the optimal solution with Dijkstra\u2019s algorithm on a graph calculated from the pixel grid.\n\nThis important missing information alone makes it difficult to assess the paper, but the rest of the writing is similarly confusing. The authors focus on very short and dense descriptions of mathematical properties, but seem to have forgotten to ground the different symbols and to connect them to physical entities of the problem. The technical writing is in large parts disconnected from the problem which is addressed by it.\n\nFurther examples are:\n\n-\t\u201cthe data (\u2026) is collected in a self-supervised manner\u201d: what does this mean? Self-supervision is way of creating loss from data without labels, but I am not sure what is meant by collecting data this way.\n-\tThe paragraph on CPC in section 2 can only be understood if the contrastive loss is known. To make the paper self-consistent, this should be properly explained, and tied to a training procedure which details how exactly the positive and negative samples are defined \u2026 and collected.\n-\tThe CPC objective in section 2 is only loosely connected to its usage in section 3.2. Barely writing \u201cwe optimize a CPC\u201d objective is not sufficient for understanding how this objective is really tied to the different entities of the problem. This paper contains maths (which is always a pleasure to read), but it is not a purely and abstract mathematical problem - a real task is addressed, so it needs to be connected to it. This connection has certainly been done by the authors while they were working on the problem, but they should also communicate it to the reader.\n-\tThe section on ML trajectory is too dense and should be rewritten. I don\u2019t understand what the authors want to tell us here. Basically, a (generalized) Dijkstra is run on a graph, where edge weights are the density or density ratios learned by the CPC objective, and if the edge weights are probabilities, that the shortest path corresponds to a trajectory likelihood. This is known, and this information is buried in a dense set of equations which are difficult to decipher and do not add any further value to the paper.\n-\tThe connection between the planner (generalized Dijkstra) and the policy is never explained. We don\u2019t know how the policy is trained and how it works.\n\nOne of the downsides of the method is that it requires a context image. This image is responsible for the generalization to unseen environments, but it is a major drawback, as the image must be created beforehand. The authors claim that the context image must only contain the layout in any format which makes it possible to extract information about navigational space from it, but in the experiments the context image corresponds to the full map \u2013 and it is probably equivalent to the observed images, but we can\u2019t be sure as we haven\u2019t been told. In any case, it is far from sure how this could generalize to more complex environments, let alone 3D navigation as is currently addressed in standard simulators like VizDoom, GIBSON, Matterport, Deepmind Lab, Habitat AI etc. \n\nThe authors\u2019 claim that the proposed environment requires long-term planning, but looking at the images this does not seem to be the case. \n\nThe paper claims to perform zero-shot generalization and to adapt to changes in the environment, like the slight changes in camera motion, variations in lightning, but it unclear how the solution solves this claim.\n\nHow does the agent determine that a goal has been reached, without ground truth information? \n\nWhat happens, if the hallucinated images are disconnected (form several connected components) or are disconnected from the current position and/or from the goal position?\n\nAs mentioned, the method is evaluated on an environment, which is too simple. The experiments are difficult to assess, as we don\u2019t really know what the agent observes. An information asymmetry is mentioned (visual foresight having the object\u2019s (=agent\u2019s) position and the others not) \u2026 but if the proposed method observes the bird\u2019s eye view, it can infer the agent\u2019s position (as the position of the green dot).\n\nSubjective evaluation by humans on this kind of simple data does not seem to be meaningful, in particular with a very low number of observers (5 people).\n"}