{"rating": "6: Weak Accept", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This paper proposes a feature-wise transformation layer to augment the image features, which is a new regularization of neural networks and leads to better generalization ability of the features. And the proposed method performs well in the few-shot classification problem. Furthermore, the paper develops a learning-to-learn model in the cross-domain setting to choose optimal hyper-parameters of the feature-wise transformation layers. Which leads to consistent improvement in the cross-domain leave-one-out setting.\n\nAlthough I vote weak accept for this paper, I still have several concerns:\n* In equation $(7)$, how to calculate the gradient of $L^{pu}$ w.r.t $\\theta_f^t$ in the condition that the $L^{pu}$ is calculated after removing the feature-wise transformation layers from the model? In my understanding, The $L^{pu}$ is not related to $\\theta_f^t$ after the removal of the feature-wise transformation layers.\n* In Section 4.2, why not choose the Prototypical networks? According to the results in (Chen et al., 2019a), it performs much better in the mini-ImageNet to CUB setting.\n* In Section 4.3, what's the initial value of $\\theta_{\\gamma}$ and $\\theta_{\\beta}$? Is the initial value sensitive to the performance?\n* In Section 4.2, actually, you can learn the $\\theta_{\\gamma}$ and $\\theta_{\\beta}$ automatically even in a single domain. For example, use a different batch to update $\\theta_{\\gamma}$ and $\\theta_{\\beta}$. What's the performance under this setting?\n* There is no direct comparison to the state-of-the-art methods.\n\nOverall, the paper is well written and the figures are well illustrated. The experiments show the effectiveness of the proposed feature-wise transformation layers and the learning-to-learning approach. But the above concerns should be addressed."}