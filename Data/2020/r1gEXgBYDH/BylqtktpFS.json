{"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I did not assess the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The authors propose  to use randomized tensor factorization in the weight space as a defense to adversarial attack, which builds upon the existing works on using randomization on the weights or activation as a defense methods.\n\nPros:\n1. The idea of using randomized tensor factorization for dense is novel\n2. It seems that this defense is robust to large perturbation (epsilon), and the accuracy on clean data is high when combined with PGD adv.training.\n\nCons:\n1.  I don't understand why using randomization in the latent space of the weights can retain the classification accuracy on clean data. The authors say that this is because both the weights and the activations are not sparse. But I don't understand the relation between sparsity and accuracy. Can the author can provide some evidence on this (probably from the previous acceleration literatures). Besides, I think an accuracy of 90.1 on CIFAR10 (Tab.2) is not high.\n2. As in the review written by Anthony Wittmer, the author should include experiments to check the obfuscated gradient issue."}