{"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "In this paper, the authors propose a randomization-based tensorization framework towards robust network learning. The high-level idea of this work is to reparameterize the network parameters W of each layer with low-rank tensors, where the factor matrices are injected with randomization through randomly sampled sketching matrices. Since the randomization is is done within a subspace than directly on the weight matrix itself, the authors claim that this brings certain advantages such as less sparsity.\n\nStrengths:\n+ Well-written paper with good clarity and technical correctness.\n+ Interesting idea with novelty.\n+ Good ablation study with clear performance improvement from the proposed framework.\n+ Good applications with binarized networks and audio classification.\n\nWeaknesses:\n- Insufficient and badly conducted comparative study with recent SOTAs.\n- Insufficient experiment with larger datasets (such as CIFAR-100) or enough variety of datasets (such as SVHN).\n- No direct experiment verification that supports the advantage of randomization in a subspace\n- No discussions on the training complexities and the extendability to large-scale datasets/networks, such as ImageNet/ResNet-101.\n- Missing citation and comparison to the following two SOTAs:\n1. Xie et al., Feature Denoising for Improving Adversarial Robustness, CVPR19\n2. Mustafa et al., Adversarial Defense by Restricting the Hidden Space of Deep Neural Networks, ICCV19\n\nComments:\nI consider the idea of this paper novel and interesting. Considering tensor factorization with randomization for network robustness makes a lot of sense but overall the experiments of this paper are not well-conducted towards comparative studies with other SOTAs, although ablation study shows the considerably improved robustness from the proposed method. The main concerns of this paper lie in several aspects:\n1. It seems that the authors did not report their comparison to recent SOTAs (such as Lin et al, 2019) comprehensively enough, nor were the benchmark measures (missing several other attacks, especially black box ones), datasets and backbones fully aligned. It is unclear how much the architecture of a backbone can impact the fairness of comparison. There is also no apples to apples comparison to directly verify the advantage of this work over non-subspace-based randomization method.\n2. The authors failed to cite and compare to recent two SOTAs (listed above) which conduct large-scale experiments with bigger models. And there is no discussion about the extendability/generalizability of the proposed method to these data and models. Therefore, the contributions of this work somehow become less convincing.\n\nMinor typos:\nIn page 4 \"Randomizing in the latent subspace\": \n\\lambda^F \\in R^O --> \\lambda_F \\in R^F\nM_O = diag(\\lambda_F) --> M_F = diag(\\lambda_F)\nplease unify subscripts/superscripts for all \\lambda."}