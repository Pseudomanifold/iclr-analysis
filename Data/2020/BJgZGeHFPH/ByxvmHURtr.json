{"experience_assessment": "I have published in this field for several years.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "The author propose a representation learning method based on predictive information. They compress a start state and an action sequence to predict the following state. Since the latent space is factorized between state and action sequence, it can be used as an abstract action space to accelerate model-free algorithms.\n\nStrengths:\n- While the state representation is a simple successor representation, the action abstraction is a simple method that seems novel.\n- The multi-step return is a nice way of handling variable horizons in the context of temporally abstract actions.\n- It is nice to see that the representation learning method can accelerate learning not just from pixels but also when learning from low-dimensional inputs.\n- The method description and overall writing is very clear.\n\nWeaknesses:\n- Doesn't the multi-step return render the update on-policy, since the reward sequence is tied to the data collecting policy? If so, it might be worth to apply off-policy corrections from the literature. If not, this should be explained in Section 3.2.\n- A comparison across more domains would be desirable. While there are 6 visual tasks, they share only two environments. The paper could be strengthened by comparison on standard benchmarks such as Gym or DMControl. I'm willing to raise my score when these or comparable results are added.\n- I could not find a clear description of how the hyper parameters of baseline methods were selected, so it is unclear how much of the benefit comes from tuning.\n\nComments:\n- Equation numbers are missing on page 4.\n- An assumption of the work is that the pixel observations are Markovian. Maybe I missed this in the paper, but was there any frame stacking that would make this hold at least approximately?"}