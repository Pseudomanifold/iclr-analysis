{"experience_assessment": "I do not know much about this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The authors define two new methods for ranking the influence of individual units on the output of convolutional networks. They show that some overlap exists between the units chosen by these two methods, they use these methods to select filters to visualize, and they use one of the methods to prune/compress trained convolutional networks. Their compression method outperforms prior work.\n\nPros\nThe neuron ranking method produces compressed models that compare favorably with prior work (Table 2).\n\nCons\nI found the clarity of this paper overall to be somewhat poor. These points especially need to be addressed\n\nThe acronyms for the baselines in table 2 are not defined or cited.\nLack of clarity about the pruning experiment: Why is the Shapley value method not included here? I'm assuming NR stands for neuron ranking.\nLack of clarity about visualizations: \nAre the rankings used to choose filters to visualize from Shapley values or neuron ranking? The units [1,8,3,7] don't seem to be seem to all be selected by either method for MNIST conv1 in Table 1. \n\nI wasn't convinced by the feature map visualization section, because as far as I can tell the unimportant nodes don't look very different from the important nodes. Specifically, in both the important and unimportant node feature maps, a class example is clearly visible. Perhaps the authors could clarify what the critical difference is between these feature maps.\n\nThe neuron ranking method seems to give only a marginal advantage over simple magnitude pruning.\n\nOverall\nThe compression results seem strong in comparison to past work, but marginal in comparison to the simple baselines. The feature map visualizations were not compelling, and may require clarification.\n\nComments\n\"the deeper architecture also become wider\" -- I'm not sure what this means.\n\n\"the units in the network (both convolutional filters and nodes in fully connected layers) are not equally important when it comes to performing an inference task.\" -- Morcos et al., 2018 seems relevant https://openreview.net/pdf?id=r1iuQjxCZ.\n\n\"We visualize the most significant features which significantly show the significance of repeated and complementary features\" -- I didn't quite understand this.\n\nTypos\ngaining insight what the CNN -> gaining insight about what the CNN\nfilter rankingse -> filter rankings\nin the the case\non the other and\n"}