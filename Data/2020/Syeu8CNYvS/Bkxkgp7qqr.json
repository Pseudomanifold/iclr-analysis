{"rating": "3: Weak Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This is an interesting paper that proposes the use of few shot regression to predict complicated experimental measurements such as protein-ligand binding affinity from very small, noisy real-world datasets. It is great that the authors make the effort to apply their approach to these important questions in drug-discovery. However, the paper as currently written is difficult to follow, and in particular it is hard to distinguish between places where existing methods are combined from novel contributions made by this paper. It would be helpful if the authors could explicitly delineate the novel contributions that they make. Moreover, there is a large body of work in the drug discovery literature that uses sparse experimental data on the interactions of multiple target proteins and multiple ligands to build models that predict the outcome of biological assays for held out protein targets, where this problem is known as drug-target interaction prediction, but these papers are not referenced in this work (e.g. reviewed in Chen et al. Molecules 23(9):1-15, 2018, Ezzat et al. 2017, 2018, 2019). \n\nIn addition, it is hard to understand the results of the experiments that the authors carry out in this paper using data from BindingDB and PubChem. I don't understand the scaling that is applied to the MSE metric for the binding or antibacterial datasets. Why are the reported MSEs so low for all the methods? What does this metric mean? If the targets are first log2-scaled, then scaled linearly, then how different are they after this process? Given the tiny amount of data available, it seems surprising to me that the MSE is so low. From the brief description given, these problems appear significantly harder than the artificial Sinusoids task, yet the reported MSEs are orders of magnitude smaller. How is molecule similarity measured in Figure 2c? It would be useful for the authors to visualize performance for the Binding and Antibacterial tasks - for example how different are the different protein targets? What are the molecular ligand structures in the train and test set in each case - could the authors provide some examples? Using random splits into train and test likely means that some test data points are very close to train data points - can the authors stratify their analysis to provide some insight into the performance beyond the average MSE? \n\nOverall this paper makes a potentially interesting contribution, but it is not well situated within the drug discovery literature, and the results are not explained in enough detail to be understandable by experts in the drug discovery field. \n"}