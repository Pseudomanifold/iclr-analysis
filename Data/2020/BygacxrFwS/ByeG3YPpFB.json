{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper proposes a fractional graph convolutional networks for semi-supervised learning. The proposed method used a classification function of a fractional graph semi-supervised learning (GSSL) [De Nigris et al., 2017] as a graph filter. In addition, the authors adopt a parallel system and weighted combination of max and average pool. Experimental results show that the proposed method (FGCN) shows the best accuracy compared to other recent graph-based neural networks for all datasets except one.\n\nThe key approach of the proposed method is to apply a classification function (equation (3)) obtained by solving a GSSL problem to graph convolutional networks. However, this idea is too incremental and applying the classification function to graph filter is very trivial. This works also combines the fractional GSSL with a parallel system and weighted pool. But, it is not clear which contribution actually improves the results. Moreover, the intuition of the fractional approach is not clear too, e.g., how the optimization (equation (2)) is derived?, and some explanations are unnatural to demonstrate the methodology, e.g., equation (4). For these reasons, this paper is under the bar of acceptance.\n\nMain concerns:\n1. What is the intuition of the optimization of GSSL? How is it obtained? And among all fractional methods (e.g., SL, NL, and PR), which one doe achieve the best performance?\n\n2. The FGS filter in equation (7) is the sum of infinite terms. However, in practical, it is impossible to compute the infinite terms. Does this approximate the sum of finite terms? If does, what is the number of truncation?\n\n3. The authors mention that they establish a theoretical guarantee of the parallel system. But, I could not find any theoretical results. It would be better to include the analysis in the paper.\n\n\nMinor concerns:\n1. In page 3, please edit \u201cforulation\u201d -> \u201cformulation\u201d\n2. In equation (8), I think \u201cX+\\alpha \\tilde{L} X\u201d should change to \u201c\\tilde{L} X\u201d\n"}