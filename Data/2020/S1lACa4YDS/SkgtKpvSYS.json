{"rating": "3: Weak Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper proposes to use a meta-learning approach to learn the divergence used in variational inference and initial variational parameters. It considers two families of learnable divergences, including the alpha-divergence and f-divergence, and proposes two double loop algorithms. In both algorithms, the inner loop adjusts the variational parameters for a specific variational inference task. The outer loop adjusts the parameters in the divergence (and perhaps an initial variational parameter for all tasks) in terms of a human-designed meta-loss. Proposition 1 (following Wang et al. 2018a) shows that the gradients with respect to the meta-parameters in the f-divergence can be obtained using f''. This makes it convenient to parameterize f'' by neural networks to implicitly model f.\n\nThe experiments show that the proposed method can outperform a Bayesian optimization (BO) baseline if the meta-loss is the metric of interest in the MoG example. For the regression and recommendation system examples, it compares with a VB baseline and a p-VAE baseline and shows better results.\n\nAs for the significance of the paper, I have the following issues:\n\n1. To apply the proposed method, we need to have a family of tasks that shares similarity at hand, which seems to be restricted. For instance, the first two examples are synthesized by hand. The recommendation system example is from real life but also crafted by splitting groups by age. If we just use all of the data by a p-VAE and fine-tune the hyperparameters a little bit (meta-learning needs more time than a p-VAE in a single configuration), can we obtain better results? If so, the last example is not appealing.\n\n2. To apply the proposed method, we need to have some knowledge about our preference in the evaluation and encode that knowledge into the meta-loss. In the first example, the comparison with BO in the alpha=.5 case is unfair because Meta-D uses this knowledge as the meta-loss while BO does not leverage such information. Besides, if we already know the preferred divergence, it is not necessary to learn that divergence. For the other settings where Meta-D does not leverage any knowledge about the evaluation preference, it lacks stronger baselines such as BO.\n\n3. The idea is straightforward and the most challenging part of how to model a convex function by a neural network is solved by existing work.\n\nBased on these issues, I think the contribution of the paper is not sufficient and I tend to reject the paper. Also, note that the paper length extends 8 pages.\n\nThe motivation should be strengthened and the experiments should be more precise to improve the paper. "}