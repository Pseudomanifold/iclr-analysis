{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "title": "Official Blind Review #4", "review": "This paper proposes a method to create adversarial perturbations whose target labels are similar to their ground truth. The target labels are selected using an existing perceptual similarity measure for images.  Perturbations are generated using a DeepFool-like algorithm. Human evaluation supports that the pair of the generated images and target labels are more natural to humans than prior attack algorithms.\n\nThis paper should be rejected due to the lack of motivation to create adversarial examples less detectable by humans automatically. Attackers can manually select target labels and apply targeted attacks. In the target label selection, attackers can choose less detectable labels if necessary. It is encouraged to provide some applications where attackers want to create less detectable adversarial examples in label space without manually assigning target labels.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}