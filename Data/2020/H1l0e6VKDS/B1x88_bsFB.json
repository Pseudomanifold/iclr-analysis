{"rating": "3: Weak Reject", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "The submission is proposing an importance weighting based transfer learning algorithm in which the importance weights are learned using reinforcement learning. The reward function used in the work is the evaluation accuracy. Moreover, the learned parameters are class-based importance weights.\n\n* Novelty *: The paper is somewhat novel. The idea of re-weighting source dataset for a better transfer has been known, and used in the literature of domain adaptation well over a decade (eg. Daume&Marcu JAIR 2006). The main contribution of the paper is learning these weights using reinforcement learning. However, a similar approach of learning to re-weight examples using validation rewards has been published by (Ren et al, ICML 2018). Hence, only novel contribution is extending these meta-learning the weights idea into transfer learning setting. In other words, submission combines existing ideas in a sensible way. This is definitely interesting. On the other hand, it is also important to note that the novelty is very-limited. \n\n* Experimental Setup *: Authors perform very extensive collection of experiments. Unfortunately, the results are neither conclusive nor complete due to following issues:\n\n1)  It is a widely known fact that reinforcement learning algorithms have huge variance. Especially, the REINFORCE method has no internal variance reduction mechanism. Considering this potential very high variance, all tables and figures need sensitivity analysis. Authors state that the experiments are run with 3 random seeds. Not reporting variances and min/max values of obtained results is clearly unacceptable. Considering the fact that all of the margins are very low, I do not find any of the results conclusive without a sensitivity analysis. More importantly, a separate sensitivity analysis to the hyper-parameters would also be very beneficial since RL is typically very hyper-parameter dependent. \n\n2) Baselines are incomplete. The paper is performing various experiments on both transfer learning and few-shot learning. The experiments do not include any few-shot learning baselines. Instead, it only compares with fine-tuning. Hence, the conclusion stated in the paper \"...The results show that L2TL can yield significant improvements in real-world tasks where the number of training examples are limited...\" is not really warranted. Transfer learning experiments are also missing various baselines. A simple baseline would be metric learning as demonstrated by Scott et al in NeurIPS 2018 (Adapted Deep Embeddings: A Synthesis of Methods for k-Shot Inductive Transfer Learning). They show that fine-tuned metric learning is a strong transfer learning baseline. Comparing only with basic fine-tuning is definitely incomplete empirical design.\n\n* Is RL really needed? * To me, using RL for learning the weights is the real contribution of the paper. However, it is not really evaluated. There are various ways to pose this meta-learning problem and RL is only one of the ways. There are various existing methods which the paper can compare with in order to justify the RL decision. A comparison with (Ren et al., ICML 2018) is the most obvious one and can be applied in a straight-forward manner. One can replace the validation set (which is used for meta-training) with the target validation set and simply apply their method. Similarly, (Deep Bilevel Learning by Jenni et al, ECCV 2018) can be applied in a similar fashion.\n\n"}