{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper considers the meta-learning in the task un-segmented setting and apply bayesian online change point detection with meta-learning. The task un-segmented is claimed to exist in real applications and the paper explains the idea in a clear way. \n\nMy major concerns and questions are the following:\n\n1) In Eq(4), it requires a computation of normalization constant that needs to sum over support of r_t. The support gets larger and larger with the length of sequence increases over time. Does this method scale well with long sequence?\n\n2) The part I feel most confused are the experiments.  The paper tries to solve a problem in the task un-segmented setting, but why there is no such setting in experiments that the meta-training set cannot be segmented to different tasks?\n\n3) The Figure 1 is hard to read. What do the red and green points in the left panel mean? The hazard rate is not defined before the experiment which makes Figure 3 also hard to understand. \n\n4) What is the meta-learning algorithm used in the experiements, MAML, NP or RNN-based methods?  It claims MOCA can be used with any meta-learning algorithms and how does it show in experiments?\n\n5) In Rainbow MNIST, why in high hazard rates, all models perform comparable to \u201ctrain on everything\u201d? Does it mean meta-learning does not work in this configuration and why? Does \u201ctrain on everything\u201d includes fine-tuning on the meta-test training set?\n\n6) In Mini-IMAGENET, what does it mean by \"we associate each class with a semantic label that is consistent between tasks\u201d? Why it needs to form \u201csuper-class\u201d? \n\nI think the proposed method can be useful in the task un-segmented setting. But before the above-mention questions are solved and the experimental section gets more clear, I will give a conservative rating. \n"}