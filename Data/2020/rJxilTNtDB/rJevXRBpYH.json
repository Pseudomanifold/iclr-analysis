{"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "~The authors propose a modification to the attention mechanism to understand the importance of molecular moieties on DFT calculations.~\n\nTo me, it is unclear what the inverse attention mechanism is truly capturing. How does the importance feature correspond to the predicted DFT value? Does the sum of the importances correspond to the predicted DFT value? Can I compare DFTs across different molecules? What is the distribution of importances look like across a given molecule?\n\nGenerally, is there any bias for the valency of the atom and the importance?\n\nFrom \u201cStep 3\u201d on page 5, which layer from the graph neural network do to take the importance features from? Are they aggregated across layers at some point?\n\nFor Section 4.4, please show a plot relating atomic importance to whatever metric you are comparing to.\n\nIn Figures 7 and 8, the selected submolecules are not the same as those in the larger structure. You have added hydrogens and removed double bonds that were present. Please just highlight the molecule as you did in Figures 4-6.\n\nFor section 4.5, I\u2019m not sure what I\u2019m looking for at all for the qualitative analysis, and I have no idea if your figures are representative of the data.\n\nThere are much easier, simpler ways to determine the importance of molecular moieties on predicted outcome WITHOUT using a graph. Please compare to making a fixed length vector via fragments and performing regression or using a random forest. How does your model compare? What about an attention mechanism directly on the SMILES itself?\n\nIt seems like it is hard to get \u201cground-truth\u201d data to compare to. Does your dataset have molecules that differ by only one, or a few, atoms? If so, how do the importance features compare between those molecules compared to the output prediction?\n\nHow well does your method work out of distribution? What if molecules are held out by Tanimoto distance?\n\nFinally, this work should not be limited in scope to DFT calculations. Determining the importance of features in a graph is of importance in a wide variety of fields, including social networks and pharmaceutical applications.\n"}