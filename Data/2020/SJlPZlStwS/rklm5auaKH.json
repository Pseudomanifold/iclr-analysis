{"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper aims at improving the robustness of CNN models for image and edge detection. They introduce a new edge detection approach (Robust Canny) which applies gradient thresholding to perform noise reduction on adversarial images. They also propose EdgeGANRob which is a variation of the previously proposed model (EdgeNetRob). Specifically, they train a GANS model following the work pix2pix to reconstruct the original content of the image which is then used to fill in the edges detected by EdgeGANRob. They finally evaluate their model on Fashion MNIST and CelebA, and show that it is more robust to different sources of image attacks like adversarial examples, distribution shifting, and backdoor attacks (inserting watermark patterns in the original image).\n\nAlthough the paper has some interesting contributions, I am still not convinced that the experimental results support the claims made in the paper:\n\nLooking at Table 3, it seems like EdgeGANRob is doing worse than EdgeNetRob specially under RadialKernel settings (for Fashion MNIST). CelebA has the same story: PAR and EdgeNetRob are outperforming others in some cases. A discussion explaining why these failures happen is missing from the paper. It does make sense to me that performance degrades under huge shifts in color since EdgeGANRob depends on the content of the image as well as the edges and shape.\n\nIn Table 4, although EdgeGANRob is doing great at detecting poisoned images, it comes at a cost of 4 to 5 percent drop in clean accuracy. An analysis of the results an understanding of what images EdgeGANRob is mispredicting compared to the Spectral Signature method would be helpful.\n\nOne of the key ideas of this work lies in untangling image content from its structure. Although authors make several references to previous works using edge features as a means of representing the structure, there is more to an image's style than just boundaries indicating sharp transitions in color (as shown in several works on style transfer learning such as https://arxiv.org/pdf/1705.04058.pdf). I'm curious to know if authors have done (or planning to do) any work using more features in their classification before inpainting them with texture information.\n\nOverall I like the work and think it has some potential to improve if the above concerns are addressed.\n\n\nMinor edit:\nIn the introduction on page 2, the line \"Using Robust Canny is able to EdgeNetRob dramatically improve the robustness of EdgeGANRob.\" should be changed to something like \"Using Robust Canny dramatically improves the robustness of EdgeGANRob.\"\n "}