{"experience_assessment": "I have read many papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper proposes to train a classifier on top of edge detection (and, optionally, GAN-based texture filling-in) and claims to achieve robustness to adversarial examples, domain shifts and backdoor attacks using this approach.\n\nStrengths:\n+ The rationale to make nets rely more on shape features is justified\n+ The approach is relatively straightforward and easy to follow\n\nWeaknesses:\n- Solid tests for adversarial robustness are missing\n- Thresholding in the \"robust\" Canny seems to perform gradient masking\n- Use of GAN after edge detection is questionable (data processing inequality)\n\nDetailed comments:\n\n1.) My main concern with the paper is that \u2013 like many other papers claiming adversarial robustness \u2013 it does not perform a solid evaluation using a range of strong attacks. Specifically, the thresholding procedure in the \"robust\" Canny algorithm effectively performs gradient masking, as it sets the gradient to zero wherever the Canny operator is below threshold on the unperturbed image. Thus, gradient-based attacks like the ones used by the authors are not effective. Such manipulation, however, does not imply robustness! At the very least, the authors have to apply decision-based attacks like the boundary attack [1], which is trivial to apply [2].\n\n2.) It's not clear to me what purpose the GAN-based texture inpainting is meant to serve. If the GAN can learn to fill in textures that help discriminating classes, then the classifier should be able to use the same features in the edge image that the GAN uses (this statement follows from the data processing inequality).\n\n\n[1] Brendel, Rauber, Bethge, ICLR 2018: https://arxiv.org/abs/1712.04248\n[2] https://github.com/bethgelab/foolbox"}