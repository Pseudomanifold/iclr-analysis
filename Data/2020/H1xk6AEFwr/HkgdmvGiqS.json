{"rating": "1: Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "Based on the observation that encoder-decoder models can generate pathological output (e.g., reproduce noisy training data, repeated statements, contradictory statements, filler statements) and are prone to adversarial attacks (e.g., Wallace, et al., 2019], the authors propose curating clusters of prepared statements and directly classifying into this \u2018response class\u2019 space using a ULMFit [Howard & Ruder, 2018] like model. The steps to generating clusters is (1) k(=10) nearest neighbor based on standard (non-contextualized) embeddings to filter pairwise matchings, (2) generation of a similarity matrix of candidate responses using pre-trained BERT, (3) run agglomerative clustering up to a (manually determined) threshold, and (4) manual curation of remaining clusters. Using this method, they generated 187 response groups generated in ~3 hours based on 700k rounds of doctor-patient dialogue\u2014 which is then used for training. Evaluation is conducted primarily with a user study of comparing a language-model based decoder (I think AWD-LSTM crossed with [Serban, et al., 2015]) and showing that doctors prefer the \u2018classification-based\u2019 answers to the \u2018decoder-based\u2019 answers when there are differences. Secondly, they compare classification with different input encodings for the classification problem. Finally, they conduct some preliminary experiments to quantify cluster-size tradeoffs wrt accuracy, time, etc.\n\nAt a high-level, the basic premise makes sense \u2014 manual curation of responses, especially in potentially sensitive domains (e.g., medical) can lead to better responses. However, to compare pre-selected sentences to an \u2018pure\u2019 encoder-decoder model is literally the two extremes of this setting and not a nearly complete comparison. In commercial settings, slot-and-frame systems are still widely used where curated utterances are produced modulo slots that could be thought of as delexicaled expressions that are bound with a value during inference. Modern research systems generally don\u2019t rely on a strict encoder-decoder model, but have some notion of state-tracking, knowledge base lookup, and a context-sensitive generation step \u2014 or similar variants that would mitigate some of the decoder issues that motivate this work (e.g., some combination of [Wen, et al., EACL17] (policy network to response decoder), [Wu, et al. ACL19] (for state generator ), and [Lei, et al., ACL18] (wrt to generation). Furthermore, the motivating example of this work (including in the title) was multi-domain and there is no evidence of this work doing multi-domain DST, clustering transferring, etc. Honestly, it isn\u2019t even clear if the method treats the system as a dialogue since it is basically a classifier based on a set of previous utterances \u2014 more in the lines of sequential QA based on the application. Thus, I think the core underpinnings of this work need to be more clearly motivated and contextualized for it to be meaningfully evaluated. The basic idea may have some commercial value, but the basic premise isn\u2019t well-developed enough (or sufficiently contextualized) as a research contribution. Additionally, without releasing a dataset, etc., it would be difficult for others to reproduce this work. Based on these reasons, I recommend rejection in its current form. Below are some additional comments to potentially address as this work is pushed forward.\n\n\u2014 How exactly did the doctors annotate the results. How many doctors? What was the annotator agreement? How were the results presented?\n\u2014 LSTMs can be conceptually generative or discriminative (e.g., https://arxiv.org/abs/1703.01898). The distinction is really that this work is contrasting with a (compositional) language model decoder as opposed to a classifier based decoder (as both are using LM-based encoders). The tradeoff would obviously be sparsity of responses, out-of-vocabulary questions, diversity of responses, etc. All of these aspect should be evaluated.\n\u2014 Neither method has an automatic mechanism to ensure high-quality responses; one is generation and one is classification; thus, just a sparse space of answers as opposed to a structured space dictated by the combinatorics of the language. The responses in the submission are just manually curated. One could think of validation models based on distance from the canned responses that might have suitable advantages.\n\u2014 Once the equivalence class is selected, it wasn\u2019t clear which response is selected. Is there one for the entire equivalence class? Is one selected randomly?\n\u2014 With respect to being able to make changes post-training, this can also be done with slot-and-frame and other copy-augmentation/delexicalization methods.\n\u2014 Ranking models and [Wan & Chen, 2018] are indeed conceptually (and even methodologically) very similar (as the authors are aware). A closer comparison is warranted.\n\u2014 The authors touch on this in the last section, but the tradeoffs between number of clusters, quality of clusters, classification accuracy, etc. is somewhat sensitive. In principle, one could put everything in one class and get perfect \u2018classification\u2019, but would be pretty worthless as a generator. This needs to be further studied to validate the method is viable (even in a single domain).\n\u2014 The idea of using canned responses isn\u2019t entirely new beyond what the authors recognized in the paper (e.g., [Didericksen, et al., Collaboration-based User Simulation for Goal-oriented Dialog Systems, ConvAI NeurIPS WS, 2017] \u2014 even if in a different setting and not clustered)\n\nIn any case, there are some ideas here worth salvaging, but the current study is insufficiently contextualized/contrasted wrt the spectrum of conversational systems, doesn\u2019t really support what the motivation set out to do, doesn\u2019t make a sufficiently convincing case that the recommended approach is viable in practice, and would be difficult to follow-up without public datasets, etc. Finally, I don\u2019t think the scope of potential impact (if well-executed) makes ICLR the ideal venue. In its current state, this work belongs in a dialogue systems workshop where attendees may have interest in more practical settings.\n"}