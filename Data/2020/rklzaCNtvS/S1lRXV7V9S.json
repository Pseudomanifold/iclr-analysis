{"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #4", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This submission claims to adapt and improve on neural semantic encoders for the task of abstractive summarization. The submission:\n- briefly describes the neural semantic encoder (NSE) model (Munkhdalai and Yu, 2017)\n- claims that the dot-product attention mechanism in NSE is too simplistic for the task of summarization because dot-product attention does not capture word-sentence and sentence-sentence correlations, the latter two being important to summarize a document, and suggests utilizing the additive attention mechanism along with the pointer-generator mechanism instead\n- Introduces the \u201chierarchical NSE\u201d model and a self-critical sequence training scheme to optimize for ROUGE\n- Provides empirical results for these models and for other relevant baseline models on the CNN/Daily Mail dataset\n\nAt a high-level, this submission is unpolished, imprecise, lacks technical (both experimental and theoretical) rigor in its description and explanation of its methods, and generally does not have a significant contribution, which is why I believe it should be rejected.\n\nThe primary motivation underlying this submission is strong: modeling long-range dependencies in a document is very critical for abstractive summarization. However, the submission does not make a convincing case for its proposed methods/models, in the context of this motivation and otherwise. The whole premise behind the NSE (according to Munkhdalai and Yu\u2019s paper) is that its variable-sized encoding memory allows it to access the entire input sequence during reading, thus providing for long-range dependencies and helping with tasks like summarization. So the exceptionally low ROUGE scores for plain NSE in Table 2 seemed at odds with the motivation and premise. The authors attribute this very briefly to the dot-product attention mechanism and show empirically that changing it to an additive attention mechanism leads to a significant increase in ROUGE.\n\nAt an intuitive level, the notion of \u201chighlighting\u201d seems to be congruous to \u201cattending\u201d. The submission (with the title Read, Highlight and Summarize) seems to be suggesting that they are incongruous and that there is novelty in this notion itself, however there is no clear mathematical description or rigorous explanation of this notion.\n\nThe suggested improvements beyond the standard NSE architecture (augmented with the well-known additive attention and the pointer-generator mechanism) are limited to extending NSE in a \u201chierarchical\u201d fashion and optimizing for ROUGE, both of which have not been described in sufficient detail or clarity for the task at hand. Munkhdalai and Yu evaluated the NSE approach for document sentiment analysis (among other tasks) and for that task, they used two NSEs: one for obtaining sentence representations and another for document representations using sentence representations. This submission\u2019s \u201chierarchical NSE\u201d seems to overlap with Munkhdalai and Yu\u2019s approach for document sentiment analysis, except that the document memory seems to be constructed in a different fashion that is not clearly described.\n\nIn Table 1, Hier-NSE seems to be performing worse than the pointer-generator with coverage loss and only slightly better without coverage loss. Since Hier-NSE contains the pointer-generator mechanism, it seems the Hier-NSE isn\u2019t really adding any non-trivial value. What would be interesting to try out as an exercise is to see if the factoring of lemma and PoS tags described helps significantly improve the pointer-generator with coverage loss.\n\nSome typos:\n- Equation 5 should have m_{r,t}, not m_{t,t}\n- Page 5 right above equation 22 has a Stack Overflow link that has nothing to do with the submission\n\nSuggestions on improving the submission that are here to help, not necessarily part of my decision assessment:\n- Provide dimensions for every non-scalar parameter in the Proposed Models section: while I see dimensions for some parameters, I do not see dimensions for others\n- Use accessible notation that makes it easy to distinguish between a non-scalar parameter and a scalar parameter (boldface non-scalars, use capitalized letters for only matrices/tensors, not scalars or vectors, etc.)\n- Use \\mathbb{R} for depicting the set of real numbers in LaTeX\n"}