{"rating": "3: Weak Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review": "The authors are concerned with improving algorithms that propose sets of\nconcept vectors to help explain the prediction of a pre-trained network on a\nheld-out test examples. The paper examines \"completeness\" (Gilpin et al 2018) of\nthe context vector set---projecting activations on to the concept subspace does\nnot hurt predictive performance---as a desired criteria that was overlooked by\nprevious concept-based explanation methods. They show that PCA on activations\nyields complete concepts under some bijectivity assumption on the final layers\nof the network. They then discuss how to produce a set of concept vectors that\nmaximize completeness under sparsity priors when supervised or unsupervised\nclusters of candidate concepts are given. They also show that SHAP values can be\napplied to compute the relative importance of each concept to the overall\ncompleteness score.\n\nI find the focus of this research---on the completeness of concept\nexplanations---to be quite interesting and relevant to the interpretable machine\nlearning literature. The authors have approached this question from several\ndirections and have demonstrated a fluency with the existing literature and its\nlimitations. However, I think they could do much more to motivate their\nproposals by convincing the reader that (a) existing concept-based explanations\nare not complete in practice and (b) PCA in the activation space is not\nsufficient as a baseline method for proposing concepts. In the current revision,\nthe paper lacks coherency---the proposals in each section do not seem connected\nto one another---and it is difficult to assess from the experiments whether the\nproposed algorithms address a known problem in existing methods.\n\nFor example, the propositions in S2 rely on the ability of the post-concept\nfunction h to bijectively map between the Frobenius norm in the concept space to\nthe loss function in the logit space. Therefore it is logical to ask whether\nconcepts can be found directly via PCA on the concept space. The authors\nspeculate that this bijectivity of h is unlikely to hold in practice, and \ntherefore PCA would be insufficient. However I would have been more convinced by\nsome empirical evidence for this claim. What about the case where f is bijective\n(i.e. an invertible neural network); is PCA on the activation space sufficient\nto produce complete and useful concepts in\nthis case?\n\nI also wondered whether there is a corner case where the functional form of h\ncauses the components that capture the most variance in the activation space\n(i.e. top PCA vectors) to capture the least variance in the logits space. This\nseems plausible if h is an unconstrained linear mapping or non-linear mapping;\nthink about a simple whitening function that scales principal components in\ninverse proportion to their eigenvalue. In this case we may be better off using\nthe bottom PCA vectors than the top ones. Admittedly this is only thought\nexperiment, but is there any way for the authors to show that this does not happen\nin practice by characterizing the h functions we see for neural networks applied\nto application areas of interest: sentiment analysis and image classification? \n\nThe synthetic experiments seem useful to the overall story (although the data\ngenerating process is somewhat hard to parse at first), and I like that\nthere are many baseline methods in this study. It seems that PCA is neither\ncomplete nor aligned in this simple setting. It also seems that TCAV is not\ncomplete. Unfortunately the authors fail to show that similar trends hold in the\nnon-synthetic setting. My feeling is that a more comprehensive and thorough\nexperimental study---starting from a characterization of a problem with existing\nmethods---would strengthen the paper considerably.\n\n\nSome superficial comments:\nS1\n* \"This has thus lead to an increasing interest...\" It would be good to add\n  references to this claim.\n* \"Of course such degeneracy assumptions likely not hold\" -> \"Of course such\n  degeneracy assumptions likely do not hold\" -> \n* \"...which can explain how much does each concept contribute to the\n  completeness score\" -> \"...which accounts for the contribution of each concept\n  to the completeness score...\"\nS2\n* \"...that capture how complete is a given set of given concepts\" -> \"...that\n  capture the completeness of a given set of given concepts\"\n* \"...concepts hold sufficient info for prediction\" -> \"...concepts hold\n  sufficient information for prediction\"\n* \"...prediction scores for examples in class A won't be much different from\n  examples in class A\" -> \"...prediction scores for examples in class A won't be\n  much different from other examples in class A\"?\nS3\n* \"...each concept direction is semantically meaningful to human\" -> \"...each\n  concept direction is semantically meaningful to humans\" \nS5\n* \"y1 = ~...\" could you make a note that \"~\" denotes logical not? \n\n"}