{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #4", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The authors propose a new artificial neural network architecture that is derived from a human visual model (M\u00e9ly et al., 2018). The original (human vision) model can explain some of the human visual illusions, specifically contextual ones. While the adaptation from this human visual model to artificial neural networks was previously done by (Linsley et. al., 2018a), in this paper the authors extend (Linsley et. al., 2018a) to better capture some of the constraints in the human visual model, and also to add a formulation that can also model top-down connections (across layers).\nThe goal of replicating the structure of the visual human model in artificial neural networks is to improve the machine vision by mimicking the human vision. The results in this paper on contour detection show an improvement regarding sample efficiency with respect to other state of the art methods. Also, the authors show that the artificial model also suffers from visual illusions, and when these are explicitly corrected, its performance drops. This shows that these illusions are a byproduct of the system improving its visual abilities.\n\nStrengths:\n1 - Well motivated by cognitive science theory and modeling of the human visual system. The artificial modeling is not just inspired by the human visual system, but derived from an actual human system, replicating it. The paper presents an extension of (Linsley et. al., 2018a), and both the base model and the extension are biologically motivated. The paper also shows that this extension is important to get good results.\n2 - Clear structure and ideas. Clearly explained, well written, reasonable ablations and transparent presentation of results, assumptions, limitations, contributions and experiments.\n3 - Very good results in contour detection for a very-low data regime, which proves the strength of the model inductive bias. The results show both better performance and good mimicking of the human vision behavior. \n\nWeaknesses\n1 \u2013 Limited experimental results. \n- Is contour detection the only task in which surround suppression helps?\n- Lack of experiments in larger contour detection datasets (like Semantic Border Dataset or Cityscapes). Does the model improve accuracy in those, or it just improves sample efficiency in (extremely) small (subsets of) datasets? \n- The only results are regarding sample efficiency. Not accuracy, or number of parameters, or running time. \n2 \u2013 Weak results supporting the claim that the computer vision model mimics the human visual illusions. The authors show an elegant experiment where they explicitly correct the visual illusion and obtain worse results, backing the presented hypothesis. However, the ablation experiments show that the same model without the top-down connections does not present the same results. One would expect that removing a part that is not in the initial formulation from (M\u00e9ly et al., 2018) should not affect in the visual illusion experiments. Both the explanation at the end of Section 2 and at the sixth paragraph of Section 3 seem to indicate that the _non-negativity_ is the important factor to explain contextual illusions, not the top-down formulation. Can the authors explain whether or not the top-down formulation is a necessary part to model (M\u00e9ly et al., 2018)? If this is not the case (and top-down is not necessary), the current results would not support the idea that implementing (M\u00e9ly et al., 2018) in artificial neural networks produces visual illusions in the computer. Also, did the authors perform the visual illusion experiment without the non-negativity? Is it a necessary requisite for the visual illusions to appear? As a positive remark regarding weakness #2, the results still show that the model that performs best is the one having visual illusions. \n3 \u2013 Related to weaknesses #1 and #2, did the authors perform any experiment on other contextual illusions like the ones explained in (M\u00e9ly et al., 2018), namely \u201ccolor induction\u201d or \u201cenhanced color shifts\u201d? Consistent findings across different visual illusions would reinforce the presented hypothesis.\n\nRating:\n- Weak reject \nOverall it is a clear and well-structured paper, with interesting biologically derived architectures (strength #1), but as it stands the experimental results either do not completely support the claims of the paper (weakness #2) or are limited in scope (weakness #1). If the authors can address my concerns, mostly motivating the importance of the experiments for weakness #1, and providing an explanation (possibly correcting me) for weakness #2, I will be happy to increase my rating. \n\nAdditional comments:\n- While it may not be a \"bug\", arguing that the visual illusions are a \"feature\" (both in machine and human visual systems) is probably too much of a claim. At some point the authors refer to it as a \"byproduct\" of the of the system improving its visual abilities, which I consider a more suitable word. \n- For an audience outside of neuroscience, a brief explanation of the concepts \u201csuppression\u201d and \u201cfacilitation\u201d, which are very important in the paper, would be convenient.\n- Are 8 time-steps sufficient for reaching a steady state? Is the steady state checked in any way?\n"}