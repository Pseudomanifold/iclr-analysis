{"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The presented paper introduces a novel neural network architecture to explore the question whether visual illusions are corner cases of the human visual system, or whether they represent limitations of perception. The developed recurrent network architecture aims at being more sample efficient than existing methods. The findings discussed in the paper suggest that visual illusions are a byproduct of neural circuits that help to increase the robustness of the human visual system, which in turn suggests that neural networks for processing visual data could benefit from integrating circuits in similar ways. While existing work predominantly aims at explaining whether visual illusions are features or artifacts of the visual system, this work focuses on finding a computational solution to support the hypothesis that visual illusions are features. In particular, the contributions of this work are: (1) novel neural network architecture, called \\gamma-networks, which is derived from the work of [Meley et al. 2018] and (2) that the proposed architecture is more sample efficient than SOTA convolutional architectures on contour detection tasks. \n\nOverall, I think this is an interesting paper that can be accepted for publication. However, I am not an expert in this field and am excited to see what the other reviewers think. While the overall contribution of this work appears rather narrow, exploring traits of the human visual system to leverage them in the context of convolutional neural networks for segmentation tasks appears interesting and has the potential to simulate further research in this field. Furthermore, the results are promising and show that the introduced approach is on par with SOTA work in the field. On the downside, many sections of the paper appear unnecessarily cryptic and lack important details. Other sections rely on explanations in the appendix or just refer to related work instead of providing context. This gives me the impression that this work might be better suited for a journal instead of trying to discuss all necessary details into the page limits of ICLR (the paper is also two pages over the common page count). Moreover the topic this paper addresses might be a better fit for a venue that specifically focuses on neuroscience (similar as Mely et al. 2018).   \n\n\nSpecific comments: \n\n- Abstract and introduction can be improved by more carefully introducing visual illusions and how the effects of specific traits of the human visual system lead to visual illusions. In its current form abstract and introduction are quite difficult to follow for readers that are less well-versed in neurscience. \n- While the main contributions are listed at the end of the introduction, they are not clearly described. It is not clear why it is beneficial that the network generates \"an orientation-tilt illusion after it is optimized for contour detection\". More details need to be provided here. \n- The term \"hyper columns\" is not properly introduced and needs better motivation, similarly for terms like \"suppression\" and \"facilitation\", \"circuit integration\". Overall it seems the methods section relies too much on the related work for explaining concepts and terminology, which makes this section quite difficult to follow. This needs to be improved. \n- It is not clear why it is beneficial to enforce non-negativity. The provided explanation is unclear: \"The non-negativity constraints we introduce into the fGRU are necessary to guarantee separate stages of suppression followed by facilitation that can implement asymmetric contextual interactions\", which is again because terms were not properly introduced. The term \"fGRU\" is introduced after it is used.\n- Not providing training time with the argument that it is outside the scope of this work seems like a flawed argument and is uncommon practice.  \n- The datasets listed in Section 4.1. are introduced without references. \n- The term \"F1 ODS\" is not properly introduced. \n- Figure 3 (a): the term \"Ding\" is not introduced. Does this refer to [Ding et al. 2016]?\n- The references show many inconsistencies (abbreviated vs. long conference names, etc.). This should be fixed for the final version of this work. \n- No limitations are discussed. What are the edge cases in which the method does not perform well?\n\n\nTypos: \nSec 6: hihg-level"}