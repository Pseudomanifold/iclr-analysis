{"rating": "8: Accept", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I did not assess the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "The aim of this paper is to suggest randomized initializations for the various weights of a recurrent neural network (GRUs and various LSTMs are covered), such that training these networks gets to a successful start, when the model is trained on long sequences. Instead of being heuristic, their approach follows first principles of analyzing signal propagation through time, using ideas from statistical thermodynamics (mean field approximations). Some experiments, on toy datasets, validate their approach.\n\nI am quite intrigued by this paper. It is using interesting theory, shapes it to a practically highly relevant and difficult applied problem, and in the end comes up with a computable criterion of how to choose hyperparameters (means and variances of Gaussians to sample initial weights from). While the results in practice are still not too convincing, I am strongly in favour of giving this approach the benefit of doubt, as it could lead to practically very useful downstream work.\n\nThe main direction of improvement for this paper (given that experiments are what they are -- somewhat limited to toy situations right now) is to better explain the methodology to researchers not familiar with mean field methods. Most importantly, it is not explained in the main text how hyperparameters are really chosen in the end. Looking at Appendix E, I find some pretty basic choices, and no other alternatives considered. It is not explained why these choices satisfy the theory, why they'd be the only ones, etc. This creates a disconnect between the very nice (and seemingly useful) theory and its implications (they are not really well spelled out).\n\nHere is what I understood (and I am not specifically an expert on stat mech). The authors assume that the dimension of latent states (N) grows large. They assume that weights are sampled independently, and identical distributed in groups k (different cell types, weight vs bias), and that inputs are correlated with each other in each dimension. Based on these assumption, they follow Gaussians statistics through a number of time steps. In the limit, one gets a deterministic dynamical system, and as t -> infty, this may converge to a fixed point. In a very nice argument (which they could explain better), they state that such rapid convergence is bad news, because then information cannot spread across long time scales, so one has to find hyperparameters for which the system behaves \"critically\". A second arguments tries to keep gradient sizes (under MF assumptions) of O(1), so neither -> 0, not -> infty, which is again some \"critical\" range. Under their assumption, these critical conditions can be computed depending on the hyperparameters.\n\nUnfortunately, this is where the paper somewhat stops, it does not give specific methods for finding hyperpars that satisfy the criteria, at least not in the sense of characterising the whole space of such hyperpars (instead, in Appendix E, they just state some few settings that do). As a direction for future work, this would be very important. Another side question is whether for what the authors call \"trainability\", the only point that matters is whether for the initial weights, signals can spread and gradients are O(1). It is certainly necessary, I see that.\n\nDetailed comments:\n- Please fix Table 1, the expressions seem broken. What does \"r2\" mean in the GRU column?\n- At least for me, (1a) to (1c) really was too short. At least in the Appendix, please do explain how this gives GRU and LSTM\n- Please explain the untied weight assumption somewhere. s^t is a map of s^(t-1) and W_k, so how can W_k be independent\n   of all s^t? What are you really assuming here?\n- It took some repeated reading until I understood why the expressions in (2a) to (4b) do not depend on i, j, a, b (except\n  whether a = b or a != b). Explain that properly\n- The core of the whole approach seems to be first half of page 5. This seems like a very nice argument, but hard to understand. Try making it more crisp. I kind of get the rough idea why fast convergence over t would be bad, but would total divergence over t not also be bad?\n- In (12a-c), do you mean \"equal\" or \"approximately equal\"?\n- In 4.4: \"This motivates the general form of the initializations used in the experiments\": You have to make this more explicit. Why are your choices the only ones? Could there not be other choices satisfying (12a-c) approx, and be better?\n- Value of Sigma_z = 1: This seems odd to me, then your covariances are degenerate (rank 1 instead of 2). Please explain\n- Standard LSTM harder than GRU or peephole LSTM: Again, this sounds real interesting, but I did not get it from the explanation\n- I did not understand Figure 2. How are Theta_0, Theta_1 chosen?\n- As said above, the experiments are interesting, but somewhat artificial. Please do at least comment on real-world applications, and whether (and how) the ideas here would apply\n- Discussion: \"there is no clear principled way...\": Well, but practitioners need something. I'd disagree, at least one could attempt to navigate this space by global optimization techniques...\n"}