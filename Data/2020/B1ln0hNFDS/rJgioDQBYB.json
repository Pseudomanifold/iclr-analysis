{"rating": "6: Weak Accept", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I did not assess the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper proposes an unsupervised method to disentangle and quantify the knowledge of object parts used for inference by CNN. In order to achieve that, they propose to introduce an explainer network, which learns to quantitatively disentangle object-part features from intermediate layers and use the part features to reconstruct CNN features. Their main contribution is providing a simple yet effective strategy to diagnose pre-trained neural networks, which trains an extra explain network without any annotations of object parts or textures for supervision. They perform both qualitative and quantitative experiments to conclude the superior performance of the proposed strategy in boosting feature interpretability. \n\nOverall, the method proposed in this paper could make general and practical contribution, with several caveat for some clarifications. Given some responses, the work would appear more complete, and I would be willing to increase the score.\n\n1. It would have been more persuasive if comparisons on interpretability with other methods were more explicitly shown.\n\nMinor Comments:\nPage 1, In the second Line on the second paragraph in Introduction part, there seems to be a typo of \u201cobject objects\u201d, which in my understanding should be \u201cobject parts\u201d.\n"}