{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #4", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "In this paper, the authors propose to disentangle the object-information from a pre-trained CNNs for vision tasks. An explainer is introduced to extract the object-related information from the noisy feature maps of a CNN and the disentangling can be achieved in an unsupervised manner. The proposed method is original, at least to my limited knowledge of related work.\n\nHowever, I have several concerns about this paper.\n1.\tThe most important one is about novelty. From my understanding, the proposed method just applies the well-developed interpretable CNN (Zhang et al., 2018c) in the distillation stage. It enables the proposed method uses a much smaller explainer to extract the object-related information from the feature map without affecting the performance. The difference between the proposed method and interpretable CNN should be verified clearly.\n2.\tThe proposed method lack of motivation. In the second paragraph of Sec. 1, the authors claim that human annotation may contain subjective bias without giving an accurate definition of interpretability. A more detailed definition and illustration of the subjective bias are helpful to verify the authors\u2019 claim. Besides, in Table 1, the comparison is not clear, making its priority compared to existing methods not clearly presented. The argument like \u201chigh discrimination power\u201d and \u201cpotential broad applicability\u201d are vague and lack of support.\n3.\tThe experimental results are not convincing. First, the proposed method is only evaluated on the classification tasks, and the performance on larger datasets such as ImageNet is not presented. Since the proposed method is used to interpret pre-trained CNNs, it is necessary to evaluate the proposed method on larger datasets. Besides, it would be great that the proposed method can be applied to other tasks, such as detection and segmentation. Conducting the proposed method on multiple backbones does not indicate that this method can generalize to other tasks. Finally, the proposed method is not fairly compared. I think the interpretable CNN is an important baseline of this paper and it should be compared directly.\n4.\tThe authors claim that \u201cPeople usually have to trade-off between the network interpretability and the performance in real applications\u201d in Sec 1 as a drawback of previous methods. However, the proposed method also makes a trade-off as indicated in Sec. 3.3. The authors should make the paper logically consistent.\n\nBesides, there are several minor issues about this paper. For example, several arguments in the introduction, such as \u201cbecome a new demand for CNNs\u201d, need further support, such as citations. In Fig. 1, the images used here for different methods are different. The priority of the proposed method is not clear whether it is because the baselines adopt harder examples or the proposed method performs better. Some typos should be addressed, such as the double \u201cequation\u201d in the second paragraph of Sec. 3.3.\n"}