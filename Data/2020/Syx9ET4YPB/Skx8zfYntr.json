{"rating": "3: Weak Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper targets on the evaluation of model robustness on similar video frames. The authors build two carefully labeled video datasets, and extensive experiments are conducted to show that the state-of-the-art classification and detection models are not robust enough when dealing with very similar video frames.  The results are similar to my intuitive feelings.\n\nThe authors propose acc_orig (the average acc) and acc_pmk (which chooses the worse one in nearest 2k frames) to amplify the gap. I personally think acc_pmk is too stringent. I wonder if there is still large gaps if we choose a random frame in the nearest 2k frames.\n\nThe authors have tried fine-tuning and data augmentation techniques to improve the robustness, although the performance is improved, the gap between acc_orig and acc_pmk does not change much.\n\nThe paper has done many work to analyze the robustness of image classification and detection models, however, the results are expected and no effective methods are proposed to improve the results. Overall, the contribution is limited. "}