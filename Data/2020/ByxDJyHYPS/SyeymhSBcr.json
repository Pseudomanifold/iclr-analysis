{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This paper proposes a model that learns to extract a chain of sentences as evidence for answering multi-hop questions. The chains are annotated via heuristics (summarized below). Then they train a model to identify such sentences and then pass a set of chains to a reader model which reasons with them to find the answer.\n\nTreating each sentence as a node, they create a graph by connecting two sentences if they share an entity (as determined by running a tagger). Two sentences also share an edge if they are in the same paragraph. After creating this graph via the above heuristics, they exhaustively traverse the graph to create chains that lead to the answer entity. Finally the chains of shortest length and the one with highest question overlap (computed with Rouge) are preserved and are used as training data for the chain extraction model.\n\nNext, a paragraph is encoded by concatenating it with the question and passing it through BERT. Sentence representations are created by max pooling over the sentence span. After that, they train a pointer network style model that learns to select the sentence conditioned on the previously selected sentence. At test time, a beam of chains are selected. \n\nThey test their method on two datasets (Wikihop and HotpotQA) in a closed domain setting. They achieve favorable results in both outperforming baselines. Ablation studies are also performed showing the efficacy of the chain extraction model. Finally, they perform a small human study where crowd workers label whether the retrieved chains make sense.\n\nStrengths:\n* The paper is written fairly well and the ablations are well done\n\nWeaknesses:\n1. I am a bit concerned if the heuristic method of obtaining chains of reasoning would work in the more realistic open-domain setting of HotpotQA. The graph will be much larger and the number of chains that would be recovered by doing question overlap would be quite high. It is important to test whether the heuristic method would generalize in that setting (such as the more ad-hoc ones such as removing entities that occur more then 5 times). Moreover, it has been shown, that in the distractor (closed-domain) setting, all questions don\u2019t really need multi-hop reasoning and also noted in the paper, the results of beam search often have same sentences. Therefore, I think experimentation on open-domain setting is really important in this case.\n2. I am also not very surprised by the fact that the heuristic based annotation of chains is actually quite effective in this setting. Because, if you think about it, while creating the HotpotQA setting, the data set creates and crowd workers also followed a similar paradigm of finding a bridge entity and asking a question for which the answer is present in the bridge entities document. Therefore, the process of connecting sentences that share the same entities replicate the data collection process which might be a result of the improved performance. The authors should include a discussion regarding the same.\n3. Missing citations: Another way of doing multi-hop retrieval which do not necessarily follow the data generation process is via query reformulation. Two recent work \u2014 Multi-step retriever reader interaction (Das et al., 2019) and Multi-Hop Paragraph Retrieval for Open-Domain Question Answering (Feldman and El-Yaniv, 2019) do something similar. It would be nice to include citations and discussions regarding this approach. Recently Godbole et al 2019 \u2014 (Multi-Step entity centric Information Retrieval for Multi-hop Question Answering) proposed an approach to generate chains but in the more practical open-domain settings. The paper should also cite that work. However, given that this work is very new, I am not penalizing for missing the citation.\n\nOverall, I am a little skeptical about how the method proposed by the paper would generalize to an open-domain setting and I think it is important to include the results for the same."}