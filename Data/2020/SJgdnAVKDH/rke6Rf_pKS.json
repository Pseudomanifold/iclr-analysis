{"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "N/A", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This paper investigates why self-training helps in machine translation and text summarization tasks, identifying that auxiliary noise can amplify the benefits of this process. The paper is well-structured and clearly written, and conducts a fairly thorough analysis of the issue at hand.\n\nComments:\n\n- The authors argue self-training enhances smoothness, but I would like to see this explained mathematically/conceptually in greater detail. It is not immediately clear to me why this would be, particularly in the case of discrete text data.\n\n- Why not evaluate smoothness on the actual MT task instead of just the toy task?\nThe authors could measure the L2 norm between encodings of source sentences for neighboring sentences (eg. based on edit distance or word-movers) vs very different sentences. And then compare the base model vs the one obtained from self-supervised training.\n\n- If the primary beneficial effect of self-supervised training is smoothness as the authors claim, then they should try enforcing smoothness in alternative ways to see if performance improves.  Some options here could be (using dropout in all of them): 1) add your same noise process to the original labeled dataset to create augmented examples, 2) rather than the self-supervised objective, use an auxiliary training objective which says the predictions on each unlabeled datapoint should be similar to the predictions on noised versions of this datapoint, 3) some form of virtual adversarial training [VAT]. In fact, the authors should discuss [VAT] a bit more, as this paper also presents a smoothness-regularizer that is highly useful for semi-supervised learning.\n\n[VAT] Miyato et al. Virtual Adversarial Training: A Regularization Method for Supervised and Semi-Supervised Learning. https://arxiv.org/abs/1704.03976\n\n\n- As the authors write, self-training can be viewed as a form of entropy-regularization. Likewise, the input perturbation+dropout process also seems like it should affect the conditional entropies. Can the authors expound upon this connection a bit further?  Some mathematical analysis would be nice to have here as well.\n\n\n- \"Another way is to treat them separately \u2013 first we train the model on pseudo parallel data S, and then fine-tune it on real data L.\"\n\nThe authors should clarify the overall training process with a more precise explanation. I assume is actually: \n1) train initial model M on (limited) real data L\n2) use M to generate pseudo-targets for unlabeled data in S\n3) train M on this pseudo-dataset S\n4)fine-tune M on real data L\n\nIs this correct? And it should be clarified whether M in step (3) is fine-tuned from the M in step (1) or re-initialized from scratch before training begins (Based on later text, it seems like the latter, but this should be clarified early on).\n\n- Baseline in Figure 1 should be described a bit more clearly.\n\n- Since the BLEU score dropped from 3 to 1.9 when the authors continued training from the baseline model (Sec 3.2), isn't the optimum hypothesis not ruled out?  I don't think the authors should make this claim, and rather state that the initialization does seem to play some role, but does not fully explain the benefits of self-training.  \n\n- \"We use a small LSTM model for 10K, Base Transformer for 100K/640K, and Big Transformer for 3.9M\" \n\nIs this because these are the best performing models on these respective datasets? The authors should explain these decisions.\n\n\n- \"We include quantitative comparison regarding joint training, separate training, and pseudo-parallel data filtering in Appendix B\"\n\nShould clarify here (in main text) that separate training matches the performance of joint training.\n\n- typos: \"joint traing\""}