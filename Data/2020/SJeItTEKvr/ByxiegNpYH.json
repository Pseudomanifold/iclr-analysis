{"experience_assessment": "I have published in this field for several years.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "The paper addresses the problem of multi-label prediction.  It proposes a method that uses a co-embedding of instances and labels into a joint embedding space in a way that related instances and labels fall close by and unrelated ones fall far away.  For this purpose, embeddings from input space and label space to a common space are learned from training data. At the prediction time, KNN to the embedding of the test instance in the co-embedding space is used to predict relevant labels.\nFeaturized (attributed)  labels are potentially considered, which can facilitate incorporating label dependence and generalization over unseen labels.\n\nMain shortcomings:\n- The novelty of the work is limited. Ideas introduced in this work are present and being investigated in literature for a while now, leading to remaining limited contribution for the paper.  Related work on joint embedding, co-embedding, label-embedding, and zero shot learning seem to be neglected totally. For example, the paper lacks awareness of, citation to and comparison with related work such as [1-5].\n- Presentation of the paper can be highly improved. There are several grammatical and writing problems in the paper.\nFormulation can also benefit from  improved presentation. See for example Eq (1).\n- Technical arguments are not all well founded. For example, the scalability claim in the abstract  of the paper seems to refer to \"prediction\" time complexity being linear in the number of \"training\" examples, which is not actually fast.\n\nIn summary, based on the above reasons, I vote for the paper to be strongly rejected.\n\n[1] Akata, Zeynep, et al. \"Label-embedding for image classification.\" IEEE transactions on pattern analysis and machine intelligence 38.7 (2015): 1425-1438.\n[2] Weston, Jason, Samy Bengio, and Nicolas Usunier. \"Wsabie: Scaling up to large vocabulary image annotation.\" Twenty-Second International Joint Conference on Artificial Intelligence. 2011.\n[3] Li, Xin, and Yuhong Guo. \"Bi-directional representation learning for multi-label classification.\" Joint European conference on machine learning and knowledge discovery in databases. Springer, Berlin, Heidelberg, 2014.\n[4] Mirzazadeh, Farzaneh, et al. \"Scalable metric learning for co-embedding.\" Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Springer, Cham, 2015.\n[5] Yeh, Chih-Kuan, et al. \"Learning deep latent space for multi-label classification.\" Thirty-First AAAI Conference on Artificial Intelligence. 2017."}