{"experience_assessment": "I have published in this field for several years.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper introduces a novel method for an adversarial attack named mixup inference (MI).  Most of the work focuses on embedding mixup mechanism in the training phase, but MI uses the mixup in the inference phase. MI method has two main effects for the adversarial attack: one is perturbation shrinkage, and the other one is input transfer because MI can exploit\nthe induced global linearity. The experimental results show that MI can return more reliable predictions under different threat models.\n\nThis paper should be accepted because the proposed method is super simple but effective for defending from adversarial attacks under different threat conditions. This paper is well-written, including theoretical insights on why the MI method works.\n\nThe reviewer has some questions or comments to clarify the paper:\n1) In the explanation of the MI method, the authors assume only the cases where the input data is correctly classified if it is clean, or wrongly classified if it is adversarial. In a realistic situation, the classifier sometimes outputs mislabels. Thus is the discussion in Sec.3 valid if the clean input data misclassified?\n\n2) To predict the category of the input, MI methods must perform inference N times. It is not efficient. Are there any ideas to reduce the number of inferences?\n\n3) MI-Combined seems ad-hoc. It would be better to state its justification by theory.\n\n4) The same idea of mixup was proposed at the same conference (ICLR2018). It should be cited.\nTokozume et al., Learning from Between-class Examples for Deep Sound Recognition. ICLR, 2018."}