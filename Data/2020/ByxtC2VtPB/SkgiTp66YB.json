{"experience_assessment": "I have published in this field for several years.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper proposes a novel use of mixup, which is originally a data augmentation method incorporating two training samples and their corresponding labels. The authors utilize mixup not for training but for inference (MI; Mixup Inference). Experimental results on Cifar 10, and Cifar 100 show that MI can boost the classification performance in combination with interpolated AT (Adversarial  Training) and mixup.\n\nI lean to accept this paper. The proposed method is simple but effective, moreover well-motivated. The experimental results, including several ablation studies, show a high versatility with existing methods.\n\nMy minor concerns are, however, consisting of two points.\n- The authors should repeat the experiments several times and show the averages and standard errors to make the significance clear.\n- Both Cifar 10 and Cifar 100 are relatively small scale datasets. I would like the authors to investigate larger ones."}