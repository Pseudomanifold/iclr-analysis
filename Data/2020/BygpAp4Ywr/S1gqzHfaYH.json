{"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper proposes a new regularization technique called Embedding Regularization to improve the adversarial robustness.  The idea is to use generative adversarial networks (GAN) to perform inference on the latent space by matching the aggregated posterior of the hidden space vector with a prior distribution. The proposed strategy could be combined with adversarial training to achieve state-of-the-art adversarial accuracy on several benchmark datasets. \n\nOverall, I find the idea interesting and the experimental results promising. The following are my detailed comments.\n\na. About the algorithm \nThe idea of incorporating a GAN based model to regularize the representation learning is not completely novel. In [1], a similar approach has been considered for unsupervised learning (auto-encoders).  Besides the omission of reference, a few points about the algorithm need to be clarified :\n\na.1 What is the motivation of using the different of discriminator as loss in line 7 of Algorithm 1?\nIn the standard GAN literature, the discriminator loss is usually in the form log(D(z_{true})) + log (1 - D(z_{generated})). Is there any intuition to prefer the current formulation comparing to the this standard formulation?\n\na.2 Why do we separate the training of classification loss and regularized loss (line 8 and line 9)? \nFrom the optimization perspective, there is no difficulty to optimize 8+9 together, which corresponds better to the loss described in equation (2). (Just fix the discriminator and train the encoder and classifier jointly) Is there any reason to prefer the current alternative training rather than joint training? \n\na.3 How large are the discriminator loss versus generator loss?\nIn the standard GAN training, it is crucial to balance the discriminator loss and the generator loss. A plot comparing the different loss in line 7, line 8  and line 9 will be helpful to understand the role of discriminator in the framework. In particular,  it would be interesting to see whether there is a difference when combining with/without adversarial training.\n\nb. About the experiments \nb.1 Why Gaussian distribution is a good prior distribution?\nIntuitively, we would expect the latent distribution to be well clustered in several class which is clearly not the property of a Gaussian distribution. It is very curious to me why imposing a Gaussian distribution could improve the robustness. Have you tried to use clustered distribution as a prior? (examples could be find in [1]) If not, it would be interesting to try and compare the results.\n\nb.2 On CIFAR10, why the non-robust training outperform the robust training?\nIt is curious to see that on CIFAR10, ER-classifier- outperforms ER-Classifier with large epsilon. This is surprising since the min-max robust training explicitly minimize the robust loss. \n\nb.3 Have you tried to vary the regularization parameter lambda?\nIt would be interesting to see how the performance changes when varying the regularization parameter lambda. By the way, how is lambda determined in the current experiments?\n\nMinor comments: \nb.4 There is a stronger version of Defense-GAN introduced in [2]\nb.5 The study on the dimension of embedding space is interesting, is the non robust training giving similar results? \n\n[1] Adversarial Autoencoders, Makhzani et al. 2015\n[2] The Robust Manifold Defense: Adversarial Training using Generative Models, Ilyas et al, 2017"}