{"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "1.\tThe idea of explicitly forcing the encoding space to be flat by putting constraint on metric tensor is simple but neat.\n2.\tThe use of Jacobi regularization in Eq. (9) is effective but the choice of using interpolation to extend this in the entire decoding space is kind of adhoc. Can authors please justify?\n3.\tNot sure how authors put the Lipschitz continuity constraint on f. Please explain. \n4.\tThe title of \u201cFlat manifold VAEs\u201d is misleading as it potentially means VAEs for flat manifold \n5.\tI wonder what will happen if you put an unfolding constraint in the encoding space like LLE, ISOMAP etc.. The loss function is data driven so this should give atleast similar behavior.\n6.\tOverall I like the experimental setup, but the tracking experiment is kind of distracting. The authors may want to remove this experiment.\n7.\tIn Fig. 7, the authors have shown with and without  Jacobi normalization which I am really not convinced with, need better explanation.  \n"}