{"experience_assessment": "I have read many papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "Thank you for your submission.\n\nThe paper studies representation learning with vs. without supervision. It claims unsupervised learning is not enough for learning strong representations for downstream tasks.\n\nThe paper refers to previous work that supports the claim that tasks are important for representation learning in biological systems.\n\nThe paper's results provide evidence that supervised training with a specific task training set yields a richer representation than unsupervised training. The performance is measured on the same set of tasks, but with held-out realizations/configurations.\n\nI vote for rejection of this paper.\n\nThe paper is making a case for the fact that supervised training signals are richer for representation learning that unsupervised ones. This is widely accepted.\n\nThe paper makes a valid point that optimizing unsupervised learning criteria (such as log-likelihood of reconstructed inputs) is not in itself the solution to learn good representations. The point of unsupervised learning is leveraging data that is often more abundant than data for supervised learning. In my view the way to reconcile these two points is to identify/develop adequate unsupervised losses and, when possible, compare their representation learning on supervised tasks of interest. In contrast, replacing the unsupervised learning with supervised learning does not reconcile the two points, but only bypasses the issues of adequate unsupervised representation learning.\n\nThe paper's arguments in favor of task-mediated representation learning are an interesting motivation to support multitask learning.\n\nA few technical remarks: \n* The bandit problem is not really a bandit problem, because there's no decision-making involved. It's a binary prediction task with sequences as inputs.\n* I think it would be useful to introduce the problem being addressed and mention the contributions before going into the details of the dataset and network architectures. A quick few-paragraph overview of the paper (problem being addressed; what the results look like) in the introduction will help the reader navigate the paper better.\n"}