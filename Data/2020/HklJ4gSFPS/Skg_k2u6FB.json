{"experience_assessment": "I have published in this field for several years.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "The paper is driven by the argument that neural encoding in biological systems is shaped by behavioral objectives and, hence, proposes to make use of an abstract surrogate objective. This is said to result in a model that learns representations that are implicitly shaped by the goal of correct inference.\n\nIndeed, closing the gap between neural encodings in biological and artificial systems is an important goal. Unfortunately, the paper is not well presented. There are a number grammar flows. Or consider e.g. Fig. 1. Here, the variable Y is not explained. It is also not easy to understand \"the arm 13\" can be found. Or consider the introduction of the model. It follows very basic differentiable programming units, while the abstract claims that \"rather than labeling the observations ... we propose a model that learns representations that are implicitly shaped by the goals of correct inference\". Ok, now the inference is the label. Fine. But what is the benefit of doing so? Unfortunately, this is not discussed and also the experimental evaluation does not show this. A comparison to VAE on a single dataset is not enough to convince the reader that this generally holds. Moreover, it is not shown that the representation now helps better in some applications than existing approaches. It would be much more convincing the new models beats VAE in a task VAE are good at. In any case, evaluations on more tasks/datasets are definitely missing to show that the method generally works fine.\n\nTo summarize, interesting direction but the paper is not ready for publication at ICLR yet. "}