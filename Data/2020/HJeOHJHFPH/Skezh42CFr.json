{"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "This paper presents a single image super-resolution method that uses a rendered face and the corresponding parameters as priors into its residual block network layers. Given an LR image, it computes a vector of 3DMM coefficients that represents identity, facial expression, texture, illumination and pose using a face rendering network based on ResNet50 after upsampling the LR image. Using these coefficients, it reconstructs 3D shape and texture images. The coefficient vector is transformed into feature maps by reshaping, resizing and zero-padding, and concatenates them with the reconstructed face and fed into the SR network. These priors are spatially affine transformed (details are missing in the paper and the notation is confusing) and applied into a chain of spatial attention blocks, which are followed by a residual channel attention block. The feature maps deconvolved and upsampled to HR size to obtain the final SR image. The loss is computed using MSE.  \n\nExcept using a reconstructed image and heuristically rearranged coefficients as a prior, the novelty is very weak. \n\nPresentation requires a revision, many important technical details are not clearly explained. Is only MSE is used for the loss? How two branches are trained (in an alternating fashion, separately, end-to-end, etc.)? Why the face reconstruction network is not fine-tuned?\n\nThe ablation study is substandard at best since it fails to provide a detailed understanding of how hyper-parameters affect the final results. It is not clear how accurate the reconstructed prior would be for 16x16 inputs (samples for 32x32 are shown). How are the 3D shape/texture reconstruction errors handled for 16x16 inputs? 3D prior does not provide any hair texture info,  yet the estimated SR images have refined hairs than the bicubic inputs, does this indicate the prior is useless? No analysis of alternative choices for the coefficient arrangement is provided.  \n\nThe generated results look like bilateral filtered as they are over-smoothed without any texture. \n\nThe experimental evaluations are missing the method [1] which reported comparably competitive results for 8x SR than the prior work evaluated in this paper. \n\n[1] X. Yu et al., Face Super-resolution Guided by Facial Component Heatmaps, ECCV 2018. "}