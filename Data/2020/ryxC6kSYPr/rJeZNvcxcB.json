{"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #4", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper continues the recent direction (e.g. Amos & Kolter 2017) of differentiating through optimal control solutions, allowing for the combination of optimal control methods and learning systems. The paper has some nice contributions and I find this research direction to be very exciting, which is why I think it merits acceptance, however I find the experiments (Section 4) could be greatly improved.\n\nThe main contribution of the paper are the analytical derivative of the solution to the DARE. The pre-stabilising controller reformulation is a neat trick. \n\nThe main issue I have with this paper is that the experiments are performed only on a toy 2D problem. Even an LTI system can be interesting! Of course it is important to start with a toy problem, but once positive results have been shown, it would be much more convincing if the paper showed some more complicated system, possibly an iteratively linearised non-linear system. My feeling (and possibly many others') is that these type on differentiable controllers can be extremely powerful, however this power is sadly not demonstrated here.\n\nerrata:\nbefore eq (3): dt is not a pertubation to the feedback control\neq (4) argmin over \\delta u rather than \\delta, presumably\n"}