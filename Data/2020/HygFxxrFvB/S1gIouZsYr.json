{"rating": "1: Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "The paper considers synthetic data generation using deep GANs and autoencoders that can be shared for model training.\nThe authors can generate mixed-type data and consider some additional metrics that allow the evaluation of the quality of synthetic data.\n\nWhile the problem raised in the paper is interesting, and there some insights on what kind of metrics one should use, the article now lacks conclusions and discussion of obtained results. \nIn particular, there is a significant number of misprints and inconsistencies here and there (see more on this below).\nMoreover, the experiments are irreproducible e.g. I could not found information about the value of reduced dimension q in the description of the experiments.\nAlso, there is no comparison with previous approaches (e.g. [1, 2]), only results about the proposed one are presented. \n\nThe paper will also benefit from additional rounds of proofreading:\n\n1. The algorithm $\\mathcal{M}$ is not defined. The range $Range(\\mathcal{M})$ is not defined.\n1. a mixture of Gaussian distribution -> a\nmixture of Gaussian distributions\n2. comepare -> compare, matrics -> metrics, deceases -> decreases\n4. should to minimize -> should minimize\n5. In the formula \"(true) loss function\" subscript \"i\" should be dropped, as we talk about $x \\sim Z$, not $x_i$ here\n6. Articles in many places can be improved (finding good autoencoder -> finding a good autoencoder)\n7. It is possible, that in the paragraph after the formula (2) \"encoder\" should be replaced by \"decoder\".\n8.  the total number of samples the real\ndata - > the total number of available real data samples \n9. The axis labels are too small for Figure 2\n10. No reference to Figure 3 in the text of the paper. For Figure 3 the most left plot has for some reason a smaller number of points. Why?\n11. The selection of classifiers is not discussed. I.e. why in some cases authors use random forests (5.2), but in other logistic regression (5.1)? Also in my opinion mixing of R2 and F1 scores in one plot can be confusing.\n12. No conclusion in the end\n\n\n[1.] Xu et al. Modeling tabular data using conditional GAN. NeurIPS 2019\n[2.] S.K.Lim et al. DOPING: Generative Data Augmentation for Unsupervised Anomaly Detection with GAN. IEEE ICDM 2019."}