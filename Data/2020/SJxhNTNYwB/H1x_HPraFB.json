{"experience_assessment": "I have read many papers in this area.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "Review: The paper proposes a new framework (TREMBA) for black-box adversarial attack. The method utilizes a pretrained source network to learn a low dimensional embedding, it then searches efficiently within the embedding space (using NES) and produces an adversarial perturbation that can attack an unknown target network. A generator model first encodes an input to a latent vector and then decodes it to give an adversarial perturbation as an output. This generator is trained so that it can fool the source network and is then used to find the adversarial pattern when searching in the latent space. TREMBA produces perturbations with high level semantic patterns, and is easily transferable to different target architectures. The paper demonstrates its performance in terms of number of queries vs success rate on different datasets, Google cloud vision API and adversarially defended networks.\n\n- I like the exhaustive evaluation and comparative study done in the paper. It was especially interesting to see how TREMBA outperforms other techniques when attacking SOTA defended networks (on CIFAR 10 and Imagenet dataset). \n- When the method seems intuitive, it shows a novel way to combine transfer-based and score-based attack methods. \n- The motivation behind using low dim embedding space to accelerate adversarial pattern searching is also well explained in the paper. \n- The contributions are well-stated in the paper and definitely show an improvement over the past methods in not only reducing the number of queries but also improving the success rate of the attack. \n\nComments:\nThe loss function L_{target}(xi, t) on Page 3 has yi instead of t in the equation.\n"}