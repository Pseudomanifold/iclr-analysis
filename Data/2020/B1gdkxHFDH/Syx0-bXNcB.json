{"experience_assessment": "I have read many papers in this area.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "General:\nThe authors propose a method to train individually fair ML models by pursuing robustness of the similarity loss function among the comparable data points. The main algorithmic tool of training is borrowed from the recent adversarial training, and the paper also gives the theoretical analyses on the convergence property of their method. \n\nPros:\n1. They make the point that the individual fairness is important. \n2. The paper proposes a practical algorithm for achieving the robustness and the indivdual fairness. Formulating that the main criterion for checking the fainess is Eq.(2.1), the paper takes a sensible route of using dual and minimax optimization problem (2.4).\n3. The experimental results are compelling \u2013 while the proposed method loses the accuracy a bit, but shows very good individual fairness under their used metric. \n\nCons & Questions:\n1. What is the empirical convergence property of the algorithm? How long does it take to train for the experiments given?\n2. It seems like the main tools for algorithm and theory are borrowed from other papers in adversarial training e.g., (Madry 2017). Are their any algorithmic alternatives for solving (2.4)?\n3. Why do you use d_z^2 instead of d_z for defining c(z_1,z_2)?\n4. What happens when you use more complex models than 1 layer neural net?"}