{"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I did not assess the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review": "\nSummary\nThe authors propose training to optimize individual fairness using sensitive subspace robustness (SenSR) algorithm.\n\nDecision\nOverall, I recommend borderline as the paper seems legit in formulating the individual fairness problem into a minmax robust optimization problem. The authors show improvement in gender and racial biases compared to non-individual fair approaches. However, I think some sections are hard to follow for people not in the field.\n\nSupporting argument:\n1. End of P3, it is not clear to me why solving the worst case is better.\n2. Though this paper studied individual fairness, can it also work for group fairness? I am not sure whether this is the only work in this direction (baselines are not for individual fairness).\n3. Some of the metrics in the experiments are not precisely defined such as Race gap, Cuis. gap, S-Con, GR-Con. It is hard to follow from the text description. \n4. Some baseline models are not clearly defined such as \u201cProject\u201d in Table 1.\n5. Not sure how Section 3 connects with the rest of the paper.\n\n\nAdditional feedback:\n1. Missing reference: https://arxiv.org/abs/1907.12059\n2. What\u2019s TV distance in introduction?\n"}