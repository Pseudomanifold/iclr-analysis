{"rating": "6: Weak Accept", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "In this paper, the authors propose to use a dirichlet prior over the multinomial distribution outputted by blackbox DL models, to quantify uncertainty in predictions. The main contribution is to learn the parameters of the prior and use it as a wrapper over the black box, to adjudicate whether to retain or reject a particular prediction made by the model. The dirichlet parameters are learnt in conjunction with the model parameters as a fine tuning step in transfer learning tasks. Experiments on NLP and CV domains and multiple datasets demonstrate the efficacy of the method. \n\nThe paper is well written, and easy to understand. The main motivation of the paper seems to be to learn what samples to drop, but the authors do not address what can be done about the dropped samples (i.e what happens if we end up having to drop 80% of the samples?) . Adding the dirichlet prior to quantify uncertainty has also been studied in the context of VAEs before, (and LDA back in the day) so conceptually there's limited novelty. Nonetheless, the method seems to provide impressive results on multiple datasets, and I think this is interesting enough to warrant an accept. \n\nMINOR:\n1. Figure 1: the values of \\beta is the same in all subfigures\n2. Sec 2.2 line 1: SImilarly --> Similar\n\n"}