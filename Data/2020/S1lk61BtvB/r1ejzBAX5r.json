{"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I did not assess the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review": "This paper presents a new objective function for hybrid VAE-GANs. To overcome a number of known issues with VAE-GANs, this work uses multiple samples from the generator network to achieve a high data log-likelihood and low divergence to the latent prior.\nIn the experimental section, the ``\"Best-of-Many-Samples\" approach is shown to outperform other state-of-the-art methods on CIFAR-10 and a synthetic dataset.\n\nThanks for submitting code with your submission!\n\nCaveat: I'm not an expert in this domain and did my best to review this paper.\n\nQuestions:\n- Considering the smaller gap between \u03b1-GAN+SN and BMS-VAE-GAN, I was wondering how much of the improvement is due to spectral normalization vs using multiple samples. Did you do an ablation study of BMS-VAE-GAN without SN?\n- I noticed some minor typos in the text. Please fix (3.2 \"constrains\" -> \"constraints\", 3.3 \"traiend\", 3.3 \"unsure\" -> \"ensure\")."}