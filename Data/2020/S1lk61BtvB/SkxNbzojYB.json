{"rating": "3: Weak Reject", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "\u201cBest of Many Samples\u201d Distribution matching\n\nSummary:\n\nThis paper proposes to a novel VAE-GAN hybrid which, during training, draws multiple samples from the reparameterized latent distribution for each inferred q(z|x), and only backpropagates reconstruction error for the resulting G(z) which has the lowest reconstruction. The authors appear to use the AAE method instead of analytically matching KL(p||q) for enforcing that the latents q(z|x) match the prior. The authors present results on MoG toy datasets, CIFAR-10, and CelebA, and compare  against several other models.\n\nMy take:\n\nThe idea in this paper is moderately interesting, well-founded, has plenty of precedent in the literature (while still being reasonably novel),  but the results present only a minimal improvement (a 5% relative improvement in FID over the baseline model from Rosca et al on CIFAR, especially when including SN [which is not a contribution of this paper]) and come at a substantial compute cost, requiring up to 30 extra samples per batch in order to attain this minimal increase. While I think the idea is interesting, the change in results over Rosca et. al does not seem to justify its increased computational expense (which is also not characterized in sufficient thoroughness). I am pretty borderline on this paper ( about a 5/10) but under the 1-3-6-8 scoring constraint I tend to lean reject because while I like the idea, I do not think the results are significant enough to support its adoption; I think the relative compute and implementation cost limit this method\u2019s potential impact. I am keen to discuss this paper with the other reviewers.\n\nNotes:\n\n-The results on the 2D MoG toy datasets are good but are also suspect\u2014the authors state that they use a 32-dimensional latent space, but the original code provided for VEEGAN uses a 2-dimensional latent space. The authors should re-run the experiment for BMS-VAE-GAN  using a 2D latent space (this should be very easy and take less than an hour on a GPU to get several runs in).\n\n-\u201cagain outperforming by a significant margin (21.8 vs 22.9 FID)\u201d This is not a significant margin; this is less than a 5% margin and, at those FID scores, represents an imperceptible change in sample quality.\n\n-The authors seem to suggest that applying spectral norm to the GAN of Rosca et. al. is somehow a contribution (e.g. having \u201cours\u201d next to this model in the tables); I would advise against even appearing to suggest this as it is clearly not a contribution.\n\n-Characterize the increase in compute cost. \u201c. We use as many samples during training as would fit in GPU memory so that we make the same number of forward/backward passes as other approaches and minimize the computational overhead of sampling multiple samples\u201d is a qualitative description; I would like to see this quantitatively described. How do the runtimes differ between your baseline and the T=10 and T=30 runs? If they don\u2019t differ, why? Are the authors e.g. reducing the batch size by a factor of 10 or 30 to make this computationally tractable?\n\n-The latent space discriminator D_L should be referred to in section 3; its formal introduction is deferred to later in the paper, hampering the presentation and flow. \n\n-CelebA is not multimodal; it is in fact, highly constrained, and primarily only has textural variation (virtually no pose variation).\n\n-ALI and BiGAN are listed under Hybrid VAE-GANs. These models are not VAE-GAN hybrids. Additionally, this section states that BiGAN builds upon ALI. This is not true, these papers are in fact proposing the same thing and were released at nearly the exact same time.  Do not mischaracterize or incorrectly summarize papers. Please re-read both papers and refer to them correctly.\n\n-Mode collapse (when many points in z map to an unexpectedly small region in G(z)) is a different phenomenon from mode dropping (when many points in x are not represented in G(z), i.e. no point in z maps to a cluster of x\u2019s, as is the case if e.g. a celebA model generates frowning and neutral faces but no smiling faces). While these phenomena often co-occur (especially during complete training collapse), they are not the same thing, and this paper conflates them in several places.\n\nMinor:\n\nSection 3, paragraph 2: \u201cThe GAN (G\u03b8,DI\u2026\u201d There\u2019s a close parenthesis missing here. \n\nSection 3.3: \u201cThe network is traiend\u2026\u201d \n\nPlease thoroughly proofread your paper for typos and grammatical mistakes.\n\n"}