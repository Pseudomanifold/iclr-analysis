{"rating": "3: Weak Reject", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2478", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "<Strengths> \n+ This paper proposes the Mem2Mem mechanism that is applicable to general seq2seq models for summarization. The proposed approach improves the HRED base model for abstractive summarization of PubMed dataset. \n+ The paper reads very well.\n\n<Weakness>\n1. The technical novelty may need to be further justified.\n- The memory network-based model has been already proposed for the task of abstractive summarization (Kim et al. 2018), although it may not have read/write mechanism unlike Mem2Mem. This distinction may need to be clearly stated in introduction.\n- The key novelty of this work is Mem2Mem mechanism, which consists of encoder memory (section 3.1) and read/write decoder memory (section 3.2). \n- The encoder memory is rather standard with attention regularization, which is adopted from Lin et al (2017). Also, the extractive nature in the encoder memory is common standard in most memory network models.\n- The proposed decoder memory may be also incremental over the scratchpad (Benmalek et al. 2019), which also proposes memory read/write mechanism for general seq2seq models. As far as I know,  the scratchpad was not applied to abstractive summarization tasks. Is it only big update from scratchpad to Mem2Mem? The difference assertion below in Eq.(20) is not convincing but still looks incremental improvement.\n\n2. More critical weakness of this work is limited experiments. \n- First of all, the proposed approach is evaluated only on PubMed (Cohan et al 2018). I have rarely seen previous work in text summarization that is only evaluated on a single benchmark dataset. A couple of more datasets, for example newsroom dataset, should be tested to verify the success of the proposed algorithm. \n- The performance improvement by Mem2Mem is too marginal over the baseline HRED. As shown in Table 1-2, each key component of Mem2Mem only slightly enhances the base model. Especially, the effectiveness of Mem Transfer may need to be further justified empirically.\n- In my opinion, such small performance gap in a single dataset hardly convinces that the improvement by the proposed method is statistically meaningful.\n"}