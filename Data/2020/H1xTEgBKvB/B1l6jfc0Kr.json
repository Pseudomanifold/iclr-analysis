{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This paper proposes a neural model, Mem2Mem, to summarize long texts. The main contribution is to extend the typical RNN Encoder/Decoder architecture with a memory module used both for selection (from the encoder) and generation (for the decoder): essentially, the encoder transforms a document into L vectors (one per sentence) and uses an r-head attention mechanism to extract r sentences to store in the memory module. The decoder performs text generation by reading a subset of the memory and updates the memory bank during summary generation.\n\nMy main concerns about this paper are the followings:\n- Novelty is a little limited: most architectural pieces were already present: either in Lin et al. for the regularization loss to promote diversity and sparsity for the memory bank choices, or in Benmalek et al. for the memory updates.\n- The experimental section is limited to a single dataset.\n\nOn the positive side, the results are promising (especially in terms of ROUGE-L), even if limited to a single dataset, and previous summarization MAED (memory-augmented encoder/decoder) models have mostly focused on short documents or extractive summarization. I also appreciated the author presenting all the necessary details for training (in the Appendix).\n"}