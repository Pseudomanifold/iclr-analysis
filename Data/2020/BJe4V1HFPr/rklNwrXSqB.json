{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "This work introduces a Generative Adversarial Disentangling Network based on two stages training the first aims at learning a style independent content encoder and then content and style conditional GANs is used for synthesis.\nAt stage 1 training to prevent the encoder from encoding authors introduce a gan style training in which an adversarial classifier that tries to predict the corresponding artist from the encoded image.\nAt stage 2 is training a style/content conditional gan. To condition on the style (artist) authors introduce an extra adversarial classifier so the generator tries to generate samples that would be classified as the artist that it is conditioned\non. While to condition on the input content another loss is ensuring that the generated image is encoded back to its content input.\n\nAuthors compare the proposed method against the original neural style transfer and StarGAN over various styles within the context of anime illustrations and the NIST Dataset where styles are being represented by artist name. \n\nWhile the work tackles some of the problems by conditioning only on artist names other than style features that might be hard to have annotations for. The proposed modifications are quite incremental. Additionally, the experiments section is quite weak, evaluation is only done quantitatively over some cherry-picked examples, although some extra ablation study in the appendix is provided. \n\n"}