{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper modifies existing classifier architectures and training objective, in order to minimize \"conditional entropy bottleneck\" (CEB) objective, in attempts to force the representation to maximize the information bottleneck objective. Consequently, the paper claims that this CEB model improves general test accuracy and robustness against adversarial attacks and common corruptions, compared to the softmax + cross entropy counterpart. This claim is supported by experimental results on CIFAR-10 and ImageNet-C datasets.\n\nIn overall, the manuscript is easy-to-follow with a clear motivation. I found the experimental results are also promising, at least for the improved test accuracy and corruption robustness. Regarding the results about adversarial robustness, however, it was really confusing for me to understand and validate the reported values. I would like to increase my score if the following questions could be addressed:\n\n- It is not clear whether adversarial training is used or not in CEB models for the adversarial robustness results. If the results were achieved \"without\" adversarial training, these would be somewhat surprising for me. At the same time, however, I would want to see more thorough evaluation than the current, e.g. PGD with more n, random restart, gradient-free attacks, or black-box attacks.\n- I wonder if the paper could provide a motivation on why the AutoAug policy is adopted when training robust model. Personally, this is one of the reasons that makes me hard to understand the values presented in the paper.\n- Figure 3, right: Does this plot indicates that \"28x10 Det\" is much more robust than \"28x10 Madry\"? If so, it feels so awkward for me, and I hope this results could be further justified in advance.\n- Figure 3: It is extremely difficult to understand the plots as the whole lines are interleaved on a single grid. I suggests to split the plots based on the main claims the paper want to demonstrate.\n- How was the issue of potential over-fitting on rho handled, e.g. using a validation set?\n- In general, I slightly feel a lack of justification on why the CEB model improves robustness. In Page 5: \"... Every small model we have trained with Batch Normalization enabled has had substantially worse robustness, ...\" - I think this line could be a critical point, and need further investigations in a manner of justifying the overall claim."}