{"rating": "6: Weak Accept", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper proposes stable GradientLess Descent (GLD) algorithms that do not rely on gradient estimate. Based on the low-rank assumption on P_A, the iteration complexity is poly-logarithmically dependent on dimensionality. The theoretical analysis of the main results is based on a geometric perspective, which is interesting. The experimental results on synthetic and MuJoCo datasets validate the effectiveness of the proposed algorithms.\n\nThe theoretical contribution of this paper is nice and valuable. My main concern is the structure f(x) = g(P_A x) + h(x) looks somewhat limited. A more natural form is moving the perturbation into g, i.e, f(x) = g(P_A x + h(x)). \n\nThe experiments on Mujoco do not satisfy the assumption previous. Is there any real-world application which matches the theoretical analysis?\n\nIn summary, I think this is a good paper and tend to accept it.\n"}