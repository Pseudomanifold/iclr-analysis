{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "1. Summary\n\nThe authors employ a multi-agent learning approach for learning how to set payoffs optimally for crowdsourcing contests\nand auctions. Optimality means e.g. incentive alignment (the principal problem) between the principal (e.g. the organizer) and participants (e.g. bidders), assuming e.g. that participants can be strategic about their behavior. In this work the principal uses ReLU-log utility.\n\nFirst, the authors use fictitious play and multi-agent RL to train agents on a distribution of payoffs. Then, a neural net is fitted to the samples (payyoffs, expected principal utility), and finally iteratively attempts to improve the payoffs using mirror ascent within the convex set of admissable payoffs.\n\nThe authors compare the payoffs with theoretically known solutions and in situations where the optimal solution is not known.\n\n3, 4-agent all-pay auction (Nash eq known).\nSame as above, but with noise added to bids (Nash eq not known).\nThe authors analyze in some detail how the principal's utility and bidder ranking behave as the participants' bids change.\n\n1. Decision (accept or reject) with one or two key reasons for this choice.\n\nReject. Although the high-level approach is interesting (use learning to design auctions for cases where no theoretical solution is known), the actual experimental results and methodological improvement over e.g. Dutting 2017 are weak. The authors only consider 3, 4-agent auctions. There are no other learned baselines (e.g., constrained optimization without neural nets) that the authors could consider.\n\n3. Supporting arguments\n\nSee above.\n\n4. Additional feedback with the aim to improve the paper. Make it clear that these points are here to help, and not necessarily part of your decision assessment.\n\nM-EMA and M-EMD: ascent and descent? in Algo 1, 2?"}