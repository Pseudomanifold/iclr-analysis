{"experience_assessment": "I have read many papers in this area.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This work proposes to detect adversarial examples or otherwise corrupted images with the reconstruction network, which is used to regularise CapsNets. To further confirm the effectiveness of their detection method, they propose the Reconstructive Attack, which seeks both to cause a misclassification and a low reconstruction error. The comprehensive experiments are conducted.\n\nAlthough the idea is not very novel, the paper makes enough contributions to get accepted. Especially, Section 6 diagnoses the adversarial examples for CapsNets and shows the relationship between the success of the attack and the visual similarity between the source and target class.\n\nWe have the following question for authors about this work:\n\n1. Baseline models: This work creates the baseline model CNN+CR, by dividing the penultimate hidden layer of a CNN into groups corresponding to each class. The sum of each neuron group serves as the logit for that particular class. Why is the sum operation used to create the logit? The sum operation is pretty rare the existing CNN architectures. A linear combination may be a better choice?\n\n2. Detection Threshold: this paper empirically chooses the 95th percentile of validation distances as the threshold to detect adversary samples. Why not report the Area Under Curve (AOC) score? It is a more comprehensive evaluation metric for such a problem.\n\n3. Class-conditional information: This paper follows the architecture in Sabour et al. (2017) where the reconstruction is class-conditional. The work DeepCaps [1] shows that the reconstruction without class-conditional information leads to the better disentanglement of instantiation parameters. Is the class-conditional information necessary to achieve the robustness to adversary attacks?\n[1] Rajasegaran, Jathushan, et al. \"DeepCaps: Going Deeper with Capsule Networks.\" Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2019."}