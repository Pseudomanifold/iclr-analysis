{"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper investigates a pure deep learning architecture for Univariate time series analysis by simply ensembling feed-forward networks, along with the residual stacking mechanism for fluid learning. Each of the generic block consists of 4 FC layers followed by the use of forward and backward predictor to have forecast and backcast output of the original input. These blocks forms the stacks, where each stack provides the residuals and the forecast responses further to the next stacks, which ultimately provide the global forecast. To make the internal stack outputs interpretable, assumptions are imposed on the trend model, which follows a polynomial function of time vector, and seasonality model which follows periodic Fourier series. Further, the ensembling of models based on different metrics and input windows is used for better accuracy.    \n\nVery well written paper and easy to follow. It advocates a pure DL framework (instead of hybrid statistical models and DL). I found the idea simple and effective, yielding results better than the previous approaches. Also, the experimental setup is well described. I also found the link between this work and meta-learning approaches interesting.\n\nHowever, I have several questions about the interpretability results. It looks like the inductive bias based on some general assumptions can fail in some cases. For example, in Fig. 2(a), the line for FORECAST-I and FORECAST-G deviates much in case of hourly/weekly/daily data frequency. What is the reason behind this? \n\nAlso, in Fig. 2, while the StackT-I (fig.2(d)) and StackS-I (fig.2(e)) provide response lines different from the counterparts in  Stack1-G (fig.2(b)) and Stack2-G (fig.2(c)), the summations in the combined line (fig.2(a)) yield similar curves of pretty much the same shapes, without much perceived difference. Is it expected or something is wrong?\n"}