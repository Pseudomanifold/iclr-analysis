{"rating": "3: Weak Reject", "experience_assessment": "I do not know much about this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper empirically studies the lottery ticket hypothesis with limited or no supervision. First, the authors use self-supervised learning to generate winning tickets, showing that \"good\" (reasonable) winning tickets can be found without labels. Second, the authors show that finding \"good\" (reasonable) winning tickets can be accelerated by a factor 5 on ImageNet by using only a subset of the data. The authors also argue that using large datasets is important to study lottery tickets, since deep networks trained on CIFAR-10 are natually sparse, making conclusions potentially misleading.\n\nThe experimental results are rich and provide more understanding of winning ticket generation with limited or no supervision. The results on self-supervised learning task (including the layer-wise pruning results) and a subset of training dataset are reasonable and kind of expected, but it is still good that this paper provide solid experimental results to verify this. As the paper observed, \"none of the tickets found with limited access to labels and or data matches the accuracy of tickets found with all the labeled data when considering moderate pruning rates (more than 10% of unpruned weights)\non ImageNet. Indeed, we consistently observe a decrease in performance compared to the full overparametrized network as soon as we prune the network.\" In this sense, winning tickets are certainly label and data dependant. This undermines the *bold* claim in the abstract that \"we provide a positive answer to both questions, by generating winning tickets with limited access to data, or with self-supervision\". From my perspective, the ability to exactly perserve the accuracy while pruning the weights (see the flat regions of \"Lables\" curves in Figure 1,2,3,4,5) is the interesting part of the lottery ticket hypothesis. We have several different ways to achieve a descreased accuracy with a smaller network, the dynamics there may be a mixture of the lottery ticket hypothesis and standard model pruning, which needs more careful experiment design to separate different dynamics.\n\n\"using large datasets is important to study lottery tickets, since deep networks trained on CIFAR-10 are natually sparse, making conclusions potentially misleading.\" \"The definition of \u201cearly in training\u201d is somehow ill-defined: network\nweights change much more for the first epochs than for the last ones.\" These two messages are important to future study of the lottery ticket hypothesis. This paper raises the issue of ill-definedness of \u201cearly in training\u201d, but did not provide a solution. \n\nOverall, I found that the experimental results in this paper are solid and provide more understandings of the lottery ticket hypothesis. However, I feel that the novelty of this paper is limited, and do not provide much new insights. Therefore, it does not reach the bar of being published at ICLR, from my perspective. Therefore, I say \"Weak Reject\"."}