{"experience_assessment": "I have published in this field for several years.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This paper studies the problem of finding sparse networks in a limited supervision setup. The authors build on the lottery ticket work of Frankle & Carbin and investigate the validity of their idea when one has few or no labels. This work is an immediate followup on Morcos et al. who investigated the transferability of lottery tickets.\n\nThis work is more observational rather than algorithmic or theoretical. Authors study various small sample/label setups where network sparsification works well. \n\nMain contribution is Section 4.1 where self-supervision is investigated. However given that lottery tickets are transferable (Morcos paper) it is really not that surprising that semisupervised learning algorithms will do a decent job as well. I also don't see a practical benefit beyond transfer learning setup.\n\nSection 4.2 essentially sweeps through supervised problem parameters such as reducing sample size, adding noise etc and . The main application seems to be extracting lottery tickets faster by downsampling the data however this aspect is again fairly obvious. \n\nIn short, unfortunately, this paper doesn't cut it for ICLR. As improvements, I would recommend adding standard semi-supervised training techniques to their comparison. I was surprised to not see pseudo-labeling or consistency training (e.g. virtual adversarial training)."}