{"experience_assessment": "I do not know much about this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper develops a RL attack algorithm named CopyCAT, which can lure a policy into a desired behavior  with a finite set of additive masks. The experiments on Atari games validates the effectiveness of the proposed approach.\n\nDespite the previous works in RL attack, I feel CopyCAT is impressive in the potential of running in real time and taking control of a neural policy. However, I still want to see some comparisons with previous works in the experiments. With real examples we can understand the solutions better. \n\nDetailed comments:\n- Figure 1: I cannot see which curve stands for CopyCAT\n- Figure 6: hard to read"}