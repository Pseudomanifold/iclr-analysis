{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "# Summary\nThis paper proposes a pairwise communication between agents using a shared neural network. The idea is to define the joint action-value function as the sum of individual agent's values + pair-wise payoff between agents, which is based on the prior work [Castellini et al.]. In particular, this paper proposes to share the parameters of the pairwise payoff function to improve efficiency. The result on a grid-world domain shows that the proposed method performs better than baselines that either do not have pairwise communication (VDN) or learn fully joint action value function (QTRAN). \n\n# Originality\nThe main novelty seems to be coming from the idea of parameter sharing between pairwise payoffs, but the overall architecture seems to be the same as [Castellini et al.]. \n\n# Quality\n- This paper is missing an important baseline which is DCG without parameter sharing. Given that parameter sharing is the main new component from [Castellini et al.], it would be important to show the benefit of parameter sharing.\n- Although the result against several baselines looks good, it would be much more convincing to show some qualitative analysis of the proposed method. For example, showing that the learned payoff captures reasonable and intuitive knowledge would strengthen the paper.\n\n# Clarity\n- The paper is well-written, and the figures are very clear. \n- It would be better to show a figure that illustrates the domain and task. \n\n# Significance\n- Although the paper presents a new idea very well, the overall idea seems a bit incremental. This paper overall looks like a straightforward extension of [Castellini et al.] by adding parameter sharing and evaluating it on a more complex domain. In addition, showing more in-depth analysis would make the paper stronger. "}