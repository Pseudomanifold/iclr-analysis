{"rating": "1: Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #4", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review": "The paper proposes the idea of having a two-stage time selection and classification pipeline. For the first one they use a light network followed by a gating network (which learns N anchor kernels - or concepts) to choose the most representative time steps. For the second one, they use a heavy network such as I3D to classify the entire video based on the most representative time steps.\nWhile the idea is clear, simple and intuitive, it is not novel enough to be considered for publication in ICLR. This work is mostly a combination of different networks based on the idea of frame pruning, than a concrete network architecture that addresses the issue fundamentally (e.g. a temporal attentive video classification network).\nMoreover, based on Figure 1, the entire frames are fed to the heavynet and then the features are pruned. This adds to the importance of having a single concrete network that addresses the issue more fundamentally.\nAlso, the experiments are not enough to support the actual benefit of the work. This work should be directly compared to other works addressing the same problem (e.g. VideoBert), not just comparing it with its own baseline (I3D+Ours vs. I3D).\nThe paper also mentions the idea of concept kernel but it does not provide a detailed explanation on the concepts and/or any visualization."}