{"rating": "3: Weak Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This paper proposes a method named SUPER-AND to learn visual feature representations. AND (Anchor Neighborhood Discovery) combines sample specificity method and clustering method. Sample specificity method takes each sample as an independent class and tries to discriminate them from each other. Consequently, class-related semantics are missing. Clustering method learns a clear discriminative boundary for each class. However, it is hard because of the complexity of data points and solution space. The combination is proved can mitigate both disadvantages. SUPER-AND improves AND with data augmentation method by incorporating augmentation loss into the objective function. Experiments show that SUPER-AND has better performances than baselines. The paper has two novelties: \n\u2022\tThe authors propose a UE-loss function which strengthens the attraction among similar data points. \n\u2022\tThey introduce neighborhood relationship vector which measures the similarity of a data point to other data points in the same batch.\nThe weakness of this paper is: \n\u2022\tThe paper is mostly a combination of previous works: an improvement of AND with augmented data.\n\u2022\tSome experiments are not totally convinced. (a). The t-SNE visualization in Figure 3 only provides 3 classes from CIFAR-10; (b). Figure 5 only provides retrieval results of 4 classes (10 classes in total); (c). The ablation study is not complete. Specifically, there is no result from the raw model with only UE-loss which, however, is one novelty in this paper.\n\u2022\tThe paper needs more polish. The related work section does not include sample specificity method. There are also some notation problems which are listed in the following minor errors section.\nQuestions to authors:\n1.\tWhy not directly use learned feature vector v to compute augmentation loss? The proposed relationship vector r is just a linear transformation of vector v. What is the motivation to do this transformation and why does it benefit? Why not use r in other loss functions?\n2.\tThe abstract says SUPER-AND is feature invariant against augmentation. Is there any evidence in experiments?\nMinor errors:\n\u2022\tEq (2) seems to be r_i^j = \\frac{v_i m_j}{||v_i|| ||m_j||}\n\u2022\tEq (10): no notation for N^c\n"}