{"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper argues that adding noise to the inputs of an adversarial autoencoder for text improves the geometry of the learned latent space (in terms of mapping similar input sentences to nearby points in the latent space). The authors present a mathematical argument for why adding noise to the inputs would enforce latent space structure while a vanilla autoencoder would have no preference over x-z mappings.\n\nOverall, the paper addresses an important problem of improving autoencoder based generative models of text, presents a simple solution to do so and mathematically and empirically demonstrates its effectiveness. While I think that the benchmarks are somewhat artificial with small sentences and vocabulary sizes, I think the improvements demonstrated are substantial enough.\n\nI have a few questions & comments\n\n1) I\u2019m curious about whether the authors have an intuition for why input space noise is better than latent space noise? Poole et al 2014 [1] showed that additive latent space gaussian noise in autoencoders is equivalent to a contractive autoencoder penalty and contractive autoencoders have an *explicit* penalty to encourage minimal change in z when changing x (i.e.) penalizing the norm of ||dz/dx||. Additive latent space noise appears to be a key ingredient to getting the ARAE and similar work like in Subramanian et al 2018 [2] to work. Was the LAAE implemented in the same framework as your DAAE?\n2) It would be great to see Forward / Reverse PPL results on bigger datasets like the BookCorpus or WMT similar to [2].\n3) You may be able to get similar reconstruction vs sample quality trade-offs with ARAEs by varying the variance of the gaussian noise, similar to LAAEs.\n4) In Figure 3, I would really like to see how an autoencoder that isn\u2019t a generative model performs. How well would a vanilla autoencoder or vanilla DAE perform? This is a cool setup to evaluate latent space representation quality - you could even consider running some of the SentEval probing tasks on these representations.\n5) Could you use something like gradient-based latent space walks like in [2] to characterize the latent space geometry? https://arxiv.org/abs/1711.08014 also use similar gradient-based walks to characterize latent space smoothness in deep generative models. For example, if it takes 10 latent space gradient steps with a fixed learning rate for model \u201ca\u201d to turn sentence \u201cx\u201d into a *similar* sentence \u201cy\u201d but 20 steps for model \u201cb\u201d, then maybe \u201ca\u201d has smoother latent space geometry.\n6) Theorem 1 - What if the set of zs isn\u2019t unique and there is some sort of encoder collapse? Does this theorem still hold? (i.e.) there exists some set of points x_1, x_2 .. x_i \\in x, that all map to z_k (and even potentially in the limit that all points in x map to the same point in z space).\n7) It would be good to point out that the model presented in this work is far from SOTA on sentiment style transfer benchmarks like Yelp.\n\n[1] Analyzing noise in autoencoders and deep networks - https://arxiv.org/pdf/1406.1831.pdf\n[2] Towards Text Generation with Adversarially Learned Neural Outlines - https://papers.nips.cc/paper/7983-towards-text-generation-with-adversarially-learned-neural-outlines.pdf"}