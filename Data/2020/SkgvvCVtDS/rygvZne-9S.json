{"experience_assessment": "I have read many papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "Summary: \nThe authors propose a deep-reinforcement learning method for training how to choose pivot rules for the simplex algorithm for a set of LP instances. In particular, the authors applied the RL-approach to randomly generated TSP problems with five cities, which reduces the costs. \n\nComments:\nI have some concerns on the technical contribution.\nFirst of all, I wonder in what kind of realistic situations where we want to \u201clearn\u201d something from optimization problem instances. When we can learn something, the problems would share some properties and there have to be many such instances. I don\u2019 know practical examples of such a scenario. The artificial TSP instances used in the experiments are not convincing for practical applications. \n\nThe second concern is the scalability. In the experiments, TSP instances with only five cities are used, for which a simple brute-force search is still acceptable and too small. So, the proposed method is far from practical yet. \n\nAs a summary, the idea could be interesting, but the paper is not mature enough.\n"}