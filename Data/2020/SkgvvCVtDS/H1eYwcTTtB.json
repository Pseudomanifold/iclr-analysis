{"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper proposes learning a policy for selecting a pivoting rule to apply at each iteration of the Simplex algorithm for linear programming. Several pivoting rules have been proposed in the optimization literature, and different rules work better than others on different instances. By learning a policy that switches among the existing rules at each step of the Simplex algorithm, it may be possible to construct a pivoting rule that outperforms existing ones. The paper considers learning to switch between the Dantzig rule and the steepest edge rule as an RL problem. Results on 5-city TSP instances show that the learned policy can outperform both rules on a test set with respect to number of iterations.\n\nPros:\n- The problem is very interesting and definitely should be explored further. Learning could potentially help combine rules in an instance distribution-specific manner to construct better pivoting rules.\n- The paper made a reasonable attempt to provide sufficient background to understand the problem.\n\nCons:\n- The results on the 5-city synthetic TSP instances are not sufficient. While I understand the motivation for considering small problems to measure the best possible strategy\u2019s performance and to learn on Q* values, I\u2019m not convinced that the insights from such small synthetic problems would necessarily transfer to larger LPs for which the solve time is large enough to be able to afford the overhead of neural network inference to try to reduce it. The learning challenges will likely be very different, and the tradeoff between the inference cost of the neural network and the savings from reducing iterations will also likely be different. Scaling up and neural network inference cost are briefly mentioned in the conclusion, but I believe those are the main challenges.\n- Presentation of the results need to be improved significantly. Figures 2 and 3 need to be annotated properly and explained more clearly so that they are easy to understand.\n\nAdditional comments:\n- Although I\u2019m recommending rejection, the problem is interesting and I hope the authors will continue working on it to develop the ideas further and collect results on larger scale problems.\n- For permutation invariance and ability to handle variable-sized inputs, a graph neural network would be a better architecture (see, e.g., Gasse et al., NeurIPS\u201919).\n- It would be helpful to give further details on how the best possible strategy is computed, perhaps as part of an appendix.\n- Another baseline to compare against is the performance of an oracle that makes the best possible choice of the pivoting rule per problem instance. This will indicate how well a fixed choice per instance can work if that choice is made as well as possible, compared to switching among choices at each iteration.\n- \u201cTo our knowledge, this is one of the first studies to report improvements via learning for combinatorial algorithms.\u201d This sentence needs to be clarified because a literal interpretation of it is not true, as shown by, e.g., Bengio et al. https://arxiv.org/abs/1811.06128."}