{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "N/A", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "The article \"Efficient Wrapper Feature Selection using Autoencoder and Model Based Elimination\" considers the problem of feature selection for a broad class of machine learning models. The authors argue that it is important to consider the relevance of features for the considered supervised ML problem and redundancy of features. They propose the wrapper feature selection method based on this paradigm and report the results of the experimental comparison of the method with some approaches from the literature.\n\nThe proposed AMBER approach consists of 2 parts:\n1. The ranking of features based on the sensitivity of some supervised ML model with respect to the particular feature.\n2. The ranking of features with respect to their individual impact on the accuracy of the autoencoder trained on the features of the training data set.\n\nThe scores obtained on these 2 steps are added and the algorithm iteratively removes features with the lowest total score.\n\nI should note that the proposed approach is very general, but the paper gives very few details on the actual implementation. For example, it seems important to properly normalize relevance and redundancy scores before computing the final score but the paper doesn't discuss this issue. Also, there are many possible ways to compute losses. For example, one can use training or validation sets for that but the authors choose the training set without motivation. \n\nMost importantly, the experimental part of the paper considers just 4 datasets. I believe that the algorithms of such generality should be evaluated on a much broader selection of problems. The most important thing is whether it is possible to select hyperparameters of the method in a way that few human interventions are needed to achieve high-quality results.\n\nOverall, I am very concerned with making the particular instance of the proposed approach working on a vast selection of applied problems. The provided repository with code confirms my concerns as it doesn't provide the single algorithm but rather the collection of scripts tailored for particular problems considered.\n\nTo sum up, I think that while the motivation behind the paper is very natural, I am not convinced with experimental results and the overall applicability of the approach."}