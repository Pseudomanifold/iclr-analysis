{"rating": "6: Weak Accept", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review": "In this paper, the authors proposed an approach to fit locally constant functions using deep neural networks (DNNs).\nThe idea is based on the fact that DNN consisting of only linear transformations and ReLU activations is piecewise linear.\nThus, the derivative of such a network with respect to the input is locally constant.\n\nIn the paper, the authors focused on connecting the locally constant network with oblique decision trees.\nSpecifically, they proved that these two models are in some sense equivalent, and one can transform one model to another.\nThis connection enables us to train the oblique decision trees by training the locally constant network instead.\nBecause the locally constant network can be trained using the gradient-based methods, it would be much easier to train than the oblique decision trees.\n\nI think the paper is well-written and the idea is clear.\nConnecting the locally constant network with oblique decision trees looks interesting.\n\nI have one concern, however.\nThe authors mention that the training of oblique decision trees is difficult, and the use of the locally constant network is helpful.\nIf I understand correctly, oblique decision tree is one specific instance of the hierarchical mixtures of experts.\nAnd, [Ref1] pointed out that the hierarchical mixtures of experts can be trained using EM algorithm, which is another type of the gradient-based training.\nThe current paper misses such a prior study.\nI am interested in to see if the use of locally constant network is truly effective for training oblique decision trees over the algorithms considered in the literatures of hierarchical mixtures of experts.\n\n[Ref1] Hierarchical mixtures of experts and the EM algorithm"}