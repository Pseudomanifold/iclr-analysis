{"experience_assessment": "I do not know much about this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "The paper considers the problem of out-of-distribution (OOD) sample detection while solving a classification task. The authors tackle the problem of OOD detection with exploiting uncertainty while passing a test sample through the neural network. They treat outputs of (some) layers in a NN as random Gaussian-distributed variables and measure uncertainty as variance of these Gaussians. Then when uncertainty is high, OOD is detected.\n\nThe overall idea behind the paper could be interesting, but its realisation in the current form is questionable. \n\nThe paper seems totally misusing the reparametrisation trick and stochastic outputs of layers in NNs. Eq. (2) is not the objective of variational inference that seems to be required for stochastic outputs and the reparametrisation trick as presented before the equation. The objective misses the KL-divergence term! Without it what would stop a neural net to set sigmas to 0 and forget about the stochasticity altogether? Not to mention that the current objective is not mathematically justified.\nIf there is no mix and error in eq. (2) and the networks were trained using this loss (and based on provided code they were using this loss), my wild guess of explaining why this may give best results in the experiments is that the models were trained for surprisingly small number of epochs. Therefore, a hypothesis would be that this small number of epochs did not allow the networks to switch sigmas to 0. \n\nUntil the authors can clarify and justify the objective, I will vote for rejection only based on this ground.\n\nHowever, there are other issues in the paper as well. First of all, its clarity. It seems that the paper requires a lot of polishing.  The first paragraph of this review is based on my assumptions from the paper since I am not completely sure I understand it correctly. More about the clarity issues below\n\nFor strong evaluation, comparison with Malinin & Gales (2018) work seems to be important since it was the only work also using uncertainties for OOD detection in related work. Also related work section does not look like an exhaustive overview.\n\nSome of the detailed comments:\n1.\t\u201cIn other words, in-distribution samples possess more features that convolutional filters react to than OOD samples\u201d \u2013 first of all, this sentence is not easy to parse. Secondly, it is unclear, why this should be true. If OOD samples are still natural images, they would contain edges just the same as in-distribution samples. That is the power of deep learning enabling transfer learning, that low-level features are the transferable across different data and tasks. Therefore, the claim that \u201cTherefore, the uncertainties of the features will be larger when the inputs are in-distribution samples\u201d requires more elaboration and arguments\n2.\tThe arguments of the next paragraph regarding uncertainty of deeper layers should be larger for OOD samples are not very convincing either.  It is either requires a definition what the authors mean here as uncertainty, or it is not necessarily true that absence of fixed regions for embeddings leads to higher uncertainty. \n3.\t3rd and 4th paragraphs in Introduction have too many repetitions of phrases between each other. Compare, e.g. the first sentences of the paragraphs or the last sentences. \n4.\t\u201cOne cause of the abovementioned problem is that their approaches\u201d and similarly the next paragraph: \u201ctheir approaches\u201d stylistically sound wrong. It is appropriate in the previous paragraph since there is a link to \u201cprevious studies\u201d. It seems that \u201cthese approaches\u201d or \u201cthe existing approaches\u201d would be a better choice for this and the next paragraph.\n5.\t\u201cEach uncertainty is easily estimated after training the discriminative model by computing the mean and the variance of their features using a reparameterization trick\u201d \u2013 conventional discriminative models do not estimate mean and variances of the features. The issue of estimating uncertainty is addressed by several special methods such as Bayesian variational methods used in the referred papers. Therefore, in order to use a reparametrisation trick one need to firstly choose a special class of models, which is not obvious from the text.  \n6.\t\u201cMoreover, UFEL is robust to hyperparameters such as the number of in-distribution classes and the validation dataset.\u201d \u2013 the size of the validation dataset? In any case neither size of the validation dataset nor the validation dataset itself are not hyperparameters (should not be hyperparameters for out-of-distribution detection). The number of classes can hardly be called a hyperparameter also. \n7.\t\u201cdepends on the difference in the Dirichlet distribution of the categorical parameter <\u2026> In our work, the distribution of the logit of the categorical parameters\u201d \u2013 what is/are this/these categorical parameter(s)?\n8.\t\u201cFurther, they estimate the parameter of the Dirichlet distribution using a DNN and train the model with in-distribution and OOD datasets\u201d \u2013 this sentence may mislead to impression that the proposed method does not need OOD dataset for training, which does not seem to be the case, since \\lambda and \\theta are trained based on OOD samples\n9.\t\u201cbecause they will not be relevant to the classification accuracy\u201d \u2013 who are they?\n10.\t\u201cand \\epsilon is the Gaussian noise\u201d \u2013> the standard Gaussian noise\n11.\t\u201cwhere z^0 = x\u201d \u2013 it seems this should be placed somewhere earlier when z^l is introduced since z^0 is not used in eq.(2) after which this text is placed\n12.\tIt is unclear how \\lambda^l and CNN \\theta are learnt\n13.\tIt is unclear how the values of features d(x) are used to detect OOD samples\n14.\t\u201ccomparison methods, and models\u201d \u2013 not clear what models mean here\n15.\tMissing references to datasets in the main text. At least reference to Appendix A.2 is required\n16.\t\u201cWe used 5,000 validation images split from each training dataset and chose the parameter that can obtain\u201d \u2013 which parameter? \n17.\t\u201cAll the hyperparameters of ODIN\u201d \u2013 a reader does not know yet that ODIN is used for comparison\n18.\t\u201cwhich consists of 100 OOD images from the test dataset and 1,000 images from the in-distribution validation set\u201d \u2013 it is a bit confusing to call OOD dataset as a test dataset in this context\n19.\t\u201cWe tuned the parameters of the CNN in Equation 4 using 50 validation training images taken from the 100 validation images. The best parameters were chosen by validating the performance using the rest of 50 validation images.\u201d \u2013 this is confusing. What parameters do the authors talk about in the second sentence if not the parameters of the CNN?\n20.\t\u201cWe used TNR at 95% TPR, AUROC, AUPR, and accuracy (ACC),\u201d \u2013 Some elaboration is required, at least the reference to Appendix A.1. What is the changing threshold for AUROC and AUPR? Why AUPR-In and AUPR-Out are considered and only a single AUROC is considered. What is the positive class for AUROC?\n23.\t\u201cFor LeNet5, we increased the number of channels of the original LeNet5 to improve accuracy\u201d \u2013 do the authors mean that they allowed RGB images as input rather than greyscale? If yes, this explicit explanation would be preferable \n24.\t\u201cWe inserted the reparameterization trick\u201d \u2013 not the best word choice. Reparametrisation trick is a computational/implementation trick/method and it is hard to say that it can be inserted into a network. I believe what the authors mean is that they inserted mean/std outputs instead of point outputs. Conceptually, this means that the output of the corresponding layers is considered to be stochastic rather than deterministic. \nAlso, it is unclear when the authors say they insert it to the softmax layer. According to Section 3 the softmax layer is never considered to output means and stds.\n25.\tThe numbers of epochs for training NNs are very small for LeNet and WideResNet in the experiments. Did the models manage to converge during this short training?\n\nMinor:\n1.\t\u201cThese data were also used\u201d -> \u201cthis data\u201d"}