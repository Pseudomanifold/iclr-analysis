{"rating": "3: Weak Reject", "experience_assessment": "I do not know much about this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I did not assess the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper studies the relationship between Distributionally Robust Optimisation (DRO) and Chance-Constrained Optimisation (CCO). In particular, the paper finds that with a particular cost function and a series of approximations applied to both DRO and CCO, the two optimisation problems start to resemble each other. This enables the authors to relate the hyperparameters of CCO and DRO. The paper then concludes by a series of toy and real-world experiments demonstrating this relationship.\n\nI am currently leaning towards rejection. The main reasons are:\n\n(1) The paper does not seem to be a good fit with the aims of the conference. Instead of using standard statistical/ML terminology, it seems to be written for an audience with quantitative finance background. While some of the employed techniques could be of interest to the broader ML community, I am afraid most readers of the ICLR proceedings will not appreciate these insights due to the unusual terminology and framing of this paper which obfuscates the underlying theory. Relatedly, the authors claim that the main benefit of their discovered relationship between DRO and CCO is that it \u201copens a door for financial practitioners to interpret the radius parameter [of DRO] through parameters [of CCO] that are directly linked to investment  performance.\u201d While this statement may be appreciated by readers of a quantitative finance journal, it only left me wondering why not use CCO directly and not bother with the DRO relationship, if the \u201cinvestment performance\u201d interpretation is already embedded within CCO?!\n\n(2) I am not sure whether the amount of the contributions relevant to the ICLR community goes far enough beyond those made in the cited Gotoh et al. (2018) paper.\n\n(3) The paper is difficult to read with a significant number of grammatical errors (especially within the first two pages) and in contrast to its relative preciseness within the proofs section in the appendix, contains a noticeably high number of confusing or imprecise statements within the main body. \n\n\nMajor comments:\n\n- I would have liked to see more discussion of the o(eta_2^(n - 1)) from Lemma 3.2 and of the kappa(epsilon) approximations from sect.3.2. From your experiments in sect.4, it seems like the error introduced by the approximations can be quite substantial. If this is true, I am not sure how to interpret the results in sect.3.3. For example, one of the claims that you emphasise is that the approximation of CCO achieves better results than the approximation of DRO when both have finite optimal value (1st bullet point in thm.3.6). However the original formulations of both the DRO and CCO problems are intended to provide an additional set of guarantees about the obtained solution beyond how good is the value they achieve (robustness and low probability of negative return respectively) which AFAICT are not guaranteed to be satisfied by their approximate versions derived in this paper. Can you please clarify whether the approximate \nversions of DRO and CCO satisfy the original constraints and/or whether you can quantify by how much these can be violated?\n\n- On a related note, can you please clarify what do you mean by \u201coptimal value\u201d in sect.3.3? In particular, is it x^T mu for both (9) and (10), or do you take the value of the whole expression inside the curly braces in (9)?\n\n- Could you please provide some citations or discuss why you have chosen the particular set-up of experiments in sections 4.1 and 4.2?\n\n\nMinor comments:\n\n- In the abstract, you say \u201cBased on this non-robust reformulation, we then show that when a\nboundedness constraint is added to the investment strategy. The DRO problem\ncan be cast as a chance-constrained optimization (CCO) problem without distributional uncertainties.\u201d Wasn\u2019t this supposed to be a single sentence with a comma in the middle?\n\n- Can you please provide citation for the first sentence in the sect.1? Also, in the second sentence, by \u201ctrue\u201d distribution, do you mean population distribution?\n\n- In the 4th sentence in sect.1, I\u2019d recommend replacing \u201cit\u201d; e.g., you can say \u201cHowever, the estimates are often inadequate due to an insufficient number of available data points.\u201d\n\n- Last sentence of par.1 in sect.1, \u201cunder a scarcity of data\u201d -> \u201cwhen data is scarce\u201d.\n\n- Can you please provide a citation for the first sentence in par.2 of sect.1? Also can you please reword the very next sentence (particularly the phrase \u201ccontains distribution as uncertainty\u201d the meaning of which was unclear to me until sect.3.1)?\n\n- In par.2 of sect.1, within the statement starting with \u201cThe second way is the moment-based approach ...\u201d, I would suggest moving the words \u201cfor instance\u201d before the citations (i.e., \u201cwas studied for instance in \u2026\u201d).\n\n- There are many more places which are not entirely grammatical. To shorten my review, I will not include further comments related to grammar, and would instead strongly recommend that you proof-read the paper again please, particularly the abstract and sect.1.\n\n- In the 2nd sentence of par.3 in sect.1, you say \u201cAs a result, optimal solutions become meaningless ...\u201c while speaking about the moment-based and geometric approaches. Can you provide citation please? While I generally agree with the sentiment that we would like to ensure that the true distribution is within the ambiguity set with high probability, this is AFAIK not guaranteed even by the statistical approaches without further assumptions on the underlying population distribution (which allow to derive an appropriate setting of the diameter rho).\n\n- By the end of the introduction, the reader still did not learn what you mean by the \u201cnon-robust interpretation\u201d. Please consider either explaining this within sect.1 or removing all mentions within sect.1.\n\n- In the \u201cNotations\u201d paragraph within sect.2, does \u201cnominal probability distribution\u201d mean the same as what is commonly called the \u201cempirical distribution\u201d, or rather just any distribution  (not necessarily the empirical one) that you will use as the center of the ambiguity set?\n\n- In the \u201cphi-divergence\u201d paragraph within sect.2, please consider restating the expressions which include division by zero in terms of limits. Also, for the benefit of the reader, I would add that for the Radon-Nikodym derivative to exist, Q must be absolutely continuous w.r.t. P, and that if it exists then Q(A) = int_A dQ/dP dP for any measurable set A.\n\n- Please reconsider use of contractions throughout the paper (e.g., \u201cIt\u2019s defined by a convex \u2026\u201d -> \u201cIt is defined by a convex \u2026\u201d in the \u201cphi-divergence\u201d paragraph within sect.2).\n\n- In eq.1, it is somewhat strange to writhe P(dt) given the variable \u201ct\u201d does not appear anywhere in the integral. Please consider either writing int phi((dP / dQ)(t)) P(dt) or simply int phi(dP / dQ) dP.\n\n- On the penultimate line of p.2, you cite Glasserman and Xu (2014) for the name \u201calpha-divergence\u201d. I find this somewhat strange as alpha-divergences (or Renyi alpha-divergences) date back much further---see [1, 2]. On a related note, some of the other quoted examples like Hellinger distance and xi-squared distance are (up to a scaling factor) members of the alpha-divergence family.\n\n- In the \u201cMotivation\u201d section, you say that the CRRA utility function is ln(x^T r) when eta = 1; however, you did not constrain the vectors x and r to always have positive inner product (only constraint is x, r in R^n). Can you clarify please?\n\n- At multiple places, you use max and min instead of sup and inf but it is not entirely clear to me the optimum exists in all those cases. Some examples are the definition of the objective max_x E_r [f(x, r)] in sect.2 (with f an arbitrary measurable function), or of max_x min_P instead of sup_x inf_P in eq.2 (which AFAICT allows substitution of any phi-divergence?!). Can you please either switch to sup and inf or provide a justification for using the min and max operators where the existence of an optimum is not obvious?\n\n- Below eq.2 in the sentence starting with citation of Pardo (2005), is N supposed to be n? Also, I am assuming phi^{(2)} stands for the second derivative of phi (?), which should be probably better to state explicitly. Also, AFAICT you have only assumed \u201cphi\u201d is convex which implies differentiable almost everywhere, but does not imply phi is twice differentiable. Is this discussion restricted to the two choices for the phi function from tab.1? Please clarify.\n\n- Also in the paragraph below eq.2, you use the term \u201ccenter distribution\u201d likely to what you were referring to before as the \u201cnominal distribution\u201d. Perhaps it would make it easier for the reader if you chose to stick with single name?!\n\n- Please consider explicitly stating delta > 0, epsilon > 0 (or similar according to the intended use) somewhere around eq.3.\n\n- In the paragraph under eq.3, I cannot see where the abbreviation \u201cVaR\u201d was introduced?!\n\n- In the proof of thm.3.1, it would have been nicer if you explicitly commented on incorporating the L >= 0 constraint (which you eventually introduce with the convex conjugate of phi), and why dividing by eta_2 is ok in the second unnumbered equation after A.2. A subtler point is that by introducing L, you are implicitly assuming P is absolutely continuous w.r.t. P_0 which is in principle implied by the fact you are taking infinum over a phi-divergence ball of size rho (which only contains distributions that satisfy this condition), but never discussed explicitly.\n\n\nReferences:\n\n[1] A. R\u00e9nyi, \u201cOn measures of entropy and information,\u201d Fourth Berkeley symposium on mathematical statistics and probability, vol. 1, 1961.\n\n[2]  S. Amari, Differential-Geometrical Methods in Statistics. New York: Springer, 1985."}