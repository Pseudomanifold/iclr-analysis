{"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "N/A", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "Nice connections but novelty and practical takeaways unclear\n\nSUMMARY OF THE PAPER:\n\nThis paper views recent IWAE-based [1] methods (IWAE-STL [2], IWAE-DREG [3], RWS [4, 5]) for training generative models p and inference networks q under a common framework, AISLE.\nThis heavily relies on the \"double-reparameterization\" property by [2] and is restated in Lemma 1.\nThis framework makes it explicit that we're interested in\n1) maximizing the (log) marginal likelihood wrt p parameters, and\n2) minimizing some divergence between the posterior in the learned model to q.\n\nIn AISLE, IWAE-STL's q-gradient is viewed as a doubly-reparameterized self-normalized importance sampling (SNIS) estimate of KL(p || q).\nThis is in contrast to viewing it as a biased estimator of the IWAE's q-gradient.\nThis can potentially explain why it performs well when number of SNIS samples are increased.\nIt is also some evidence against the fact that having no unified objective is bad (because there isn't evidence of IWAE-STL diverging despite there being no unified objective).\n\nIWAE-DREG's q-gradient is viewed as a doubly-reparameterized SNIS estimate of X-divergence(p || q) (up to multiplicative constant of the number of SNIS samples).\nThis is in contrast to viewing it as an unbiased estimator of the IWAE's q-gradient.\n\nThe view on RWS is unchanged: the q-gradient is a SNIS estimate of KL(p || q).\n\nFor me, the main contribution is viewing IWAE-STL and IWAE-DREG q-gradient estimators as biased gradients of an explicit divergence rather than of the IWAE objective.\nI also found the observation that the signal-to-noise (SNR) decrease in IWAE's q-gradient can be proved by noting that it is a SNIS estimator of a zero vector nice.\n\nSTRUCTURE:\nThe article is well-written and easy to understand.\n\nNOVELTY:\nA different view on IWAE-STL and IWAE-DREG is interesting and novel (as mentioned above).\nThis means that IWAE-STL and IWAE-DREG are good not only because they reduce gradient variance (as previously understood) but also potentially because they directly target a divergence.\nViewing generalization of RWS as a main contribution (first bulletpoint of Section 1.2: \"...we show that AISLE admits RWS as a special case.\") is a bit of a stretch since this generalization is very straightforward from the way RWS is formulated.\nThe recommendation of using RWS-style algorithms over IWAE as given in the abstract (\"we argue that directly optimising the proposal distribution in importance sampling as in the RWS algorithm is preferable to optimising IWAE-type multi-sample objectives) is also not novel since this is also advocated by [5] (section 3.2: \"This makes RWS a preferable option to IWAE for learning inference networks because the phi updates in RWS directly target minimization of the expected KL divergences from the true to approximate posterior\").\nThe recommendation as a method for non-reparameterisable latent variables at the end of section 1.2 (\"as well as further algorithms which do not require reparameterisations\") is also given in [5].\nAre there different adaptive importance sampling algorithms that could be used within AISLE that would improve on IWAE-STL/IWAE-DREG/RWS?\n\nEXPERIMENTS:\nThere are no experiments in the main paper.\nHowever, experiments that would support/falsify the following points could be good:\n- RWS and IWAE-STL don't suffer from non-unified objectives because IWAE-STL has non-unified objectives but doesn't diverge,\n- [targeting direct divergence] is more useful than (or as useful as) [lower variance gradient estimators].\n\nCONCLUSION:\nWhile I really like the presentation and connections made in the paper, I'm not sure what the practical takeaways are (other than use IWAE-STL, IWAE-DREG, RWS over IWAE which is advocated by [2], [3], [5]).\nI'm giving this a weak accept due to the former.\nI'm willing to bump up my score if\n- the paper is modified to more accurately reflect the contributions or\n- there are experiments that provide additional support for the [targeting direct divergence] view in addition to [2, 3, 4, 5], or\n- there is a new practical algorithm that the AISLE generalization would suggest that is better than IWAE-STL, IWAE-DREG, RWS in some respects.\n\n[1] Importance Weighted Autoencoders. https://arxiv.org/abs/1509.00519\n[2] Sticking the Landing: Simple, Lower-Variance Gradient Estimators for Variational Inference. https://arxiv.org/abs/1703.09194\n[3] Doubly Reparameterized Gradient Estimators for Monte Carlo Objectives. https://arxiv.org/abs/1810.04152\n[4] Reweighted Wake-Sleep. https://arxiv.org/abs/1406.2751\n[5] Revisiting Reweighted Wake-Sleep for Models with Stochastic Control Flow. https://arxiv.org/abs/1805.10469\n[6] Variational Inference via \u03c7-Upper Bound Minimization. https://arxiv.org/abs/1611.00328\n[7] Tighter Variational Bounds are Not Necessarily Better. https://arxiv.org/abs/1802.04537"}