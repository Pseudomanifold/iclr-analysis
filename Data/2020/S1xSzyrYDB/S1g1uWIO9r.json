{"rating": "6: Weak Accept", "experience_assessment": "I do not know much about this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper proposes a machine learning framework for periodic data. The authors note that representing input data in vector form does not encode input coordinates relationship to one. Capturing this structure can be especially important for periodic signals. The authors address this by adding graph structure to each data point to encode relative structure about each coordinate. They then apply a graph neural network to the resulting structured data. They evaluate the method on an anomaly detection in a low data setting.  \n\nThis paper would be greatly improved by an addition of a related work section. It is unclear where the novelty comes in precisely in this work because it is not very well situated within previous work on (i) anomaly detection w/ periodic signals, (ii) temporal and periodic signal processing and (iii) graph neural network approaches. Contextualized this work within these related areas would improve the clarity and readability of the work and also help frame the results. \n\nThe method is evaluated on synthetic and real datasets, comparing a couple variants of the model (one that can deal with phase shifts). Results support the main claims of the paper.\n\nIt is hard for me to assess the significance of this work since this is a very specific application of known techniques. I think the application is an important one, and also one that requires some domain knowledge, so there does appear to be a useful contribution in terms of adapting graph-based methodologies here. However, the methodology and application is outside my area of expertise.\n \nDetailed suggestions / questions / comments:\n- the ws-dimensional \u00a0vector v_i is defined as v_i = (x_{(i\u22121)\u2217ss+1}, x_{i+1}, . . . , x_{(i\u22121)\u2217ss+ws}). Is there a typo here? It's not obvious to me how the second index relates to the sequence or how this sequence is specified? Perhaps it should say \u00a0v_i = (x_{(i\u22121)\u2217ss}, x_{(i-1)*ss+1}, . . . , x_{(i\u22121)\u2217ss+ws})?\n\u00a0- The authors mention alternative methods of capturing structured temporal information in the input features. For example, they suggest concatenating the original signal with the cross correlated signal. They also suggest time-frequency analysis methods (such as a Fourier transform and the wavelet transform) and applying a CNN to the time-frequency signal. They authors mention that these methods would require much more data than their graph convolution approach. I agree this is probably the case, but this would still be a useful empirical result to show the degree of data required for these alternative. \n- What are previous approaches to detecting the properties explored in this work? In addition to discussing previous approaches in a related work section, some empirical analysis comparison would help contextualize this work as well. \u00a0\n\nOverall, I think this paper is a useful application of graph-based methods. The claims are verified empirically on real and synthetic data. I think it could be significantly improved with a discussion of related work and better situating of the methods / more comparisons in the results. As a result of these significant weaknesses I'm really on the fence with my recommendation -- the work is sensible but the paper has a lot of room for improvement and I'm not quite sure its ready for publication. However, it is possible underestimated the significance/impact of this work because I am not very familiar with the topic."}