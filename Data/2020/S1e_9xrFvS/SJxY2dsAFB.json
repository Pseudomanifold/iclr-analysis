{"experience_assessment": "I have read many papers in this area.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "Summary of the paper\n\nThe authors propose a predictive model based on the energy based model that uses a Transformer architecture for the energy function. It accepts as input an atom and its neighboring atoms and computes an energy for their configuration. The input features include representations of physical properties (atom identity, atom location within a side chain and amino-acid type) and spatial coordinates (x, y, z). A set of 64 atoms closest to the beta carbon of the target residue are selected and each is projected to a 256-dimensional vector. The predictive model computes an energy for the configuration of these 64 atoms surrounding a residue under investigation. The model is reported to achieve a slightly worse but comparable performance to the Rosetta energy function, the state-of-the-art method widely used in protein structure prediction and design. The authors investigate model\u2019s outputs and hidden representations and conclude that it captures physicochemical properties relevant to the protein energy in general.\n\nStrengths\n+ A very interesting contribution to structural biology with a non-trivial application of deep learning.\n+ The study is accompanied with structural biology interpretation of the designed energy predictor. Usually similar studies do not attempt and are limited with prediction rates and mathematical analysis.\n+ Appropriate background is provided for non-experts in protein structural biology. The paper is clear and well written.\n+ An adequate literature review is provided relative to the problem. Bird-eye view is given for future direction with justified optimism.\n\nWeaknesses:\n- The study claims to provide an energy predictor in general while training is performed on rotamer recovery of a single amino acid. These claims should be downplayed and what was shown at most is that this predictor can be applied to predict energy for a restricted problem of the rotamer recovery task. \n- A reader gets a wrong impression at the beginning of the manuscript that the study tries to solve general and classical rotamer prediction for an entire protein. It becomes clear only at the very end that the study does not try to resolve all rotamer conformations in a protein, it can only predict one rotamer at the time given the atoms surrounding the target residue are correct. This should be explained in the beginning that the study does not attempt combinatorial side chain optimization for a fixed backbone;\n- In-depth description of the neural network is required at least in supplemental materials, so that the study could be replicated. Ideally, a working application and training protocol code would be available.\n- No techniques against overtraining are discussed. How was the model validated?\n\nSmall issues:\n* function f_theta(A) is used before it is introduced. \n* noun is missing: using our trained with deep learning.\n* articles missing: that vary from amino acid to amino acid.\n* KL abbreviation not explained\n* MCMC abbreviation not explained\n* wrong artile:  that processes the set of atom representations.\n* misprint: resolution fine r than 1.8\n* wrong word, has to be \u201clower\u201d: sequence identity greater \u02da\n* everyday word: break out\n* abbreviation not explained: t-SNE\n* misprint case: Similarly, In contrast to our work\n"}