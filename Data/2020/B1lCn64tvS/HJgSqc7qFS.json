{"rating": "8: Accept", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper investigates the problem of learning new branching heuristics in SAT solvers. The idea is very simple: take MiniSat, remove the usual VSIDS heuristic, and replace it with a variable selection policy that has been trained from a deep reinforcement learning algorithm. The architecture advocated in the present study is based on GNNs coupled with usual DQN techniques. The resulting GQSAT heuristic is endowed with attractive properties: on random SAT instances, it outperforms VSIDS and generalizes relatively well to other SAT distributions. \n\nOverall, this is a very interesting paper. It is well-written, well-motivated, and well-positioned with respect to related work. The conceptual idea is simple and elegant, the choice of the graph-based DQN architecture is relevant, the experimental protocol is well-detailed, and the experimental results look promising. To sum up, I have no major reasons for not accepting this paper. \n\nSome potential improvements:\n\n(a) Obviously, the decision model for GQSAT is an \u201cepisodic\u201d MDP. It would be relevant to emphasize this aspect by presenting episodic MDPs (instead of standard ones) in Sec 2.2. \n(b) States representations only encode SAT formulae (using Q-labeled incidence graphs). Although this is a conceptually simple idea, GQSAT could exploit additional information provided by MiniSAT (e.g. number of propagations, number of clauses which have been learned, etc.). I am wondering whether such \u201csolver features\u201d in state representations could improve the GQSAT heuristic, and could help in generalizing from a class of SAT problems to another one. \n(c) The notion of \"terminal state\" is a bit ambiguous. Since the number of actions per episode is capped, a terminal state can be a leaf of the MiniSat search tree (where a satisfying assignment was found, or a dead-end was reached), or an internal node of the tree (when the maximum number of actions per episode was reached). \n"}