{"experience_assessment": "I have read many papers in this area.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "N/A", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review": "\nThe author question an important aspect which is very often taken for granted in the RL community, that a good representation could lead to data-efficient RL. They show negative results, providing pessimistic lower bounds for both value-based and policy-based learning.\u2028\u2028\n\nI believe the paper is an important contribution, in particular, it has the following advantages:\n\n\u2028- Well written, clear, and nicely structured. It is self contained, with main results and convincing sketch proofs provided in the main body of the document, and extended technical proofs made available in the supplementary material.\n\n\u2028- Authors provide the relevant related work and elegantly show how their work connects to the existing literature. \u2028\n\n- The notation is consistent throughout the document, with necessary assumptions clearly stated. \u2028\n\n- The discussion highlights important findings, in particular the difference between value-based and policy-based learning. Additionally, it offers some hope for sample-efficient RL, by discussing the exponential separation between policy-based RL and imitation learning, reminding the community that sample-efficient RL can still be achieved by IL even if it can\u2019t be achieved through good-but-not-perfect representation. \n\n\u2028\u2028\u2028Minor comment:\u2028- Phrasing of Assumption 4.3 seems to be off."}