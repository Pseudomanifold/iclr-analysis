{"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "* Summary\n\nThe work considers sparse and short blind deconvolution problem, which is to inverse a convolution of a sparse source (such as spikes at cell locations in microscopy) with a short (of limited spatial size) kernel or point spread function, not known in advance. This is posed as a bilinear lasso optimization problem. The work applies a non-linear optimization method with some practical improvements (such as data-driven initialization, momentum, homotopy continuation) and applies it to 3 real imagine problems.\n\nI think the work can be described as bridging from the known problem formulation, available theoretical understanding of its properties and available selection of optimization methods, to an implementation that can be applied in practical cases. The practical improvements made are not specifically novel, but result in a well-fit optimization method.\nOn the practical end, it is shown that the method can be applied in multiple cases but it is not demonstrated to give practical improvements over any alternative reconstruction approaches. The emphasis is more on showcasing possible further extensions (many deferred to appendices). I view this work as not very strong but a valid contribution.\n\n* Detailed Comments\n\nWhile the ideas from a provable algorithm by Kuo et al. are used here (sphere constraints, data-driven initialization), can the authors show in their setting, this leads as well to optimal recovery guarantees for sufficiently simple problems?\n\nSomehow the discussion advocates spherical constraint, because different shifts of the kernel become different local minima. But at the same time, this increases the non-linearity of the problem, and thus makes it more difficult to solve. Although, these multiple local optima provide equivalent solutions, I find this somewhat counter-intuitive. Cannot the shift ambiguity be resolved in a convex manner, e.g. by fixing the mean value of the kernel?\n\nIn Fig 1 an explanation of the axis and projections would be needed.\nWhile in the introduction, the setting m>>p0 is assumed, in the experiments n0 is used to denote kernel width and some experiments actually work in the setting of comparable values such as n0=50, m=100.\n\nWhat are similarities / differences to related reconstruction problems such as non-negative matrix factorization with sparseness constraints?\n\n"}