{"experience_assessment": "I have published in this field for several years.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "*Summary* \n\nThis paper study the convergence of Hamiltonian gradient descent (HGD) on minmax games. The paper show that under some assumption on the cost function of the min max that are (in some sense) weaker than strong convex-concavity. More precisely, they use the \u2018bilinearity\u2019 of the objective (due to the interaction between the players) to prove that the squared norm of the vector field of the game follows some Polyak Lojasiewicz condition. Thus the proof is concluded by the linear (resp. sublinear) convergence of gradient descent (resp. stochastic GD) under PL assumption.\n\n*Decision*\n\nI think that is work is clearly very interesting. The fact to prove linear convergence rate without strong-convex-concavity is quite surprising. And this paper brings nice tools to analyse HGD. Also the result on Stochastic HGD is very interesting.\n\nHowever, I am wondering whether this paper is perfectly suited to ICLR conference due to the lack of experiment, practical implication given by the theory, or theory in the non-convex setting (I know that the latter is a huge open question and I am not criticizing the absence of theory in the non-convex-concave setting).\nOne way to improve to work would be to provide practical takeaways from the theory or to provide experiments in the main paper. \n\nRegarding the practical limitation of this work: \n- the sufficient bilinearity condition are hard to meet in practice. (even for convex-concave problems)\n- In a non-convex-concave setting, Hamiltonian gradient descent is attracted the any stationary point, even \u201clocal maxima\u201d (or the equivalent in the minmax setting). Making this algorithm not very practical. (However, CO is)\n\nHowever, I really think that the community is currently lacking of understanding on minmax optimization and that we need better training method in many practical emergent frameworks that are minmax (such as GANs or multi agent learning). That is why, I would vote for a weak accept.  \n\n*Questions* \n- What are the practical implication of your work ? for instance does it say anything on how to tune $\\gamma$ for CO ?\n\n*Remarks*\n- It is claimed that Theorem 3.4 gives the first linear convergence rate for minmax that does not require strong-convex or linearity. Note that, recently [1] seem to propose a result on extragradient in the same vein (i.e. without strong convexity or linearity).\n- (Minor) $\\alpha$ not alway have the same unit: Thm 3.2 it is proportional to a strong convexity and in Lemma 4.7 it is proportional to a strong convexity squared (actually the PL of the squared norm of the gradient). For clarity it might be interesting to use the notation $\\alpha^2$ in Lemma 4.7. The same way for unit consistency I would use $L_H^2$ instead of $L_H$\n\n[1] Azizian, Wa\u00efss, et al. \"A Tight and Unified Analysis of Extragradient for a Whole Spectrum of Differentiable Games.\" arXiv preprint arXiv:1906.05945 (2019).  "}