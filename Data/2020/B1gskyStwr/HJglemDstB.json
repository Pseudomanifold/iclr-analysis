{"rating": "6: Weak Accept", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "Summary:\nThis paper basically built upon [1]. The authors propose to do sampling in the high-frequency domain to increase the sample efficiency.  They first argue that the high-frequency part of the function is hard to approximate (i.e., needs more sample points) in section 3.1. They argue that the gradient and Hessian can be used to identify the high-frequency region. And then they propose to use g(x)=||gradient||+||Hessian || as the sampling metric as illustrated in Algorithm 1. To be noticed that, they actually hybrid the proposed metric (6) and the value-based metric (7, proposed in [1]) in their algorithm.\n\nStrength:\nCompared to [1], their experiment environment seems more complicated (MazeGridWorld vs. GridWorld). \nFigure 3 shows that their method converges faster than Dyna-Value.\nFigure 5 is very interesting. It shows that their method concentrates more on the important region of the function. \n\nWeakness:\nIn footnote 3: I don't see why such an extension is natural.\nIn theorem 1, why the radius of the local region has to be?\nTheorem1 only justifies the average (expectation) of gradient norm is related to the frequency. The proposed metric $g$, however, is evaluated on a single sample point. So I think if adding some perturbations to $s$ (and then take the average) when evaluating $g$ will be helpful.\nThe authors only evaluate their algorithm in one environment, MazeGridWorld. \nI would like to see the experiment results of using only (6) as the sampling rule. \nWhat kind of norm are you using? (||gradient||, ||hessian||)\nWhy $g$ is the combination of gradient norm and hessian norm? What will be the performance of using only gradient or hessian?\nFigure 4(b), DQN -> Dyna\n\nReference:\n[1] Hill Climbing on Value Estimates for Search-control in Dyna"}