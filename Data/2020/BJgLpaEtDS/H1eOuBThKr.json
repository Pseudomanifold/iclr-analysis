{"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "In this paper, the authors proposed a Poincare Wasserstein autoencoder for representing and generating data with latent hierarchical structures. \nThe proposed model extends the Wasserstein autoencoder to the hyperbolic space. It is a new and powerful member of the family of VAEs. \nA hyperbolic Gaussian reparametrization method is designed and a Wasserstein loss with MMD regularizer is applied as an objective function.\nThe paper is well-organized and easy to read. The notations are clear. \n\nOverall, I think this work is interesting. My main concern is about the experiments. \nThe results on MNIST is not sufficient to demonstrate the usefulness of the proposed method. \nAs the authors mentioned, a potential reason is that the MNIST is not a typical hierarchical dataset. \nI suggest adding experiments on real-world hierarchical datasets, e.g., representing/generating sentences (which can be viewed as trees of words) or articles (which can be viewed as trees of sections/subsections)."}