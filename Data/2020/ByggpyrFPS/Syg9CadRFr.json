{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper leverage probabilistic inference techniques to maintain a posterior distribution over the parameters of a variational autoencoder (VAE). This results in a Bayesian VAE (BVAE) model, where instead of fitting a point estimate of the decoder parameters via maximum likelihood, they estimate their posterior distribution using samples generated via stochastic gradient Markov chain Monte Carlo (MCMC).\nThe informativeness of an unobserved input x* / latent z* is then quantified by measuring the (expected) change in the posterior over model parameters after having observed x* / z*.  The motivation is clear, when considered inputs which are uninformative about the model parameters, they are likely similar to the data points already in the training set. In contrast, inputs which are very informative about the model parameters are likely different from everything in the training data.\n\nThe contributions are:\n- A Bayesian VAE model which uses state-of-the-art Bayesian inference techniques to estimate a posterior distribution over the decoder parameters.\n- A description of how this model can be used to detect outliers both in input space and in the model\u2019s latent space.\n- Results showing that this approach outperforms state-of-the-art outlier detection methods.\n\nThe paper is well written, and the proposed ideas are well motivated.\nHowever, the experiment section is too limited. The authors should at least use one more dataset such as CIFAR10. They just use FashionMNIST vs MNIST FashionMNIST (held-out).\nIn addition, it would strengthen the paper if the authors could show at least initial result about how the model performs to detect out of distribution in the latent space, given that it is considered as part of the contribution.\n\nThe paper lacks some references such as:\n- Predictive uncertainty estimation via prior networks, NEURIPS 2018.\n"}