{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "The paper advocates to use information gain to detect whether a sample is out of distribution. To that end, a Bayesian VAE is introduced for which that quantity is tractable. The experiments show a solid improvement over previous methods.\n\nI like the paper, but I have a few questions. I am more than willing to increase my score from weak reject to weak or strong accept if these are addressed properly.\n\nWhat is the relationship of information gain to the marginal likelihood of the data? Since both can be expressed in entropies, I can see a very strong relationship, but would enjoy the authors opinion here\u2013what exactly is it that gives the edge?\n\nThe experiments report results on the likelihood based score. Were these results taken from previous publications or obtained from exactly the same pipeline?\n\nWhy is the \"outlier in latent space\" section included even though it is not experimentally verified? I think it should go, as conducting experiments is cheap in ML. On the other hand, if we cannot come up with an experiment to conduct, then what is hypothesis is tested? I think the section needs to be removed and be revisited in future work.\n\nIs the method really principled? Where is the connection from the assumption that the score should be high for out of distribution and low for in distribution? If a method is called \"principled\" I want to see a rigorous derivation of how a method derives from what principles exactly and how it is approximated.\n\nSince only the 10 most recent samples are kept to represent the posterior, I am worried about their diversity. I think the authors should back up that this is sufficient to represent the posterior.\n\nWhat happens in the non-parametric limit, where the posterior will collapse to a point? Does the method not rely on an insufficiently inferred model?"}