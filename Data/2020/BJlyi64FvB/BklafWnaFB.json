{"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The authors observed that the wider deep neural networks can learn much rich representative features than shallower deep neural networks while both networks show similar level of the test performance. They show feature visualization about their observations using two different networks n=20/n=2048.\n\nAt the first, I feel that the visualizations on figure 1 about two different width are too marginal. Almost they look similar, it's hard to say that significantly show difference.\n\nAlso there is no guarantee that the quality of the feature visualization follows linear relationship according to width. Comparison with just two different width is not enough to analyze the situation.\n\nI wonder if human-interpretable features are always better. Machine-interpretable information also do important role, as adversarial attack.\n\nEven the total number of parameter is preserved, the performance will be largely vary according to the network architecture, such as the number of the layers. Then, I have a doubt whether experiments on Sec 5.1 are meaningful not. More, the model can suffer from the gradient vanishing problem when the network has a number of layers. I wonder that the results on figure 4 are caused from this problem.\n\n\n\n"}