{"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This paper advertised the use of student-t prior, instead of the standard normal prior, in variational autoencoders. The authors listed a few candidates, including the diagonal and full covariance matrices. Several experiments on two datasets were then performed.\n\nIn general, this paper is confusing and difficult to follow. For example, the same terminology has different meanings across this paper. The novelty in this paper is also quite limited, as the main technical part is basically to list Equations (2) and (3) to show the KL divergence for normal and student-t distributions. Finally, the experiments need to be significantly improved, as there are not sufficient takeaways.\n1. The authors used the word \"prior\" to denote different distributions, e.g., p (z) and q (z | x). This is pretty confusing, as q (z | x) is usually treated as the posterior. In Table 1, the posterior was even described under VAE priors. It would be better for the authors to read the original VAE papers (e.g., Kingma & Welling, ICLR 2014) carefully to understand these terminologies: https://arxiv.org/pdf/1312.6114.pdf\n2. The contributions of this paper are far from sufficient: In Section 2, the main takeaway for me is the list of KL divergence from different distributions, which is pretty standard and difficult to be treated as the authors' own contributions.\n3. I feel confused about the purposes of Figures 2 and 3. First, they were solely focused on reconstruction tasks, which may not be interesting enough, especially on such a toy dataset. Furthermore, the standard deviations in Figure 3 were set to be one, which may not be fair for MVN-Diag, as Figure 2 suggests that one is a bad choice. As a result, it's not convincing to conclude that student-t is the best candidate.\n4. Again, the \"prior\" used at the top row of Figure 4 is difficult to understand. How did you compute the scale parameter and plot the figure? "}