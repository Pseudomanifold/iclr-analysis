{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review": "The paper introduces a method to self-supervised train a model for object detection/segmentation. The idea is that the background is easy to reconstruct while the foreground/object is hard. Experiments demonstrate the effectiveness of the proposed methods.\n\nHere are some high-level concerns.\n\n1. As mentioned in the \"Implementation details\", 'naive end-to-end training is difficult... we use ImageNet-trained weights for initialization'. This is worrisome to justify the effectiveness. It may be possible the imagenet-trained model has already captured salient objects. To justify the claims and effectiveness of the method, it should include a comparison with [R1], which demonstrates the possibility of doing detection with a pretrained model. Other work along this line should be also good reference.\n\n2. As a moving camera is available, it is also possible to segment background with frames through a 6DoF prediction on the camera, rotation and translation, e.g., [R2]. The supervision signal is from frame reconstruction through learning to predict both camera pose and pixel-level depth. This is also self-supervised learning. At least such a self-supervised trained model can act as an initialization.\n\nConsidering the above points, the paper does not appear compelling, due to lack of either careful claims or justification.\n\n\n[R1] Learning deep features for discriminative localization\n[R2] Unsupervised learning of depth and ego-motion from video"}