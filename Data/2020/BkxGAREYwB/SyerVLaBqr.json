{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper is about a method for estimation of parameters of a collection of HMMs and the main contribution is the  combination of classical EM with a neural net. \n\n+ I like the idea of generally approximating gradients in more specific layers that are usually not easy to compute. They clearly formulate their message here and the technical parts of adapting work from prior literature looks solid. \n- At the same time I don\u2019t know how much the computational constraints that are formulated are really constraints in practice. A couple of the related works that are cited don\u2019t seem to have these issues. Naively O(T^2) doesn\u2019t really sound like too much of a problem unless the sequences are really long. (In their practical example that isn\u2019t applied to more general recommender systems, this doesn\u2019t really seem to be the case. So it\u2019s unclear )\n+ The technical contribution of the gradient estimation seems sound. While I didn\u2019t really go through the proof of convergence, it at least looks rigorous. But I would have to spend a lot more time here to form a well informed opinion.\n+ The experiments on synthetic data are clear and further empirically motivate the authors\u2019 work. \n\nThe paper is very well written in some parts and in other parts is difficult to understand.\n\n- I am not sure what the benefit of the \u201ce-commerce\u201d application is to the community. The dataset seems to be neither open-source, nor referenced and is insufficiently described. The comparison and conclusion with respect to e.g. GraphSage is hard to interpret as GraphSage is neither explained nor referenced properly (unless I missed it somehow). The authors repeatedly emphasize that their approach works well here but not in the \u201cmore general recommender systems scenario\u201d. It would be good if the authors showed something that the rest of the community can directly relate to instead of something that is closed-source and by definition not reproducible. \n- I suppose \u201cWe apply DENNL in a clearly defined and fast-growing sector on OUR e-Commerce platform, namely Home Decoration\u201d is technically a violation of the blind review if the authors were to now include a reference/link etc. to the dataset. On the other hand, if the dataset remains closed-source then blind review isn\u2019t violated but results aren\u2019t reproducible and hard to follow by the community with the current level of description. \n\nIf the authors can comment about the last few points above (especially about open dataset, reproducibility) then I will reconsider raising the rating. "}