{"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper describes an approach to improve the confidence on deep\nneural networks (DNN). The proposed approach uses a distance-based\napproach (distance to prototypes) and train using a confidence\nmodel with the classification model using mis-classified examples.\n\nIt first learns using a loss function based on pre-computed centroids\nof each class evaluated from the training examples. At inference it\nassigns the class with the closest center.\n\nTo estimate a confidence level, it learns a new model to estimate the\ndistance using only the misclassified examples.\n\nThe authors experimentally showed the benefits of the proposed approach\nover several methods.\n\nFinding prototypes and training with distances, on one hand, and\nevaluating confidence with Gaussian, on the other, assumes\nthat the classes are \"well defined\". Although the authors show\npromising results, it is not clear how well the proposed method will\nbehave in more challenging classification tasks where the classes are\nmixed.\n\nAlthough the authors show that estimating the confidence with\nmisclassified examples works better I will like to see a further\nanalysis in the paper.\n"}