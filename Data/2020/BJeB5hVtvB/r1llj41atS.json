{"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "Summary:\nThe paper proposes a method to do confidence calibration for deep neural networks. It uses standard\nepisodic training for prototypical networks, and first shows empirically that the distances of the\nembedded test point to its ground truth class center embedding (*not* the predicted class embedding)\nare indicative of the confidence of the prediction. Further it proposes to exploit this by training\nan auxiliary confidence prediction MLP carefully. To do so they demonstrate that the training needs\nto be done of erroneously predicted training examples cf. all the traning examples. They show\nresults with MLP+MNIST, VGG11+CIFAR10, ResNet50+CIFAR100 and ResNet50+TinyImageNet.\n\n\nDetailed comments:\nThe paper is interesting but largely empirical. It shows empirically that:\n1. when prototypical networks (and episodic training) is used the distance of test example to true\nclass center reflects the confidence.\n2. this does not hold when `vanilla' training is used\n3. an auxiliary MLP can be used to learn to predict this while training only with erroneously \nclassified training examples cf. all training examples\n                                      \nThe results are reported on three networks (MLP, VGG11 and ResNet50) on different benchmarks of \nimage classification. The confidence prediction improvements wrt baselines are non trivial, while \nkeeping the accuracy similar, and the computation cost lower than competing methods. Ablations \nstudies are also convincing.                    \n            \nI would have two broad critical comments on the paper:\n1. Would this generalize to other image classification tasks and datasets. Generally distance\n(embedding) based networks perform less than softmax based networks on bigger datasets, so an\nimmediate disadvantage if that happens, is that you would be trading off accuracy cf. vanilla\nnetworks, for better confidence prediction using the required distance based network here.\n2. The vanilla training is never formally detailed. I am assuming it was softmax + cross entropy loss \nwith gradient descent. Would some other loss be helpful? Specially the metric learning based losses like \ncontrastive or triplet losses come to mind, since they are also distance based. Does the method work\nwith prototypical networks only or it generalizes to other distance based methods as well?\n                                                                                    \nMinor comments:\nThe notations are a bit confusing sometimes, and require going back and forth a bit. Eg. \\mu is used\nfor representation of feature (Eq4) while it usually denotes a mean of some sort (so the reader's expectation\ncould be that it represents class center). Similarly, boldface p is used for class centers, which is\nagain a bit confusing as being a probability of some sort. In general the notations are different\nfrom the original prototypical networks paper (which I needed to revise); keeping them similar would\nhelp the reader. The contribution of the present paper is more than that anyway.\n\nThe erroneously classified training examples are called errors (eg. just before eq8). By errors one\ncould think that it is a difference between some sort of prediction and the ground truth. Explicitly\ncalling them erroneously classified training examples would help the reader as well.\n\nThe notation \\odot is not explained (before eq.9).\n"}