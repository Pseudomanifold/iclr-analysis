{"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper addresses the task of evaluation of point-based architectures for deep learning, aiming at establishing the contribution of various architectural blocks (e.g., local density reweighting) to a number of desirable properties of the resulting models (such as adversarial robustness, rotation robustness, etc.). To assess the influence of such blocks on the resulting models, authors formulate and test a variety hypotheses while measuring model performance using a number of existing measures, such as information discarding/concentration, etc. \n\nI believe the paper cannot be accepted in its present form, as (1) no clear motivation for the work is presented, (2) the problem statement and the research questions are very blurry, and consequently (3) the results do not provide significant new knowledge related to the point-based neural architectures.\n\nWhile the specific architectural choices do influence the characteristics of commonly used models and a systematic evaluation of the former is indeed useful for practice, the paper does not indicate a particular application context, which I believe is crucial to the entire following narrative. Do the authors aim at evaluating in the recognition/labeling context? In the synthesis context (e.g., novel shape synthesis, completion, or upsampling)? In the geometry processing context (normal estimation, patch decomposition, or denoising)? Would the claimed hypothesis, let alone the results, even be formulated the same way, once one switches to a different class of applications? If yes, it would be hard to understand from the paper. If no, this could potentially diminish the value of the entire work significantly. \n\nIf the paper targeted a particular class of applications or simply a specific task, the hypotheses might have looked more natural; however, currently I find the motivation for these hypotheses rather vague. New insights into neural architectures or other models could emerge from (empirical and/or theoretical) regularities revealed by a purposeful experiment; however, the authors perform a seemingly random evaluation of point-based architectures which is of a fairly limited value per se. The reader might wonder: what is the exact problem that the study aims to address? Thus, I believe, a clarification of the problem statement and the basic research questions for the entire work is needed. \n\nThe paper does a good job of thoroughly presenting results of numerous computational experiments and values of the selected measures. However, as stated before, the results fail to provide significant insights into point-based neural architectures due to (1) lack of specific applications the authors are trying to solve and (2) arbitrariness of the chosen experiments lead to equally arbitrary conclusions. If \u201carchitecture of We et al., which uses local density information, improves adversarial robustness\u201d, what difference would it make? Would it open novel opportunities for point-based deep nets, and if yes, which exactly?\n\nOne minor additions is that since the paper focuses on empirical evaluation of machine learning models, significance measures such a statistical confidence intervals would be very useful to present in the results.\n"}