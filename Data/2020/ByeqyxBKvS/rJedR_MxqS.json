{"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "N/A", "review_assessment:_checking_correctness_of_experiments": "N/A", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper proposes a quantum computer-based algorithm for semi-supervised least squared kernel SVM. This work builds upon LS-SVM of Rebentrost et al (2014b) which developed a quantum algorithm for the supervised version of the problem. While the main selling point of quantum LS-SVM is that it scales logarithmically with data size, supervised algorithms shall not fully enjoy logarithmic scaling unless the cost for collecting labeled data is also logarithmic, which is unlikely. Therefore, semi-supervised setting is certainly appealing. Technically, there are two main contributions. The first is the method of providing Laplacian as an input to the quantum computer. The second contribution, which is about the computation of matrix inverse (K + KLK)^{-1}, is a bit more technical, and could be considered as the main contribution of the paper.\n\nMy main concern about the paper is on its organization. The paper provides a very gentle introduction to both semi-supervised LS SVM and quantum LS-SVM. While this helps readers to be equipped with relevant background, it is at the cost of having less space for the main contribution in Section 3.2. I would suggest to remove the content in page 2; most results about kernel methods are not really relevant to this paper. For a machine learning conference paper, one shall safely start with half-page intro in page 3. Some background in quantum computing offered in page 3, 4, 5 are quite nice, but for a conference paper, I think this is an overkill. I recommend providing the very minimal content needed to discuss Section 3.2, and then use more space to discuss the idea in 3.2 better. Specifically, Generalized LMR technique and Hermitian polynomials in Kimmel et al. (2017) could be discussed in more detail. "}