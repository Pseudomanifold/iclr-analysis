{"rating": "3: Weak Reject", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "Learning Latent Representations for Inverse Dynamics using Generalized Experiences\n\nIn this paper, the authors propose to utilize the symmetry property in locomotion problems (more specifically navigation problems), and more efficiently generate additional training data from existing data, and learns a more efficient representation.\n\nI tend to vote for rejection for this paper mostly because, while it seems to me to be a very efficient and practical engineering project, but relatively lack the novelty in terms of the algorithm.\n\nPros:\n- The experiments are of good quality, providing a lot of ablation studied and hyper-parameter specifications.\n- The proposed idea is combined with some of the state-of-the-art algorithms, showing it\u2019s compatibility and good practical performance.\n\nCons:\n\n- The proposed algorithm lack novelty.\nGoal conditioned reinforcement learning, where a generalized inverse dynamics is used, has been widely studied in [2, 3].\nAnd the use of symmetry has also been studied [1].\nThe augmentation of data by considering symmetry is relatively straight-forward.\n\n- limited to navigation environments\nThe proposed methods do not seem to be directly applicable to tasks other than navigation, where a very task-specific goal position can be provided.\n\n\n[1] Yu, Wenhao, Greg Turk, and C. Karen Liu. \"Learning symmetric and low-energy locomotion.\" ACM Transactions on Graphics (TOG) 37.4 (2018): 144.\n[2] Ding, Yiming, Carlos Florensa, Mariano Phielipp, and Pieter Abbeel. \"Goal-conditioned Imitation Learning.\" arXiv preprint arXiv:1906.05838 (2019).\n[3] Merel, Josh, Leonard Hasenclever, Alexandre Galashov, Arun Ahuja, Vu Pham, Greg Wayne, Yee Whye Teh, and Nicolas Heess. \"Neural probabilistic motor primitives for humanoid control.\" arXiv preprint arXiv:1811.11711 (2018)."}