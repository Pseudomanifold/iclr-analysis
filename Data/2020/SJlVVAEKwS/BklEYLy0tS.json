{"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "Authors propose a GAN-based adv imitation attack that can use less training data to produce a replica of the model.\n\nThe idea of using a GAN in producing adv examples in quite interesting. But the proposed approach is closely related to the following paper:\n\nhttps://arxiv.org/pdf/1801.02610.pdf\n\nTherefore, I am not sure about the novelty of the proposed approach.\n\nAlso can authors comment on the stability of GAN's training? Are any stabilizing methods integrated in GANs being used? \n\nHow does the proposed approach relate to the adversarial distillation literature? "}