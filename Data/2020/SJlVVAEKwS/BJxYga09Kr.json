{"rating": "6: Weak Accept", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This paper proposes a new approach to conduct adversarial attacks, where an imitation classifier is trained to mimic the behaviours of the targeted/attacked classifier and adversarial attacks can be generated with existing attack methods on the imitation classifier. The training of the imitation classifier only requires the predictions of the targeted classifier, which may fit better in practice with limited access to the targeted classifier.\n\nThe reasons that I am going towards accept are as follows:\n\n1. I feel that the idea of learning an imitation classifier is somehow novel and intuitive, which would improve the applicability of existing adversarial attacks in more realistic cases. In addition, using GAN framework in the training of the imitation classifier is also interesting.\n\n2. The experiments are quite comprehensive and promising, including the comparisons with gradient-based attacks as well as the decision-based attacks. In addition, the different model configurations of the imitation classifier are also reported.\n\nSuggestions:\n\n1. It is a bit unclear of the model configuration of the generator, which seems to be not introduced in details.\n\n2. It would be interesting to visualise what the generator generates.\n\nMinor:\n\n\"sometimes the ability of G is much stronger than G\""}