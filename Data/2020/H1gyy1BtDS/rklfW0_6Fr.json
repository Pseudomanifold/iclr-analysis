{"experience_assessment": "I do not know much about this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper extended the Gaussian Information Bottleneck method to the case of multi-view learning and provided a variation bound for the accuracy optimization with constrain on the sum of complexity. It also proposed an algorithm to learn the distributed representation without any prior knowledge of the data distribution.\n\nThe multi-view learning problem has been quite well studied in the literature. The paper reformulated the multi-view learning problem as a Bayesian inference problem and provided solid analysis for it.\n\nThe writing of the paper was pretty hard to follow for me, with a lot of notations that are not defined clearly. \n* For example, I can roughly guess that U in theorem 1 represent the learned descriptors, but what\u2019s the variable T in theorem 1?\n* What is \\Omega in Theorem 2?\n\nThe experimental result doesn\u2019t look very comprehensive at all as it was mostly compared with variations of the proposed algorithm and it doesn\u2019t include any other multi-view learning algorithms.\n\nThe algorithms in the experimental result are not very clearly defined. I don\u2019t see much explanation of what is exactly D-VIB and C-VIB. There\u2019s some formulation of the algorithm in Section 3.4, but it only gives a loss function briefly. I\u2019m not sure if many practitioners will be able to implement this algorithm from the description here.\n"}