{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "title": "Official Blind Review #4", "review": "The paper investigates the important problem of detecting changes in seasonal patterns, and proposes ATR-CSPD to learn a low-dimensional representation of the seasonal pattern and then detects changes with clustering-based approaches.  ATR-CSPD achieves improved results on part of synthetic and real-world datasets.\n\nThe paper may not have enough contribution to be accepted due to the following key concerns:\n  - The proposed model is not quite novel, and the design needs more justification.\n  - The empirical results are not strong enough to show the effectiveness of ATR-CSPD. \n\n# Model design\n\nThe idea of using auto-encoder with temporal smoothing to learn a low-dimensional representation of time-series need more justification.\n- What are the main intuitions of using an auto-encoder? e.g., removing anomaly or denoising. Why will it be easier for the model to detect the changes on the reconstructed time-series?\n- The temporal smoothing makes adjacent periods similar to each other. However, this may have side effects like low recall.  For example, in Figure 2(a), the pattern in Aug 17th (Sat) and that in Aug 18th(Sun) can possibly be different (i.e., a change in seasonal pattern), while the difference is smoothed out by the temporal regularization.  Is the model sensitive to the regularization, e.g., $\\lambda$? Why L1 regularization instead of L2 is used?  It will be helpful to provide more justification/intuition of the model design.\n- Why only the smoothness regularization between adjacent seasons is used? Other potential regularization includes penalizing the difference between the same phase in different seasons. \n\n# Assumption and limitation\nThe proposed method requires the seasonal period being provided, and also requires a large number of hyperparameters being specified, e.g., 1) the threshold of silhouette score, 2) the hidden representation dimension $q$, 3) the regularization coefficient, 4) $\\gamma, \\lambda$,  5) hyperparameters for constructing the encoder/decoder and 6) training the models.  \n\nRegarding the threshold of the silhouette score in the clustering step, is setting this hyperparameter easier than the number of clusters, i.e., the number of changing points?  Is ATR-CSPD sensitive to this parameter?  How this hyperparameter is tuned? Having too many hyperparameters (that are potentially non-trivial to set/tune) may make the proposed method less robust. \n\n# Experimental results: \nAccording to the results in Table 1, ATR-CSPD is mainly better at detecting Category C/D/E change points, which are mainly caused by changes of height/position of the spike.  However, it performs either similarly or worse than the other baselines on other tasks.  Besides, the lack of ground-truth data on NYC Taxi dataset and the Azure monitor dataset makes it hard to evaluate the effectiveness of the proposed algorithm. Moreover, only uni-variate time series tasks are investigated.  These issues may limit the application domain of the proposed algorithm. \n\n# Minor notation and presentation issues\n- In Definition 2, does CSPD assume F is the same in $G_k$ and $G'_k$? If not, CPD might be a subset of CSPD. \n\n- In Equation 1 and 2, $n$ is used to represent the number of observations, while in Definition 1, capital $N$ is used to represent the same concept.\n\n- In Figure 2, it might be easier to understand if all the weekdays are drawn using the same color (blue or green) and all the weekends are also drawn in the same color (yellow or red).", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}