{"rating": "6: Weak Accept", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "The paper tackles the problem of generating long-range, diverse and natural looking motion sequence between initial and end states, and proposes to use a semi-parametric approach consisting of local and global models. Specifically, first the proposed approach extracts local motion feature from a reference subsequence and style feature from another, and then generates a new motion sequence. Then, global motion composition is done to interpolated generated local subsequences by bi-directional composition. In experimental validation, the approach outperforms two baselines (GAN and VAE). \n\nThe proposed approach seems interesting and relatively novel, and technically sound. Also using disentangled representation of style and content is well-motivated. In addition, its generated motions look natural and visually appealing. However, the paper needs more thorough experimental validation to demonstrate its effectiveness better. First,  it was not quite clear which specific baselines were exploited. Are they simple VAE and GAN, or HP-GAN (Barsoum et al. (2018)) and MT-VAE (Yan et al. (2018)) ? And no animated sample of baselines was provided in the demo website. Additionally, in the global composition results, there is no other baseline except its own variants. Finally, even thought the provided figures and animated demos look appealing, it may be required to provide more qualitative results such as user study. \n\nWriting is fine but there were many typos and it may need more proofreading. Also it might need to add more detail in the presentation.\n\nDetailed comments:\n- Why is GAN better than the proposed model with 10% of training data in Fig. 3? Do you have any explanation about it?\n- The paper uses separate training of local and global models. But how about joint training of them?\n- Difference between style and content is sometimes not clear, for example, rightmost one in the last sample in the demo website. Could you add more constraint or model specification to induce more disentangled representation?\n- It is not quite clear if standard deviation is a good metric for motion diversity metric since visual diversity might not be directly correlated to standard deviation of joints (for example, some joints might be more important than others for inducing diversity.) \n\nTypos:\np4: lone-range one -> long-range one\np5: (Gupta et al.) -> (Gupta et al., 2018), (Zhao et al.) -> (Zhao et al., 2019), (Wang et al.) -> (Wang et al., 2019) \np6: Our works -> Our work\np7: Fig. 3: standard diviation -> standard deviation \np8: Recall that we representation -> Recall that we do representation?\np9: As shown in Fig 7(A) -> As shown in Fig 7(B)\np10: rout constrain -> route constraint, gravity constrain -> gravity constraint\n\n\nIn sum, I think the paper is at the borderline but it could be improved and better by having more through experimental validation and more detailed presentation."}