{"experience_assessment": "I have published one or two papers in this area.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper proposes a new estimator to infer the stationary distribution of a Markov chain, with data from another Markov chain. The method estimates the ratio between stationary distribution of target MC and the empirical data distribution.  It is based on the observation that the ratio is a fixed point solution to certain operators. The proposed method could work in the behavior-agnostic and undiscounted case, which is unsolved by the previous method.\n\nThis paper tackles an interesting problem with an increasing number of studies in the reinforcement learning community and gives a practical algorithm with strong empirical justification, as well as theoretical justification. I think this paper should be accepted.\n\nDetailed comments:\n1) This paper provides experiment results in multiple domains, including two continuous control domains which are more complex than experiments in previous OPE methods. The paper also provides many details about the learning dynamics and ablation studies, which is very useful for the reader to understand the result of the paper.\n2) The theoretical result is as same strong as previous work DICE and DualDICE, under similar assumptions.\n3) I appreciate this paper formalizes the two difficulties of degeneration and intractability, and then explain how those are addressed in a principled way. Degeneration is important and is at least ignored in two similar works on this topic."}