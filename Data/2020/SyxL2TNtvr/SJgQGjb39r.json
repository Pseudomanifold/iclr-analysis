{"rating": "6: Weak Accept", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #4", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This paper addresses the problem of unsupervised model selection for disentangled representation learning. Based on the understanding of \u201cwhy VAEs disentangle\u201d [Burgess et al. 2017, Locatello et al. 2018, Mathieu et al. 2019, Rolinek et al. 2019], the authors adopt the assumption that disentangled representations are all alike (up to permutation and sign inverse) while entangled representations are different, and propose UDR method and its variants. Experimental results clearly show that UDR is a good approach for hyperparameter/model selection.\nOverall, I think a reliable metric for model selection/evaluation is needed for the VAE-based disentangled representation learning. According to comprehensive experimental studies performed in this paper, UDR seems to be a potentially good choice.\n\nHowever, I am not sure if very good disentangled representations must benefit (general) subsequent tasks, though the authors provide experimental evidence on fairness classification and data efficiency tasks. Actually, the data generation process in the real-world may consist of different generative factors that are not independent of each other. Though good disentangled representation provides good interpretability, it needs not to be better than entangled representation for concrete tasks. Specifically, for concrete supervised classification tasks, VAE with beta smaller than 1 (not towards disentanglement) might be the best (Alexander A. Alemi et al. 2017, Deep VIB).\n\nAnother concern is about the choice of some key \u201chyperparameters\u201d.\nFor the KL divergence threshold in equation 3, you set it to be 0.01. It looks like the choice would control how much the UDR favors a \u201csparse representation map\u201d. The larger the value, the few \u201cinformative dimensions\u201d would be considered.\nIn supplementary material, you say that \u201cuninformative latents typically have KL<<0.01 while informative latents have KL >>0.01\u201d. Is this judgment based on \u201cqualitative feeling\u201d? For me, as you are contributing a ``quantitative measurement\u201d, it is interesting and important to see how this threshold would generally affect UDR\u2019s behavior in one (or more) datasets you have tried. \nAnother hyperparameter I cared is P (number of models for pairwise comparison). In the paper, you validate the effect of P in the range [5,45]. How would P smaller than 5 affect UDR? According to Table 1, if I was using UDR, I\u2019d rather using P>=20 (or at least 10) rather than 5.\nAlso, it seems to me P would grow up due to the size of factors that generate the data. Thus, I also have a little concern about the computation cost of the proposed metric (as also mentioned by the authors).\n\nOthers concerns:\n-- As a heavy experimental paper, most experimental results are in supplementary material, while the authors spent a lot of time in the main text explaining the conclusions found in other papers.\n-- To validate the fundamental assumption of UDR, the authors might consider to quantitatively validate that, disentangled representations learned by those approaches you used in the paper are almost the same (up to permutation and sign inverse). "}