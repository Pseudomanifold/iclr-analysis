{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper presents a model for effectively hierarchically \u2018searching\u2019 through the space of (continuously relaxed) FOL formulas that explain the underlying dataset. The model presented employs a three-level architecture to produce logic entailment formulas, skolemized with a set of skolem functions, i.e. \u2018operators\u2019. The three-level search, which is implemented via a stack of transformers, first searches through a space of variable and predicate embeddings to select operators, after which it searches through the space of predicates to form primitive statements of predicates and operators, and finally it generates a number of formulas from the previously \u2018selected\u2019 primitive statements. The model is applied on a toy task to showcase its speed, a knowledge base completion task, and modeling the visual genome dataset, where the model shows the ability to induce meaningful rules that operate on visual inputs. The presented benefit of the model is scalability, ability to induce explainable rules, and the ability to induce full FOL rules.\n\nThe paper is well motivated from the explainability perspective and based on the evaluation does what it claims. The model is fairly elaborate, yet manages to be faster than the competing models. In general, I think the model itself is a welcome addition to the area of neuro-symbolic models, especially logic-inducing models, and that the evaluation done is appropriate (with a few caveats). However, my major critique of the paper is in its clarity.\nIn the current state, the paper is quite difficult to read, partially due to its density, partially due to its confusing presentation, notational issues and missing details. It would be difficult to reimplement the model just by reading the paper, which brings me to ask: will you be releasing the code?\nI would be willing to accept the paper if the authors improve the notation and presentation significantly. I\u2019m enumerating issues that I found most confusing:\n\nResult presentation:\n- The figure captions are uninformative. In figure 1, one needs to understand what the graph is before reading the text at the end of the paper which explains what that is. It is not clear from the figure itself. Figure 2 presents the model, but it does not follow the notation from the main body of the paper.\n- Table 1 is missing SOTA models. TransE is definitely not one of the better models out there: check [2, 3, 4] for SOTA results which are significantly higher than the ones presented. I would not at all say that that invalidates the contribution of the paper, but readers should have a clear idea of how your model ranks against the top performing ones.\n- Please provide solving times for TransE, as it has to be by far the fastest method, given that it is super-simple.\n- Are provided times training or inference times (in each of the table/figure) because one gets mixed statements from the text?\n- In which units is time in Table 1?\n- Can you include partially correct or incorrect learned rules in Table 4? It would be great to get some understanding of what can go wrong, and if it does, what might be the cause.\n\nModel presentation and notation:\n- You mention negative sampling earlier in the text but then don\u2019t mention how you do it\n- Notation below (6) is utterly confusing and lacking: what is s_{l,i}^(t), is there a softmax somewhere, what are numbers below \u2018score\u2019\n- What is the meaning of e_+ and e_- given that you omit details of negative sampling?\n- The notation does not differentiate between previous modules well so there\u2019s V^(t-1) across modules, and it is not clear which one is used at the end --- last choice over V^(0) - V^(T) is over the LAST output, not the output from previous steps?\n- The notation in the text does not follow the notation in the figure (V_ps, V_\\phi)\n- Notation gets quite messy at some points, e.g. R^c^(0), is e_X and e_Y in H or not? Is H_b there too?\n- The differentiation of embedding symbols is not done well. H_b is an embedding for binary predicates, or a set of predicates? Does that mean that there is only a single embedding for a binary predicate and a single embedding for its operator (thought I thought that operators have an embedding, each)?\n- The explanation of what a transformer does is not particularly useful, the paper would benefit more from an intuitive explanation, such as that the transformer learns the \u2018compatibility\u2019 of predicates (query) and input variables (values), etc.\n- The \u2018Formula generation\u2019 subsection lacks the feel of fitting where it is right now, given that the notation in it is useful only in \u2018Formula search\u2019 paragraph. The other thing is that that subsection is wholly unclear: where do p and q come from, do they represent probabilities of predicates P and Q? How are they calculated? Does your construction imply that a search over the (p, q, a) space is sufficient to cover all possibilities of and/not combinations? In which case alpha is a vector of multiple values different for each f_s  in (5) or no? It is unclear \n- What is the relationship between alpha_0 and alpha_1, sum(alpha_0, alpha_1) = 1? Are alpha_0, and alpha_1 scalars, and how are they propagated in eq 5? Because if they\u2019re just scalars, the continuous relaxation of formulas represented in (5) cannot cover all combinations of p, q, not and and. What is the shape of the alpha vector?\np and q are probabilities of what, predicates P and Q? How are they produced?\n- are \\phi functions pretrained?\n\nRelated work:\n- I do not condone putting it into the appendix, but I\u2019m not taking it as a make-or-break issue.\n- It is notably missing an overview of symbolic ILP, and a short spiel on link prediction models (given that you compare your model to TransE, as a representative of these models)\n\nThe paper is riddled with typos and consistent grammatical errors. I would suggest re-checking it for errors. Examples include:\n- singular/plural noun-verb mismatches (rules..and does not change -> do, Methods ...achieves -> achieve)\n- Q_r^(t) - choice of left operands -> right\n- An one-hot -> a one-hot\n\n\nMinor issues:\n- The claim that the NeuralLP is the only model able to scale to large datasets is a bit too strong given [1]\n- You say \u201cWe could adopt\u201d but you \u201cdo adopt\u201d\n\nClarification questions:\n- Are 10 times longer rules of any use? Can you provide an example of such rules, a correct one and an incorrect one?\n- How many parameters does your model use? What are the hyperparameters used in training?\n- How big is T in your experiments, and why?\n- Why are queries only binary predicates?\n- How discrete do these rules get? You sample them during testing and evaluation, but are embeddings which encode them approximately one-hot, so that the (Gumbel-softmax) sampling produces the same rules all over again or are these rules fairly continuous and sampling is just a way to visualise them, but they are internally much more continuous?\n- Just to confirm, \\phi are learned, right? Given that they are parameterised with a predicate matrix, and that matrix is trainable?\n- Do you have a softmax on the output? It seems  f^*(T+1) should be a softmaxed value?\n- The rule generation generates a substantial number of rules, right? What might be the number of these rules? Does the evaluation propagate gradients through all of them or to a top-k of them?\n- Why is the formula in Eq.4 written the way it is. I assume it can be written differently, for example \u201cInside(\\phi_Identity(X), \\phi_Car())) and Inside(\\phi_Clothing(), \\phi_Identity(X))\u201d. I do not understand why Clothing was treated as an operator and Car as a predicate, while treating Inside both as an operator and a predicate. Sure, nothing in the model forces it to consistently represent a formula in the same way always, but an example such as this one would need a good explanation why you chose it or at least mention that this is but one way to present it.\n- Why is Identity(X) used? Is it because you did not want to mix in variable embeddings during the primitive statement search?\n\n\n[1] Towards Neural Theorem Proving at Scale\n[2] Canonical Tensor Decomposition for Knowledge Base Completion\n[3] RotatE: Knowledge Graph Embedding by Relational Rotation in Complex Space\n[4] TuckER: Tensor Factorization for Knowledge Graph Completion"}