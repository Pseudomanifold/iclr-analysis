{"experience_assessment": "I have read many papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper attempts unsupervised representation learning, via a patch prediction task on ImageNet. The paper is sparse on details, but the method appears to be: (1) split the image into non-overlapping visible and masked patches, (2) from features extracted from the visible patches, predict the masked patches. Rather than predict RGB, they choose to predict 2-bit grayscale images. Also, rather than use the full patches, they use random crops of the input ones, and a center crop of the output ones.\n\nThe paper seems to be an early draft of something bigger, submitted with the hope of getting some feedback. The method description is mostly composed of tiny details, such as the number and sizes of the patches; I recommend rewriting this to focus on the big idea first, and pack the details into another sub section like \"Implementation Details\". The paper barely includes any evaluation. Also, the method does not appear to be very novel: I recommend the authors look at and compare against \"Unsupervised Visual Representation Learning by Context Prediction\" (ICCV 2015), which is conceptually very similar.\n\nThe evaluation right now is not good. \"Unknown\" is not a valid point of comparison. I understand the code for CPC++ might not be released yet, but the authors could at least implement their best approximation of it, and also find older works (which CPC compared against in their paper), to fill out the results and make a convincing argument.\n\nIn Table 2, the proposed model performs worse than CPC++, yet its values are bolded anyway. Please only put the best-performing result in bold. "}