{"experience_assessment": "I have read many papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "The motivation of this paper is to use the idea of Transformer-based NLP models in image data, which is appreciated. However, this seems to be a far unfinished paper. The introduction part is well written. But, the method is not well described.  It is very unclear how exactly the model is built. Moreover, the network structure in Figure 2 is not explained.  The experimental part is very brief, and unconvincing. Much more investigations and comparisons are needed.\n\nMinors:\ndeicisons? \nmodel the only the most significant few bits -> model only the most significant few bits\nposition position embedding -> position embedding\n"}