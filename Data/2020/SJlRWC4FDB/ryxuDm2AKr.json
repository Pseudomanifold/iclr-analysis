{"experience_assessment": "I do not know much about this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This paper points out that the industrial copyright detection systems are susceptible to adversarial attacks and discuss the reason why these systems, especially the neural-network-based systems, are vulnerable to attacks. The authors describe a widely used music identification method and propose a simple gradient method to attack this system in this paper.  Specifically, the authors build a simple song identification method using neural network primitives and propose a differentiable surrogate loss to measure how close two fingerprints of audio are, which is used to generate the adversarial examples. And then they attack a song identification using the adversarial examples. \nThe authors conduct experiments to evaluate the proposed method. The white-box attack on their own model and the experiments on two real-world systems (AudioTag and YouTube) validate the effectiveness of the proposed method. The experimental results on AudioTag and YouTube seem impressive.\n\nWeak points:\nFrom my point of view, this paper is more like an application-oriented paper than a research paper. Because the main contribution of this paper is the results of experiments on a real-world system. Though the experimental results seem to support the justification of the model, this paper has limitations in terms of Model and Experiments.\n1.\tModel\na.\tThe description of the proposed model is not clear enough. The whole architecture of this model is not presented. The authors should describe how to generate the adversarial example more clearly.\nb.\tIn section 4.1.2, \u201cwe build a shallow neural network that captures the key ideas of Wang et al. [2003] while adding extra layers that help produce transferable adversarial examples\u201d. The Audio fingerprinting models proposed in the paper are quite incremental.\nc.\tThe proposed differentiable surrogate loss, which measures how close two fingerprints of audio are, should have more theoretical analysis to illustrate its reasonability or provide some analysis of the difference between adversarial examples and real examples.\n2.\tExperiment\na.\tThe results of the paper are hard to reproduce.  The detail of the model used in the experiment is not presented, such as how to train the model.\nb.\tThe authors should add more baseline or other intuitive methods to make the results of both the white-box attack and real-world more convincing.\n"}