{"experience_assessment": "I have read many papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper proposes a framework for neural architecture search which the authors\ndub Hurricane. They describe their approach and evaluate it empirically.\n\nAs far as I understood the presented approach, its main novelty lies in being\nable to take hardware characteristics into account when designing a network,\nwhich mainly manifests itself in reduced latency and prediction time on a\nparticular platform. The flip side of this approach is that hardware-specific\ninformation is necessary.\n\nThe overall approach is unclear in some places and not sufficiently motivated.\nFor example, what is the significance of the number 4 in algorithm 1? Is this\nsimply because 4 operators were chosen here? Why was this not made generic for n\noperators?\n\nThe paragraph that describes the reduction of the search space for each layer\nseems to imply that layers are configured largely independently, i.e.\ninteractions between layers are not taken into account. While this would\ncertainly lead to a reduction of the search space, it also potentially reduces\nthe performance of the final network.\n\nThe description of the latency models is unclear. In section 4.1, the authors\nmention that 21.84ms corresponds to 4.2% error, but the section after that\nmentions that the CPU latency is set to 310ms. It is unclear how the 4.2% were\ncomputed.\n\nIn summary, I feel that the paper cannot be accepted in its current form."}