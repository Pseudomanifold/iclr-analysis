{"rating": "3: Weak Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "In this manuscript, authors extend one-shot NAS with coordinate ascent. The motivation that different layers have different impacts on latency and accuracy is interesting. It implies that layers should be tuned individually. However, the developed algorithm cannot serve the purpose well. \n1.\tAuthors provides a large set of candidate operators for each layer, which enlarges the search space. However, the set is shrunk by an ad-hoc function before running NAS algorithm, which turns it to a standard NAS problem.\n2.\tThe algorithm applies the concept of coordinate ascent algorithm while they only divide the whole network into two parts. The simple splitting is not sufficient to illustrate the effectiveness of a coordinate ascent algorithm. Besides, the Fig. 2 in the Appendix C shows that the splitting will reduce the performance and the only benefit is the efficiency.\n3.\tThe performance on ImageNet is not state-of-the-art. For example, it is worse the the performance of MobileNetV3 under the similar FLOPS constraint."}