{"experience_assessment": "I do not know much about this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "In this paper, the authors raise and address three questions about graph neural network: (1) Whether there is a best filter that works for all graphs. (2) Which properties of the graph will influence the performance of the graph filter. (3) How to design a method to adaptively find the optimal filter for a given graph.\nThe paper proposes an assessment method called the Graph Filter Discriminant Score based on the Fisher Score. It measures how well the graph convolutional filter discriminate node representations of different classes in the graph by comparing the Fisher score before and after the filter.\nBased on the GFD scores of different normalization strategy and different order of the graph filter in the experiments on synthetic data, the authors answer the first two questions: (1) There is no optimal normalization for all graphs. (2) row normalization performs better with lower power-law coefficient, but works worse with imbalanced label classes and large density gap.\nFor the third question, the authors propose a learnable linear combination of a limited family of graph convolutional filters as the layer of model AFGNN, which can learn the optimal arguments of the combination based on the FGD score.\nThe paper focuses on a significant topic and proposes an assessment tool for the graph filters. Based on that, it also introduces a model to choose filters from a family of filters for any specific graph.\nThe description of preliminaries is clear.\nThe observations of the impact of the graph properties on the filter choice are interesting and explanations are provided.\nThe results of the test accuracy on both bench mark and synthetic datasets demonstrate the good performance of the proposed model.\nIt is good that the paper provides proof for the claim that the graph convolutional can help the non-linear separable data to be linearly separable, so it is reasonable to use Fisher score. However, does this claim support the second term in equation (3), where the Fisher score is used to evaluate before the filters applied?\nThe presentation of the last paragraph of \u201cgraph filter discriminant score\u201d in page 4 can be improved. The Figure references seem incorrect and confusing.\nThe analysis of the influence of label ratio seems not accurate enough.\nFor the GFD score comparison in Figure 4, why choose order 1,3,7 for density and different order 2,3,6 for density gap?\nWhat is the meaning of the symbol psi(l)?\nIt would be better if the explanation of the raining loss section is more detailed and clear.\nWhat is \u201cAFGNN_P\u201d in the experiment analysis?\nIt could be interesting to see the comparison of time between the proposed method and the GAT.\nFor the graph filter discriminate analysis, is it fair to compare the learned layer with the other base filter using the GFD score? Since the learned layer is picked with highest GFD score. Maybe one or two sentences on this will be helpful.\nThe writing of the paper must be improved. Too many typos and grammar problems will impair the presentation and the reader can be distracted.\nMinor comments:\nThe layout of the sub caption of Figure 1 can be improved.\nThe usage of capital letter in the phrase \u201cdensity gap\u201d is inconsistent.\n\u201cAs shown in figure\u201d instead of \u201cAs is shown in figure\u201d.\nMany sentences miss article.\nThere are many typos in the writing.\nFor example, \u201cNote that for given (feature)\u201d, \u201c\u2026make the representation of nodes in different (class) more separable.\u201d, \u201cNoted that there are some other (variant) of GNN filters that (does) not fall into\u2026\u201d in page 4.\n\u201cHere we give (a) empirical explanation to this phenomenon\u201d, \u201cthis normalization strategy (take) into account\u2026\u201d, \u201cThus even in the case that the other two (doesn\u2019t) perform well\u2026\u201d in page 5.\n\u201c\u2026a very important factor that (influence) the choice of normalization strategy\u201d, \u201cwhen power-law coefficient (decrease)\u201d, \u201cwhen the (sizes) of each class (become) more imbalanced\u201d,  \u201cThis is because column normalization better (leverage) \u2026\u201d , \u201cin a similar manner (with) label ratio\u201d, \u201cwhen the density or density gap (increase)\u201d, \u201chigh-order filters can help gather\u2026 and thus (makes) the representations\u2026\u201d, \u201cwhen the density gap (increase)\u201d in page 6.\nThese can be continued but it is obvious that this paper needs proofreading.\n"}