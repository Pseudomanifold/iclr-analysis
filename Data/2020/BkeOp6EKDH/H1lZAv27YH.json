{"rating": "3: Weak Reject", "experience_assessment": "I do not know much about this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "The paper proposed ``TriMap\u2019\u2019---a novel dimensionality reduction technique that learns to preserve relative distances among points in a triplet. The paper has done extensive experiments and presents the results in very nice visualizations. The paper is clearly written. \n\nMajor merits of this paper are: \n\n1. The proposed method seems effective. \n\nOn some datasets (e.g., S-curve), the learned low-dimensional embeddings indeed look very good. And the proposed method has much less runtime than other baselines as shown in table-1. \n\n2. The paper is well written. \n\nHowever, I am still leaning towards rejecting this submission because the proposed method is lack of necessary justification. \n\n1. Many important technical decisions on this method seem arbitrary, including the parametrization of functions (e.g., s, \\omega, \\zeta, etc) and values of hyperparameters (e.g., \\gamma and \\delta). For function forms, the authors should justify why particular parametrization has been chosen; for the hyperparameters, the authors should clearly explain how they are picked---maybe using domain knowledge or tuned on data? \n\n2. The argument for ``global score\u2019\u2019 is not clear enough. There are at least two points that need clarification. \n\nFirst, ``non-local\u2019\u2019 is not equal to ``global\u2019\u2019. The proposed method indeed considers non-local (or non-near) points while learning embeddings, which helps preserve non-local information. But I am not convinced that the preserved information is actually global. Maybe what helps is to first define ``global\u2019\u2019 in a dimensionality reduction context. \n\nSecond, the definition of ``global score\u2019\u2019 depends on another baseline method (i.e. PCA), which seems odd. A principled evaluation (or a score) should be method-independent. What seems right to me is to compute global score (i.e. how much global information has been preserved) by comparing to some statistics in the (high-dim) x space, not to another method. \n\nMoreover, the authors had a strong claim that the proposed ``GS is the only DR performance measure that can reflect this property\u2019\u2019---it doesn\u2019t sound right and why one can\u2019t just use another score which is monotonic wrt the proposed score? The authors mentioned that ``PCA has the lowest possible MRE\u2019\u2019---but this is only right up to the use of a linear transformation and F-norm, so this shouldn\u2019t be a justification for my questions above. \n\n3. What is the reason for the successful runtime? \n\nThe authors didn\u2019t clarify why the proposed method is theoretically faster than the baselines. \n\nWhat I noted is: the authors chose a subset \\mathcal{T} for the TriMap method and used \\mathcal{T} throughout the paper---is it a typo or is a subset always chosen? If the latter holds, then how was it chosen and how large is it compared to the training data used by other methods? In the end, is the proposed method faster because it uses less data? \n\nBesides the weakness above, I also suggest the authors evaluate their method with some extrinsic evaluations. What\u2019s currently used is only intrinsic---the embeddings are trained to preserve relative distances and are evaluated on a trade-off between local accuracy and the defined global score. It is fine because extensive visualizations are provided and readers can subjectively judge the quality of the learned embeddings. However, the experimental section can be stronger if the authors can show the learned embeddings are better at helping some downstream tasks than other baselines (by preserving non-local information?). \n"}