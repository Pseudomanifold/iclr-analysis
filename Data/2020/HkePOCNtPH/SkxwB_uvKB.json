{"rating": "1: Reject", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This paper presents a DCGAN for generating Irish folk music. The fixed length of Irish reels (in terms of bars) means that a piece can be represented as a 2-D image with fixed height and fixed width. This study represents each performance as a 4x64 image, where each successive row represents a phrase and pixels in neighbouring rows represent corresponding notes in successive phrases. A DCGAN architecture is then used to generate novel melodies using this representation. Each pixel has a normalised value between [-1,1] which correspond to the notes A-G, a-g in the vocabulary. \n\nThis study to me appears incomplete and at an early stage and requires further work before it can be accepted as a conference publication. Firstly, I believe the title is misleading. The title encourages the reader to expect a general model for generating melodies with GANs however the application is specifically to generate monophonic Irish folk music only, with a fixed number of bars. Secondly, the main novelty in the paper, the DCGAN architecture has not been described in enough detail, for instance the optimiser and hyper parameters are not mentioned, making it difficult for this work to be reproduced. \n\nThe authors claim 3 major motivations for  the DCGAN; 1) Dilated convolutions for introducing music related inductive priors, however the model description does not provide any intuition or insight for why the exact filters used were chosen. 2) The authors claim the GAN also yields a discriminator in addition to a melody generator, but they do not provide any explanation for why a discriminator might be useful. 3) They claim using random noise instead of a musically meaningful seed is better, but they do not describe the input noise distribution that the proposed generator is conditioned on.\n\nFor the evaluations, the Frechet distance is introduced without a reference/citation and the \u201cmodels in Magenta\u201d are referenced without a citation.  One downside of using the GAN is that there is no way to calculate the log-likelihood of the generated samples under the model distribution, which makes evaluating/comparing models a difficult problem. I think the distribution of notes in the generated samples is not a very informative metric for comparing the quality of generated samples. A few audio examples would have been extremely useful in getting a sense of how this model performs. \n\nI think this work should be resubmitted with major revisions. \n\nMinor Comments\n\n1. Section 2 does a good job of providing background for Irish folk music and the ABC notation. \n2. \u201cnormalised MIDI value\u201d should be elaborated. I inferred it to mean the MIDI values are normalised to the range [-1,1] after reading the whole paper, however this is not clear in Section 2.1 \n3. \u201cresulting vectors of 256 values as a 64x4 image\u201d, I think the image is 4x64 (Figure 1). \n4. \u201c..to use bidirectional RNNs with an activation mechanism\u201d, this should be attention mechanism. \n5. There should be some comment on the motivation behind the specific choice of filters in the generator and discriminator. \n6. There should be some details about the optimisation algorithm, batch sizes, learning rate schedules etc used to train the network. \n7. The magenta model requires a citation as it is not obvious what is being referred to. \n8. The Frechet distance should be introduced with a citation. \n\n\n\n"}