{"rating": "3: Weak Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This paper proposes an extension of the conditional GAN objective, where the generator conditions on an attention map produced by the discriminator in addition to the input image. The motivation is that the discriminator is usually too powerful, and so the gradient the generator receives is often too small in magnitude. By conditioning on the attention map, the generator could leverage information about the regions in the image that the discriminator attends to and use it to generate a new image that better fools the discriminator. \n\nMy main concern is about whether the proposed extension achieves the desired goal. The intuitive motivation provided in the paper aims to add a cooperative component to the two-player game, but the min-max objective corresponds to a zero-sum adversarial game. As a result, when training the discriminator, the discriminator is encouraged to reveal as little information as possible via the attention map, so that the loss maximized. This appears to be the opposite of the desired behavior, so the objective needs to be reformulated. \n\nAlso, it is unclear how inference is performed: at test time, the attention map is unknown and so some placeholder must be used in its place. The paper should clarify what is done at test time, and clearly state the shortcomings as a result of this, i.e. different procedures are used for training and testing, which is not principled. I imagine the generator could rely too much on the attention map as a result - how this is alleviated/prevented should be explained. \n\nFigure 2: Only the qualitative results for unsupervised image-to-image translation are available; qualitative results for supervised image-to-image translation should also be provided. \n\nWhile the quantitative improvement over existing methods is somewhat insignificant, I appreciate the authors discussing their hypotheses why this might be the case. It would be more useful to empirically validate these hypotheses as well. For example, for the claim that \"maybe the attention map only focuses on a few domain specific classes so the generator works too hard on those classes and ignores others\", it might be good to compute the average per-class attention map intensity to show that some classes appear rarely in the attention map. \n\nThe evaluation protocol should be explained in greater detail (perhaps in the appendix); the segmentation model (which I assume is FCN) should be described and each of the evaluation metrics (per-pixel acc., per-class acc. and IoU) should be described for the benefit of researchers outside the area. \n\npg. 4: \"in their implementation contains several Resblock (He et al., 2016), which makes it infeasible in our framework\". Why is it infeasible?\npg. 6: What are the architectures used by the baselines? Are they comparable to the architecture the proposed method used?\n\nMinor Issues:\n\npg. 3: \"differences between P_x and G_Y \\cdot P_y, P_y and G_X \\cdot P_x are minimized\" - confusing; should rephrase as \"the difference between P_x and G_Y \\cdot P_y and the difference between P_y and G_X \\cdot P_x are minimized\". Also should replace \\cdot with \\circ. \npg. 4: \"like random noisy\" -> \"like random noise\"\npg. 4, last paragraph: \"Our trainable attention module follows the same structure of the attention block in RAM (Wang et al., 2017). They built a very deep network with several such blocks, each containing two branches: mask branch and trunk branch. Mask branch cascades the input features through a bottom-up top- down architecture that mimics human attention. Trunk branch is applied as feature processing.\" - this is very confusing; it would be easier to refer readers to the appendix. \npg. 5 - \"Attention mask can potentially break good property of the raw input.\" - what does this mean?\npg. 6 - \"as showed in Table 4.1\" -> \"as shown in Table 4.1\"\n"}