{"experience_assessment": "I have published in this field for several years.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper provides an in-depth analysis of the recently observed phenomenon [7] that deep generative models may assign higher likelihood to out-of-distribution (OOD) examples for the specific model class of Variational Autoencoders (VAEs). The paper demonstrates that if appropriately designed in terms of network capacity (of the decoder) and latent dimensionality, VAEs indeed are capable of estimating the support of the data manifold and accurately detecting OOD examples. Different failure regimes (insufficient/excessive network capacity and limited/superfluous latent degrees of freedom) are identified and characterized showing that a proper detection model must find the effective balance of a suitable network capacity and sufficiently high latent dimensionality. The paper further formally demonstrates that too high of a latent dimensionality (larger than the original data manifold dim.) is less of a problem for VAEs since uninformative dimensions may just collapse in optimization, but this necessarily requires unbounded gradients to emerge during training. An experimental evaluation on Fashion-MNIST vs. MNIST and CIFAR-10 vs. SVHN/CelebA conclusively confirms the preceding theoretical considerations.\n\nI think this paper should be accepted since it clearly and concisely dismisses the existing hypothesis that deep generative models \u201cdon\u2019t know what they don\u2019t know\u201d for the important model class of VAEs. The presentation of the paper is polished and the technical quality is high. The only two (minor in my opinion) pitfalls of this work are (i) some related work is missing, and (ii) the novelty/originality of this work is rather limited as much in this paper is closely related to previous work [4]. Overall, however, I strongly believe this paper makes an important and significant contribution to the ongoing scientific conversation on understanding the anomaly detection capabilities of deep generative models.\n\n(i) Some related work from two lines of research are missing that I believe might lead to interesting connections and insights in the future. Major works on deep anomaly detection [10, 8, 5, 9, 2] and works taking an information-theoretic perspective on VAEs [3, 1, 11]. Specifically, connections to the rate-distortion trade-off [1] and the so-called information preference property [11], which describes the phenomenon that powerful decoders (excessive network capacity) reduce the information encoded in the latent code and well approximate the data marginal p(x) independent of z, might lead to interesting insights in the future.\n\n(ii) As referenced in the paper, this work builds quite a bit on results from Dai and Wipf [4]. However, the previous work specifically does not consider the anomaly detection problem.\n\nSome questions that I have:\n(1) Did you find unbounded gradients to make optimization unstable in practice? If yes, do you have some practical advice?\n(2) Do you employ any weighting hyperparameter between the reconstruction term and the prior KL regularization in Eq. (1) as in \u03b2-VAE [6] in your experiments?\n(3) Did you find one of the two terms (reconstruction or prior KL regularization) dominate in the NLL? I\u2019m curious if accurate detection is mainly to due errors in reconstruction or deviations from the prior in the latent encoding.\n\n\n####################\n*Additional Feedback*\n\n*Positive Highlights*\n1. Clear demonstration that VAEs \u201cknow what they don\u2019t know\u201d if properly designed in terms of network capacity and latent dimensionality.\n2. Good technical quality. Theoretical considerations seem correct and experiments are scientifically rigorous.\n3. Good, polished presentation. Eloquent, yet not ornamental writing that is clear and concise.\n4. Practical recommendations on how to choose the network capacity and latent dimensionality are presented (Section 3.2).\n\n*Ideas for Improvement*\n5. It took me longer to process Figure 1 than it should have. Maybe reiterate what the latent and what the manifold dimensionality is directly in the figure and highlight the optimal case (d). Otherwise it is a nice illustration of the regimes.\n6. Trends in Table 2 would be easier to see in line plots.\n7. Extend experiments over the full capacity \u00d7 latent dimensionality grid in the two setups (F-MNIST vs. MNIST and CIFAR-10 vs. SVHN/CelebA).\n8. Might add one-vs-rest deep anomaly detection benchmarks from Ruff et al. [8] and Golan and El-Yaniv [5].\n\n*Minor comments*\n9. Eqs. (1) and (4) numbering pushed down since equations are too long.\n\n\n####################\n*References*\n\n[1] A. Alemi, B. Poole, I. Fischer, J. Dillon, R. A. Saurous, and K. Murphy. Fixing a broken ELBO. In Proceedings of the 35th International Conference on Machine Learning, volume 80, pages 159\u2013168, 2018.\n[2] R. Chalapathy and S. Chawla. Deep learning for anomaly detection: A survey. arXiv preprint arXiv:1901.03407, 2019.\n[3] X. Chen, D. P. Kingma, T. Salimans, Y. Duan, P. Dhariwal, J. Schulman, I. Sutskever, and P. Abbeel. Variational lossy autoencoder. In International Conference on Learning Representations, 2017.\n[4] B. Dai and D. Wipf. Diagnosing and enhancing VAE models. In ICLR, 2018.\n[5] I. Golan and R. El-Yaniv. Deep anomaly detection using geometric transformations. In NIPS, 2018.\n[6] I. Higgins, L. Matthey, A. Pal, C. Burgess, X. Glorot, M. Botvinick, S. Mohamed, and A. Lerchner. beta-vae: Learning basic visual concepts with a constrained variational framework. ICLR, 2(5):6, 2017.\n[7] E. Nalisnick, A. Matsukawa, Y. W. Teh, D. Gorur, and B. Lakshminarayanan. Do deep generative models know what they don\u2019t know? In ICLR, 2018.\n[8] L. Ruff, R. A. Vandermeulen, N. Go\u0308rnitz, L. Deecke, S. A. Siddiqui, A. Binder, E. Mu\u0308ller, and M. Kloft. Deep one-class classification. In International Conference on Machine Learning, pages 4393\u20134402, 2018.\n[9] L. Ruff, R. A. Vandermeulen, N. Go\u0308rnitz, A. Binder, E. Mu\u0308ller, K.-R. Mu\u0308ller, and M. Kloft. Deep semi-supervised anomaly detection. arXiv preprint arXiv:1906.02694, 2019.\n[10] T. Schlegl, P. Seebo\u0308ck, S. M. Waldstein, U. Schmidt-Erfurth, and G. Langs. Unsupervised anomaly detection with generative adversarial networks to guide marker discovery. In Proceedings International Conference on Information Processing in Medical Imaging, pages 146\u2013157. Springer, 2017.\n[11] M. Tschannen, O. Bachem, and M. Lucic. Recent advances in autoencoder-based representation learning. In Third Workshop on Bayesian Deep Learning (NeurIPS 2018), 2018."}