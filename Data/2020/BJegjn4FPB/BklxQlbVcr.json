{"experience_assessment": "I have published in this field for several years.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "ILS-SUMM is applying ILS (iterated local search) to video summarization problem. The paper is well written and explains the method succinctly. The authors also introduce a new dataset for video summarization which consists of 18 movies of duration 10-104 minutes and summaries of <4 minutes. \n\nAuthors claim that the application of ILS to video summarization is first, which if true (i verified and could not find other references that negate the claim) seems like valuable work and connection. But, I think the authors can strengthen the paper further by addressing improvements along the axis below:\n\n* Authors just apply ILS to the problem of video summarization, is there any change to ILS that we can do to make it work better for video summarization. ANy insights of it's limitations?\n* Both the datasets are very small (25, 50 videos) to do real comparisons of hand crafted vs deep features\n* Authors don't talk about how they can incorporate semantics (specific people, actions etc.) in to the framework which is still important after doing shot boundary"}