{"experience_assessment": "I have published in this field for several years.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "The paper studies adversarial training \"at scale\", i.e., on the ImageNet dataset. The paper makes two main contributions in this context:\n- An in-depth investigation of the effect batch normalization (BN) has on adversarial robustness when the network is trained adversarially.\n- Training increasingly deeper residual networks (up to 600 layers) and demonstrating that adversarial robustness still increases in this regime (unlike standard accuracy).\n\nOverall I find the findings presented in the paper interesting and recommend accepting the paper. Experimenting with adversarial training on ImageNet is still hard for many academic groups due to the high computational cost. Hence the results of the paper may be useful for the wider robustness community. To achieve this goal, I strongly encourage the authors to release their models in a format that is easy to build on and experiment with for other researchers (e.g., PyTorch model checkpoints). Moreover, I find it interesting that very deep models on ImageNet can achieve increased adversarial robustness. To the best of my knowledge, these are the best robustness numbers published on ImageNet.\n\nFurther comments and questions:\n\n- It would be good to know if BN also affects adversarial robustness on CIFAR-10 or other datasets.\n\n- What happens when the width of the network is increased? Does this also help adversarial robustness?\n\n- Section 4.1 states that \"Adversarial training can be dated back to (Goodfellow et al., 2015), [...]\". While the specific form of adversarial training for adversarial robustness in CNNs is indeed recent, it may be helpful for readers to provide additional context, e.g., min-max formulations have a long history in robust optimization and statistics.\n\n- Section 4.4 states \"Interestingly, we find that the accuracy on clean images can be significantly boosted from 62.3% to 73%.\". It would be good to add context and state what accuracy the network achieves with standard training."}