{"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper proposes a method to reduce numerical error when predicting sequences governed by physical dynamics. The idea is that most physics simulators use finite difference differential operators, and the paper adds trainable parameters to them (the derivative and Laplacian operators). The added parameters are computed by a GNN. The paper concats the original graph feature and the output of the differential operators, and inputs them to a recurrent GNN to obtain the final prediction. \n\nI think the idea is interesting. Incorporating modulated derivative and Laplacian operators into physical simulators is novel and well justified. It could strengthen the argument is there is more justification of why this particular parameterization is selected. \n\nI think the experimental evaluation is somewhat adequate. There are a good selection of baselines including both manually designed iterators and GNNs. In particular, the weather prediction experiment show improved performance over several baselines. I am not familiar with this task or its state-of-the-art performance, but I am convinced that the proposed approach is superior compared to the claimed baselines (RGN, GRU). \n\nI have several confusions or concerns about the synthetic experiments\n\n1. In the synthetic experiments, is the evaluation task different from the training task? It is unclear from the description how well the learned parameters generalize. Does the method generalize to a. New functions/dynamics b. New graphs with similar properties (e.g. another graph draw from the same distribution) c. New graph with different properties (e.g. more or less sparse)? \n\n2. One short-coming of the synthetic experiment is the lack of error bars, or analysis of statistical significance. I think some of the improvements are not large enough to be statistically convincing without additional analysis. It seems necessary to experiment on multiple random problems (e.g. with random meshing, dynamics parameters). \n\nMinor comments:\n\nA related idea is \u201cLearning Neural PDE Solvers with Guarantees\u201d which modulates the finite difference iterative solver with deep networks, but the objective is solving PDEs with known dynamics instead of prediction with unknown dynamics. Conversely, the method the authors proposed seem also useful for speeding up PDE solvers. \n\nI think there is an error in the type definition of f and F in section 2.1. The two claimed types contradict each other.\n"}