{"experience_assessment": "I do not know much about this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper explores adversarially robust neural encodings for text that ensure robustness to text typos. The key idea is to balance two criteria, namely (i) the fidelity of a model, i.e., accuracy for a task, and (ii) stability, that captures the robustness of the model to perturbations. The paper proposes two methods that balance these criteria: (i) using connected components  over text features and their perturbations, and ii) agglomerative clustering of the encodings. Experiments are provided on six GLUE tasks and show some promise against baselines, when using the BERT encoding scheme.\n\nPros:\n1. The paper, while a bit too verbose, has a tutorial flow to it. However, I would think it could be significantly trimmed, as there is an \"oversimplification\" of obvious details. \n2. The key idea is straightforward, and make sense. \n3. The results show promise.\n\nCons:\n1. The proposed methods (connected components and agglomerative clustering) seem very basic ideas in this context. The paper proposes hand-crafted schemes to decide the connected components. Can't we have more principled end-to-end learning for achieving robustness? I am not an expert in NLP so cannot judge the significance of the ideas or the results, however from what I read, the contributions look basic/very incremental and heuristic.  \n\n2. The experiments show some promise, however the edit distance of perturbations is limited to one. While prior works have also reported in this setting, it appears to be a very constrained setup. Further, the baseline accuracy of the model is substantially lower (standard in Table 1) against the perturbed performance. Is this justifiable? \n\nOverall, the paper uses classical techniques in a heuristic way to combat sensitivity to adversarial perturbations in the text domain. Experiments show promise, however, the novelty and significance of the contribution is questionable."}