{"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "Overall the paper is written quite well and addresses a relevant topic. The experiments are thorough and make sense given the research question.  The paper furthermore provide additional ablation studies and does a good job in model analysis.\n\nThere are some critical points I have about the paper summarized below:\n\n\nIntroduction:\nThe 3 categories to solve POMDPs appear artificial. All 3  (whether using a window directly, using a RNN or building a surrogate model) aim to transform the POMDP to an MDP by taking history of observations (either explicit, or implicit).\n\nFigure 1 is too  complicated for an illustrative figure  and the presentation and clarity needs to be improved.\n\n\nMethod:\nThe idea is sound and described well. However, some design decisions appear ad-hoc  (only justified by empirical observations). For instance, the authors argue it is better to keep 2 models (the \"first-impression\" and \"keep-learning\" model) and show an ablation study in appendix C.  \nNow, one could wonder if the proposed method would still perform better than the baselines if with, say, the just using a single VRM.   The improvement compared to SAC-LSTM is not very large except in a few cases, so possibly just using the VRM would perform no better.\n\nThis could then defeat the theoretical argument of the method that \"[..] the actor network of SLAC\ndid not take advantage of the latent variable, but instead used some steps of raw observations as input,\nwhich creates problems in achieving long-term memorization of reward-related state-transitions.\"\n\n\nReference that should be included and possibly compared to:\n[1] Watter, Manuel, et al. \"Embed to control: A locally linear latent dynamics model for control from raw images.\" Advances in neural information processing systems. 2015.\n\n\nQuestions:\n1. What is the scalability, such as wall-clock time and #parameters  of the approach compared to the baselines? (When using 2 VRMs the # of parameters is doubled)\n2. Why the need to input the original observation x (and not just the latent representation) into the RL controller?\n"}