{"rating": "1: Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "= Summary\nThis paper tackles a new image recognition task called unsupervised few-shot object recognition, which is the few-shot classification with unlabeled training images of unseen classes. The proposed model is learned to discover and predict object parts shared among different object classes so that it can utilize the part information to represent target object classes in the support set during testing. The model is trained by multiple loss functions that have been proposed for GAN and self-supervised learning so far. With the model, the proposed method achieves impressive performance on the task, even outperforming the prototypical network relying on stronger supervision. \n\n\n= Decision\nIn spite of its notable performance, my current decision is reject mainly due to the following reasons.\n\n1. The target task (i.e., \"unsupervised few-shot object recognition\") seems neither realistic nor practically useful. The task assumes that there is no labeled training images at all, but in these days image-level class labels are very cheap and readily available in a large-scale well-established datasets like ImageNet; there is no reason to avoid them during training. \n\n2. The technical contribution is limited. The proposed approach is a combination of many existing losses and tasks. Furthermore, there is no clear justification for the components and their combination (e.g., what's the effect of the rotation prediction?), except the empirical verification in Table 1. Besides, the two-stage training strategy is not justified too. The method thus seems like a naive multi-task learning approach in which well-known tasks relevant to the target task are all adopted for training. \n\n3. The metric learning part is something new and its basic idea sounds quite interesting. However, its implementation is not convincing enough due to its main assumption: corner patches of an image will not be relevant to object parts while center patches will include distinctive object parts. This assumption does not hold always, but it depends on the image content.\n\n\n= Other comments\n1. In the manuscript, D is often called \"discriminator\", but it is not true as D has three branches and only one of them, specifically, D_r/f plays the role of discriminator. This could make future readers getting confused. \n\n2. The metric learning objective used in this paper also relies on a kind of self-supervision, so it seems natural to introduce this objective together with the rotation-prediction in the self-supervised learning section.\n\n3. Not justified: \n- Sampling from the uniform distribution \n- Predicting binary values (one of -1 and 1) instead of continuous numbers within [-1, 1]"}