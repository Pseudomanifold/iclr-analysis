{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This paper presents a technique to gradually prune the depthwise separable convolution networks, such as MobileNet, for further improving the speed. By imposing more structural constraints and using multi-stage iterative pruning, the proposed pruning algorithm can achieve roughly 2x speedup with little accuracy drop on standard benchmarks.\n\nIn my opinion, this paper is a borderline paper because it lacks novelty in terms of the algorithm itself. Particularly, multi-stage gradual pruning has long been used in network pruning for better performance. Nevertheless, applying the technique of network pruning to lightweight architectures (so as to handle depthwise separable convolution) seems to be new and promising. Given that, I've given a score of 3 and I'm willing to increase the score if the authors can resolve my concerns below.\n\nConcerns:\n- All experiments are done with MobileNet (v1 and v2), I wonder if the algorithm works well on other architectures. I suggest the authors to conduct an extra set of experiments with a new architecture.\n- The scope of the paper seems to be a little narrow. I wonder if the authors can include a few other lightweight operators.\n\nMinor Comments:\n- I think a recent paper [1] is quite relevant, though they focused on pruning standard convolution kernel. In particular, the paper utilizes filter pruning to get depthwise separable convolution from standard convolution kernel. I wonder if the technique in this paper can been applied to depthwise separable convolution operator to further reduce parameters.\nFor example, you can first reparameterize the original depthwise separable convolution with three consecutive layers with the first and third layers 1x1 convolution (the first and third layers serve as eigenbasis to whiten the middle layer).\n\nReference:\n[1] EigenDamage: Structured Pruning in the Kronecker-Factored Eigenbasis. ICML, 2019."}