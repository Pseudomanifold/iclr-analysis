{"experience_assessment": "I do not know much about this area.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review": "The authors propose a very interesting solution to training better GANs. The authors the explanation of previous work that training GANs is hard due to the proximity of real/fake samples and propose a novel way to augment the training sample by considering some fake samples as real during training. The experiment on synthetic data are illuminating and the experiments on real data show some benefit of this approach.\n\ncomments/questions\n1. I'm not very sure I fully buy the stability part (Fig 5), the objective itself is changed in such a way to be more stable (unless that is removed from the graph/objective).\n\n2. Have the authors considered the inverse, i.e. instead of considering fake examples as real, how about just throwing away those samples ?"}