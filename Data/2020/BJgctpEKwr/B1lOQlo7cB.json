{"experience_assessment": "I do not know much about this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "This paper proposes the Random Path Generative Adversarial Network (RP-GAN) to serve as a tool for generative model analysis.  The main idea is to have several different buckets in each block of the generator and then train the generator with random paths. To interpret the features captured by each block, the authors unfreeze one block and show the variance of the generated images via different buckets.\n\nThe contribution of the paper is limited. Most of the observations proposed in this paper are just to confirm the findings in the recent paper Bau et al (2019). And the authors did not clarify why their methods are better than the previous work. In addition, this work changes some standard ways of generating images. For example,  they use a fixed input vector Z rather than a random vector Z following Gaussian distribution. Then when they claim that their findings are also valid to standard GAN generators, e.g., SN-ResNet, they add the noise to the weights in SN-ResNet and claim that we can conclude similar findings as RP-GAN. Therefore, my question is if adding noise to the weights to a generator is sufficient for the interpretation of the generator, why do we still need this work for further interpretation?\n\nMinor:\nIn Figure 3, there are 10 images in each line but the number of buckets in each block is 40 for CIFAR10, as you claimed in Section 4. It should be clarified how you get those 10 images from 40 blocks in the unfreezed bucket.\n\nIn conclusion, I vote for a weak reject for this work. "}