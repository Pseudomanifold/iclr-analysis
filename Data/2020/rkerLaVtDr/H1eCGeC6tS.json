{"experience_assessment": "I have published in this field for several years.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "Summary\n-------\nThis paper presents a novel theoretical analysis for unsupervised domain adaptation by revisiting the \\lambda joint error term charactering adaptability in the seminal analysis of Ben-David et al. They propose to replace it by considering discrepancy between information on constrained class hypothesis and a possible discrepancy term that related the learned model with the class A cross-margin discrepancy is proposed in the multiclass context. They extend their approach by proposing to reweight differently some errors with an expected performance of target models on source and an additional one where they distinguish the performance with respect to accuracy on pseudo-labeled target data. Their approach leads to an adversarial-based loss function to optimize which is evaluated on two visual domain adaptation tasks. \n\nEvaluation\n--------\nThe idea is novel and I find the discussion on the considered restriction on the hypothesis class interesting. The experimental evaluation is interesting with good results reported on the two problems considered. I think that some parts could be improved in terms of presentation, in particular The paper contains many typos that make sometimes the reading difficult.\n\nOther comments\n------------\n\n-The comparison with other existing bounds is interesting. I think the authors should expand this by also taking into consideration the bound of Mansour et al., COLT'09 which has some links with the proposed approach (check their comparison to Ben-David's bound). \nThe links with this bound and the one of Ben-David could also be summarized in an appendix, I would like to see a better characterization of the cases where the proposed bound is better and worse. \n\n-About original proposal. I am wondering if the authors could discuss the relationship between the value of \\gamma and the expressiveness of the considered model. If the model is powerful enough, \\gamma should certainly be large. In a context of a training with \"Learning without forgetting\" strategy, the performance on source could maintained in a high standard. \nNote that in this context, the classic joint error of Ben-David et al. can be considered as rather small.\n\n-About the alternative proposal: I am a bit skeptical on the ration \\eta and (1-\\eta) for accuracy on source and pseudo-labeled data respectively. Indeed, since the pseudo-labels are obtained from a classifier that make use a lot of source information, one may think that their performance is rather related. So using to correlated ratios would probably be more relevant here, but maybe the authors can bring some arguments against.\n\n-In the experimental evaluation, the tuning of the different parameters, in particular \\gamma and \\mu, is not particularly discussed and there is probably an issue. I tend to think that these values are rather difficult to assess. A discussion on this point would be welcomed.\n\n-I am not sure to understand the optimization problem (8), (9) and (18), in particular the term after the \"s.t.\": I would expect an inequality somewhere, otherwise everything can be added to the general objective function. If there is an alternate optimization scheme, this should be mentioned explicitly.\n\n-Table 1 and Table 2: use a third identifier different from the second for the last version of your method.\n\n-Please check the typos.\n"}