{"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The authors introduce a novel decision point discovery method, wherein the VIC objective is constrained to minimize the amount of information between the option and the actions taken along the trajectory. After relaxing the constraint and introducing an upper bound to I(a; o), a tractable algorithm is produced. An implementation is then tested empirically on several partially observed grid worlds and a simple continuous control task on both qualitative bottleneck identification and quantitative benefits as an exploration bonus in a transfer learning setup.\n\nOverall I think the approach is well motivated and interesting, but the resulting implementation takes too many unmotivated modifications to make work, and the results aren't terribly convincing despite this; as such I currently vote for it's rejection. Specifically, the usage of privileged information (x,y coordinates in what is described as a partially observed domain) and the ad hoc choice of which networks had memory (i.e. an LSTM) don't fit the narrative that motivates the work. Constraining the empowerment should be thing that handles spurious diversity, so the need to use x,y coordinates is concerning.\n\nRegarding the empirical results, do all of the baseline make similar use of domain knowledge / privileged information? For example, does your implementation of DIAYN utilize x,y coordinates in the option predictor? Is the Beta=0 case considered? It isn't mentioned, but perhaps it amounts to one of your other baselines?\n\nThe empirical evidence isn't terribly convincing. On two of the three exploration setups, the random network is as performant, and does need a Beta hyper-parameter to tune. Though, to be fair, the connection between decision state identification and a good count-based exploration bonus is loose. The qualitative results are also a bit lacking. I was expecting the doorways to \"pop out\" more; the relatively muddled decision state activations made me wonder if they were really better than DIAYN's.\n\nThis work would really benefit from a quantitative measure of decision state identification accuracy. Some prior work (e.g. \"Grounding Subgoals in Information Transitions\") were able to do this by choosing environments where the quantities of interest were tractable to calculate exactly. This would at least allow us to see if the discovered decision states correspond to those that are optimal under your metric."}