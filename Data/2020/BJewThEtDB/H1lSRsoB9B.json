{"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper presents a new method to extend an RNN autoencoder for multi-decoder setting. The presented algorithm and derivations are not novel, although the presented idea is a reasonable extension for sequential data which should be processed by multi-decoders. \n\nIn principle, the main idea of multi decoder is to use separate decoders since one decoder is not applicable to express various types of sequential data (decoding part) when a single encoder is enough to handle input sequences. \n\nHowever, in my personal opinion, it is not motivated enough why multi-decoder is necessary (except for an empirical evidences in Table 2) when many people use a RNN model as a good but approximate function approximator.\n\nAuthors may argue that multi-decoders are necessary to process some sequential data. Unfortunately, experimental results are not promising enough for me, the proposed algorithm/method is compared only with an existing method."}