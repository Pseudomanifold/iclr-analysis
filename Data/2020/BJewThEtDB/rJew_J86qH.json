{"rating": "1: Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #4", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "The authors propose an RNN-based variational autoencoder model with one encoder and multiple decoders. The authors utilize multiple decoders to model different dynamical systems, aiming at addressing variations in time series such as phase shift, length variation, stretch and compression and so on. EUNN-based RNNs are used in the proposed model. The authors derive the ELBO of the proposed model and describe the EM training steps. The idea brought by this paper has some merits, but given the discussions and evaluations in the current manuscript, it has not been supported and validated that the proposed model does address those a variety of problems/properties in time series comprehensively and systematically.\n\nLots of related work fields are missing. For example, time series clustering should be included. Recent models on extracting hierarchical / multi-scale temporal features should be discussed as well. Distance- and density-based methods are also relevant.\n\nOnly RNN-AE are compared in the experiments. At least the authors should compare baselines such as LSTM/GRU-based models and other VAE-based RNNs.\n\nThe datasets and tasks are relatively simple. On the synthetic dataset, the models are supposed to distinguish time series with different numbers of periods. Results on the driving behavior dataset (Figure 8 and Table 2) are not strong. What is the metric shown in Table 2? Are the results from 5 runs of 10-fold cross-validation? If the accuracy is shown, ~0.5 for 3-class classification is not strong.\n\nHow about the training and inference efficiency of the proposed model, especially compared with recent RNN baselines? This may prevent the model from being applied to large datasets in practice. \n\nAdditionally, the authors could better organize contents in the main paper and the supplementary. The main paper should be self-contained and include, for example, how to calculate r_{nk}, Algorithm 2, explanations of Fig 4, and what the baseline RNN-AE exactly is."}