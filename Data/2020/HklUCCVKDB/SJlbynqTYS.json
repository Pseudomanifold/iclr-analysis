{"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "- Summary:\nThis paper proposes to use a way to improve continual learning performance by taking \"Bayes-by-backprop\" method. They claim that the uncertainty can naturally be measured by estimating (log of) the standard deviation, and it is indeed useful to judge the importance of each learnable parameter. Experimental results on several benchmarks show that their method outperforms few state-of-the-art methods.\n\n\n- Decision and supporting arguments:\nWeak accept.\n\n1. The proposed method is simple but effective. However, It is still questionable whether \\sigma is the best measure of the weight importance. An ablation study with different choices of the importance measure (maybe \\mu can also be incorporated as well as \\sigma?) would be good to see.\n\n2. Survey and comparison with memory-based methods are limited. Though memory-based methods require some memory to keep the experience, the proposed method also requires additional memory for \\sigma; it essentially doubles the model capacity, assuming that \\sigma is solely for measuring the weight importance. In particular, when it comes to large-scale models, memory for storing some important experiences would be small compared to the memory to store the model.\nHere are some papers about recently proposed memory-based methods, which are not cited:\n\nCastro et al. End-to-End Incremental Learning. In ECCV, 2018.\nWu et al. Large Scale Incremental Learning. In CVPR, 2019.\nLee et al. Overcoming Catastrophic Forgetting with Unlabeled Data in the Wild. In ICCV, 2019.\n\n3. Comparison should include the model capacity as in Table 1(b). Again, compared to the conventional non-Bayesian model, half of the model capacity is used for computing \\sigma (uncertainty), I wonder it causes a performance drop when the model capacity is the same over all compared methods. If they used the same model architecture and just doubled the number of learnable parameters for \\sigma, then it is obviously unfair.\n\n\n- Comments:\n1. Pruning is not beneficial in terms of the performance. I hope to see some quantitative benefits obtained by introducing pruning. In Table 1(b), why doesn't pruning reduce the number of parameters?\n"}