{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "This paper proposes an interactive approach to enable the machine inquire missing information before it finally makes classification over users\u2019 incomplete queries. Based on their assumption of independence between interaction turns, they use a simple approach to croudsource the initial user queries and interactive qa pairs for two existing datasets (i.e. FAQ document suggestion and bird species identification). To model the interaction, they employ information gain to select question at each turn, and proposes to use a policy controller to decide when to stop the interaction. Their experiments on the two datasets show that their approach outperforms several non-interactive and interactive baselines by large margin.\n\nStrengths:\n1. The interactive approach to do classification is well-motivated and looks interesting in real-world settings where computers can interact with users.\n2. Good formulation of the task and detailed mathematical derivations from the original problem to their final model based on their assumptions.\n3. Great improvement over the baseline methods, and promising human evaluation.\n\nWeaknesses:\n1. I am not sure whether the assumption of independence between turns in the interaction is valid or not. Basically, following this assumption, we can ignore the order of the interactions, and the problem can be reduced to finding the most supportive attributes of the label and then do classification.\n2. The FAQ and BIRD datasets using in this paper are not very popular datasets in NLP and CV, and both of them are not originally designed for interactive classification. So, I am wondering why the author chose these datasets. As the author mentioned, there are many existing works on interactive classification. Why not just use their datasets?\n3. The NLP model used in this paper is too simple. They just use recurrent neural network (SRU) without attention or state-of-the-art encoders.\n4. The author claims great improvement in the introduction over non-interaction baseline. However, the non-interaction baseline doesn\u2019t make sense for their task. Because they encourage workers to provide incomplete information intentionally during the data collection.\n5. The interactive baselines they compared might be too easy, or old. Maybe the author should consider better retrieval models. I also don\u2019t understand why is the STATIC INTERACT baseline not conditioned on the initial query."}