{"rating": "1: Reject", "experience_assessment": "I do not know much about this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper is concerned with trying to \"explain\" the predictions of a deep conv NN by identifying input neurons which most contribute to the prediction (\"salient input regions\"). This seems to be done in a similar way than a lot of prior work, by defining some sort of relevance which can be backpropagated from the final softmax to the input image. Comparisons to some selected other methods are provided.\n\nI am having a very hard time to understand how the proposed method works in detail. The authors choose a notation that is, nicely speaking, extremely non-standard (using maths operators in circles as indexes, instead of letters, for example). There are equations without clear definitions of the symbols in them, and in general a lot of text talking about \"preceding layer\", \"succeeding layer\", talks about a \"counter\", and other unclear speaking. The equations contain argmax and set unions, and all symbols have at least 2 subscripts and 1 superscript, none of which are explained properly. Despite the abundance of sub- and super-scripts, it is interesting to note that in eq (2), activation and weight are indexed by the same scripts, even though many weights feed into an activation. Somehow, this weight is connected to a \"selected neuron from the succeeding layer\" (which one??). \nSince previous work, like layer-wise BP, ended up with pretty simple formulae, I suspect this to be the same here, but this would be a random guess, as what is written here is (at least to me) inpenetrable.\n\nIn section 3.2, the authors choose to use reinforcement learning in order to learn some parameters, and a bit further down they talk about binary MAB problems. It is beyond me why RL would apply here, even though I know it is in fashion right now.\n\nFinally, there are some results, consisting of reasonably looking pictures. They compare against 3 other methods, while citing a lot more. While I am not an expert in visualization techniques, I note that some very popular ones are just cited, but not compared against (check for example http://www.heatmapping.org/). There is no mentioning of why the authors compare against exactly these 3, because in general the authors do not motivate what is not optimal about prior work and what is better about their proposal.\n\nIt does not help that the writing of the paper is pretty sloppy, so in general most sentences first have to be slightly translated so they make sense in English. This would not be a problem if anything was clearly defined here in mathematical terms, but nothing is."}