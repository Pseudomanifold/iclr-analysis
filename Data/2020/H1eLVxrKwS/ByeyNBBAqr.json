{"rating": "6: Weak Accept", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "The paper proposes to improve perturbation-based explanation techniques by complementing the perturbation step with an inpainting step that removes artefacts caused by it.\n\nThe approach is sound and intuitive.\n\nThe authors show the flexibility of their approach by applying it to a variety of perturbation-based attribution techniques.\n\nIt is unclear what is the computational cost of the inpainter. Perturbation-based explanations are generally quite slow due to having to evaluate the function many times, and therefore a further slowdown could harm practical use. I'm curious whether the inpaiting approach could be in some way also extended to faster explanation techniques (e.g. gradient-based, or propagation-based).\n\nEvaluation experiments are not fully conclusive. Bounding box experiments are rather indirect and the deletion/insertion metrics do not systematically show the performance improvement of using inpainting. Perhaps the deletion metric should have been equiped with inpainting as well in order to avoid deletion artefacts. (See e.g. Samek'17 MoRF / LeRF experiments where various perturbation schemes are tested for deletion).\n\nThe evaluation benchmark is restricted to perturbation-based approaches. It could have been useful to broaden the comparison to non-perturbation approaches.\n\nAn experiment I found particularly interesting is the robustness to perturbation hyperparameters. Given the difficulty of designing evaluation metrics that can support hyperparameter selection, hyperparameter insensitivity is indeed strongly desirable.\n\nI'm wondering whether it is really necessary to use a strong deep neural network inpainter since the goal is just to remove artefacts. Some inpainters provided as part of standard computer vision libraries work quite well, and do not need to be trained and adapted to a certain shape of missing data.\n\nOverall, the paper presents an interesting and sound approach to improve perturbation-based explanations. Experiments are extensive, although some of them remain so far not fully conclusive."}