{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "This paper studies a new problem, i.e., generating graphs conditioned on an input graph. The authors proposed a new framework GT-GAN, which is composed of (i) a graph encoder to representation of the input graph; (ii) a generator to generate graphs; (iii) a discriminator to fool the discriminator so that the generated graph can be more realistic; and (iv) a l1-norm regularizer to make the generated graph similar to the target graph. Experimental results on synthetic and real-world datasets demonstrate the effectiveness of the proposed method for graph translation. Overall, the problem studied in this paper is interesting and novel, and the proposed method makes sense. There are some concerns about the paper and I would like to increase my rating if the authors can address my concerns:\n\n(i) Could you double check if E_{ij}^{1,1}=A? The dimension seems to be problematic in Eq.(5) if E_{ij}^{1,1} is of dimension N x N. If E_{ij}^{1,1} is N x N, then E_{I,k1}^{l-1,n} is also N x N. In Eq.(5), mu_{k1}^m is 1 x 1 and S_{k1} is 1 x N. Please double check. E_{ij}^{1,1} is of dimension N x N\n\n(ii) The explanation of why the proposed graph convolution can learn global information in the graph embedding is unclear. For example, how the embedding can preserve the scale-free property? Could you provide more explanations?\n\n(iii) Though the studied problem is interesting, the proposed method makes sense but is not very novel. It seems to be adopting GAN with GNN and l1 regularizer.\n\n(iv) The contribution of the l1 regularizer is not analyzed. What the performance will be if we remove the l1 regularizer?\n"}