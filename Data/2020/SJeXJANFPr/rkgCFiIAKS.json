{"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper embraces the idea that better multi-task/lifelong learning can be achieved if tasks produce gradients that are orthogonal to the gradients produced by other tasks. The authors propose an approach to regularizing learning in order to incentivize this to happen. However, as they mention themselves, the regularized loss is computationally intractable in general and they only apply it to a subset of their network as a result. Given the computational scalability concerns, it is natural to wonder why researchers in the community would adopt this approach rather than other approaches that also aim to make gradients orthogonal. \n\nThe idea of producing orthogonal gradients across tasks or examples is not new in the context of lifelong/multi-task learning. In fact, just to name a few, [1] demonstrated that noise alone can lead to orthogonal gradients, [2] demonstrated that modular neural network architectures can lead to orthogonal gradients and less interference. Additionally, sparsity naturally leads to orthogonal gradients as does the recent approach in [3].  These approaches achieve orthogonal gradients without adding a significant computational burden to learning. This paper can be greatly improved by discussing past approaches to producing orthogonal gradients and why they are theoretically / empirically worse than CosReg. \n\n[1] \"A theory for how sensorimotor skills are learned and retained in noisy and nonstationary neural circuits\". Robert Ajemian, Alessandro D\u2019Ausilio,  Helene Moorman, and  Emilio Bizzi. PNAS'13. \n\n[2] \"Routing Networks: Adaptive Selection of Non-linear Functions for Multi-Task Learning\". Clemens Rosenbaum, Tim Klinger, and Matthew Riemer. ICLR'18. \n\n[3] \"Meta-Learning Representations for Continual Learning\". Khurram Javed and Martha White. 2019. \n\nAdditionally, despite much past work, I tend to think that the entire quest for orthogonal gradients is not particularly well motivated as it is missing half of the story. Orthogonal gradients only address the problem of interference during learning, but don't help maximize transfer during learning. In fact, intuitively Figure 2 showcases that CosReg diminishes transfer during learning in comparison to baselines. Some recent work, such as [4] and [5], argues that what we really want is to maximize the dot product of gradients i.e. their alignment. This perspective achieves the best of both worlds as it incentivizes orthogonality to address interference while also incentivizing positive transfer. I wonder how the authors would position their work relative to the body of work that optimizes for the gradient dot product. Why would we like gradients to be orthogonal if there would otherwise be transfer? Why focus on the cosine rather than the dot product, which naturally comes out of the first order Taylor expansion derivation for each task? \n\n[4] \"On First-Order Meta-Learning Algorithms\". Alex Nichol, Joshua Achiam, John Schulman. 2018. \n\n[5] \"Learning to Learn without Forgetting by Maximizing Transfer and Minimizing Interference\". Matthew Riemer, Ignacio Cases, Robert Ajemian, Miao Liu, Irina Rish, Yuhai Tu, and Gerald Tesauro. ICLR'19. \n\nGiven my major concerns about the theoretical motivation and comparisons to past work, I do not find the experiments comprehensive enough to prove the value of the proposed approach to the community. At the very least, I would be interested in comparison with additional very relevant baselines and in experiments with more tasks.  "}