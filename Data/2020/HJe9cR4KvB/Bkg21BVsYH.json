{"rating": "6: Weak Accept", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I did not assess the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "\nThis paper proposes ConNet, a new label aggregation method for sequence labeling tasks, including crowd-annotation and cross-domain model adaptation. The model consists of a decoupling phase, which learns annotator-specific transforming matrices A, and an aggregation phase with an attention module. Extensive experimental results demonstrate the superiority of the proposed model over baselines. \nThe paper is generally well-written and easy to follow, and the results seem convincing, so I think it can inspire other works on this topic. My main concern on the paper is its generalization. Crowdsourcing usually involves lots of annotators, and some of them only give very few labels. In these situations, the proposed model introduces lots of new parameters (A, Q), which may cause difficulty during training. So the positive results in Fig 3(b) are very important to dispel my worry, which requires more explanation. \nBelow are some detailed questions:\n-      How do you calculate the sentence embeddings h_i during training?\n-      Have you introduced some regularization terms on A and Q?\n-      What are the most important hyper-parameters for this model, and how to tune?\n-      Can this method be extended to new tasks other than sequence labeling?\n-      Can you compare your method with the aggregation method used in on-the-job learning paper [1]?\n-      92.33 in tab 2 shouldn\u2019t be bold.\n \n[1] Werling K , Chaganty A , Liang P , et al. On-the-Job Learning with Bayesian Decision Theory[J]. Computer Science, 2015.\n"}