{"experience_assessment": "I have published in this field for several years.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper proposed an encoder-decoder-based summarization network as a loss function within a similar encoder-decoder-based summarization framework to demonstrate that the proposed model obtains better automatic and human evaluation scores compared to the baseline model of See et al. (2017) with just traditional loss functions. Overall, the paper is well-written and the presented results, analyses, and comparisons appear to be reasonable. One notable advantage of the proposed model would be to circumvent the approaches that rely on the evaluation metric, ROUGE as a reward component e.g. in a reinforcement learning setting, although with the expense of additional memory and time complexity.   \n\nFew comments:\n\n- \"A presents either a word ....\" --> this sentence is not clear.\n\n- \"Embedded representations ... differ somewhat from w_i\"--> Please clarify this aspect with more details.\n\n- In Figure 1, the proposed model with recoder seems to be suffering from issues related to redundancy and referential clarity, as it repeats the name \"malia\" several times. Would you comment on why this is the case?\n\n- It would be great if you could provide more details on the selection criteria/qualifications of the mechanical turk workers. Also, it is not clear why each example was given to only one worker and not to multiple workers. Wouldn't it be ideal to evaluate each example by multiple workers to get a sense of the inter-rater agreement? Please clarify. "}