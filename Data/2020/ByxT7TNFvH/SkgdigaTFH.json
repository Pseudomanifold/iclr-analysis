{"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "The paper proposes a using pixel-adaptive convolutions to leverage semantic labels in self-supervised monocular depth estimation. The semantic features are predicted by a pretrained network rather than relying on a ground truth. Moreover, a two-stage training process in proposed in order to filter out images leading to erroneous SfM predictions. The method is evaluated with different networks on the KITTY dataset.\n\nThe paper is very well written and clear. The applications of per-pixel convolutions to this problem seems sound and the experimental validation seems satisfactory. I have however one main concern (1) and a few additional questions below:\n\n1) While (Guizilini 2019) shows that using a larger set of unannotated videos and allows the self-supervised method to eventually outperform supervised methods, this study is not done here. This makes me question the applicability of the approach, as using large unlabelled videos would probably lead to noisy segmentations that could be unhelpful to the depth estimation. Showing an improvement over the supervised baseline would be a much stronger experimental validation, as for now it is difficult to know exactly why in which scenario this method should be used, rather than a supervised network or vanilla packnet.\n\n2) I see that you obtain the same numbers in Table 2 / PackNet / row 1 as in (Guizilini 2019); I would like to confirm that you used exactly their self-objective loss, in all your experiments? I would suggest adding to section 3.1. the fact the fact that the loss is the same is in (Guizlini 2019), as a reader could assume that there is novelty in the loss formulation.\n\n3) Have you tried fine-tuning the whole architecture including the semantic network end-to-end?\n"}