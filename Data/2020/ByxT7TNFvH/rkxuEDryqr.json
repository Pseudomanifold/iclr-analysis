{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The underlying problem considered in this manuscript is inferring depth from geometry of two dimensional images. The novelty here is to integrate a semantic classification model along with depth inference. It is a challenging problem and a neat idea to pursue. The paper is well-written and easy to follow. \nHowever, the empirical work in the paper is not persuasive. Table 1 contains results whose significance is hard to judge. What does a RMSE difference of 2.3 mean in the context of depth estimation? Table 1 carries no uncertainty in results which is just not acceptable in a setting that has several sources of uncertainty. Similarly, Fig 4 shows there is advantage in the use of the pre-trained semantic network, it is not clear if this difference is significant. And I also think consideration should be given to the fact that in a deployment setting, new objects not previously seen in the semantic categories (UFO) may appear and one ought to understand if the semantic network might decrease performance (because of the unseen class). Hence I think which the idea advanced in the paper has merits, the manuscript is not really ready for publication.  "}