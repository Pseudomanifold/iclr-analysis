{"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper proposes a method called InfluenceNet to deal with partial observations in reinforcement learning. The idea is to keep track of only a small amount of available information using a recurrent mechanism and attention - based on the previous work of Oliehoek et al (2012). The model is composed a RNN (tracking the past) and a FNN (current only) which jointly influence the value and policy functions. The model is tested on a simple traffic control task and four Atari video games.\n\nIt is hard to distill novelty out of the paper and it is unclear how the idea of \"influence-based abstraction\" helps in the evaluated cases, where the performance of the InfluenceNet is highly correlated with the FNN component. At best the proposed is a simple combination of FNN and RNN, and the RNN hardly does any job. The experiments are very inadequate to empirically confirm any hypotheses.\n\nThe reference list seems to ignore much of recent works in solving partial observations, e.g., memory-based methods.\n"}