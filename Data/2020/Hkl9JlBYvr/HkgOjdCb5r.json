{"experience_assessment": "I do not know much about this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "Summary: \nThis paper considers a version of reinforcement learning problem where an unknown prior distribution over Markov decision processes are assumed and the learner can sample from it. After sampling a MDP, a standard reinforcement learning is done. Then the paper investigates the Bayes-optimal strategy for such meta-learning setting. The experiments are done for an artificial maze solving tasks. \n\nComments: \nConsidering a Bayesian setting of reinforcement learning is sound and well-motivated in a mathematical or statistical sense. On the other hand, I wonder what kind of practical applications motivate such formulation. Unfortunately, I don\u2019t have any examples in mind and the paper also shows some artificial experiments. So, the formulation seems, so far, not to be convincing in a practical sense. \n\nAnother concern in my mind is that the proposed methods are not supported by any theoretical analyses. I think mathematical papers without practical applications are acceptable if they contain strong mathematical analyses. The present paper, however, does not contain such analyses. \n\nAs a summary, I feel that the paper is not strong for theoretical analyses nor practical usefulness, and thus further investigation for either side is necessary.  \n"}