{"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper proposes a means of improving the predictions of a \"simple\" (low-capacity) model. The idea is to take the predictions of a \"complex\" (high-capacity) model, and weight the loss in the simple model based on the ratio of complex to simple models' predictions. Intuitively, this seeks to focus on instances which the complex model can fit, but the unweighted simple model cannot. Experiments show the proposed method to have some benefits over existing approaches.\n\nThe application of importance-weighting to the \"model distillation\" problem is interesting, and the paper gives a reasonable intuition for why this approach might work. One general comment is that in contrasting their approach to a number of existing approaches, they note that several of them are typically employed with fairly complex simple models (e.g., neural networks). This may be true, but it was not clear that any of them require this to be the case. Surely they can also be used with simple models as ones you consider in the paper? In this case, I would've liked more elucidation as to why the proposed method can be expected to offer superior performance.\n\nThe theoretical justification of the approach is provided by means of Lemmas 3.1 and 3.2, for which I have some comments:\n- Lemma 3.1: the notation here is a bit imprecise. In general, a loss for example (x, y) takes in a true label y and predicted score z(x). You refer to the loss of a probabilistic prediction p(y | x), but do not refer to the actual label y itself. From the proof, it is implicit that you are considering y to be binary, and the use of a margin loss. This is ok, but for the hinge loss one doesn't use a probability estimate p(y | x) as input to the loss, but rather, a real-valued score.\n\nI think the result itself could be proven by noting that if \u03c6 is non-increasing and q < p, then \u03c6(p)/\u03c6(q) <= 1 < p/q.\n\n- Lemma 3.2: the result is interesting, but it seems that for practical purposes you are only using the first term, since it is the only quantity that depends on \u03b8. Since max(1, .) >= 1 and -log p\u03b8(y | x) >= 0, it seems one could trivially bound the LHS by the first term since -log p\u03b8(y | x) <= max(1, .) * -log p\u03b8(y | x)? Would this not suffice for the purposes of justifying your method? It should also be noted here how the subsequent requirement that the weights be capped (so as to prevent outliers) fits into the analysis.\n\nIn describing the method itself, the authors introduce a notion of \u03b4-graded subsets. I found this to be a bit difficult to parse, and it was not clear why this notion was needed. It does not seem to feature in the description of Algorithm 1, nor the subsequent discussion. On the other hand, I felt that the meaning and need for parameters \u03b2 and \u03b3 ought to have been discussed more prominently upfront.\n\nThe experiments show favourable performance of the proposed method over baselines, including the distillation approach of Hinton. The datasets are mostly small-scale, but this is in keeping with the goal of the paper, viz. addressing scenarios where simple models may be desired. Per earlier comments, I did not have a deep sense of what additional information the proposed method exploits so as to improve performance. I gather that the weighting including the predictions of the simple model is one difference; it might have been nice to give a sense of what fraction of points this amplifies or suppresses, compared to just using the predictions of the complex model.\n\nThere is a nice illustration in Fig 1 (right) as to the class-labels of the training samples assigned various weights. This shows that points with low weight tend to have low agreement with their neighbours' labels. One question is how using a nearest neighbour probability estimate itself (i.e., using this as the \"complex\" model) would fare.\n\nMinor comments:\n- the title is a bit confusing. It is not clear what \"its\" refers to. You are leveraging the predictions of a complex model to enhance those of a simple model?\n- the text has a number of long sentences that could benefit from rewriting or splitting.\n- proof of Lemma 3.2, use \\cdot not *.\n- proof of Lemma 3.2, \u03b8* should use superscript.\n- Fig 1, the caption is overlong. Most of this should be in the text.\n- Fig 1, use crisper fonts for the text."}