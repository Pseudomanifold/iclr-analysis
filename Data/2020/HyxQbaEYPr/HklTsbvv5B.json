{"rating": "6: Weak Accept", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper is about re-weighting training sets in such a way that simple and interpretable models like trees or small networks can mimic the performance of potentially very complex learning architectures. The main difference to some existing approaches of this kind is the universal applicability to many complex-simple model combinations (and not only layered networks). Technically, this paper is an extension and formalization of some ideas proposed in (Dhurandhar 2018). The main methodological contribution is the formal justification of the proposed weighting scheme for samples which utilizes the ratio of conditional probabilities p_complex(y|x)/p_simple(y|x) in the Lemma 3.1 and 3.2. The practical algorithm described in the paper is based on the concept of delta-graded classifiers which basically defines a nested set of classifiers of increasing accuracy -- such as, for instance, simple classifiers trained on intermediate layers of a deep network. The second important input argument is the learning algorithm for the simple model, which is trained on the re-weighted samples. The motivation for this algorithmic procedure is somewhat \"hand-waving\", but rather intuitive. Experiments for different benchmark datasets and different complex-simple model combinations nicely demonstrate that this method is indeed quite useful in practice. In summary, I think that this work addresses a highly relevant problem and provides a relatively simple method that might be very useful in many applications. A potential weakness could be the gap between the formal treatment of the cross-entropy loss in Lemma 3.2. and the rather \"ad hoc\" practical algorithm that crucially depends on two tuning parameters. Nevertheless, in my opinion, this work provides some interesting ideas that have the potential to trigger future research in this area.        "}