{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper aims at training a GAN that can generate data matches the real data distribution well especially at the boundaries of the classifiers. A Boundary-Calibration loss (BC-loss) base on multi pretrained classifiers is introduced to match the statistics between the distributions of original data and generated data. The motivation is interesting. The story is clearly explained. However, the experiments part is weak.  \n\nThere are several typo and mistakes. The experiments only show that the proposed method got a good performance, but the analysis of the reason is not shown. The reason to name the loss as Boundary-Calibration loss (BC-loss) should be explained and the experiments should show some effect on the boundary areas. Some concerns are listed below,\n\n1.\tIf the generated dataset exhibits very good property as the real dataset, it means the data is to some extent perfectly foreseen, and there is little to no privacy, is it contrary to the aim of not leaking the real dataset?\n2.\tIt is more interesting to see the difference between the distribution of real data and the generated data, However the author only show a simple toy data distribution comparison, I would like to see more comprehensive results about the distribution differences on real dataset , e.g. the TSNE embedding? \n3.\tEquation (3) is not correct.\n4.\tThe author said that image quality of MNIST and CIFAR10 are not improved, then why the classification results are improved?  there should have some differences existed among different compared methods, it would be more convincing if you can show it out.\n5.\tWhat kind of  generator do you use for the UCI data?  How do you settle the output problem?  Since some of the data are continuous and some are discrete.\n"}