{"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "Summary:\nThe paper proposes an explanation method by interpolating examples in the latent space of a generative model that can sample from the data distribution. In particular they interpolate between two samples (called litigation examples) that have the right labels according to the blackbox. The explanations primarily consist of the examples sampled along the interpolation path. The main argument is that by optimizing the encoder and decoder w.r.t. litigation examples, the gradient of logit estimates change is the sharpest. \n\nI have several concerns with this approach. First it is unclear what the explanation is supposed to represent in the first place. \n\n1. For instance, what insight about the classifier should we obtain from these interpolations? \n2. Only one classifier is shown for the celebA data so it is hard to compare different black-boxes in the evaluation. \n3. Is it fair to change the explanation paths (by optimizing the VAEs) to reflect explanations that more closely reflect \" a human standpoint\" as opposed to finding the shortest path that would change the label even if it has no semantic clarity for the human? What kind of bias are we inducing and are we suggesting the classifier is more reliable than it actually is by using a PATH-Auto Encoder as opposed to a vanilla VAE without the litigation examples? \n4. The related work is incomplete. This whole domain is by now well studied under counterfactual explanations, or contrastive examples - see: \na) https://arxiv.org/abs/1802.07623\nb) https://openreview.net/forum?id=HyNmRiCqtm\nc) https://arxiv.org/abs/1806.08867\nd) https://arxiv.org/abs/1711.00399\n\n5. Baseline comparisons: Comparing different VAEs is not sufficient to justify why this explanation method is a good choice. Comparisons with adversarial examples, any of the counterfactual explanation methods above and a quantitative measure of comparing across them seems crucial for a fair assessment of the contribution."}