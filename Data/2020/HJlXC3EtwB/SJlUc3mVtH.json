{"rating": "8: Accept", "experience_assessment": "I do not know much about this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "\nSummary:\nThe authors propose an extension of proximity graphs, Annealable Proximity Graphs (APG) for similarity search. APG augments pre-built proximity graph with a learnable weight and a keep probability with each edge in the graph which are updated in an iterative manner. This allows identifying important edges while preserving graph monotonicity which is important for search efficiency. All the edge weights are initialized with uniform weights and are updated using a stochastic optimization algorithm. Once the optimization finishes, edge weights are ranked and less important edges are pruned as per the desired pruning ratio. The authors also theoretically prove convergence and correctness of their proposed algorithm. The results demonstrate that APG maintains almost the same accuracy while decreasing search time by 21-41 %. Overall, I find that the proposed method and its results are convincing. The paper is very well written and all steps are rightly justified. \n\nQuestions:\n1. In Figure 4, for all three datasets, the performance starts to drop exactly after 50%. Can you provide any intuition behind this consistent pattern across all datasets?\n\n2.  In Figure 7(b), can you explain the cause behind the discontinuity of the \u201cBefore Pruning\u201d plot?\n"}