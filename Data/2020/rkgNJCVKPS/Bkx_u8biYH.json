{"rating": "1: Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "Paper summary\nThis paper aims to make model predictions of DenseNet more interpretable in order to aid the decision making process in clinical radiology. To do that, the authors suggest to visualize the layer-wise activations of the network, as well as the class activation map for a binary prediction task. The authors suggest that these visualisations be given to a radiologist in order to speed up, and improve reliability of the decision making process. To support their claim, the authors train the DenseNet on an abnormality detection task on the MURA data set under 4 different training conditions (data subset, pre-trained vs. not pre-trained). The authors then visualise an exemplary case study in figure 4 which they interpret in the results section (with additional cases in the Appendix). The authors conclude that these visualisations have been \u201cinsightful to the authors\u201d and that this work has revealed \u201ca close resemblance of a trained DenseNet [...] to the approach of a human\u201d.\n\nReview\nI vote to reject this paper. Unfortunately, I am having difficulties in identifying either novelty or usefulness in the presented approach that would support an ICLR publication.\n\nOn Novelty\nThe paper uses two ingredients to make DenseNet interpretable: (1) Layer activation maps, and (2) Class activation maps. Both of these ingredients are common approaches to do qualitative analysis of deep learning models. The authors don\u2019t claim novelty on these aspects, however since these are the major ingredients in their method it is important to comment on this. Both visualisation techniques belong into the standard toolbox in deep learning, applying them to DenseNet is not a novelty in itself. \n\nOn Usefulness\nEven though there might be no technical novelty, one could expect some practical usefulness in the presented approach. Either, (1) to build better models in the future, or (2) to aid - as the authors envisage - clinical practitioners. I will focus on the example presented in figure 4 to discuss these points. For this example, the authors argue that the \u201cfeature mechanism followed an intuitive hierarchical path\u201d, and that \u201cat the end of the network, most of the feature maps were activated close to where the fracture was located\u201d. I disagree with the authors. The only thing I can see with these feature maps is that they become coarser the deeper we go in the network, but that is simply owed to the model architecture. I cannot identify the fracture location from the feature maps in block 3 and 4. I believe that the authors judgement on the feature map is a result of their knowledge of the fracture location. But that is not a realistic situation in the clinical setting. Another point why I believe feature visualisation is not useful in the clinical practice is a point which the authors argue themselves: work fatigue (see the first sentence in the abstract). The original goal of the authors was to reduce overload for radiologist by giving them interpretable information. But what they suggest here is to increase the number of images that a radiologist has to look at from a couple of images to several 10s or even 100s of images. In my opinion, this would put more mental overload on radiologist even under the assumption that the feature maps give useful insights - which I still disagree with.\n\nImprovements\nIf the authors believe that feature maps visualisations can help to make models more interpretable, this is what I would suggest the authors to show:\n\n(1) Show that radiologists can actually improve in performance (speed, accuracy) when using CAM and feature activation maps. Run a study with radiologists that use the tools that you are suggesting.\n(2) Use insights from looking at the feature maps to motivate and train a different model architecture. Does the model behaviour change? Can you improve performance? Do features become more interpretable?\n"}