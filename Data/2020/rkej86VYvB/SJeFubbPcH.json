{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I did not assess the experiments.", "title": "Official Blind Review #4", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "1.\tThe paper suggests an ensemble method that leads to better performance over the execution of a single agent. The final (behavior) agent is a weighted average (or majority vote) of the members, where weights are determined by the accumulated TD error of the agent in the episode so far. The TD error serves as a confidence measure of the ensemble members in their predictions.\n2.\tAssume that one of the Q functions, Q_i is Q*. I.e., the optimal Q function. Let Q_ii = Q_i + B. I.e., a biased version of the optimal Q function. We know that both Q_i and Q_ii induce the same (optimal) policy. However, while delta_t^i is zero everywhere (the bellman error is zero for Q*), delta_t^ii is not zero (because of the discount factor). If B is large enough then delta_t^ii will be arbitrarily large to the point where the TDW algorithm will completely overlook Q_ii.\n3.\tFear of uncertainty: in stochastic settings the TD error will almost surely won\u2019t be zero. How does the method work in the presence of stochasticity?\n4.\tIn my understanding, TDW favors policies that go to deterministic parts of the state space (where the TD error can be arbitrarily small), over policies that go to uncertain parts of the state space (where the TD error will never be zero). However, it is not difficult to construct an example where the optimal policy is to go to the uncertain parts of the state space. Therefore, TDW favors determinism over uncertainty. However, determinism is not necessarily linked to better performance.\n5.\tThe paper links between certainty (as reflected in the TD error) and performance. If the performance criterion would be risk-sensitive, e.g. CVAR, then I could agree more with the claim (maybe then performance is linked with certainty). However, certainty and performance do not go together, at least not when talking about the expected return criteria. \n6.\tOut of curiosity: since the method requires calculating the max over Q. How would it work in a continuous action space?"}