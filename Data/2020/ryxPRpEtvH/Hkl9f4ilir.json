{"experience_assessment": "I have read many papers in this area.", "rating": "1: Reject", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "title": "Official Blind Review #4", "review": "Summary of the paper:\nThe paper tackles the probabilistic classification problem which is interesting and important in deep learning. The paper proposes an approach called omnibus dropout. Omnibus dropout is a sequential execution of existing dropout techniques such as drop layer, drop channel, drop block and regular dropout. The experimental results suggest that omnibus dropout perform reasonably well in various datasets.\n\nPros:\n1. The proposed approach is reasonable which I found no surprising it produces reasonably well results.\n\nCons:\n1. The paper could be improved in writing, especially on justification why this kind of dropout combination gives better performance. \n2. The results are mixed and the improvements are not significant. So I am not convinced the proposed approach is always a better strategy.\n3. The proposed approach is simply a combination of the existing dropout methods. The contribution of the paper is very limited.\n\nQuestions:\n1. In table 1, different dropout rate is chosen for different method. I think it is also reasonable to compare different methods with the same dropout rate (basically this corresponds to the actual model capacity).", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}