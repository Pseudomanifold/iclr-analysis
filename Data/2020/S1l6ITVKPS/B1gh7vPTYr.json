{"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This paper presents a network architecture based on the multi-head self-attention module to learn a new form of relational representations. The proposed method is shown to improve data efficiency and generalization ability on a sequence of curriculum learning tasks. \n\n+ The major novelty of this paper is a new attention-based network architecture that aims to discover objects and the relations between them. The idea of explicitly appending the patch positions to the representations is interesting, though I am not sure whether it can be generalized to real data.\n\n- Since the proposed network takes patches of full images as inputs, my major concern is about its effectiveness on high-dimensional images with more realistic objects as in the CLEVR dataset other than 2d-grid objects. It would be better if the authors could extend their method to natural images. \n\n- A closely related work is the NLM model [1], which can perfectly generalized to new tasks. Please compare the proposed model with it.\n\n- Minor: Figures are understandable, but some of them are too small, especially for the graphical legend. As space is an issue, I would suggest removing some plots and increasing the size of the ones provided. \n\n- In Figure 1, is g equal to n? \n\n[1] Neural Logic Machines. Dong et al., ICLR 2019."}