{"rating": "3: Weak Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review": "The paper is mostly concerned with multi-aspect sentiment classification.\n\nMulti-aspect sentiment analysis is an old problem (> 10 years), that usually operates on datasets with multidimensional sentiment labels (price, cleanliness, etc.). This paper has some variation on this old problem in the sense that it's more focused on generating explanations / justifications rather than purely on sentiment analysis.\n\nAlthough an interesting variant on a (somewhat niche) existing problem, I do feel that some aspects of this paper are a little dated -- claiming that the method is more useful for interpretability / justification doesn't seem so convincing these days unless you can make a stronger argument as to how it could actually be used to generate justifications that would be shown to users. I don't really see that in the current version. At the moment the output of the system appears to be attention weights over several aspects, showing which words in a review focus on which aspect. But this doesn't seem so different from how older methods (e.g. Bag-of-Words based techniques for multi-aspect sentiment classification), though their labels were possibly at the level of sentences rather than reviews.\n\nThe actual method itself seems appropriate, and is a nice update on previous techniques for multi-aspect sentiment analysis.\n\nPerhaps I missed some detail explaining why such a comparison is impossible, but there seems to be no direct comparison against traditional techniques for multi-aspect sentiment analysis. E.g. aren't even traditional models (like say Titov & McDonald) comparable to this? I understand the goal is somewhat different, but the input/output modality seems similar and such a comparison could be helpful.\n\nOverall, I think these days the standard is quite high for papers that make claims about generating convincing justifications/interpretations/explanations. There's little by way of human evaluation (there's a bit in the appendix, but it's not really focused on whether or not the model is useful for the claimed purpose of \"explanation\").\n\nMore positively, the authors have done *a lot* by way of experiments, in terms of ablations, and showing quantitative performance from different dimensions. The appendix is detailed and shows many examples. Overall I feel somewhat borderline about this paper, because there's a lot here, but I feel some of these key components mentioned above are missing."}