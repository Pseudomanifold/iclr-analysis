{"rating": "6: Weak Accept", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #376", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This paper produces a new method call TVmax and presents that the selective visual attention could improve the score in the Image Captioning task. Different from the fusedmax[2] which fuses attention in one dimension, the proposed method encourages the sparse attention over contiguous 2D regions. Compared with the softmax function, the sparsemax[1]  and the TVmax are able to sparse the visual attention very well. The paper also evaluates the score in both automated metrics and the human rating. Experiments show that the sparse visual attention achieves higher performance with a little computational cost.\n\nOne problem in this paper is that the author applies their proposed TVmax on Image Captioning  task, however it only achieves a little improvement on the automated metrics compared with the baseline(softmax). I wonder whether there is a better task for evaluating the visual attention. \n\nAlthough the proposed method (TVmax) is slightly worse than the sparsemax in the automated metrics, it is still promising in multimodal problems. \n\nTherefore, My decision leans to a weak accept.\n\nSome questions:\n1.From the experiments, the proposed method achieved only a little higher performance than the baseline(softmax). Could you please show some reasons about that?\n2.Could you show some results of TVmax on the other task in order to show the effectiveness of the proposed method?\n\n\n[1]From Softmax to Sparsemax: A Sparse Model of Attention and Multi-Label Classification.      Andr\u00e9 F. T. Martins, Ram\u00f3n Fernandez Astudillo\n[2]A Regularized Framework for Sparse and Structured Neural Attention .            Vlad Niculae, Mathieu Blondel"}