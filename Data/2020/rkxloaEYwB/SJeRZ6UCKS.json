{"experience_assessment": "I have published in this field for several years.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "This paper proposes to train a one-step transition model given fixed pre-trained representations, and shows how to leverage it in a best-first search to reach goals in toy grid-world like environments.\n\nThis paper tries to tackle an interesting problem, but there is unfortunately not much novelty in its approach, and the use of pre-trained modules is rather unsatisfactory for ICLR. In this current state I do not believe this paper is appropriate for publication at ICLR.\n\n1.\tTheir use of the cerebellum literature analogy was quite unhelpful, and did not actually leverage any of the recent discoveries of the cerebellum community [see 1, 2, 3]. There is nothing in their model that actually computes prediction errors (i.e. \u201csensory discrepancy\u201d in Figure 1), and in effect they just feed the action as any transition model would do. \u2028It is not appropriate to point to such neuroscience literature in such a light-hearted fashion, I found this quite misleading and below the expectations of a paper submission to ICLR.\n2.\tThe target of training a transition model in a fixed representation state is not particularly novel, and the architecture is quite standard as well. It is unlikely to handle any stochasticity, or to perform well when used in a multi-step fashion.\n3.\tA comparison to some other recent publications would have been helpful:\n     a.\tVariational state tabulation: https://arxiv.org/abs/1802.04325\n     b.\tUPN: https://arxiv.org/abs/1804.00645\n     c.\tFloyd-Marshall Reinforcement Learning: https://arxiv.org/abs/1809.09318\n     d.\tSub-goals trees: https://arxiv.org/abs/1906.05329\n4.\tThe problems considered were really about moving on a grid with fully connected actions. The distance metric shown in Figure 3 did not seem particularly well-behaved, or indicative of this approach scaling up to more complex planning problems.\n5.\tThe Laplacian Eigenmaps usage was not described in enough details. How was it trained, what happened if you chose the wrong number of dimensions?\n6.\tThe paper is rather too sparse on implementation and hyperparameter details, which may hinder reproducibility.\n\nReferences:\n[1] Cerebellum, Predictions and Errors, Laurentiu S. Popa and Timothy J. Ebner, Front. Cell. Neurosci., 15 January 2019, https://www.frontiersin.org/articles/10.3389/fncel.2018.00524/full\n[2] Most of Reza Shadmehr work: http://www.shadmehrlab.org/publications \n[3] Older works by Daniel Wolpert et al: http://cbl.eng.cam.ac.uk/pub/Public/Wolpert/Publications/WolMiaKaw98.pdf\n"}