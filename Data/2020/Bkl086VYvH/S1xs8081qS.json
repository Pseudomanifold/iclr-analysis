{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "A new online knowledge distillation is investigated by utilizing feature map information next to the logits via GAN. Instead of direct feature map alignment, the algorithm tries to transfer the distribution of the feature maps. There is no teacher per se, but the big and small nets are trained via an adversarial game where 2 discriminators try to minimize the distributions of the two nets. The idea is understandable but some issues remain:\n1-\tTraining GAN is by itself an expensive task and optimization is difficult, so how computationally expensive is this online KD compared to the offline one?\n2-\tIt is not clear form the paper feature maps from which layers are being used? If multiple layers are considered, how did you choose which ones are better. Also the smaller model has a different structure, h ow did you choose to pair feature maps in the big model and the small model?\n3-\tWhat would be the performance difference compared to offline knowledge distillation? For example in Table 1 can you please add a column with offline KD?\n4-\tMutual training brings some generalization, and when you compare the results in Table 3 with vanilla model, I am wondering if you made sure this is not only due to a better generalization.\n5-\tIn cyclic learning framework, it is not well-motivated why someone wants to train multiple networks that mimic each others\u2019 behavior; also the complexity increases in that case which makes me wondering wouldn\u2019t it be better to do it offline then?\n"}