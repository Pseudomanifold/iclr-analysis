{"rating": "8: Accept", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This paper proposed another graph embedding method. It focuses on directed graphs, and it embedded the graph nodes into exponential power distributions, which include the Gaussian distribution as a special case. The method is implemented by optimizing with respect to the free distributions on a statistical manifold so as to achieve the minimum distortion between the input/output distances.  The method is tested on several directed graph datasets and showed superior performance based on several metrics.\n\nOverall, the submission forms a complete and novel contribution in the area of graph embeddings. A key novelty is that the authors used the asymmetry of KL divergences to model the asymmetry of the distances in directed graphs, and they use the fact that KL is unbounded to model the infinite distances in undirected graphs. The proposed method has three main hyperparameters, \\lambda in eq.(1), \\beta in eq.(2), and the dimensionality of the target embedding. The author showed that \\lambda and \\beta are not sensitive and can be set to the default values, and 2-dimensional distributions already give much better results as compared to alternative embeddings. Moreover, the author proposed a scalable implementation based on sampling. Furthermore, the authored justified their choice of the target embedding space through some minor theoretical analysis given in section 3.\n\nThe writing quality and clarity are good (well above average).\n\nTo further improve this paper (e.g., in the final version), the authors are suggested to incorporate the following comments:\n\nIn the experimental evaluation, it should include some cases when the dimensionality of the target embedding has a large value (e.g., 50). This will make the evaluation more complete.\n\nThere are some typos and unusual expressions.  For example, page 3, what is \"a good proposal function\"?\n\nAfter eq.(1), mention \\lambda is a hyperparameter (that is not to be learned).\n\nTheorem 1 (2), mention the Fisher information matrix is wrt the coordinate system (\\sigma^1, \\cdots,\\sigma^k, \\mu^1, \\cdots, \\mu^k)\n\nIdeally, the experiments can include an undirected graph and show for example that the advantages of the proposed method become smaller in this case."}