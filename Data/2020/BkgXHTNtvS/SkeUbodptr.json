{"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "N/A", "review_assessment:_checking_correctness_of_experiments": "N/A", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper analyzes the existence of descent paths from any initial point to the global minimum for the two-layer ReLU network and gives a better characterization of the network width that guarantees the descent path property. Concretely, the paper shows that there exists poor local minima under the case of $n > m+2d-2$ by constructing concrete examples of datasets.\n\nTo show the global convergence property of the optimization method, this kind of landscape analysis is very important. Basically, I like this paper and I think it makes a certain contribution to this line of researches. However, I did not verify the proof.\n\nA few questions:\n- I am not sure why the authors say that \"it was not known whether the descent path property holds for $m \\in (2n/d, n)$\" by citing [Soudry and Hoffer(2017)]. I think [Soudry and Hoffer(2017)] does not mention the descent path property. Is this my misunderstanding?\n- The theory is limited to 2-layer ReLU. Can it be extended to deep networks?\n- The datasets producing poor local minima seem quite artificial. Does this theory hold for a more natural setting (e.g., assume a true distribution or function having preferable properties)?\n\nTypos:\n- In abstruct: exit -> exist\n- Section 1.2: $m < n - 2d$ -> $m < n - 2d + 2$.\n- After Corollary 1: Note that 1 does not ... -> Note that Corollary 1 does not "}