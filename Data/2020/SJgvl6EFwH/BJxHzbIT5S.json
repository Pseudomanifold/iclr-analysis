{"rating": "1: Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This paper proposes a conditioning approach for CNF and explore speed-up by tuning error tolerance of the ODE solvers.\n \nOverall, this is a mediocre paper which directly use a similar structure introduced in InfoGAN but absolutely lose beautiful insights in the construction of the loss function in InfoGAN, i.e., the mutual information between the generated image and codes. In other way, this paper is just an incremental paper with even less insights than the seminal paper. \nAt least in the loss function Eq. (4), I didn't see any mutual information regularization used here. Instead, the authors use a GMM but I am totally not sure why a GMM is better than the mutual information regularization. At the same time, in equation (4), I didn't see the specific definition of L_xent and L_NLL and thus I am not even able to verify that the use of the loss function is correct. For the current version, I am not be able to gain any insight from the loss function. It seems to be an ensemble of several existing works and definitely not innovative. \n\nFor the tuning error of the ODE solvers, I didn't even see the problem statement.  Is it possible to make the problem more clear? It seems that the first time when the authors mentioned error tolerance is in contribution 2, but I didn't see the definition of the error tolerance. I am not sure whether it is a good idea to introduce two problems in one paper. At the same time, I do not know why the problem should be formulated in the form of the reinforcement learning problem. I didn't see any advantage.  Intuitively, learning a generative model can be time consuming  and solving a reinforcement learning problem is also hard. I do not understand why combining them together would be beneficial and even time efficient? For me, it seems that authors are just trying to make the problem unnecessarily more complicated and thus they can use fancy tools to solve it.  \n\n"}