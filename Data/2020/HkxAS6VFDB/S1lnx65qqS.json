{"rating": "3: Weak Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #4", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "The authors propose a hardware-agnostic metric called effective signal norm (ESN) to measure the computational cost of convolutional neural networks. This metric aims to fairly measure the effects of pruning and quantization. What\u2019s more, based on the metric, the authors demonstrate that models with fewer parameters achieve far better accuracy after quantization. A large number of experiments are carried out to prove the effects of the metric and related conclusions, however, several experiments and arguments are confusing. \n\nPlease see my detailed comments below.\n\nPositive Points:\n1. The authors propose a hardware-agnostic metric named effective signal norm (ESN), aiming to measure the computational cost of the pruned and quantized models.\n\n2. Based on the proposed metric, the authors conclude that a moderately quantized slim model with fewer weight parameters achieves better performance rather than an extremely quantized fat model with huge number of parameters.\n\n3. This paper presents many interesting assumptions and possibilities, which can be further researched and explored in the future.\n\n\nNegative Points:\n1. The authors argue that ESN is a hardware-agnostic metric. However, ESN is based on ideal hardware, where the energy consumption is linearly proportional to the number of non-zero weight parameters and monotonically depends on the bit-width of weight parameters. Therefore, ESN is not suitable for existing hardware.\n\n2. Both of ESN_a and ESN_d are based on the assumptions instead of the fact, which is not convincing. What\u2019s more, the assumptions are hard to be proved.\n\n3. The experiments are not strong enough to support the author's conclusions. For example, the authors argue that \u201cmodels with fewer parameters achieve far better accuracy in low computational cost region after quantization\u201d. However, this conclusion is only based on the ESN metric. Since ESN is based on some assumptions, this conclusion is not convincing.\n\n4. Please give more details about the quantitative relation between the quantization noise and the perturbation of weight parameters during SGD training.\n\n5. In terms of Figure 2, the author's description is not objective. The similarity between the ESN_a curves and the validation accuracy curves is not very high. Besides, the authors mention that \u201cafter steep rise at 80 epoch, both ESN_a and validation accuracy decrease gradually\u201d. However, the performance degradation in Figure 2 is not obvious. Therefore, the conclusions drew by the observation are also unreliable.\n\n6. The ESN can not make an accurate evaluation of a model. The trade-off between accuracy, speed, model size is often required in model compression. However, the ESN can not make the trade-off between them. Moreover, the ESN does not have a clear application scenario.\n\nMinor issues:\n1.\tThere are lots of spelling and grammar mistakes in the paper, such as \u201can ideal hardware \u201d, \u201ca extremely quantized fat model\u201d and so on.\n"}