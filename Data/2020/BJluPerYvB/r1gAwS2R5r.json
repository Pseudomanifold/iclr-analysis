{"rating": "6: Weak Accept", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review": "This study introduces a simple regularisation scheme that enforces an alignment between the logit distribution of two samples from the same class and/or augmented samples. The results demonstrate substantial gains in accuracy across several data sets compared to other output-based regularisation schemes.\n\nThe manuscript is well written, the story is clear and straight-forward, and the amount of experiments is extensive. I only have a few comments:\n\n* Please reference the logit-pairing paper [1] which uses a similar idea (encouraging logits from the same class to be similar) but uses a slightly different formulation and only evaluates it in the realm of adversarial robustness. Nonetheless, I believe this is an important related work to cite.\n* I did not find any comparison to simple L2 weight decay. I understand that weight decay is not an output regularisation, but most readers would still be interested (maybe add it to Table 2?).\n* How important is the regularisation on augmented samples relative to the regularisation based purely on the different samples from the same class?\n* It is unclear which networks you have used in table 2 and 3.\n* Assuming that you used ResNet-18 in table 2, I am wondering about a discrepancy between the values you report for mixup: in the original paper mixup decreases the error of ResNet-18 on CIFAR-100 from 25.6% to 21.1%, while you see a decrease only to 23.28%. Could you please explain the difference?\n\n[1] Adversarial Logit Pairing, Harini Kannan, Alexey Kurakin, Ian Goodfellow"}