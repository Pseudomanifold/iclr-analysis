{"experience_assessment": "I have published in this field for several years.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "The authors propose a tensor based approach to multi-task learning. The layers of a deep neural networks are parameterized with a low-rank tensor decomposition (tensor ring). Some of the cores are shared between all tasks, while others are task specific.\n\nHowever, the novelty is low as this has been already well studied, and the novelty is limited to the use of a tensor-ring decomposition instead of tensor-train or Tucker decomposition.\nWhile the use of tensor-ring instead of tensor-train is intuitively a good idea, since it removes the boundary conditions, it is not enough.\nOverall the paper feels a little \"all over the place\" with several small parts, not well connected, or justified.\nIt would be more convincing to focus on a few established experimental scenarios and demonstrate better performance on these.\nThe best such scenario is probably the Visual Domain Decathlon [1], which would allow to both evaluate the method and rigorously compare it with previous works.\n\nThe paper is relatively hard to read. The use of summation based notation for tensor operations (e.g. in 3.1) makes it unnecessarily cumbersome. \nThe paper could be made much clearer by reorganising it and improving the writing. In particular, the contributions are not made clear enough by the authors.\nThe sharing of the cores seems somewhat arbitrary and not grounded in any theory. How is this chosen? Note that this adds a significant parameter to optimize.\n\nThe experimental setting is not convincing. In particular, MNIST and Omniglot do not demonstrate any advantage of the proposed method. \nThe experiments on UFC11 are not informative as the proposed method is not compared with any state-of-the-art method or even baseline.\nRather than hand picking datasets, it would be more convincing to test on an established benchmark for multi-task learning (e.g. [1]).\n\nThe proposed methodology should be compared with other similar, recent methods (e.g. tensor based \"Incremental multi-domain learning with network latent tensor factorization\", or SVD based, \"Learning multiple visual domains with residual adapters\").\nTable 3 and 5 could be moved to appendix and replaced with a table of results comparing the proposed approach to existing methodologies.                                                                    \n\nHow are the various hyper-parameters of the models chosen in practice? e.g. the choice of shared factors, rank of the decomposition, etc? In general, the paper is not easily reproducible due to the lack of implementation details.\n\n\n[1] Learning multiple visual domains with residual adapters, NeurIPS 2017.\n"}