{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "This paper proposes a framework to predict valence and arousal tasks in videos. The framework mainly employs LSTM in a two-time-scale-structure to take multimodal inputs. In general, the proposed framework groups well-studied techniques to solve a well-known task of multimodal learning. \n\nDNN based Multimodal learning has been heavily investigated for a long time. Numerous frameworks have been proposed with various success. Although the proposed framework is technically sound, the proposed \"residual-based training strategy\" and \"long temporal fusion\" are kind of trivial or lackluster. I can hardly identify any significant contributions that support a publication in top machine learning conferences such as ICLR."}