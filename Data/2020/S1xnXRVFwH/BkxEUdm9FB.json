{"rating": "6: Weak Accept", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper describes an application of lottery ticket hypothesis to NLP and RL problems. An extensive set of experiments on very strong baseline models on language modeling, machine translation and atari games demonstrates that lottery ticket hypothesis is not only present in feed-forward and convolutional nets on image classification tasks as demonstrated originally in papers by Frankle & Carbin, 2019 and Frankle et al 2019. I don't have any major complaints regarding this work and I believe it is well executed.\n\nFor NLP problems it would be nice to have additional ablation studies comparing lottery ticket hypothesis pruning with methods like distillation (Hinton et al 2014) and attention pruning (Michel et al 2019 Are Sixteen Heads Really Better than One?). \n\nFor RL it is quite interesting that pruning weights sometimes improves the final scores on Atari games like Berzerk, Kangaroo, Krull and Centipede perhaps due to exploration. As a future work it would be interesting to see a way to using lottery ticket hypothesis to guide exploration in RL.\n\nOverall it is well executed paper, although it is mainly an application of existing lottery ticket hypothesis techniques to NLP and RL."}