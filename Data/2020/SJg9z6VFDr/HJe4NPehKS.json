{"rating": "6: Weak Accept", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "Summary:  This work extends Neural ODE to graph networks and compares the continuous adjoint method with propagation through the ODE solver.\n\nThe paper addresses an interesting and important problem and it is well-written in general.\nTo determine the significance of this work, I have two questions:\n\nQuestion: \n1. What is the major difference between the original Neural ODE and the Graph Neural ODE? \nFor example, In graph networks, each node\u2019s representation may depend on its neighbor nodes. Will this impact the way you formulate the adjoints or compute the derivative?\n\n2. It seems in Mechanical engineering, various adjoint methods such as Discrete adjoint (e.g. [1])  has been studied.\nHow does the direct propagation through solver related to the these Discrete adjoint methods?\n\nSome minor comments for experiments:\nThe authors have 10 runs and take the best one. How about the average? which maybe a better indicator for stability.\nHow is the runtime comparing normal NN, adjoint, and direct propagation. Runtime has been a major disadvantage for Neural ODE.\n\nDecision:\nOverall, the novelty seems somewhat incremental, but I still feel the work is concrete and meaningful. I vote for weak accept.\nLooking forward to the code.\n\n[1] A Discrete Adjoint-Based Approach for Optimization Problems on Three-Dimensional Unstructured Meshes. Dimitri J. Mavriplis"}