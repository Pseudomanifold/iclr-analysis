{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I did not assess the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "The paper defines a representation learning strategy based upon estimation\nof a matrix of Wasserstein distances.\n\nThe idea is excellent.  The ability to \"solve\" IPMs reliably is a recent\ndevelopment in deep learning whose ramifications are still being explored.\nIntuitively this line of research could plausibly result in general\nmethods which are theoretically intelligible and broadly applicable.\nIndexing at least one side of the matrix of estimated WDs with events\n(rather than classes) has interpretability properties useful for\ninformation retrieval and also conveys benefits reminiscent of learning\nwith privileged information.\n\nHowever, the exposition could be greatly improved by using the\nstandard language of probability theory.  The discussion in 3.1\nwas particularly painful to read.  What is the difference between\n\"existing in an environment\" and \"conditioning on a measurable event\"?\nPhrases like \"belonging to any random subset of the dataset\" suggest\na non-deterministic method of selecting an element of the power set of\nthe training data, but it is unclear what to do if more training data\narrives in this case.  \n\nThroughout the entire paper the word \"random\" is apparently used in the \ncolloquial sense of \"arbitrary\".  *Correct every instance of this.*\nIf you actually are referring to generating samples from a distribution,\nbe explicit about the generative process.\n\nSection 3.5 was more confusing than enlightening.  In general I understand \nthat environments can be leveraged for intelligibility and admit manipulation \nfor information retrieval.  The exact strategy remains somewhat opaque.  If \nyou are under space constraints refer to an appendix with more explicit details.\n\nIn the experiments section phrases like \"environments consist of random \ncombinations of classes\" is also not helpful.  Do you mean something like \n\"uniformly selected from the set of all class pairs?\"  Or something like \n\"uniformly selected from the power set of all classes?\"  How volatile\nare the experimental results with respect to the non-deterministic choice \nof environments? \n\nI want to accept this paper if the exposition is improved, which I think\nis possible during the response period.\n\nMy other comments are not blocking issues, but would either improve the\ncurrent paper or inform future directions of research.\n\nThe technique bears some resemblance to Wasserstein Discriminant\nAnalysis.[1]  That paper seeks a projection that maximizes the ratio of \nWasserstein distance between classes vs. within classes.  Here, \nalthough the common representation is a nonlinear mapping \nanalogous to a projection, we merely try to estimate all the\nWasserstein distances rather than maximize them, so it is not trained\nto be discriminative per se.   That is ok since the representation is\ndesigned to be used for a variety of tasks (modulo section 4.2), but it \ndoes leave open the question \"what if the matrix of estimated \nWasserstein distances isn't informative, e.g., due to poor choice of \nenvironments?\"  There is no attempt to assess the representation \nexcept via utility in downstream tasks.\n\nThe common representation was justified computationally, but I suspect\nis beneficial statistically.  It might facilitate safely including a\nlarge number of environments and then spectrally compressing (i.e., SVD)\nthe resulting matrix without overfitting the data.  However clearly if\nthe capacity of this layer is too small, then all estimated WDs will\nbe close to zero.  If we posit a low Bayes error classifier for the\nmulti-class problem associated with the dataset, that might imply there\nis some conditioning of the input under which the matrix of (actual) WDs\nhas rank equal to the number of classes, which would in turn provide a\nuseful diagnostic to guard against an insufficiently discriminative choice\nof environments or insufficient capacity in the common representation. If\nthe matrix is full rank with a flat spectrum, however, that might indicate\nthe choice of environments is too granular and overfitting has occurred,\nit's not immediately obvious to me how to guard against this.  \n\nI am curious what the results in appendix A.1. look like relative to the spectral \nnorm or the smallest eigenvalue of the estimated WD matrix (smallest \neigenvalue assuming number of environments < number of classes,\notherwise the k-th eigenvalue where k = number of classes).\n\n[1] https://arxiv.org/abs/1608.08063\n"}