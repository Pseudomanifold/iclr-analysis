{"experience_assessment": "I do not know much about this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "This paper proposes a method to cluster subjects based on the latent lifetime distribution. The proposed model clusters by maximizing the empirical divergence between different clusters. \n\nThe problem setting of this paper is not clear to me. I am not sure which variables are observed and which are not.  For example, in the Friendster experiment, the data of 5 months from joining is used for clustering. However, the termination windows are chosen to be 10 months. Therefore, it is clear that the observed data will not contain the termination signals, and I do not believe the training of the model is possible, without observing any termination signals.  In the paper, do we consider only one type or multiple types of events? Is $M_{k, i}$ a vector that represents the attributes or properties of an event?\n\nSome details of the model are not clear to me. In Equation (2), the input of the neural network differs in length across different subject $u$, because the number of observed events for each subject is different. \nHow does the proposed neural network take inputs of different lengths?\nHow the non-decreasing function $\\xi^{(u)}$ is defined in Section 3.2? Is it a function of the observed data for each subject?  \n\nHow the empirical distribution $\\hat{S}_i$ in Equation (4) is computed is also not clear to me. How $\\hat{S}_i$ is a vector? Is it constructed by concatenating $\\hat{S}_k(W_1, W_2; D)[t] $ with different $t$? How to normalize $\\hat{S}_i$ such that it is a valid probabilistic distribution? Since $\\hat{S}_i$ is high dimensional, it looks very challenging to estimate the joint distribution.\n\nThe overall objective function is given by Equation (4), is it correct? In Equation (4), why should we compute the minimum values across all possible pairs of clusters rather than the summation of all pairs? If Equation (4) is the overall objective function, then it looks like the model does not contain a component that maximizes a likelihood function. How is it guaranteed that the model will fit the data? It looks like the model will converge to a trivial solution that $\\beta$ is a constant such that $\\beta = 1$ for one cluster and $\\beta = 0$ for another cluster, if the likelihood function is not involved. This will give a maximum divergence between distributions. \n\nIn summary, it seems that numerous technical details are missing and the paper might contain technical flaws. I do not suggest the acceptance of this paper.\n\n"}