{"rating": "3: Weak Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "The authors tackle the important problem of generating saliency maps. First, a decoy image is defined (in short, it is a perturbed version of the image that leads to very similar activations) and then, the method that leverages decoy images is proposed. The method can be understood as a improvement that can be applied to enhance an existing saliency extractor. For a given image, the method generates a bunch of decoys images, and then a given saliency extractor is applied to not only the original image but all generated decoy images. The resulting saliency maps are aggregated to output the final saliency map. I found this idea technically sound.\n\nHowever, there are two keys reasons why this paper should be rejected.\n(1) The idea of using decoy images is interesting but computationally expensive. In practice (as showed in the paper) using blurred images leads to comparable results.\n(2) The paper misses one very important experiment which is a quantitative comparison with the existing works on Imagenet ILSVRC\u201914 localization task. This is the standard experiment and is used in a few works cited (Fong & Vedaldi, 2017; Dabkowski & Gal, 2017).\n\nEven though the idea of using decoy images is technically sound, I find the algorithm for generating these decoy images very complex and computationally expensive. First, under Eq.6 one can find \"Our strategy is to set c to a small value initially and run the optimization. If it fails, then we double c and repeat until success.\" And then below Eq.8 there is \"After each iteration, if the second term in Equation 8 is zero, indicating that \u03c4 is too large, then we reduce \u03c4 by a factor of 0.95 and repeat\". Hence, the algorithm is nested and the paper does not provide any details how long the procedure is in practice. On top of that, since a population of decoy images is needed (12 in the experiments), this expensive procedure has to be run a few times. When decoy images are replaced with blurry images the results are almost the same and hence, unfortunately, using decoy images is not justified.\n\nIn general, the experimental results are decent and prove the possible benefits of using the population of images (decoys or blurred ones). However, I think that Imagenet ILSVRC\u201914 localization task is the standard experiment that provides the quantitative view and should be performed. The paper evaluates on Imagenet data set already, and hence adding this experiment should be straightforward.\n\nThe paper does a good job motivating the problem and covering related work. The paper states that the key limitation of existing saliency maps is that they \"evaluate pixel-wise importance in an isolated fashion by design, implicitly assuming that other pixels are fixed\" and \"the presence of gradient saturation\". While it is valid for gradient-based methods, it is not for perturbation-based methods. The latter are just briefly mentioned and then it is stated that \"for any perturbation-based method, a key challenge is ensuring that the perturbations are effective yet preserving the training distribution\". However, I do not find this reason to be strong enough to exclude these work from consideration, because there are works that train saliency extractor and the classifier simultaneously and then the argument mentioned does not hold (Fan et al., 2017; Zolna et al., 2018).\n\nThere is one more thing that I would like to ask about. In Eq.3, Z_j is defined as max(E\u02dc_j ) \u2212 min(E\u02dc_j ). Hence, if a given pixel is very important for all decoy images, all elements of E\u02dc_j will be high and then Z_j will be very small. As a result, a saliency value assigned to this pixel will be low which seems to be counter-intuitive. Can you please elaborate on that?\n\n\n(Fong & Vedaldi, 2017): Ruth C Fong, and Andrea Vedaldi. Interpretable explanations of black boxes by meaningful perturbation\n(Dabkowski & Gal, 2017): Piotr Dabkowski, and Yarin Gal. Real time image saliency for black box classifiers\n(Fan et al 2017): Lijie Fan, Shengjia Zhao, and Stefano Ermon. Adversarial localization network\n(Zolna et al 2018): Konrad Zolna, Krzysztof J. Geras, and Kyunghyun Cho. Classifier-agnostic saliency map extraction"}