{"experience_assessment": "I have published in this field for several years.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "N/A", "review_assessment:_checking_correctness_of_experiments": "N/A", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "Summary: the paper consider representational aspects of neural tangent kernels (NTKs). More precisely, recent literature on overparametrized neural networks has identified NTKs as a way to characterize the behavior of gradient descent on wide neural networks as fitting these types of kernels. This paper focuses on the representational aspect: namely that functions of appropriate \"complexity\" can be written as an NTK with parameters close to initialization (comparably close to what results on gradient descent get).  \nThe main technical ingredients are a constructing a \"transport\" map via a Fourier-expansion style averaging (ala Baron), and subsequently subsampling this average ala Maurey-style analyses to get a finite width average. \nThe authors also identify function classes which are well-behaved with respect to these techniques: smoothed functions (via convolving with a Gaussian), functions which have a small RKHS norm (for an appropriate RKHS derived from NTKs), functions with small modulus of continuity. \n\nEvaluation: the paper is a strong contribution, on a topic which is of great current interest, and I recommend acceptance. It is very nice that many of the standard tools in approximation theory (Fourier expansions, Maurey sampling, etc.) play nicely with NTKs, and also that the scaling of the # of neurons necessary that appears in the current literature can be also recovered via a representation theoretic viewpoint. The paper is written well, and is easy to read. \n\nMinor comments: \n* I'd rearrange the bullets bounding B_{f,\\epsilon} for the various subcases of Theorem 1.3: I think the RKHS is the most \"vanilla\" bound, given that you can extract a RKHS; bounds in terms of the modulus of continuity should go next (this is the \"weakest\" assumption); smoothed f's should go last (this is like a smoothed complexity kind of result) \n* w_f isn't defined until section 3.2 -- I'd put a pointer in the statement of Theorem 1.3 to the equation, not just the section. \n* I'm not sure \"transport\" is the ideal term -- it brings to mind \"optimal transport\", and I kept expecting some Wasserstein connection. \n\n"}