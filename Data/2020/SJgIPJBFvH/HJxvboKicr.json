{"rating": "8: Accept", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "The paper addresses the well-known generalization problem for deep networks: why do these models successfully generalize even though they contain more parameters than the size of the training set? Recent works on this problem have proposed various measures of model complexity (that is, different from the number of parameters) with the claim that they (at least partially) capture the \"true\" capacity of deep networks in order to answer this question. The authors report the results of a large-scale, systematic study of the empirical effect of these complexity measures on the observed generalization behavior of deep networks.\n\nThe empirical study of generalization behavior is inherently tricky, and the authors make a non-trivial contribution just by designing an experiment that can convincingly address this question. The authors give careful attention to various potential obstacles related to experimental design and statistical validity. \n\nThe results of the authors' experiments are highly valuable to the research community. I recommend to accept.\n\n*********************************************************************************\n\nTechnical comments for the authors: \n-Please rewrite or elaborate on the first two paragraphs of section 6 for clarity.\n\n-It seems to make little sense to consider norm-based complexity measures that are not margin-normalized (or at least normalized in some other way). Please include a margin-normalized version of each such measure in Table 5; certain key quantities (e.g. \"frob-distance\") have no corresponding margin-normalized entry.\n\n-The quantity \"sum-of-frob/margin\" is certainly a quantity of interest and it should be included in table 2 and possibly merits some discussion.\n\n-I disagree somewhat with the discussion of the spectral bound in section 7. In particular, I would not agree that the poor performance of \"spec-orig\" is surprising, because it contains an astronomically-sized \"proof artifact\" (as you call it). Namely, in this bound and in similar norm-based bounds, the term which is the product of the matrices in the network is (heuristically) unnecessary; in particular it (heuristically) ought to be able to be replaced with the network's \"average-case Lipschitz constant\" (this is one of the issues which Arora et al. 2018 attempted to address; unfortunately formalizing an adequate notion of \"average-case Lipschitz constant\" can be quite cumbersome). This superfluous product of matrix norms is of course highly correlated with model size, so it is not surprising that the quantity would have a sizable negative correlation with generalization. The quantity I would consider to be the \"main term\" is the quantity \"fro/spec\". Furthermore, the fact that this quantity (which appears in both Bartlett et al. and Arora et al.) performs somewhat worse than simply \"sum-of-fro\" is fairly interesting and possibly merits some discussion.\n"}