{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "N/A", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This paper proposes Resizable Neural Networks, which trains networks with different resolution scalings at the same time with shared weights. It serves as data-augmentation and improves accuracy over base networks. Additionally, the same technique can perform an architecture search. Experimental results show significant accuracy gains.\n\nThe reported accuracy gains are substantial. The proposed method is potentially useful in many applications. However, several details are missing or hard to understand. Without additional descriptions, it is not straightforward to implement the method. Thus, I suggest for rejection. The score might be raised depending on updates and code release.\n\nMajor comments:\n1) Algorithm 1 has \"predefined spatial list L.\" How to choose it in practice?\n2) Algorithm 1 indicates that the training time is len(L) times longer. Additionally, according to the implementation details, Resizable Networks are trained two times many epochs. It seems hard to justify such a longer training time.\n3) This is similar to (2), but why Resizable-NAS is better than the all len(L) models separately to find better architectures?\n4) In Sec. 3.4, how the \"target model\" is selected after the training of Resizable Networks?\n5) Why is Resizable-Adapt omitted from Table 2?\n6) References are out-dated. For example, there are no \"Figure 5.\"\n\nMinor comments:\n1) Are any ablation studies available for Fair Sampling?"}