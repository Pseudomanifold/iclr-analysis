{"rating": "8: Accept", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "The paper tackles a very important problem, manipulation robustness of modern machine learning models, by applying a chain of design choices perfectly well:\n  * VAEs as probabilistic generators\n  * Manipulations as independent causes that can be generated by interventions\n  * Causal inference for manipulation-corrected training\n  * Bayesian inference for robust prediction\n\nSticking to the Bayesian point of view, the method can perform model averaging across potential manipulations at the test time. This is an extremely elegant property, which is also proven in the experiments to be very effective.\n\nBeing able to learn previously unseen types of manipulations only by proper application of causal inference tools is a very important news for the adversarial robustness community.\n\nFigure 9 is a spectacular proof of concept to illustrate the disentanglement property of the proposed method.\n\nI have only one point for improvement. I do not buy the argument that we should do q(m|x) but not q(m|x,y). Why should we exclude class-specific manipulations? This wouldn't affect the cause (the class) but only the outcome, so would be a valid manipulation. I would actually expect the model to work still well with q(m|x,y). Could the authors comment on what the concrete benefit of leaving out y from manipulations is?\n\nThe construction of the loss in Eq 5 is in spirit semi-supervised learning on m. We show the true m=0 cases to the model during training but assume not to know the labels of the manipulated samples. It could be beneficial to draw a link to semi-supervised learning here and even tie it to the arguments about the relationship between causal inference and semi-supervised learning:\n\nSch\u00f6lkopf et all., On Causal and Anticausal Learning, ICML, 2012.\n"}