{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "*Summary*\nThis paper studies the impact of momentum for escaping Saddle points with SGD (+momentum) in a non-convex optimization setting. \nThey prove that using a large momentum value (i.e. close to one) provides a better constant for the convergence rate to second order stationary points.\nThe approach is well motivated by the current seek for a better understanding of the training methods used in practical deep learning. The related work seems to be well addressed.\n \n*Decision*: \nI think that this paper is borderline for the following reasons: First I would like to acknowledge the fact that the problem of studying the impact of momentum on SGD is a very challenging problem with a plethora of open questions even in the convex setting. Thus, trying to show evidence of a significant additive value of momentum in the non-convex setting is a very hard problem. \nHowever, I am not fully convinced that this work provides a results that exhibits a regime where momentum helps to escape saddle point faster (or to converge faster).\nThus I am leaning toward a weak reject but I am eager to change my grade if the authors convince me that their results bring theoretical improvements.   \n \n*Questions*:\n- I would like to be convinced that the analysis use the momentum aspect to improve in some ways the convergence rate of SGD and does not reduce to a perturbation analysis of the SGD method. Because of the constraints on $\\beta$ (for instance $1-\\beta < L^{1/3}$) , your $1-\\beta$ dependance in the convergence rate cannot be better than $L^{1/3}$. Thus, one could believe the $\\beta$ in the bound is only a hidden proxy for the Lipschitz constant or for $\\sigma$.  One way to be convincing about the fact that this bound is interesting would be to provide some regime where we can see improvements compared with related work. (e.g. $L >> \\sigma, c\u2019>> 1$) Or maybe if the current theoretical interest of the momentum is only in escaping saddle point better (since its convergence in the convex case is still not well understood) than regular SGD methods.\n- To what extend your assumptions are comparable to the ones made in the close related work (papers presented in Table 1) ?\n \n \n \n*Minor remarks*:\n- You should cite something for the NP-hardness of finding local minima. \n- The definition for $(\\epsilon,\\epsilon)$-second order stationary point would be a bit cleared with two different epsilon $\\epsilon_1,\\epsilon_2$.\n- I think should should put the constraints you have on $\\beta$ in the main paper.\n-  In definition 2 does $M_t$ depends on $k$ or is it a typo, (the summation index for $G_{s,t}$ depends on $k$ that make the definition confusing) ? Can $G_{s,t}$ be rewritten as $I- \\eta (1 - \\beta^s)/(1-\\beta) \\nabla^2f(\\omega_t)$ to avoid to introduce an unnecessary sum notation ?  \n- Usually footnotes are after the punctuation sign (because you want to comment the whole sentence and not its last word).\n- Footnote 4 is in the wrong page.\n"}