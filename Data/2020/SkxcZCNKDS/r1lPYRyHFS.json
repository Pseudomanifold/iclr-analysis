{"rating": "8: Accept", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "The paper investigates the reason behind the success of MaxEntropy in reinforcement learning theoretically, connecting it to  robust control.\n\nI  think the paper should be accepted, as it investigates an important approach and offers useful insight. I think that the robust reward is an interesting perspective and the paper is also well written.\n\nI need to remark that I am not familiar enough with RL theory literature to know of novel this work is,.\n\nDetailed remarks:\n- There is an error in the proof in A.1. You are optimizing a functional not a function, so the cannot simply use Lagrange multipliers (also the derivation ignores the integral). The problem is solved easily with (constrained) Euler-Lagrange and must be corrected.\n- I disagree with the exploration paragraph in sec. 2. While the final applied agent might be deterministic, using a stochastic agent for exploration during learning is helpful. Exploration might not be only (or main) motivation behind MaxEntRL but it still a good motivation.\n-  I was happy to see the limitation of lemma 4.1 stated clearly, as some paper are less honest with their limitations.\n- You write \"Only the oracle version of fictitious play, which makes assumptions not made by MaxEnt\", maybe I missed it but I didn't see what assumptions the oracle made.\n- MaxEnt has been very successful in inverse RL where we try to find the reward, which seems connected to the conclusions here about robustness to reward perturbations. While adding analysis on IRL might be outside the scope of this paper, something at least should be said about maxEnt and IRL and the connection to the current results. \n\nTypo:\n\"inference problem be defining\" -> \"inference problem by defining\""}