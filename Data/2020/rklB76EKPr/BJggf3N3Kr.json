{"rating": "6: Weak Accept", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "Summary:\n\nGradient clipping has been studied as an optimization technique and also as a tool for privacy preserving, but in this paper, it studies the robustness properties of gradient clipping.  More specifically, the main question of the paper is: Can gradient clipping mitigate label noise?  The paper reveals that the answer is no, but further proposes a simple variant of gradient clipping is robust and has nice property of classification calibration.  Experiments show that the proposed variant works under label noise.\n\n\nStrength of the paper:\n\nThe motivation and goal of the paper is stated in the title and is very clear, making it easier to follow the story of the paper.  There are sufficient background on the loss functions and gradient clipping in the beginning that helps guide the reader.  The proposed method is robust to label noise and has theoretical guarantees.  The relationship between similar work is summarized.  Experiments have both synthetic and benchmark datasets to demonstrate the behavior of the proposed method.\n\n\nWeakness of the paper:\n\nCurrently, the experiments only include methods studied in the paper.  It would be better to include baseline methods stated in the end of Section 5 or in Section 4.3."}