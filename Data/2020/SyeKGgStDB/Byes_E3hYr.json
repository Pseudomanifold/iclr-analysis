{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The authors present the results of training a natural media painting agent using reinforcement learning for different types of strokes. The agent seems to be capable of learning how to pain under different types of constraints and produce visually interesting images.\n\nComments:\n\n- Given that the authors give an implementation of the constrained RL agent as one of the key contributions of the paper, there is a glaring absence of mentioning related work on constrained reinforcement learning and reviewing the existing approaches in literature, in order to compare and contrast what the authors propose in this paper. This makes it hard for the readers to assess the novelty of the contribution.\n\n- Similarly, the authors should discuss in more detail the limitations on the types of constraints that are possible to easily express in this framework, given the simplicity of the constraints that are shown in the experiments\n\n- The readability of the paper seems like it could be improved. Apart from typos, there seem to be many long enumerations of approaches that other researchers have taken in this space, but for a reader it is not immediately obvious how these come together and relate to the work that is being presented.\n\n- With the above in mind, one thing that was conceptually unclear to me is that one of the main advantages of the proposed approach, according to the authors, when compared to some of the cited related work, is that this approach can generate intermediate representations and not just the final output with most resemblance to the reference picture. There is a mention of this opening up new artistic possibilities. Yet, this particular use case is not given central stage in evaluation. The authors should provide more examples of why this particular capability is relevant and how it leads to interesting outcomes.\n\n- The authors say: \u201cwe use 5 strokes to reproduce hand-written digits images, 20 strokes to reproduce character images, 100 strokes to reproduce face and object images\u201d - which does seem reasonable, but the actual numbers (5, 20, 100) are not well motivated. After all, why not (10, 50, 200) or (5, 40, 100) or (5, 40, 200)? It would be good to show experimentally (for one of these) that the choice is justified. I\u2019m not familiar with KanjiVG - but there do exist kanji characters with more than 50 strokes. I\u2019m guessing they are not present in this dataset?\n\n- The authors should provide more details on the specifics of the model architecture and the hyperparameters that have been used / explored.\n\n- In the results/discussion of the paper, the authors should compare to prior work and highlight their novel contributions. Given that multiple papers out there that have had at first glance similar-looking results, it is hard to otherwise qualitatively judge whether what is proposed in this paper is better, without any form of side-by-side comparison.\n"}