{"rating": "3: Weak Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "The submission is proposing an adaptive derivative-free optimization method. In this method, the sampling covariances are adapted between different covariance adaptation heuristics. The main intuition is seeing each algorithm as an arm in multi-armed bandit (MAB) setting. Moreover, authors use EXP3.P as an online learning mechanism.\n\nThe idea and intuition is definitely interesting. Although the idea of adapting DFO using MAB has been already explored, using MAB for choosing covariance adaptation scheme is definitely novel and interesting. However, the submission has various issues which need to be fixed.\n\nThe claim that the existing adaptation mechanisms have no guarantees is not correct. (Ye et al, 2019) provides convergence guarantees. Moreover, most of the existing adaptive optimization method convergence guarantees can be extended to DFO in a straightforward manner.\n\nThe main claim (\"we can show that our method converges with a high probability when the underlying function is convex\") is not completely substantiated. The high-probability no-regret guarantee (Theorem 2) the authors state is using the iterates (w_t) as an input. It shows that given adversarially chosen iterates (w_t), the Exp3.p has no regret. However, this says nothing about the convergence of these iterates (w_1,...,w_t). I think it is not hard to prove the main claim; however, the reasoning provided in the paper is incomplete. More importantly, both Thm.1 and Thm.2 are specifying the sample complexity of the methods. Whereas, authors only give rather asymptotic argument. Authors should 1) rigorously prove the convergence guarantee as an additional theorem. And, 2) give sample complexity of the proposed method.\n\nAnother issue is the empirical validation. It is clear from the results that the adam-style Hessian method outperforms the proposed method. This is counter-intuitive and no explanation (theoretical or empirical) is given for this discrepancy. \n\nAs a minor question: Why do you only update one method after each gradient update in Line 9 of Alg5? It is an unbiased estimate of the gradient, hence all sampling oracles can update itself using this estimate?"}