{"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The authors present a series of simple experiments to characterize the objective that emergent languages are optimizing and why we see various behaviors (not aligned with natural language) when training them to play these language games.  The paper is clearly written, the tasks are simple and minimalist (in a good way) and the experiments are often followed by the exact ablation I was just noting that I wanted to see. \n\nQuestions:\n1. What happens if the vocabulary is too small to completely communicate the space?  Do models accept that some concepts are not expressible, discover a random behavior that overloads a lexical item, or fail to learn entirely?\n\n2. Why are values for lamda_r not investigated or plotted?\n\n3. How many runs are averaged for each experiment? Should I assume one per seed? why are there different numbers of seeds for each experiment?\n\n4. Page 5 -- \"We conclude that in this case there is no apparent entropy minimization pressure on Sender simply because there is no communication\" -- Was any analysis performed on the gradients to see if they are completely random or what kind of signal they are getting?\n\n5. How important is the architectural design to these experiments? e.g. number of hidden layers, etc?"}