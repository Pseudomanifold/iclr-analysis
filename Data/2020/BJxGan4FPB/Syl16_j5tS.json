{"rating": "1: Reject", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This paper proposes a TAN model for double blind UDA problem, which supposes that partial data drawn from source domain is unlabeled and the target domain is completely unlabeled.\n\nActually, blind domain adaptation has been proposed several years ago. The double blind domain adaptation has no signficant difference.\n\nFrom the model, I could not observe the technical novelty, although the authors focus on the \"Aligner\". Actually, autoencoder based domain adaptation has also been proposed for several years.\n\nThe aligner can actually be removed, by jointly training a domain-shared encoder in Step 3 when the unlabeled target data is used for training.\nIn other words, step 4 can be removed and in test stage, the output of encoder means the domain aligned feature representation. \n\nAdditionally, the source classifier is trained independently from the unlabeled target data. Although the domain aligned feature representation can be learned, it is still risky to directly apply the source classifier for unlabeled target data. Therefore, I suggest a safe strategy to train the source classifier and the domain aligned feature represenation module by jointly feeding the labeled source and unlabeled target data into the Step 2. That is, the step 3 can be integrated into step 2 for safer training.\n\nI also have concerns on the experimental datasets. Why not use the benchmark visual datasets?\n\nThe proposed model lacks of comparisons with many state-of-the-art models.\n"}