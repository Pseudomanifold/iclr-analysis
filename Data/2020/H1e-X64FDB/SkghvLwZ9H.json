{"experience_assessment": "I do not know much about this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review": "This paper proposes two techniques for fast linear interpolation on CPUs. They achieved speedups by reducing 1) fixed overhead cost and 2) per example computation (linear interpolation operation level optimization).\nAuthors consider this problem for small operation models like linear interpolation rather than the models requiring large operations such as ResNet. In this case, dispatch overhead cannot be ignored and so they use the MLIR frameworks to optimize trained model into the C++ code (reducing fixed overhead cost). This results in 2-3x speed up. Secondly, they propose the way to construct auxiliary index-mapping function by considering spacing of the key points rather just using for example evenly spaced index-mapping.\nThey compare proposed method to C++ interpreter implementation on two-layer and deep lattice networks and achieve 5-10x speed improvements.\n\nIt seems the topic of this paper does not fit ICLR and most machine learning researchers are unlikely to be interested in and even understand this paper. This reviewer also does not have enough knowledge and background to judge this paper. But my impression is that achieving\u00a0speed up using existing MLIR framework has no surprising novelty.\u00a0\nMoreover, the experimental results seems quite limited in the sense that they only experiment with trained 2 and 4-layer calibrated lattice models which are kind of small.\u00a0\u00a0\n\nIt would be better to highlight why the proposed method is meaningful and provide more background knowledge to understand this paper.\u00a0\n\nThis is only consider optimization on CPUs. What about the case of using GPUs?\n\nIs branch free assumption for functions \u2018Adjust\u2019 & \u2018T\u2019 is valid? (I don\u2019t have much knowledge on compiler..)"}