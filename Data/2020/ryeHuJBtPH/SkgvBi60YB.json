{"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper proposes a new graph neural network model capable of performing tasks over hyperedges of variable type and size (i.e. different number and types of graph nodes connected by different hyperedges).  They experimentally verify its effectiveness over the previous state of the art on several datasets and tasks.\n\nI lean toward accepting this paper.  It is a relevant topic area, the design appears novel relative to recent work, and the presentation is mostly clear.  The design decisions are well-motivated and discussed (e.g. the choices to use the static embedding, the exclusion of the diagonal self-attention weights).  Performance is tested on previously used datasets and tasks, for a thorough comparison against recent best methods (DHNE).  The model is clearly described.\n\nA possible weakness of this paper is that the evaluation data sets are all k-uniform hypergraphs with k=3.  This is perhaps the minimal case which their method can address.  For all the discussion of generality to heterogeneous hyperedges, it would have been better to include some dataset (even if synthetic) to establish baseline performance over while ablating k>3 and multiple hyperedge types.  This remains completely un-investigated (even the genome dataset appears to be k=3?).  Although, their edge/hyperedge ablation on these datasets partially addresses the point and the result (Fig 5) seems promising.\n\nSome other notes:\nEq 5.  Given that it is the default, explicitly write that the summation is over j!=i\nEq 8.  Probably leave the ellipses out between v_{i-1} and v_{i+1}?\nThe tasks and measures like AUC, AUPR, and network reconstruction could be described somewhere, even if in an appendix.\nSome/many training hyperparameters not listed?"}