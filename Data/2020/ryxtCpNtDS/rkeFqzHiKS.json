{"rating": "3: Weak Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "The paper consider important and interesting problem: how to generate a sequence from minority class if we want to do oversampling with synthetic data in a way similar to SMOTE. \n\nNow from the paper, the exact used approach is not clear, as the details are too scarce (see some examples below). Experiments are not convincing, as the authors don't compare to the state of the art approaches. As the exact problem statement is hard to grasp, it is hard to identify the exact contribution of authors.\nNote, that the proposed approaches, in my opinion, are not that different from approaches from modern data generation for imbalanced classification [1, 2], as we propose some kind of GAN to generate new data and so have only two variables: how we select loss for this GAN and how we select the architecture.\n\nI assume, that to be accepted at a major venue a deeper investigation is required at the moment.\n\nSee also the following comments:\n1. Figure 4: title is not required, as we have a caption with the same information. Better to use confidence bars too.\n2. The figures will benefit from usage of vector format.\n3. Figure 3: tSNE can vary from one run to another. It is better to provide at least 3 random figures or even better train e.g. a simple classification model for t-SNE embedded model and present ROC AUC scores for identification synthetic/non-synthetic.\n4. Table 1&2 formatting is different from that usually used in Academy (see e.g. https://dl.sciencesocieties.org/files/publications/style/chapter-05.pdf)\n5. F1 score is often not the best metric for imbalanced problems. The paper will benefit from providing also PR AUC (average precision) scores.\n6. Figure 2: avoid confusion matrices presented in this form, as they take much space providing almost no information. Classic tables are better.\n7. From the problem statement at the very beginning of section 2 it is not clear what kind of labels do we expect (I suppose that for each sequence we have a specific label i.e. all y_i are 0 but one, that is 1)\n8. Sometimes bigger weights for minority objects or dropping significant part of majority sequences are enough, so results for these approaches also should be included\n9. How the hyperparameters mu and lambda were selected?\n\n[1.] Guo, Ting, et al. \"Discriminative Sample Generation for Deep Imbalanced Learning.\" Proceedings of the 28th International Joint Conference on Artificial Intelligence. AAAI Press, 2019. IJCAI 2019, https://www.ijcai.org/proceedings/2019/0334.pdf\n[2.] Douzas, Georgios, and Fernando Bacao. \"Effective data generation for imbalanced learning using conditional generative adversarial networks.\" Expert Systems with applications 91 (2018): 464-471."}