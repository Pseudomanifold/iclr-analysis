{"rating": "6: Weak Accept", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "In this paper, the authors tackle the task of compressing a network. While there\nare many effective solutions so far regular computer vision tasks, as they demonstrate,\nthey fail catastrophically  when applied to generative adversarial networks(GANs).\nThey propose a modification to the classic distillation method, where a\n\"student\" network tries to imitate the uncompressed one under the supervision of\na fully converged discriminator network. They perform evaluation on multiple\ntasks from image synthesis to super-resolution. They also study the influence\nof the compression factor on the quality of the generated images.\n\nThe task is well motivated and situated in the related literature. The first\nsection is very thorough and extremely efficient at describing the failure modes\nof existing methods. On one side, the results demonstrated in the evaluation are\ncompelling, on the other side, the compression factor is only 50%, which is much\nlower than seen in related work. However, as it is shown in section 3 the task\nmay be much harder for GANS than regular models so I still consider it a \nsizeable contribution.\n\nThere are a couple of points that require clarification. I personally found the\ndescription of the method (Section 4) rather confusing. It is clear\nwhat \"discriminative loss\" is as it is the one used in every GAN.\nUnfortunately, I could not understand what \"generative loss\" means in the general\ncase. An example is given for StarGAN in equation (7) and I have a rough idea of\nwhat to choose for Style Transfer, Domain Translation, Super Resolution and\nImage translation. Though, it is unclear to me what to use in the case of\nimage synthesis. The experiments clearly show that it is possible so I think\nit is necessary to show how this framework is concretely applied to each task at\nhand.\n\nDuring training, the discriminator only ever saw pictures from the true distribution\nand the distribution generated by the generator (at each of its training steps).\nIf I understood the framework properly, here, the compressed generator is trained\nfrom a random initialization. The distribution it outputs is therefore\ncompletely unknown and potentially non overlapping with either of the true or\nthe generator ones. In that case it is hard to predict what the discriminator\nwould do on completely out of distribution samples. I seems reasonable to\nconjecture that it might consider them \"true\" because it was never trained on\nthem. Could you provide an explanation of why it is not a problem in practice?\nDo you have to try multiple initializations? Is the generative\nloss enough to force the compressed discriminator to match the support\nof the distribution of the dense generator?\n\nI think this paper is novel, tackles a hard task and presents compelling results\n(albeit using very mild compression ratios). It should be accepted if some\nclarifications are made in section 3.\n\nMinor Remarks:\n\n- Figures 2, 9, 42 and 43 are unreadable when printed with a regular color office\n  printer.\n- It is unclear what it would take an extra 10% of the original number of epochs to train the compressed network. Why couldn't it be faster, or much longer?\n\n\n"}