{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "title": "Official Blind Review #4", "review": "The problem tackled in the paper is the compression of generators in adversarially trained models. Considering the success of large generative models (like BigGAN) one may wonder if these models can be compressed after being trained to improve practical applicability. \n\nThis paper is focused on the compression of image to image translation models and uses distillation on discriminator's outputs to achieve better results.\n\nMy decision is weak reject.\n\nThe message of the article is misleading. The whole goal of pruning a neural network is to remove filters from it, therefore, reducing the computation or, at least, storage space for the parameters. The attempt to remove filters was presented in the last figure, and it does not work as good as all other results presented in the paper.\n\nThe comparison in Figure 1 is arguably misleading as well. For example, one of the methods that were mentioned (LIT) does achieve a factor of 1.8 model compression, yet the comparison was not carried out directly with that method, but a modification proposed by the authors of this paper.\n\nI would like to see more comparisons in terms of FLOPs or inference time between the baselines, SotA methods, and your proposed method. Weights pruning is simply one of the approaches for model compression, so you cannot ignore the alternatives.\n\nAlso, section 4 probably has to be rewritten, since some unorthodox notation is used. The authors should consider using some reference paper for the notations, like CycleGAN, that was mentioned in the paper. That will improve the clarity and readability of the used objectives.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}