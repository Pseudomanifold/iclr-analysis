{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "The paper presents a signature that summarize the structure and weights of deep networks for MNIST images. This signature is then used to determine if a training set contains a backdoor or not. The signature takes the form of a single image, but does not depend on individual training examples. The authors show that the signature is not model specific and generalizes within reason.\n\nStrength:\n + Novel and simple idea\n + Good results on MNIST\nAreas of improvement:\n - Approach lacking motivation\n - Limited to MNIST\n\nI found the idea presented on the paper interesting and haven't seen this before. The paper is well written and easy to understand, and the technical section contains sufficient details to reproduce the paper. The evaluation shows that their method works well on MNIST, and even generalizes between classifiers.\n\nThe technical section lacks some motivation. Why is (1) a good signature? Why not just use the max, instead of the value at the argmax? This would be easier and save some space. Other alternatives include taking the difference between min and max, or starting with random noise or random images. It would be nice to know that what is presented in the paper is (locally) optimal among similar design choices.\n\nThe second area of improvement is in experiments. The current version of the paper seems tailored to MNIST (and only MNIST). In fact, the formal definition of the signature doesn't even contain a color channel used in most deep network inputs. Using this signature on any other dataset would require training 500+ networks on a single dataset. For anything other than MNIST this seems infeasible (e.g. on CIFAR training time for a single network is 4+hours leading to 2k+ hours to train a classifier for this signature). It would help if the authors could comment on how they plan to generalize this to real datasets (e.g. CIFAR, ImageNet, COCO, ...), where larger models (e.g. ResNet-152, ...) are required. The current detection results in section 6, don't actually defend the detector from backdoor attacks, but rather classifiers trained on the result of a detector.\n\nMinor:\n * Why is the signature computation O(m x n x K x V) instead of O(m x n x V). A single forward pass should provide all K probabilities required for the computation of the signature.\n * The writing is a bit defensive at times. e.g. first paragraph in Sec 3: Conceptually, we are inspired by ... but these two also have a large difference to your work. No need for the \"but ...\".\n * The correct ImageNet citation is \"ImageNet: A Large-Scale Hierarchical Image Database\""}