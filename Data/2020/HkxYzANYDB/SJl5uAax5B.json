{"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "Authors propose a new Dataset CLEVRER, a simulated video dataset involving interaction between objects. It is discussed, the existing state-of-the-art models for visual question answering, doesn\u2019t capture the causal structure between the objects and their claim is supported by their experiments.  Authors also proposed a model which captures the dynamics of the objects involved in the video, through experiments they have shown their model performs better than the existing models. \n\nThe CLEVRER dataset is designed to test a model capability to answer the queries involving causal relationship between the objects involved in the video. \n\nDetails.\nThis work begins with a well motivated problem by pointing out the drawback in existing VQA(Visual Question Answering)  models, that existing works focus on visual and input language patterns to answer the queries and doesn\u2019t tackle the task involving causal structure.  It  explores the current literature around the problem related to visual question answering(both real world data and simulated data). Through experiments they have shown the existing state-of-the-art work on visual question answering doesn\u2019t perform well on the dataset CLEVRER. \n\nTo prove the incompetence of existing models to capture causal structure, authors designed an artificial dataset with questions which can be answered only when the model is capable of capturing the causal structure between the objects.  \n\nThe process involving the creation of CLEVRER dataset is well explained. But, it is unclear how the questions are generated. \n\nThrough experiments authors revealed the drawbacks of existing models on capturing the dynamics between the objects and  proposed a model which is said to be inspired by previous VQA[1] model. An important modification by incorporating neural dynamics predictor module to the existing model is key, and also achieves good performance on the dataset. \n\nComments:\n\n- The paper is well written, but it is unclear how the questions are generated during dataset creation process.\n- The main contribution of the paper is to show the incompetence of existing models to capture dynamics. Which is a form of analysis.\n- It is shown that,  learning dynamics of the objects the model can achieve better performance.\n- This dataset is created in more restricted environment like height of the objects should be same. How can this be generalized to a more real world setting ?\n\nSome minor issues:\nIn few places causal is misspelled as casual(page 2,8).\nEquation 2, in the appendix the subscripts are not proper. \n\n[1] Yi, Kexin, et al. \"Neural-symbolic vqa: Disentangling reasoning from vision and language understanding.\" Advances in Neural Information Processing Systems. 2018."}