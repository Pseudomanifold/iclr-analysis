{"rating": "6: Weak Accept", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "The authors build on recent work for non-autoregressive encoder-decoder models in the context of machine translation (most significantly [Gu, et al., ICLR18]) and adapt this to dialogue state tracking. Specifically, as in [Gu, et al, ICLR18], they use a fertility decoder modified for DST to be on a per-slot basis which is input to a second decoder to generate the (open-vocabulary) tokens representing dialogue state. An interesting aspect of the resulting model as formulated is that the latent space also takes into account interdependencies between generated slot values, which leads to a direct structured prediction-like loss of joint accuracy. Additionally, as slot values have a smaller (and likely peakier) combinatorial space, NAT models actually are more applicable to DST than MT. The resulting model achieves state-of-the-art empirical results on the MultiWOZ dataset while incurring decoding times that are an order of magnitude faster. \n\nOnce one understands this conceptual modification of modifying the NAT string encoder-decoder to a more structured NAT encoder-decoder (which in DST is more of a normalized string), they apply all of the state-of-the-art techniques to build a DST system: gating of all potential (domain, slot) pairs as an auxiliary prediction (e.g., [Wu et al., ACL19]), de-lexicalizing defined value types [Lei, et al., ACL18], content encoder, and domain-slot encoder (with pretty standard hyper-parameters, etc.). The significant addition is the fertility decoder and the associated NAT state decoder. Thus, from a conceptual level, this isn\u2019t a huge leap and something many researchers *could* have done (i.e., I think many people, including myself, to have expected this paper to come out) \u2014 thus, it is more of a \u2018done first\u2019 paper than a \u2018done unexpectedly\u2019 paper. However, it is done well and the results are convincing and interesting. Given the impressive performance, I expect others to continue building on this work and potentially even influencing people to combine encoder-decoder models with a more structured prediction approach to DST.  Thus, I would prefer to see it accepted if possible.\n\nThat being said, I do have a few questions regarding this work \u2014 but these are more questions that might be able to be addressed than actual criticisms per se. First, in Table 5, why without the delexicalized dialogue history does the performance drop from 49.04% to 39.45%? This does not make sense to me as the model is much more complex than TRADE; however, TRADE does not do delexicalization yet achieves 45.6% joint accuracy. Meanwhile, with such complex model, I would expect the model can learn from raw data without delexicalization. Moreover, the proposed method use both previous predictions and *previous system actions* to do delexicalization. Also, the NATMT models don\u2019t do delexicalization (although they have significantly more data). I think the authors should do an ablation study that do not use previous system actions, because this is extra information compared with TRADE \u2014 even if delexicalizing. Secondly, another worthy baseline would be an autoregressive decoder (with other blocks of the model remain the same). I\u2019d assume that the performance is slight higher. It is interesting to see the gap, because this gap is the cost to speed up decoder using fertility \u2014 even if it is a bit counter-intuitive. If there is no improvement in this setting, then structured prediction in general may make more sense. Honestly, I think more would be interested in the second point than the first.\n\nIn any case, nice paper \u2014 well-written, well-motivated, interesting empirical results. The only reason I am recommending \u2018weak accept\u2019 is that the novelty is fairly straightforward and the strength is in the execution."}