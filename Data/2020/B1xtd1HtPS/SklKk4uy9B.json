{"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper proposes a quaternion equivariant network for 3d point clouds. It builds on the capsule networks and dynamic routing, but instead of using arbitrary 4x4 transforms, they propose to use quaternions to represent 3D rotations.\n\nInvariances and equivariances are very important in DNN for classification/detection, so extending these properties to 3d point clouds based applications is interesting and important. The proposed approach is novel and seems to be equivariant to SO(3) rotations, translations, and set permutations.\n\nHowever, there are a couple of major negatives in the paper. The first is that the details of the architecture are very unclear. A large amount of space is allocated to discussing equivariant properties but not enough is dedicated to the actual implementations of the network. In particular,  only on page 5 in section 3.2 is the QE network detailed discussed.\n\n- How does one obtain Q_i from points X_i ?\n- How are the points subsampled to create LRFs? is there a clustering first step? If so, how would that clustering be invariant to global rotation?\n- Does the method require a known centroid of the object point clouds in order to compute the quaternions of the LRFs?\n- Theorem 1 has shown that equation 6 of Alg. 1 is equivariant, but are the multiple interactions of DR equivariant? In particular, after k iterations of DR as presented in algorithm 1, with nonlinear sigmoid activations, are the output capsule representations equivariant?\n- How do you guarantee that the LRF\u2019s are the same under any global rotation+translations of the point cloud? Or do you assume the same LRFs are known?\n\nThe main selling point for equivarince and learning the separation of pose and object class representation is in the hope of more accurate classification. However, empirical classification results are far from the state-of-the-art. \n- As a side question, there are other methods listed on the ModelNet40 website with performances in the high 90\u2019s, are there reasons those results are not included as a part of Table 1?\u2028"}