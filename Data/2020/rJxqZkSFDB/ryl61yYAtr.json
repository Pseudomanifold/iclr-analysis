{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper studies the problem of learning from corrupted labels via picking up clean instances from training dataset. The sample selection mainly based on function R(t), which controls how many instances are kept. This paper proposes a unique curvature of R(t) based on intuition and presents how R(t) can be learned via combination of some existing functions. Natural gradient is presented to optimize the parameters in the autoML framework. Experimental results on both synthetic data and real-world data demonstrate the effectiveness of the proposed method. \n\nA few comments on this paper:\n1. The paper is very verbose and hard to follow. It introduces too many basic concepts in autoML.\n2. A key part of the paper is the curvature of R(t), which is based on intuition. Meanwhile, the learned curvature (in Fig 5) doesn't follow the curvature. Does this mean this paper is contradicting its self? The curvature of defined R(t) is not needed?\n3. The major difference between this paper and (Han et al. 2018) is how R(t) is defined and learned. The technical contribution of this paper is limited. \n\nMinor comments:\n1. For all the figures, it is difficult to view the y-axis (or the y-axis is missing). \n"}