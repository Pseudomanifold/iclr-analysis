{"rating": "8: Accept", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper presents an encoder-decoder model architecture for knowledge-grounded dialogue generation in a low-resource setting. The model includes two GRU-based encoders which represents knowledge and dialogue context independently from each other. The decoder also has the following three independent components: language model, context processor, and document reader, each of which works as an individual response decoder. While the language model considers the decoder's hidden state only, the context processor and the document reader apply the copy mechanism from dialogue context and knowledge, respectively. Then, the decoding manager generates the final distributions by aggregating the component outputs with Gumbel softmax.\n\nThe main contribution of this work is the disentangled architecture where the following three types of internal components are trained separately on different data from each other. Firstly, context encoder, context processor and language model are trained on un-grounded dialogues with no knowledge. Secondly, knowledge encoder can be built purely on knowledge sources in parallel with the dialogue-based components. Finally, document reader and decoding manager require knowledge-grounded dialogues as training data.\n\nThe experimental results show that the proposed architecture help to resolve the low resource problems of knowledge-grounded dialogue generation. The model achieved state-of-the-art performances on both Wizard of Wikipedia and CMU DoG even with only 1/8 of the training data.\n\nOverall, this is a well written paper with reasonable ideas supported by strong empirical evidences.\n\nPlease find below some questions and minor comments:\n- Would it be possible to evaluate the performance of the model with no grounded dialogues? It would be interesting to see how well the model works only with the un-grounded Reddit and Wikipedia data.\n- Have you thought about plugging in other language models trained on larger amount of texts such as Common Crawl? It seems possible, since the language model itself has no dependency to the context or the knowledge.\n- What do you think of generalizing the architecture for general dialogue generation problems with no knowledge grounding? This disentangled decoder may be applied to the language model trained on the larger amount of texts and the context model on the smaller amount of dialogues.\n- I suggest to provide some actual outputs from the models to show the advantage of the proposed method qualitatively.\n- Could you possibly make the subfigures of Figure 2 and 3 larger? They are now too tiny to see the details.\n"}