{"rating": "6: Weak Accept", "experience_assessment": "I do not know much about this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "The authors investigate off-policy actor-critic reinforcement learning where they want to make use of shared experience replay. Two approaches were suggested and compared. One was to mix replayed experience with on-policy data and the other was to create trust regions that only selects well-behaved behavioral distributions for state value estimation.\nAccording to the authors the several experiments provide evidence that their algorithm achieves competitive or even state-of-the-art results in data efficiency. They underpin this with some theoretical analysis.\n"}