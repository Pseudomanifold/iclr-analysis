{"rating": "3: Weak Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "The submission follows a recent line of work that formulates adversarial training (https://arxiv.org/abs/1412.6572) as a differentiable game and attempts to reduce the computational complexity of solving the inner maximization, corresponding to finding (an) adversarial example(s) for a given parameter setting. The authors propose a way to anneal the truncation of the inner iteration, and investigate a quantity to represent the suboptimality of the truncation.\n\nStrengths:\n- (From Table 3), the method is competitive with adversarial training (PGD; Madry et al. (2017)) as well as an improved method for adversarial robustness (FOSC; Wang et al. (2019)), while requiring half the computation time.\n- The writing is very clear.\n\nWeaknesses:\n- Significance: The technique AMATA itself, is a  heuristic to gradually increase the length of the inner loop optimization in adversarial training. It is unrelated to the optimal control formulation.\n- Novelty: Much of the motivation from the perspective of an optimal control formulation of adversarial training is similar to https://arxiv.org/abs/1803.01299, including the PMP and successive approximation components; Eq. (13) of the submission is the continuous version of Theorem 2 in this paper.\n- Some experimental details are missing.\n- Minor clarity issues (see below).\n\nQuestions for the authors:\n- Could the authors better contrast their work in reference to prior work (https://arxiv.org/abs/1803.01299)? \n- Could the authors clarify if they use random restarts for the PGD attacks? How was the number of iterations for the PGD attack (40) selected? Why was the iteration count of the PGD attack not varied?\n\nClarity issues:\n- Please provide references for the optimal control formulation in 2.2.\n- Some references to variables in the text are not made precise by identifying the variable in question (e.g.: \"a set of optimal parameter choices\"; \"requires information on the entire training interval\").\n- The function of the hyperparameters \\alpha, \\gamma, K are not well discussed in Section 2.4.\n- Reduce plot sizes and include more experimental details in the main text."}