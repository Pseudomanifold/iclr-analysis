{"rating": "6: Weak Accept", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "The authors presented an interesting paper which tries to solve a practically important question. Biomedical and tech industries usually hire human labelers for machine learning tasks, whose labels are usually noisy. Therefore, it is important to have a metric that can distinguish the performance of models with noisy labels.\n\nIn this paper, the authors proposed to measure the model performance based on the ratio of the discrepancy between the model prediction and the labeler, with the discrepancy between the labelers. The authors showed that in binary classification settings, their proposed metric can be reduced to simple to analyze quantities. The authors demonstrated the performance of their proposal in synthetic data as well in two real-world medical image datasets.\n\nOverall, the paper is well motivated with a reasonable amount of novelty. The numerical experiments are well conducted, but I am not totally convinced by their results.\n\nDetailed comments:\nSignificance: The paper is trying to address a practically important issue in machine learning. \nNovelty: The mathematical formulation of the metric consists of simple sums and averages, which in itself is not novel. However, the authors' choice of using such formulations to assess model performance is novel.\nClarity: The authors could simplify their notations, and could periodically remind the readers about the notations. For example, I was stuck by the sigma^2 notation in (6) (undefined) and the m notation in (7) defined in the past page in small texts. It would help me a lot if the authors reminded me the definition of those notations when they appeared.\nNumerical Experiments: This is my biggest complain. I wasn't able to conclude that the authors proposal is better than majority voting based on Figures 1b and 2b. To me they look qualitatively the same. Is there any reason that the discrepancy ratio is superior to the majority vote? In addition, I didn't see whether the curves in Figures 1 and 2 are an average of numerous simulated samples. if not, the authors should use the average to mitigate randomness; and if the curves are averages, then the distribution of the metrics should be described, because I think ultimately, we don't care about whether the average black curve is above the average red curve, but the chance of black curve being above the red curve. "}