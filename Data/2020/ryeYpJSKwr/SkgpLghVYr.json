{"rating": "3: Weak Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "The authors present MetaBO, which uses reinforcement learning to meta-learn the acquisition function (AF) for Bayesian Optimization (BO) instead of using a standard constant AF. The authors shows that MetaBO enables transferring knowledge between tasks and increasing sample efficiency on new tasks. The paper is mostly clearly written and I am not aware of existing work on meta-learning the AF for BO. However, the approach is related to Chen et al, which is cited in the text but not used as a baseline. It is also not shown clearly enough how the performance of MetaBO depends on the number of training tasks and distance between training and test tasks. I therefore consider the paper as borderline.\n\nMajor comments\n=============\n1. The presented approach is very similar to Chen et al, which is discussed in the related work section but not used as a baseline. Although Chen et al assumed that f(x) is differentiable, their approach can be easily generalized to non-differentiable functions by using RL as Chen et al discussed in the last paragraph of section 2.1. Chen et al does not depend on a GP and is therefore more scalable. The source code is publicly available (https://github.com/deepmind/learning-to-learn) and you can also adapt your implementation by removing the GP part.\n\n2. Global Optimization Benchmark Functions: How does the performance of MetaBO depend on the number of training samples (number of training tasks times the budget T)?\n\n3. Figure 3: How does MetaBO generalizes to functions that are translated and scaled at the same time? This can be visualized as a heatmap with the scaling and translation on the x and y axis, and using the color to show the number of steps to reach a certain reward. How does the generalization performance depend on the noise level, where the noise can be sampled from standard normal distribution? Why does EI perform better if the function is translated more?\n\n4. Simulation-to-Real task: How does the generalization performance of MetaBO depend on the distance between training and source tasks (x-axis: distance; y-axis: steps to reach a certain reward)? You sampled test tasks 10%-200% around the true parameters. Test tasks can therefore have identical or similar parameters than training tasks.\n\n5. Simulation-to-Real task: How does the performance depend on the number of training tasks (x-axis: # training tasks; y-axis: steps to reach a certain performance)?\n\nMinor comments\n=============\n6. Section 1, 2nd paragraph: The performance of BO also depends on the GP kernel and kernel hyper-parameters, not only the AF. Please mention this. Similarly, \u2018no need to calibrate any hyperparameter\u2019 in section 4 ignores GP hyper-parameters. Please clarify.\n\n7. Section 2, 4th paragraph: A Neural Process (https://arxiv.org/abs/1807.01622) is another scalable alternative to a GP. Please cite.\n\n8. Section 3, 2nd paragraph: Please cite standard AFs such as EI, PI, UCP. \n\n9. Section 4, last paragraph before \u2018Training procedure\u2019. The state s_t is undefined at this point. This section misses a clear description of the state, reward, and transition function of the MDB. Does the state s_t take previous function evaluations into account (e.g. via a RNN state), or only \\mu and \\sigma at the current step t? Does the state include the time step as described in the text and in the section about the value network in the appendix but not in table 1.\n\n10. Section 4, \u2018the state corresponds to the entire functions\u2019.  It only depends on the first two moments (and the time step t?).\n\n11. Section 4: replace \u2018not to be available\u2019 by \u2018unavailable\u2019.\n\n12. Section 4: reference or describe \u2018Sobol grid\u2019.\n\n13. Section 4: The approach to maximize the AF on grid points does not scale to high-dimensional search spaces. Please also clarify how global and local grid points were chosen. In particular, \u2018local maximization\u2019 is unclear. Also, \u2018cheap approximation\u2019 of the global maximum of f(x) is infeasible if the search space is high-dimensional. \n\n14. Please move figure 3 above figure 4."}