{"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "The authors evaluate convolutional autoencoders (CAE) by varying the size (width & height) and depth of the bottleneck layer on three datasets and compare test and training performance. They furthermore evaluate the quality of the bottleneck activations for linear classification. The authors also investigate the belief that a bottleneck layer of size equal to the input image will copy the image. \n\nI am not an expert in the field of (C)AEs. As such, I cannot approriately judge the relevance of the questions which are answered here. In the following, I will therefore make the assumption that those questions are relevant.\nIf so, I (weakly) recommend accepting the paper. \n\nWhile it does not propose any novel algorithms, it does ask a clear question and provides a compelling experimental answer, which (assuming the question is relevant), should be interesting for the community. \nOn the other hand, further experiments to provide initial insights into the further questions raised by the authors would improve the 'novelty' aspect of the paper. \n\nMinor comment: \nI believe the paper \"Reconciling modern machine learning practice and the bias-variance trade-off\" by Belkin et. al is relevant. \n\n"}