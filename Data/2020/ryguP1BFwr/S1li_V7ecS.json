{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This paper investigates convolutional autoencoder (CAE) bottleneck. The research problem is important, as CAE is widespread adopted. It cam be interesting to shed insight into how the bottleneck works. \n\nIn particular, two observations are made: (1) By measuring the performance of the latent codes in downstream transfer learning tasks, the authors show that  increased height/width of the bottleneck drastically improves generalization; The number of channels in the bottleneck is secondary in importance.  (2) CAEs do not learn to copy their input, even when the bottleneck has the same number of neurons as there are pixels in the input.\n\nIt would make this submission more convincing if the authors show the some important applications of their findings. For example, \n\nA. How does (1) above help architecture search when designing CAEs in a new application? \nB. How does (2) above help style transfer if ``\"CAEs do not learn to copy their input\" \n\nConcerns: If (2) is true, Could the authors explain that almost perfect reconstruction results are shown in [*] ?\n\n[*] Generating Diverse High-Fidelity Images with VQ-VAE-2"}