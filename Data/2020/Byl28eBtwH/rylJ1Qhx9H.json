{"experience_assessment": "I have published in this field for several years.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "The paper combines deep learning and compressed sensing. Specifically the RW-LISTA algorithm is proposed for cluster-structured sparse recovery, building upon two existing methods: the Reweighted Iterative Shrinkage Algorithm and the LISTA algorithm. The reweighing process is employed to infer the dependencies between coefficients and encourage cluster structure. Strategies for local and global dependence are presented. The approach is evaluated on synthetic and real datasets.\n\nThe paper considers and important topic. However the proposed approach is too incremental and the empirical evaluation could also be improved. In addition the presentation needs more work.  Specifically:\n- the use of unsupervised vs supervised is misleading. Traditional CS approaches are in fact supervised as they map to a regression problem when both input sensing matrix and response vector are available. The distinction has more to do with the ability (or lack of ability) to learn representations.\n- the proposed approach is a straightforward combination of LISTA and RwISTA and the section of global/local dependence regarding cluster-sparse structures is unsurprising.\n- Even though signals may exhibit cluster-sparsity, the size of such cluster might vary widely and it is therefore questionable if such patterns can be best captured via connections in the proposed reweighing blocks. Indeed for some blocks wider or lower neighborhoods might be needed to capture various radii of dependence.  \n- As an alternative to adopting RwISTA it might be pertinent to compare against a counterpart using fused lasso penalty (Tibshirani et al 2005).\n- Experiments are limited: a wider variety of block structure with more or less variability in block size etc should be considered. In addition it would be important to compare against vanilla  Rw-ISTA, as one of the classical CSS solvers.\n- It is somewhat disappointing that the proposed approach should be better the higher the SNR, where other approaches can do well enough. Ideally we are looking to improve in less favorable conditions of low SNR.\n"}