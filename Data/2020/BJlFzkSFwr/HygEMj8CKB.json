{"experience_assessment": "I have read many papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper addresses the problem of text classification by incorporating classification at both token and sentence levels, with the aim of better learning composition. The paper finds that introducing losses at multiple levels, along with additional auxiliary objectives, generally improves performance over simpler baselines.\n\nThe paper is clearly written, and I like the combination of token-level and sentence-level objectives with the aim of better learning compositional properties of language. I think the architecture described is interesting, with reasonable motivation, so overall I think the paper has potential. However, I don't think the paper in its current form has clear enough takeaways or strong enough results to make a publishable contribution -- in particular, it's not clear that the model in fact advances our ability to capture composition, nor do the results clearly advance the state of the art, and the contextualization with respect to related work is too minimal. \n \nThe main claim of the paper is that this multi-level labeling scheme incentivizes the network to learn better composition functions. However, there is no compelling reason to conclude that composition has necessarily been improved here. The majority of tasks being tested on are not related to composition -- it seems that the token/sentence relationship in the error detection and entity detection tasks simply involves identifying whether one token in the sentence has a positive label, which really has nothing to do with composition. The SST task can plausibly require non-trivial composition to relate between the token-level sentiment and the sentence-level sentiment, but that would typically involve incorporating sentiment at the phrase level along the way, rather than jumping from the token to the sentence level, which seems more likely to focus on individual lexical cues rather than composition. Beyond the choice of tasks, there is also no further analysis/discussion to help in determining whether anything about composition has been improved. \n\nIf the results were strong enough to advance the state of the art in these tasks, the composition takeaways might be less critical, but since the only baselines compared against are simpler versions of this model, it's not clear that the results here advance the state of the art in any way.\n\nAs another point: the contextualization with respect to related literature should also be improved. Currently the related work is described extremely briefly and fairly obliquely, and it is not clear how exactly this work differs from other work that has involved prediction at multiple linguistic levels (or work on composition).\n\nOverall, I think the paper has potential, but it needs a clearer contribution and better contextualization.\n"}