{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The authors try to estimate the probability distribution of the image with the help of GAN. Intriguingly, they develop a proper approximation to the PDFs in the latent space and train a simple network to predict the distribution. The experiments seem enough for the sanity check. \n\nThe word \"density\" seems a little bit unfamiliar to me. This concept adds to the difficulty to read the paper fluently. For example, \"We perform sanity checks to ensure that GANs do indeed produce reasonable densities on images.\" How can a GAN \"produce\" density? I'd better say the generated images of a GAN conform to a specific distribution. There are lots of places in the paper should be carefully revised.\n\nI have some disagreements on the theoretical analysis part in Section 3. The authors made a strong assumption that G is injective and hence has the following to come. While I disagree that G is injective, a very straightforward phenomenon to support my claim is the common mode collapse that happens nearly in all GAN models. Therefore, training the regressor could be pretty much problematic.\n\nMoreover, I'm pretty curious about whether it is possible to measure the difference between some similar datasets (for example, some classes are the same). The experiment proves that data points in MNIST can be outliers for CIFAR, but MINIST and CIFAR basically are very different from each other. How about data points in two very similar datasets such as CIFAR and ImageNet? Should their distribution be the same or similar? I'll pretty grateful if the authors could give me some insights into this question.\n\nUp to the deadline of the review process, I haven't seen the anonymous github repository and the supplementary materials. Did I miss something here?\n\nConsidering the drawbacks mentioned above, I tend to reject this paper because it has theoretical flaws."}