{"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "This paper approaches GANs as a polynomial expansion task. While the proposed approach is sound and mathematically appealing, the result of generation was only carried out on an easy benchmark (MNIST). With the recent advancement of GANs, we've been able to generate real-world and high-resolution images. I'd expect some more comparison with the published methods on other more complicated datasets.\n\nSome more details:\n- Figure  5 (d), the digits generated by PolyGAN seems to have a mode-collapse problem, in particular, if you count the number of \"0\"s. \n\n- Would the proposed approach of polynomial expansion applicable to other neural-network related architectures, such as image recognition?"}