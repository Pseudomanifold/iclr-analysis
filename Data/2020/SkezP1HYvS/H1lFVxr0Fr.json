{"experience_assessment": "I do not know much about this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper is well-written. The authors propose a new graph convolution neural network framework (DiagGCN) with an adaptive neighborhood aggregation step to adaptively scale the output signal for each node. In addition, they also propose an adaptive nonlinear encoder for the node's signal. Interestingly, sophisticated propagation models like graph networks \n with node/edge/path attention can also be formulated as the permutations of the adjacency matrix and diagonal matrices in the DiagGCN.\n\nGenerally, from my perspective, the idea in the paper is to reformulate the attention mechanism used in the GCN and this new diagonal mechanism is simpler and more general. One of my concerns is the \"node adaptive encoder\". Based on the experimental results, I did not see an obvious improvement between DiagGCN and DiagGCN with rescaling alone in Table 2 and Table 3. The classification improvement is 0, 0.1, 0.1, 0.3 with the node adaptive encoder. In addition, when comparing DiagGCN with baseline GAT, which is proposed in 2018, the performance approvement is also limited for the transductive learning tasks. \n\nIn conclusion, the idea proposed in the paper is interesting to me but the effectiveness of each module is not very well-supported by the experiments.\n\n"}