{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "This work proposes node adaptive rescaling and node adaptive encoder to enhance GCN. The proposed method is well explained and simple to implement. The experimental results indicate improvement and use t-test to show it's statistically significant.\n\nCons:\n1. I am not convinced that GCN does not consider node importance. When aggregating information, the degree information is used. In the example of opinion leaders, the nodes corresponding to opinion leaders usually have large degree.\n2. The proposed method is very similar to the attention method in \"Hierarchical Attention Networks for Document Classification\", where the query vector is a learnable vector. The authors should at least cite it and make appropriate discussion.\n3. The node adaptive encoder is more suitable to be called a new activation function. Then ablation study on different activation functions should be made.\n4. The experiments should cover comparison to more recent works, as well as graph classification tasks. For example, comparison to GIN or extending the proposed method to GIN would be interesting.\n5. Examples of how the proposed method learn the node importance correctly should be provided.\n\nMinor Cons:\n1. Figure 1 has a part of low resolution.\n2. The updated node importance in eqn.(6) should use a modified notation to differ from eqn.(3).\n3. The position of Table 2&3 is strange."}