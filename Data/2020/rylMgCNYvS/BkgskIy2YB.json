{"rating": "6: Weak Accept", "experience_assessment": "I do not know much about this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "N/A", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review": "Motivated by a link between LSTMs and counter machines (suggested by recent work, e.g. Merrill, 2019 et al.), this paper studies the formal properties of counter machines (and LSTMs by extension) as grammars, in hopes of discovering why LSTMs perform particularly well in language tasks despite having no obvious hierarchical structure.\n\nIt makes the following contributions. It shows that: (1) many variants of counter machine converge to the same formal language, (2) the counter languages are closed under common set operations (e.g. intersection, union, and complement), (3) counter machines are incapable of evaluating boolean expressions, and (4) only a weak subclass of CLs are sublinear (and most are not).\n\nWhile this paper gives thorough proofs, I would have liked to see more connection to practical NLP with some experiments. Also, I would have liked to see more concrete takeaways from this paper: if correctly detecting surface patterns doesn't mean that LSTMs build correct semantic representations, what can ensure that LSTMS do have a correct semantic representation? \n\nAs this paper is far from my area of expertise, I'm willing to change my score based on my co-reviewers."}