{"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "This paper studied the problem of the encoded position information in convolution neural networks. The hypothesis is that CNN can implicitly learn to encode the position information. The author tests the hypothesis with lots of experiments to show how and where the position information is encoded.\n\nClarity:\nThis paper is interesting for me. It tries to understand the encoded position information that is easily ignored by researchers. I like adequate experiments with learned position information and position illustrations.\n\nExperiments:\n1. The paper mainly discussed the zero-padding and found it is the source of position information. How about other padding modes like constant-padding, reflection-padding, and replication-padding?\n\n2. The partial convolution-based padding method [1] (padded regions are masked out) shows that its recognition accuracy is higher than the traditional zero-padding approach. Can you help investigate where the position information comes from for this case?\n\n[1] Partial Convolution based Padding, https://arxiv.org/pdf/1811.11718.pdf.\n"}