{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "Summary:\n\nThis paper proposes a certifiable defense against data poisoning attacks by using a randomized smoothing approach. An adversary in such a setting is permitted to flip any r labels from a dataset of size n. The smoothing procedure (stated roughly) is to train on a dataset with \"noisy\" or \"smoothed\" labels, obtained by flipping each label with some probability q. The authors obtain a lower bound on r in terms of q. Directly using this technique requires training multiple classifiers on multiple noisy datasets. To show that this method is useful, the authors study the effectiveness of this model against a classifier that performs linear regression on a pre-trained feature extractor. \n\nThe authors provide a succinct summary of current research concerning randomized smoothing. The novelty in this paper is that it considers randomized smoothing defenses for data poisoning (label flipping) attacks, as opposed to perturbation based attacks. While the paper was an enjoyable read, I recommend rejecting the paper due to the following shortcomings that:\n\n(1) The paper is essentially studying (a variant of) linear regression. This was really not obvious from the title or the abstract. It meant that as a reader, I had high expectations but was let down upon reading section 4.1.\n\n(2) What prior work exists for data poisoning attacks against linear regression or logistic regression? How does the contribution in this paper fit in that context?  Adding some discussion along these lines to the paper seems necessary.\n\n(3) There is no explanation why the authors chose the specific datasets that they studied."}