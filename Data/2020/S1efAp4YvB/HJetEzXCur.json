{"rating": "6: Weak Accept", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "The paper shows a way to compare what is learned by two very different networks trained for a video classification task. The two architectures are state-of-the-art methods, one relying on 3d-CNNs (time= one dimension), the other on conv-LSTMs (time is treated sequentially, using hidden states to pass information). The idea of the authors is (i) to provide saliency maps for each of them, and (ii) to create interesting perturbations in order to measure the influence on the networks. The results indicate that these complex networks are usually focused on interesting features, and as we would imagine, LSTMs is more learning from temporal coherence than CNNs.\n\nOverall, I think the paper is worth to be published at ICLR, even if I am not aware of the recent publications in this field. The contribution in terms of method is small, but I think that such careful studies can be very fruitful to the community.\n\nPositive aspects:\n- A significant effort has been put to creating meaningful perturbations for this particular task, i.e. temporal dependance and coherence.\n- The effort to compare as best as possible two different approaches is fruitful, and very useful for the community as this is a real question to be raised.\n- The experiments are made also with care, on 2 different datasets, and large efforts were made on explaining the different results.\n\nQuestions/remarks:\n- As I was under Linux, I did not manage to view the videos, and I have not seen a link for downloading them. It would be best to add it as supplementary materials?\n- What do you mean by 'The TV norm penalizes masks that are not coherent'? what is coherent?\n- '...the mask is defined as a vector of values between [0,1]' : I understood that it was a real value between 0 and 1, but I think you meant more 'a binary vector'?\n- Have you looked at the importance of the sub-sampling in the CNN framework? i.e., since the LSTM framework does not have that, maybe the differences in activation also depend on the length of the sequence. Maybe the large sequences, where CNN and LSTM would have the same number of frames, are less different?\n- You are saying that the code will be made public, is it possible to make it public now?\n\nSmall remarks:\n- '3D CNNs instead instead convolve'\n- 'As outlined in section 2' when we are in the introduction\n- '(Mahdisoltani et al.(2018) contains...'. parenthesis.\n- Figure 1: the first figure is in too poor quality.\n"}