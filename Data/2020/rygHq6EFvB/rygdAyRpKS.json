{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "Summary\n-------\nThe paper addresses the problem of Multi-Source Domain Adaptation for a specific application on image classification. Each image is assumed to depend on 3 factors: the domain, the style (low level feature variations) and the content. The approach proposes to use a generative model constituted of generator G that can take as input an image of any domain, and G contain 4 blocks each having a particular objective: (1) address the style discrepancy, (2) address the domain discrepancy, (3) impose a specific domain (4) impose a specific style. The output is an image with the same content as input, with a chosen style and a target domain. The content should help to learn an invariant representation across multiple source domains. The generative part can be used to generate \"target instances\" from which a classifier is then learned.\n\nEvaluation\n--------\nThe proposed method makes use of 2 blocks existing in the literature and the authors propose the use of 2 novel blocks. The methodology appears to be interesting in the context of image classification and the results presented are good. There is no theoretical foundation for the proposed model, but the interest of the components are experimentally assessed by an ablation study. While the method is specifically designed to image classification - which in a way reduces a bit the scope the possible applications but this is a minor remark - I find the experimental evaluation a bit limited in the sense that authors use mainly small or relatively easy datasets. Some parts of the method certainly deserves more justification.\n\nOther comments\n------------\n\n-The two datasets Digits-Five and Office-Caltech are relatively easy and low-resolution datasets. I think larger experiments on more recent datasets such as Office-Home (http://hemanthdv.org/OfficeHome-Dataset/) or Visda are important here. In particular, an more complex analysis on the possible style transfer and domain characterizations on large domain will reinforce the study of the paper.\n\n-I may have missed, but I did not really understand in the experimental setup how many additional target instances are used to train the classifier because I guess that the random aspect of the generator can help to generate multiple additional data but in this context the quality of the model can dramatically decrease. \nSo I would like more discussion on the real applicability of the generative part of the method classification.\n\nAnother point unclear for me in the setup is the use of target labelled information: are they use for learning the classifier? If so a comparison with a classifier only trained with target labelled data should be added.\nOtherwise, the approach is strange since target domain is included as one of the domains and the number of target labelled data seems important in the experiments.\n\n-I have a question about Hyperparameter tuning, in particular wrt the digit classification experiment: only one configuration is used to find the parameters for the others. 1st this requires to have enough target labels, second it assumes in some way that similar information is shared among all possible configurations making all the adaptation tasks similar which can explain why only one tuning can work.\nComparisons on other datasets would probably not allowed such a strategy.\n\n-The ablation study is interesting, but I do not find the difference in terms of result very significant, one can wonder if it is not possible to achieve the target avg. accuracy by a finer hyperparameter tuning.\n\n-Training generative models including GAN often leads to optimization issues and instability. The proposed architecture is rather complex and I would appreciate if the authors can discuss the difficulty encountered for training their model (note that this can be in part related to the second item).\n\n-If possible, I would like to have a characterization of the style block: what are the style changes that can be done and what are those that cannot.\n\n-The authors consider that learning invariant representations is an holy grail for domain adaptation but it must be noticed that actually it may lead to undesirable situations are reported in the following recent paper:\nHan Zhao, Remi Tachet des Combes, Kun Zhang, and Geoffrey J Gordon. On learning invariant representation for domain adaptation. ICML 2019.\n\n-A suggestion: As far as I understand, the role of blocks (3) and (4) is only to produce a target image in order to apply loss functions to train G, but they do not extract any more useful information of the input image. In other words, all useful information G seems to have from the input is only captured by blocks (1) and (2). I would be interested to see the result of the following strategy: Train G, then use the output after block (2) (Domain invariant representation) as the input of the classifier to train it. I think it would be interesting to compare this idea to TriGAN. \n"}