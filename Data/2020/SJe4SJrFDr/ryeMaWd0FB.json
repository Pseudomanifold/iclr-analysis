{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper proposed an adversarial training method that aims to obtaining sparse and robust networks at the same time. First, the vulnerability is defined at the latent feature space and measured as the expected difference between clean latent feature vectors and adversarial latent feature vectors across all layers. Then this vulnerability measure is incorporated as a regularization and the network is trained in an adversarial training setting. A Bayesian sparsification algorithm is used to prune the network at the same time. The method makes sense to me. However, my main concern is the evaluation. See below for more details.\n\nIt seems no other defense algorithm except AT has been compared with ANP and its variants. Since this paper, to my understanding, is an adversarial defense algorithm, it should be compared to other SOTA defense algorithms.\n\nHow does this method work for different adversarial attacks? ANP is trained under L_inf black and white box attacks (Papernot et al., 2016), and test under the same attacks. What if trained attacks are different to the attacks at the test time. Will the robustness is generalizable across different attacks?\n\nThe 3rd loss in Eq.6: why is the mask only optimized on the loss on the adversarial examples? Why not with the clean example loss?\n\nEq. 1: is that an L1 or L2 norm?\n\nDefinitions 1 and 2 are almost identical with only 1 or 2 different words. Can you combine them to make it more concise?\n\nIn summary, without the thorough evaluations as suggested above, it\u2019s hard to see if the proposed method is competitive or not.\n"}