{"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The authors propose in this paper a variant of Deep SVDD which brings semi-supervision to this model. The paper is well written and contains a thorough experimental evaluation (even disregarding the supplementary material). As far as I know, the proposed method is new and improve anomaly detection. The modification of Deep SVDD are in a way minimalistic, but they do the job.\n\nThe only negative aspects, in my opinion, is the \"information-theoretic view\" which is close to hand waving. The authors are indeed 1) disregarding the regularization term 2) considering an upper bound of the entropy 3) pretending the results on the pre-trained NN hold after post training. Putting everything together, I do not see how this reasoning could accepted. In fact, its extension to Deep SVDD is even more problematic as the discussion in the paper contradicts the reasoning. The authors emphasize the fact that anomalies should not fulfill the clustering assumption (which is indeed an important remark). But then the distribution of phi(x,W) cannot be approximated by a Gaussian for anomalies and thus the bound on the entropy is not valid. \n\nI strongly recommend to remove this part of the paper and to derive Deep SAD from Deep SVDD from heuristics consideration (which is fine!). This will provide an opportunity to remove the cute sentence \"We are happy to now introduce Deep SAD\"."}