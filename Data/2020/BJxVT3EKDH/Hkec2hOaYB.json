{"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper introduces a corpus-based approach to build sentiment lexicon for Amharic. In order to save time and costs for the resource-limited language, the lexicon is generated from an Amharic news corpus by the following steps: manually preparing polarized seed words lists (strongly positive and strongly negative), calculating the co-occurrence of target word in its context via Positive Point-wise Mutual Information (PPMI) method, measuring the similarity between target words and seed words by cosine distance, iterating with the threshold 100 and 200. The PPMI lexicon is stemmed and evaluated from aspects of subjectivity detection, coverage, agreement and sentiment classification. Three other lexicons: Manual developed by manual, SOCAL and SWN developed by bilingual dictionary, are used as benchmark to compare with the PPMI lexicon. In sentiment classification experiment the PPMI lexicon did not show a superior performance. All the four lexicons have similar accuracy, between 42.16% ~ 48.87%.  Only when the four are combined together the result is improved to 83.51%. \n\nWhile this paper presents an economical and practical method to generate a sentiment lexicon for resource-limited language it is not acceptable in it's current state to ICRL. The following points should be improved or clarified. \n(1) The generalizability to any language needs to be shown. What are the lessons learned for any resource-limited language?\n(2) The fit to ICLR is not perfect. I would expect a stronger focus on representation learning.\n(3)\tThe conclusion is not well proved. Especially about the claim that their method is \u201cwith almost minimal costs and time\u201d. PPMI lexicon might cost less than Manual lexicon, but SWN and SOCAL (Neshir Alemneh et al., 2019) are automatically generated by English-Amharic dictionary, not manually. Their generation costs and time are not told and can not be compared here. \n(4)\tThe paper is incorrectly structured. The part \u201c4 RESULTS AND DISCUSSION\u201d presents neither results nor discussion. Part 4.1 shows seed words which should belongs to part 3. Part 4.2 shows stemming which should belong either to part 3 or to part 5. Therefore, it is better to make a restructure. \n(5)\tThe contents following \u201cDiscussion:\u201d in part 5 are not discussion.  Moreover, there is almost no discussion in this paper. \n(6)\tIn part 5.4 Table 4, why there is result of PPMI in column \u201c2500 Amharic Comments\u201d but no result in column \u201c20 million Amharic tokens\u201d? Are the 2500 comments stemmed? \n(7)\tIn part 5.6, why negation handling is adopted in part 5.6?\n\nMinor comments:\n(1)\tGrammatical problems such as: Page 3 last paragraph: \u201cAmharic is highly morphological language both inflectional and derivational morphology is complex.\u201d \n(2)\tPage 6 last paragraph: \u201cWe will evaluate in three ways: external to lexicon and internal to lexicon.\u201d It should be two ways. \n(3)\tThe number of facebook comments varies: it is 2800 in part 5.3, 2500 in 5.4 including Table 4, and 2821 in 5.6.  \n"}