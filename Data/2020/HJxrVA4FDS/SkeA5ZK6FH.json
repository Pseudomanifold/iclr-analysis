{"rating": "8: Accept", "experience_assessment": "I do not know much about this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "The article tries to examine existing hypotheses from the neuroscience and perception literature by using neural networks as a computational model of the brain. Namely, the authors assess the efficiency of different strategies for solving two visual challenges, one of which is novel. The authors also evaluate the level of consistency between the performance of humans and different types of neural architectures.\n\nI believe that the quality of this work is above the acceptance threshold. The results seem to clearly support the claims. The experiments are well-designed and an adequate number of baselines are provided. However, it should be mentioned that the conclusions are by no means surprising.\n\nThe following sentence should probably be fixed:\n> \".. models that not learn overfit the training set.\"\n\nSome questions (answering is optional):\n -  In the second paragraph of the introduction, the authors state that the two feedback mechanisms should be iterative. Can the authors provide elaborate as to why these strategies should be inherently iterative and simply applying the same model a small/finite amount of times is not enough?\n - The authors claim that the relatively low performance of ResNet-18 and U-Net on Pathfinder is due to a higher computational burden, yet the reason for the poor performance of ResNet-50 and ResNet-152  on cABC is the result of overfitting. Is there any evidence to support this distinction or are the authors simply arguing this because it is the most plausible explanation?"}