{"experience_assessment": "I have read many papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "In this work, the author(s) presented a regularization scheme that intends to suppress the identification of spurious features when learning deep representations. Their construction was inspired by the information bottleneck framework. By making Gaussian assumptions on the form of label conditioned feature distribution, the entropy penalty can be efficiently computed in the form of L2 loss, which is easy to implement. My major concerns for this submission are its clarity, novelty, and theoretical depth. The arguments provided are not very convincing and reported experimental results are based on toy-scale datasets. I recommend rejection for this submission, with more detailed comments attached below. \n\nStrength\n+ The author(s) are trying to resolve the issue of learning spurious discriminant features for predictive models, which is a trendy topic with a potential impact on the field. \n+ There are some interesting discussions in the related work section. \n\nWeakness\n- The presentation needs to be much improved. In its current form, the lack of clarity leads to serious confusion. Examples include but not limited to the following:\n\t- \"violates the IID assumption which is the foundation of existing generalization theory\". Not sure what this IID assumption means, please briefly/intuitively describe these classical generalization theories. \n\t- \"all the correlations btw inputs and targets.\"\n\t- \"throws away maximum possible information about the input distribution\"\n- The author(s) have made a strong statement, quote \"it is the second term that regularizes the model representations to become invariant to non-robust features\"\n- Eqn (1) and Eqn (3) is equivalent, what's the point??? There is no novelty here. \n- Prop 1. Modeling the conditional entropy H(f_{\\theta}(X)|Y) nonparametrically is not any easier than modeling the marginal entropy H(f_{\\theta}(X)). The assumption of a parametric form of f_{\\theta}(X) given Y is very strong and needs to be justified (at least experimentally). Although the author(s) are honest about this limitation in the discussion. \n- The concept of distribution shift is not formally introduced in the manuscript. \n- Eqn (7) implicitly makes a strong prior assumption that the feature distribution condition on the label is isotropic Gaussian. This reminds me of Linear Discriminant Analysis (LDA), which followed from a similar heuristic, and might partly explain the empirical success of this practice (the model is forced to be LDA like, which combats the overfitting via appealing to simpler models). However, I have not found any discussion related to this, which evidence that the author(s) might lack a proper understanding of classical treatments.  \n- Theoretical analyses of synthetic examples do not lend strong support to this paper. \n\nQuestions\n# What is the fundamental difference btw the proposed work differs and domain adaption?\n\nMinors:\n% Conditional entropy H(f_{\\theta}(X)|X) is zero. \n% I do not see the point of referencing adversarial robustness literature. "}