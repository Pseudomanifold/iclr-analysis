{"experience_assessment": "I have published in this field for several years.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "CONTRIBUTIONS:\nTopic: Disentangling syntax from semantics in contextualized word representations\nC1. A method for generating \u2018structurally equivalent\u2019 sentences is proposed, based only on the assumption that maintaining function words, and replacing one content word of a source sentence with another to produce a new grammatical sentence, yields a target sentence that is equivalent to the source sentence. \nC2. The \u2018structural relation\u2019 between two words in a sentence is modeled as the difference between their vector embeddings.\nC3a. The structural relation between a pair of content words in one sentence is assumed to be the same as that between the corresponding pair in an equivalent sentence. \nC3b. The structural relation between any pair of content words in one sentence is assumed to be different from the structural relation between any pair of content words in an inequivalent sentence. \nC4. Given a selected word in a source sentence, to generate an alternative \u2018corresponding\u2019 content word for an equivalent target sentence, BERT is used to predict the source word when it is masked, given the remaining words in the source sentence. The alternative corresponding word is randomly selected from among the top (30) candidates predicted by BERT. Given a source sentence, the set of target sentences formed by cumulatively replacing content words one at a time in randomly selected positions defines an \u2018equivalence set\u2019 in which words in different sentences with the same left-to-right index are corresponding words. (To promote the formation of grammatical target sentences, a word is only replaced by another word with the same POS.) A pre-defined set of equivalence sets is used for training.\nC5. A metric learning paradigm with triplet loss is used to find a function f for mapping ELMo or BERT word embeddings to a new vector space of \u2018transformed word representations\u2019. Implementing C2 and C3a, given the indices i and i\u2019 of two content words, the triplet loss rewards closeness of the difference D between the transformed embeddings of the pair of words with these indices in sentence S and the corresponding difference D\u2019 for an equivalent sentence S\u2019. Implementing C3b, the triplet loss penalizes closeness between D and D\u201d, where D\u201d is the difference between transformed word embeddings of a pair of content words in a sentence S\u201d that is inequivalent to S. (Eq. 4).\nC6. (Implementing C5.) To form a mini-batch for minimizing the triplet loss, a set of (500) sentences S is selected, and for each a pair of indices of content words is chosen. Training will use the difference in the transformed embeddings of the words in S with these indices: call this D, and call the set of these (500) D vectors B. For each sentence S in B, a \u2018positive pair\u2019 (D, D\u2019) is generated, where D\u2019 is the corresponding difference for S\u2019, a selected sentence in the equivalence set of S. Closeness of D and D\u2019 is rewarded by the triplet loss, implementing C3a. To implement C3b, a \u2018negative pair\u2019 (D, D\u201d), for which closeness is penalized by the loss, is formed as follows. D\u201d is the closest vector in B to D that is derived from a sentence S\u201d that is not equivalent to S. \nC7. 2-D t-SNE plots (seem to) show that relative to the original ELMo embeddings, the transformed embeddings cluster better by POS (Fig. 3). (No quantitative measure of this is provided, and the two plots are not easy to distinguish.)\nC8. Pairs of closest ELMo vectors share syntactic (dependency parse) properties to a greater degree after transformation than before (Table 1). To check that this goes beyond merely POS-based closeness, the syntactic relations that least determine POS are examined separately, and the result remains. Furthermore, the proportion of pairs of closest vectors that are embeddings of the same word (in different contexts) drops from 77.6% to 27.4%, showing that the transformation reduces the influence of lexical-semantic similarity. Similar results hold for BERT embeddings, but to a lesser degree, so the paper focusses on ELMo. \nC9. Few-shot parsing. Two dependency parsers are trained, one on ELMo embeddings, the other on their transformations (under the proposed method). In the small-data regime (less than 200 training examples), the transformed embeddings yield higher parser performance, even when the encoding size of the ELMo embeddings is reduced (from 2048 to 75) to match that of the transformed embeddings by either PCA or a learned linear mapping. (Fig. 4) \nRATING: Weak accept\nREASONS FOR RATING (SUMMARY). Using deep learning to create an encoding of syntactic structure with minimal supervision is an important goal and the paper proposes a clever way of doing this. The only \u2018supervision\u2019 here comes from (i) the function/content-word distinction (C1 above): two grammatical sentences are structurally equivalent if [but not only if] one can be derived from the other by replacing one content word with another; and (ii) filtering candidate replacement words to match the POS of the replaced word. BERT\u2019s ability to guess a masked word is put to good use in providing suitable content word substitutions. The experimental results are rather convincing.\nREVIEW (beyond the summary above)\nC1. This assumption is famously not deemed to be true in linguistics, where the structural difference between \u2018control\u2019 and \u2018raising\u2019 verbs is basic Ling 101 material: see https://en.wikipedia.org/wiki/Control_(linguistics)#Control_vs._raising. This particular structural contrast illustrates how verbs can differ in their argument structure, without there being function words to signal the difference. So substituting *verbs* in particular may be non-ideal for the purposes of this work. Even the third example given by the authors in Sec. 3.1 illustrates a related  point, where function words do signal the contrast:  while the meaning of \u2018let\u2019 and \u2018allow\u2019 may be very similar, their argument structures differ, so that replacing \u2018lets\u2019 with \u2018allows\u2019 in the first sentence, or the reverse in the second sentence, produces ungrammatical results: \n*their first project is software that *allows* players connect the company \u2019s controller to their device\n*the city offers a route-finding website that *lets* users to map personalized bike routes\nTherefore, contrary to the paper, relative to linguistic syntactic structure, it is not a good result that \u2018lets\u2019 in the original version of the first sentence is the closest neighbor in transformed embedding space to \u2018allows\u2019 in the second. Rather, it is probably meaning, not structure, that makes \u2018let\u2019 and \u2018allow\u2019 similar.\nIt would improve the paper to make note of this general concern with C1 and to provide a response.\nOn another point, an important premise of the proposed method (C2 above) is that differences in vector space embeddings encode relations; this has been used by a number of previous authors since the famous Mikolov, Yih & Zweig NAACL2013, and that work should be cited and discussed."}