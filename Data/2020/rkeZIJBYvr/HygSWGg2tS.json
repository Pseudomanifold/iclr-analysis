{"rating": "8: Accept", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "The paper proposes a Bayesian approach for meta learning in settings were the tasks might be OOD or have imbalanced class distribution. The proposed approach has 3 task-specific balancing variables with a prior and an inference network. Using an amortized inference scheme, the model unifies the meta-learning objective loss with the lower bound of probabilistic model marginal likelihood. \n\nThe paper is well-written and well-motivated. I only have some minor comments and questions:\n- Can you add the standard errors for the results in Section 5.2 (maybe at least in the Appendix)? \n- Specifically it would be interesting to see if the results for analyzing the class imbalance variable are statistically significant; specially in light of the recent work on the effects of importance weighting in DL (see \u201cWhat is the Effect of Importance Weighting in Deep Learning?\u201d by Byrd and Lipton) which essentially question the value of importance weighting for handling class imbalance in various DL settings. \n- For the experiments in Section 5.1 can you also report the values for the three task-specific balancing variables? (Maybe in the Appendix).\n\nMinor:\n\u201cobtains significantly improves over\u201d -> \"significantly improves over\"\n\nOverall, I found the paper interesting and practically useful, although I believe some additions to the empirical evaluation can improve the impact of the paper. "}