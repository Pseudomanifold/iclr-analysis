{"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "In this paper, the authors propose a simple and effective method to address the problem of targeted clean-label poisoning where the adversary injects a few samples into the training data thus causing the deployed model to misclassify a particular test sample during inference. Experiments demonstrate that the proposed defenses are able to detect over 99% of poisoning examples. The paper is clearly written by addressing an important problem but I still have several concerns:\n1.\tIn general, the Knn is sensitive to the parameter k, which is not robust in some cases. The authors are expected to clarify how to set the proper parameters especially for the complex tasks. \n2.\tThe authors are expected to make more comprehensive evaluations to demonstrate their advantages compared with alternative methods, and the effectiveness to other poisoning attacks. \n3.\tIt is supposed that the performance highly relies on the feature extraction and the authors are expected to further justify how the performance would be if the features are not reliable due to the adversarial attacks. \n"}