{"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper proposed a joint network embedding model to incorporate the information of network structures, node attributes and labels simultaneously. Specifically, three auto-encoders, which are responsible for the three kinds of information, respectively, are developed, and are then combined in an intuitive but direct way to consider the mutual influences among different types of information. The weights of combining different types of losses are claimed to be learned from data, although it is achieved in the most direct way. \n\nStrengths: \n\nThe paper proposed an auto-encoder based framework, which can handle the information of network structure, node attributes and node labels simultaneously\n\nWeaknesses: \n\nThe novelty of this paper is very limited. The proposed model seems to be constructed by simply combining several existing methods mechanically. For example, the authors follow the work of GCN (Kipf & Welling, 2016) and use Eq. (4) for network structure embedding. However, the adjacency matrix (structural information) is used to convolute node features (attribute information) in GCN, it is not convincing that the authors apply this method by just removing the node feature matrix.\n\nThe number of baselines is not enough, and lacking baselines with only structural information.\n\nThe experimental results are not satisfactory. In the experiments of link prediction and attribute inference, the baseline `CAN` performs better than the proposed model in most cases.\n\nIn the experiment of efficiency evaluation, the experimental environment is not explained and the number of iterations of compared models are different, which is not rigorous enough.\n\nQuestions to the Authors:\n\nIn Eq. (4), (9) and (12), why the parameters of the network (W^((0) ),b^((0) ),W^((1) ),b^((1) )) are the same? Are these formulas wrong? If they are correct, then what is the difference between H_x and H_y? A similar problem exists in Eq. (6), (10), (13).\nIn Eq. (9) and (12), why the attribute encoder and label encoder do not utilize attribute matrix X and label matrix Y respectively, why they only encode the structural information?\n"}