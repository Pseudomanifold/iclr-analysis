{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper presents a method for multimodal sequential learning. The input consists of three modalities (e.g. visual, language, acoustic data). The output is the classification label for multimodal sentiment analysis, multimodal emotion recognition, and multimodal speaker traits recognition. The approach explicitly accounts for possible unimodal, bimodal and trimodal interactions existing within the multimodal input space by using the factorization. Compared to previous works, this method is able to model the intra-model and inter-modal dynamics within asynchronous multimodal sequences.\n\nStrengths:\n1. Based on an intuitive idea, this paper shows its method outperforms the previous works on several tasks. The brief method they proposed achieves a powerful result instead of using complex structures. \n2. The overall experiments and analyses support the theory of the paper and show the necessity of the factorized method. the problem of multimodality is solved well.\n\nWeakness:\n1. The paper dis not show the training epoch and the convergence time, so we could not compare the effectiveness of the proposed method with the other methods.\n2. Theoretical justification is not sufficient."}