{"experience_assessment": "I do not know much about this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The authors present a quantum algorithm for expectation maximization on a quantum machine, which is poly-logarithmic in the size of the dataset (and polynomial in other parameters such as the dimension of the feature space, and number of mixture components, condition number of the data and covariance matrices, some precision/error parameters etc) per iteration. So, compared to the . regular EM algorithm, this yields exponential speedup in the number of data points, but is worse in other factors (such as a k^4.5 dependence on the number of mixture components). So, the quantum system could be superior to a conventional computer for some settings of parameters. They run some (simulation) experiments on a dataset (VoxForge) to report accuracies (though there is no comparison of the accuracy of the classical algorithm). Also, there does not seem to be any experimental results to confirm the theoretical analysis of the scaling characteristics (i.e., to show that the scaling is as predicted by the theory).\n"}