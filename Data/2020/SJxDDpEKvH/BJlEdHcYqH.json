{"rating": "3: Weak Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #4", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "The ideas presented in the paper are interesting and original. Whereas the theory presented has a lot of potential, it seems that the clarity of the paper could be greatly improved, in particular I would have liked more of the formal theory to be included in the body of the paper instead of relying only on the appendix. This especially matters since the theoretical aspect is a key contribution of the paper and the experimental section remains on the light side (it presents mostly examples and lacks more extensive results). \n\nI find the introduction of the proposed definition of disentanglement in sections 2.2/2.3 confusing. The authors first define \u201cextrinsic\u201d disentanglement of a transformation in the data space as corresponding to a transformation of one dimension only in the latent space. In section 2.3 a transformation is called \u201cintrinsically\u201d disentangled if it corresponds to a transformation of a subset of variables in the space of endogenous variables. It should be made clearer from the start that disentanglement is here only a property of the transformations and that the authors are not trying to define a disentangled internal representation. Further, some important questions like how to choose the reference endogenous variables and how to choose the subset E are left entirely to the experiments section. The definition of disentanglement proposed is however tied to these choices and a quick discussion would be helpful. \n\nWhereas the theory from section 2 seems precise and formal (at least in the appendix, although I did not check all the proofs), the procedure to identify modules comes with no guarantees and relies on several choices: local averaging, thresholding, nbr of clusters (the choice of this one is in my opinion well justified). Taking that into account a more extensive experimental validation would be needed to demonstrate that modules can be reliably identified. The results presented on CelebA and ImageNet are interesting, in particular using different models is a good idea, however the evaluation relies mostly on a few cases or examples and I would have liked to see more quantitative results, e.g. like in Figure 8 Appendix F. \n\nNote on related work:\nIt has been shown (Isolating Sources of Disentanglement in VAEs by Duvenaud et al., Disentangling by Factorising by Kim et al., Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations by Bachem et al.) that Beta-VAE is far from optimal for \u201cextrinsic\u201d disentanglement, the text in section 4.1 should take these results into account. It would also be interesting to contrast with the following paper: Robustly Disentangled Causal Mechanisms: Validating Deep Representations for Interventional Robustness by Bauer et al. which (whilst doing something pretty different) also treats of causality and disentanglement. \n\n"}