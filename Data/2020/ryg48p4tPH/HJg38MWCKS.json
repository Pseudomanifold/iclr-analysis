{"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review": "This paper focused on the multi-agent systems, and proposed a new network architecture (aka ASN). In the new architecture, the action set is  manually split into two subsets, each of which contains the actions that affects other agents or not.  Besides the net architecture, the authors also discussed several important issues including \u201cMulti-action ASN\u201d and  parameter-sharing. In the experiments, the authors evaluate the proposed nets in Starcraft and Neural MMO, and shows superior performance compared with other methods. \n\nComment:\nThis paper is relatively well-written and clearly introduces the basic idea of the work. The authors focuses on an important issue for MAS, i.e. how to reduce model complexity when increasing the number of agents. In their work, the authors would like to decompose the action set into two smaller sub-sets based on the so called action semantics, such that the designed nets have simpler and more straightforward (efficient) structure. It is interesting and  somehow convincing. One question on this point how to split the action set properly? My concern is from more general cases, where boundary  to classify the action set would be not so clear. In this scenario, how to obtain an proper split. And what would happen if we choose the wrong subset? At the beginning, I though the split would be learned by some sub-nets, but after reading I found it seems to manually set it. This is the motivation why I concern this problem. \n\nAnother point I concern is about the parameter-sharing (PS) issue in Page 5. I understand the authors want to impose the PS trick to reduce the training complexity for the model.  I also agree with this, but there is several points, which confuse me somewhat. (1) I\u2019m still confused the detail of PS. Does PS means the agents share the exactly same weights, same structure, some correlation or else? (2) I know the PS trick is popularly used in multi-task learning, in which the designers have to face the question \u201cHOW MUCH common information should the individual networks share\u201d. It means that PS trick might results in challenging model selection problem in practice. Hence I am curious how such issue is handled in the proposed model? I know it might not be the main contribution of this paper, but I think it is important to discuss, which might be missed in the paper. "}