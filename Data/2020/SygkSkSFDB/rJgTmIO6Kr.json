{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I did not assess the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review": "In this paper, the authors consider stochastic optimization in the setting where a validation function is used to guide the termination of the algorithm. In more details, the algorithm terminates if the gradient of the validation function at an iterate is smaller than a threshold. In this framework, the authors consider several variants of SGD, including distributed variant and SVRG, for each of which the authors study the expected number of iterations for a prescribed accuracy under an assumption between the training and validation set.\n\nWhile the use of a validation function is useful for early stopping, it introduces additional cost.\n\nWhile bounds on the expected number of iterations are derived for several variants of SGD, it seems that most arguments are adapted from the existing analysis to take into account the validation function.\n\nIn Corollary 3.4 and Corollary 3.5, the bound is an increasing function of m. This suggests that the best choice would be m=1. However, in this case, one needs to calculate the gradient of the validation function at each iteration, which may wastes a lot of computation.\n\nThe authors consider constant step sizes. In practice, step sizes are often decreasing along the optimization. Can the analysis be extended to cover the case with decreasing step sizes?\n\nIn eq (30), there is a missing factor of 2.\n\nThere is a required $\\epsilon>G62d_1(\\mu_V,\\mu_T)^2$ in the results. Therefore, to achieve a high accuracy we need $d_1(\\mu_T,\\mu_T)$ to be small. How many numbers of sample size to make $d_1(\\mu_V,\\mu_T)$ small? This has an influence on the computational cost."}