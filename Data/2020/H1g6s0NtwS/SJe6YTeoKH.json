{"rating": "1: Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "Summary of the paper:\n  \nThe authors propose a meta-learning approach for BO. The method consists in using a NN as the predictive mean of the model used to guide the search in BO. This NN is initialized cleverly so that its solutions is close to the actual solution to the problem by using related optimization tasks. The proposed method is validated on several experiments.\n\nDetailed comments:\n\nThe writing of the paper needs to be improved. It has awkward sentences like \"Bayesian optimization iteratively samples new point by\".\n\nThe intro on Bayesian optimization has to be improved, it explain very poorly this technique.\n\nThe description of the MAML method is not clear. The same for the reptile algorithm.\n\nEq. (3) is wrong. It does not take into account that the mean of the GP is different from 0.\n\nIt seems the authors replace the mean of the GP predictive distribution with the output of a neural network. This is strange and not very well justified. I would have expected that they use the output of the NN as the GP prior mean, to then compute the GP posterior mean.\n\nIn the related problems the actual objective is unknown. How is that difficulty addressed?\n\nIn Section 3.1, why do not you standardize the output values to have zero mean and unit deviation instead of using the ranking?\n\nHow are the hyper-parameters of the GP tuned? It seems GP based method will fail, essentially, because the authors do not consider the posterior distribution of the GP and change the mean of the predictive distribution to be the NN output.\n\nThere are no error bars for WRA-N in the experiments. Does this means that only one realization has been carried out? If so, this is insufficient to extract any conclusion. The results can be simply obtained by chance. The authors should consider several repetitions with different random seeds or different problems.\n\nThe experiments in section 4.1 are non realistic, since the actual shape of the objective function is known beforehand.\n\nIn section 4.2 it is not clear what relation are between the train / test functions. Therefore, it is not possible to understand why the proposed approach works better.\n\nThe experiments need another baseline to compare with. Namely, the same method in which the NN is randomly initialized. This will allow to check that the meta-learning procedure is useful. Currently, it can be the case that the improvements are simply due to using a different model for optimization.\n\nSumming up, I think that:\n\n(1) This paper needs further improvement in the writing.\n\n(2) The experimental section is questionable since there are missing methods in the comparison and no error bars in the experiments.\n\nTherefore I believe that this paper is still at an early stage and not ready for publication.\n"}