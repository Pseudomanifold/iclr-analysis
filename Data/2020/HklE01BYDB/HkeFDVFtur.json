{"rating": "6: Weak Accept", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This work presents a simple method for model-free RL from image observations. The key component of the method is the addition of an autoencoder that is trained jointly with the policy and value function, in contrast to previous methods which separate feature learning from policy learning. Another important modification is the use of a deterministic regularized autoencoder instead of a stochastic variational autoencoder. The method is evaluated a variety of control tasks, and shows strong performance when compared to a number of state-of-the-art model-based and model-free methods for RL with image observations.\n\nThe paper is well written and provides a very clear description of the method. The approach is fairly simple and appears to be effective for a suite of challenging tasks. RL from images remains a very challenging problem, and the approach outlined in this work could have a significant impact on the community. The experiments are also thorough and well thought out, and the release of the source code is much appreciated. While the overall novelty is a bit limited, this could be a case where details matter, and insights provided by this work can be valuable for the community. For these reasons, I would like to recommend acceptance.\n\nThere is mention of SLAC as a model-based algorithm. This is not entirely accurate. SLAC does learn a dynamics model as means of acquiring a latent state-representation, but this model is not used to train the policy or for planning at runtime. The policy in SLAC is trained in a model-free manner.\n"}