{"experience_assessment": "I have published in this field for several years.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "This paper presents a multi-frame super-resolution method applied to satellite imagery. It first estimates a reference image for the multiple input LR images by median filtering. Then it pairwise encodes the reference image and each of the multiple images in a recursive fashion then fuses the corresponding feature maps with residual blocks and bottleneck layers until only one feature maps for the entire multiple images obtained. In other words, LR images are fused into a single global encoding. Then, it applies a standard upsampling network to obtain the super-resolved image this image is fed into a network that estimates only the translational shift, and the shifted image with the estimated translation parameters finally resampled. \n\nA major concern is the estimation of a single translational motion for the SR image at the end of the network after all multiple images are already fused. The fusion strategy disregards the underlying spatially varying motion. This explicitly assumes the images are on a flat surface, which perhaps an acceptable assumption for high-orbit satellite imagery where the ground surface depth variances might be negligible. Still, this is a very critical limitation of the method. Besides, I am not convinced that pair-wise fusion can handle significant translational fusion as the filters have shared parameters. How a single convolutional layer accomplishes a global encoding and compensates for any translation between any LR image pair is neither articulated nor convincing discussion and evaluations are provided. Of course, such a problematic approach needs at least some kind of motion compensation, which may explain the need for the ShiftNet layer at the end. Nevertheless, this seems quite problematic. \n\nEven assuming the method only applies to satellite imagery, it lacks mechanisms to compensate/distinguish cloud coverage and atmospheric distortions. Characterization of satellite imagery noise models (Weibull, etc.) common in such imagery as a prior also completely disregarded. For these reasons, the proposed method fails to be considered as a comprehensive approach for multi-image super-resolution of satellite imagery. \n\nNovelty-wise, there is very little as all modules have been commonly used for SR tasks. "}