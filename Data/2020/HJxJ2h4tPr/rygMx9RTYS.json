{"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "The paper proposes a framework including recursive fusion to co-registration and registration loss to solve the problem that the super-resolution results and the high-resolution labels are not pixel aligned.  Besides, the method is able to achieve good performance in the Proba-V Kelvin dataset. However, I have some concerns about this paper:\n\n1) This paper lacks many references. Recently, many works focus on multi-frame super-resolution containing video super-resolution and stereo image super-resolution via deep learning.  They are using multiple low-resolution image to construct high-resolution image. For example:\n\nStereo super-resolution:\n\nJeon, Daniel S., et al. \"Enhancing the spatial resolution of stereo images using a parallax prior.\" *Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition*. 2018.\n\nWang, Longguang, et al. \"Learning parallax attention for stereo image super-resolution.\" *Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition*. 2019.\n\nVideo super-resolution:\n\nTao, Xin, et al. \"Detail-revealing deep video super-resolution.\" *Proceedings of the IEEE International Conference on Computer Vision*. 2017. \n\nFRVSR: Sajjadi, Mehdi SM, Raviteja Vemulapalli, and Matthew Brown. \"Frame-recurrent video super-resolution.\" *Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition*. 2018.\n\nFFCVSR: Yan, Bo, Chuming Lin, and Weimin Tan. \"Frame and Feature-Context Video Super-Resolution.\" *Proceedings of the AAAI Conference on Artificial Intelligence*. Vol. 33. 2019.\n\nEDVR: Wang, Xintao, et al. \"Edvr: Video restoration with enhanced deformable convolutional networks.\" *Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops*. 2019.\n\n2) Recursive fusion is aimed to fuse multiple low-resolution image information. Recently, more and more work utilize different methods to fuse multiple low-resolution image. For example, Tao et al proposes SPMC (Sub-pixel Motion Compensation) to align image, FRVSR uses unsupervised flow network that predicts optical flow to warp image, FFCVSR directly concatenate low-resolution image as the input of 2D convolutional network to fuse the information, and EDVR fuses multiple image features via utilizing deformable convolution. Thus, what is the advantage of recursive fusion compared to the above methods? This paper should discuss the difference between recursive fusion and the above methods.\n\n3) Registration loss is important in this paper and it can solve the problem the output SR is not pixel-wise aligned to the HR ground truth. Registration loss utilizes ShiftNet that is adapted from HomographyNet. Thus, what is the difference between ShiftNet and HomographyNet? This paper should add some details about ShiftNet and Lanczos interpolation. \n\n4) It is better to test more datasets and compare with more state-of-the-art methods. This paper only tests in a satellite image dataset. Some datasets can be considered such as VID4 dataset in video super-resolution."}