{"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper proposes an evaluation framework for Zero-Shot Learning (ZSL) methods called zero-shot learning from scratch (ZFS) where the model is not allowed to be pretrained on other datasets such as ImageNet. The main motivation of this approach is that it is difficult to understand what is useful for generalization in ZSL since most state-of-the-art methods use features pretrained on large datasets such as ImageNet.\nMost state-of-the-art approaches exploit models pretrained on ImageNet. Instead, the paper proposes to randomly initialize model parameters to have a better understanding of what's happening in ZSL.\nZFS adds one constraint: model parameters should not contain information about data outside that from the training split of the target dataset.\nTwo main criteria are studied to study neural networks:\n- compositionality (ability to be expressed as a combination of simpler parts)\n- locality (ability to encode only information specific to locations of interest)\nTo provide a better understanding of their claims, the authors use MTurk annotations to construct boolean map for each local part labelled in the CUB dataset.\n\n\nAlthough the paper is experimental, I vote for borderline accept for the following reasons:\n- The paper is well-written and the contributions are clear.\n- The evaluation metrics to evaluate how models generalize for both criteria are well motivated theoretically (e.g. Tree Reconstruction Error is used to evaluate compositionality), and different types of encoders (e.g. variations of DCGANS) are studied.\n- The analysis of models pretrained in different contexts (e.g. supervised classification, reconstruction etc...), with only global or local information, and their impact on generalization is clear (see conclusion for a summary of results). Some conclusions are very intuitive but useful to know (e.g. VAEs and reconstruction models are not well suited to learn representations that generalize in ZFS).\n\n\nThe weaknesses I found in the paper are the following:\n- The paper claims that the models used are smaller than the \u201cstandard\u201d backbones common in state-of-the-art Imagenet-pretrained ZSL methods. However, few-shot learning method (e.g. ProtoNet) do not retrain the whole model: Protonet freezes most layers and fine-tunes only the last layers to avoid overfitting.\n- The paper introduces \"Class-Matching Deep Informax (CMDIM)\" which draws positive samples from other images from the same class to extract information that discriminative between categories instead of individual samples. However, I did not understand its exact formulation and how it is exactly different from other DIM approaches.\n"}