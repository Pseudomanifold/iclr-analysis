{"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper builds upon the recent theoretical framework on nonlinear ICA, put forward in recent work Khemakhem et al. (2019) that draw a lot of attention. The latter work provides an extension of the basic nonlinear ICA that is closely related to a VAE with a conditional factorized prior, essentially introducing side information (with assumed extra observables u) to resolve non-identifiability issues. \n\nThis paper proposes an invertible architecture related to RealNVP and NICE, coined as  GIN: the General Incompressible-flow network. \n\nOn the positive side,\n\nA key feature of the proposed methodology is model selection (such as determining the model order) that is in general a hard problem even in linear latent variable models. \nThe performance is illustrated on the EMNIST dataset, as well as carefully constructed synthetic experiments. The semantic descriptions of each captured dimension, as detailed in the appendix, is particularly interesting. \nThe experimental section is quite extensive. \n\nOn the negative side, \n\nThe paper is largely based on the results of a recent technical report (Khemakhem et al. (2019)) and is not self contained, hence rather hard to digest. Even the proofs in the appendix and the intuition requires the reading of this longer technical report. \n\nIt is also not at all clear where the side information (variables u) is coming from. On EMNIST a natural candidate is the digit labels (and this turns out to be is indeed the case in the experimental section) but it is not very clear what conditions need to be satisfied. What prevents us selecting simply a subset of observations x as u? \n\nLacking an explicit motivation, the exercise of writing the canonical parameters of a multivariate Gaussian in (2) - (4) is not very informative. This needs to be better motivated.\n\nThe prior structure resembles quite closely the general hierarchical priors SVAE proposed in https://arxiv.org/abs/1603.06277. It would be also informative to discuss the links with this approach.\n\nArguably, the key contribution of the current paper is in 3.1. and 3.2, but these are rather hastily written and quite short. Overall, the balance of known results and new contributions \n"}