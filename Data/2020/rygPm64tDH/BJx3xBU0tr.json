{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "Summary.\nThe paper improves the existing feature attribution method by adding regularizers to enforce (human) expectations about a model\u2019s behavior. Three different datasets (i.e. image, gene expression, health-care) are chosen to evaluate the proposed model\u2019s effectiveness, while different regularizers (i.e. image prior, graph prior, and sparsity prior) are explored for the respective task. \n\nStrengths.\n1. Incorporating human knowledge into the model has a growing interest in ML / CV communities.\n2. Three datasets from different domains (i.e. image classification data, gene expression data, and health care data) are used to evaluate the effectiveness of the proposed approach. Data shows that the proposed approach shows better generalization performance (i.e. better performance in test dataset) than baselines.\n3. The paper provides well-documented supplemental materials that contain details of the experimental setting and additional supporting figures.\n\nWeaknesses.\n1. Task-specific heuristic human prior\nI agree (and personally like) the motivation that a method is needed to align a model\u2019s behavior with human knowledge or intuition -- model\u2019s behavior may be explained by feature attribution methods while making models accept human knowledge is challenging. However, such an ability is achieved by simply adding task-specific heuristic functions as a penalty or a regularizer. Also, the introduced human priors are similar to general regularization conventions, i.e. a penalty of smoothness over adjacent pixels is commonly used in the CV community. I am concerned that only a limited set of expert-invented human priors can be used in this approach.\n\nFurther, feature attribution methods aim to develop a richer notion of the contribution of a pixel to the output. However, the difficulty would be the lack of formal measures of how the network output is affected by spatially-extended features (rather than pixels). The explored priors (e.g. a total variation loss to make neighboring pixels have a similar impact on the final verdict) actually relieve this issue.\n\n2. Incorporating humans into the modeling process?\nA key motivation behind this work is \u201cincorporating humans into the modeling process\u201d. This would imply that (human-understandable) information needs first to be transferred from a model to humans. However, I am concerned about what information end-users are expected to obtain from the model. For example, Figure 1 (left) shows an attribution map that highlights multiple intermittent regions from which I cannot understand its behavior. Unless end-users cannot understand the model\u2019s behavior, how can we expect humans can provide knowledge to model? A user study would be needed to support that the proposed method can really provide a way to incorporate humans into the modeling process.\n\nMinor comments.\n1. Plots in Figure 3 are not intuitively understandable.\n2. There is no section Conclusion.\n3. A template for the reference section looks different from other ICLR papers."}