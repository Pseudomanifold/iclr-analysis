{"experience_assessment": "I have published in this field for several years.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "The authors propose a latent dynamics model that is learned by maximizing a bound on mutual information between image embeddings and the latent state h time steps later. The model is evaluated on four standard visual control tasks that are solved by online planning.\n\nStrengths:\n- The paper addresses an important open problem with latent dynamics models.\n- The paper is written clearly.\n\nWeaknesses:\n- The paper does not discuss why the mutual information is expected to pay less attention to distractor objects.\n- The paper repeatedly mentions \"task relevant\" information. However, I cannot find anything about the method that would make the learned features more task relevant than reconstruction. This should be clarified.\n- The distractor objects in the experiments randomly change locations in each frame. How would the model be expected to behave if they changed in a predictable way?\n- The paper is lacking detail about hyper parameters and model architecture. What value for h is used? Is the transition function a vanilla RNN?\n- The paper is missing an ablation study. It would be interesting which of the design choices about the model contribute to its success.\n\nQuestions:\n- Could you please explain the KL term that is weighted by lambda_2 in Eq 1? The KL notation on random variables rather than distributions seems non-standard. It is unclear why information about the reward should be penalized.\n- Is the objective summed across time steps? How is the data sampled that the model trains on?\n\nComments:\n- The paper claims in the introduction that reconstruction based approaches cannot discard low-level information. This claim should be rephrased, since the decoder variance allows to discard low-level information (the amount can be controlled by scaling the KL).\n- I would suggest to remove the word \"robust\" from the title or find a more descriptive term to replace it with."}