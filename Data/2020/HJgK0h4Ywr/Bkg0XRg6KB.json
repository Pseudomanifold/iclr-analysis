{"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper provides a mathematically-grounded set of axes to describe the effectiveness of latent representations: informativeness (as the mutual information between input and z), separability (I(x, zi, zj) = 0, i!=j), and interpretability. They accompany these with metrics to evaluate representations across those criteria.\n\nThey use this to evaluate B-VAE, FactorVAE and AAE. Tl;dr B-VAE are the most separable, FactorVAE are the most interpretable.\n\nI think the paper serves as a great primer for people who are not familiar with disentangled representations, and also proposes a necessary vocabulary for understanding the trade-offs of different representation disentangling methods.\n\nThe paper is too long, you could cut the final paragraph of S2.1 without losing anything (that's half a page already). You can (and should) edit this down. I don't think this paper should be longer than 8 pages.\n\nP.s. did you really cite \"Error Function\" to the wikipedia page for Error function?"}