{"experience_assessment": "I have published in this field for several years.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This paper proposes a framework to model the evolution of dynamic graphs for the task of predicting the topology of next graph given a sequence of graphs. Specifically, the paper uses a combination of recently proposed techniques in graph representation learning (Graph Neural Network) and Graph Generation (GraphRNN [You et. al. 2018]). Given a sequence of graphs as input, a GNN (to obtain low-dimensional representations of the graphs in this sequence) and LSTM (to model the sequence of these representations)  based encoder is used to compute a vector representation of the topology of next graph in the sequence. The learned vector is then used as input to a GraphRNN decoder to generate a graph that would serve as a predicted next graph in the sequence. The proposed approach is validated with experiments on three synthetic datasets and one real-world dataset (Bitcoin is same dataset from two different resources with little difference in characteristics) and compared against random graph models.\n\nThis paper should be rejected due to following reasons: \n(1) The authors do not justify/discuss the motivation and importance of the task and corresponding applications that would require to predict topology of complete graph in the next step. \n(2) The proposed techniques are an adhoc combination of existing techniques with major concerns (details below) but also with little novelty (if any) for achieving this combination.\n(3) The empirical efforts are very limited and does not provide enough evidence about the efficacy of the method, miss several details and does not serve as motivation for designing such a method in first place. Please note that negative results on cycle graphs has no role to play in this assessment. In fact,\nI appreciate the authors for reporting negative results as it provides a transparent insights into the effectiveness of model in different settings.\nOverall, the paper needs lot of work on all aspects - motivation, technique and experiments to make it fit for a conference publication.\n\nMajor Concerns:\n\n(a) Motivation: The authors do not discuss or motivate the problem and why it is important to the community. The authors mention that many existing work on dynamic graphs focus on learning representations. This is the case because learned representations can then be used for various downstream applications and even future event predictions. When such methods can be used to do future predictions required for most applications, why does one need to predict the topology of complete next graph? The authors need to provide concrete justification for the problem they address, instances where such a task would be useful and discussion on other techniques that can do similar tasks but lack in aspects that such a method can capture. For instance, as a preliminary step, can the authors explain how solving this problem would be helpful to bitcoin?\n\n(b) Technical: The technical contributions of this paper lack novelty and has several flows:\n\n- Figure 1 seems to show that graph only grows in size. While the authors do provide an experiment with removal process, that experiment does not seem to perform well. So, does the method is only good to support growing graphs?\n- Authors mention that the edge and node attributes are considered to be fixed. However, if the number of nodes and edges change, X and L should also change in terms of dimensions and adding values for new nodes/edges. so why should it not be considered time-varying?\n- What was the motivation for using GRU for update function in Eq 3? Was simple MLP tried and not useful? Was GRU used to capture some long term dependencies in structure? If so, the authors must explain how it is useful for this task.\n- Why Set2Set was used for ReadOut function? This seems to be a particularly adhoc and odd choice. when sum did not work well, jump to Set2Set is not justified. Can the authors provide an explanation for the same?\n- The authors claim that the embedding h_G_T incorporates topological information -- I find this claim highly unsubstantiated and needs justification. For instance, can you provide some rigorous analysis to demonstrate that this is the case? At the least, can the authors use this vector and pass it through a graph decoder to recover the original graph? \n- What is novel in 3.2.3 as compared to You et. al.? Infact, it is hard to see any novelty in the entire combination. Was it challenging to achieve this combination? If so, what was the challenging part? It is not clear what the authors contributed to address such a challenge. Was the training challenging? If so, please explain. If not, why is this a novel approach?\n\n(c) Empirical: The empirical efforts are inadequate and raises more questions than answers. \n\n- Synthetic datasets are simple and more datasets should be used e.g. You et. al. 2018 to validate the performance. Only one real-world dataset from two different sources is used. It is hard to understand author's motivation in doing so. Why not use various graph datasets available in papers that learn representations (e.g. cited by authors themselves) What is special about bitcoin dataset that makes it suitable for this task?\n\n- Node/edge attributes are chosen in adhoc manner and it is unclear what role they perform. Do they help with prediction? If not, would it be useful to first show experiments without them? Or does this method absolutely need attributes? It is not clear why it is useful to set all attributes for edge as 1.\n\n- How was window size of 10 chosen? Why is the same window size good for all graphs? What impact does window size has on performance?\n\n- What is the motivation for using Graph kernel for similarity? The authors borrow the decoder from You et. al. 2018 which also provides a principled method to compare graphs using MMD based on statistics. Why not employ the same?\n\n- GraphRNN (You et. al.) and other generative models can learn over multiple graphs? Did the authors try to feed the sequence of graphs to such models and then try to generate a new graph to see if they can produce similar results? It is true that those generative models do not specifically model temporal sequence, but such an experiment would help to distinguish the efficacy of the proposed method.\n\n-The technique of using MLP for generating predictions using random graph models seem to be highly unfair for the baselines. Can you elaborate more as it is difficult to understand why one should handicap those models by using learned information instead of data information?\n\n- A rigorous discussion on insights explaining the results is required. The authors show high performance on Bitcoin dataset. However,  it is not clear what part is contributing to the performance. Similarly, authors should dig deep into the failure cases and provide justification of why such a method would fail in particular cases and propose alternatives.\n\n- Why was Graph size used as a statistic to report? Two graphs of same size can be entirely different and I do not see any merit in using such a metric. Again, something like MMD based metric may be useful.\n\n\nImprovements that would make future revision strong but has not impacted current assessment:\n\nOverall, the presentation of the paper is very unpolished. The authors are missing many important details as described above while spending a lot of time in describing (repeating) known techniques verbatim as original works. This can be removed and condensed into very short preliminary section.\n\n- Notations: The authors must use clear notations. For instance, on Page 2, L is used to  describe edge attributes but then it is replaced by E in Page 3. Also, both X and L are shown to have dimension d. Are edge and node attributes of same dimension? w is used for window-size of sequence used as input and also as neighbor node. When modeling evolution of graphs where a sequence is available over time points 0...T, it is not useful to use T to also represent time step of GNN propagation. Infact, authors should avoid using time steps to signify GNN iterations.\n\n- Empirical details: The details provided for datasets and experimental setup is inadequate. Why are the two Bitcoin datasets different from each other? What does Pos. Edges in Table 1 mean? What does  Mean and 90th percentile in Table 2 signify? Authors only talk about train-test split but then mention\nvalidation set for hyper-param tuning. How was this validation set obtained? Also, what hyper-params were tuned and what was sensitivity of those hyper-params? Authors use GNN and multiple RNN's, what was the model capacity used and how it impacted the performance? Figure 5 (c) what is a circle graph?"}