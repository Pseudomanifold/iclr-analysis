{"experience_assessment": "I do not know much about this area.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper proposes a method to measure the difference between an\nestimated instance-level matching distribution and its ground-truth\none, based on instance cross entropy (ICE).\nThe goal is to learn an embedding that captures the semantic\nsimilarities among samples. \nIn particular, with ICE they try to maximize the matching probability\nof an instance with similar instances (same class).\nThe authors also use sample re-weighting into ICE and show the benefits\nof the approach against other state-of-the-art methods on three\ndatasets. The authors performed several experiments with convincing\nresults.\n\nThe positive aspect of the paper is introducing this instance-based\nmeasure which is shown to perform well on 3 challenging datasets.\n\nIt is not clear how is the scaling parameter (s) determined. Are there\nany guidelines for fixing its value?\nThe authors should explain in more detail how is the non-linear\ntransformation achieved.\n\nThe algorithm goes through all the examples of a class on each\nmini-batch, which seems a computational expensive procedure. The paper\nwill benefit if time results are reported for different approaches.\n\nThe paper is sometimes difficult to follow and needs a careful\nrevision. \n"}