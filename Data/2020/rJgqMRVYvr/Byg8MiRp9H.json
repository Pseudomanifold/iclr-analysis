{"rating": "6: Weak Accept", "experience_assessment": "I do not know much about this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review": "As a non-expert in differential privacy, my review is based on my educated guess and limited understanding of the paper.\n\nThis paper considers a the differential privacy problem regarding the parameter-tranfer algorihtm in meta-learning, such as MAML and Repile. To me, the setting is very interesting and according to the paper, it seems that it is the first formalization for this setting. Since meta-learning is becoming more and more popular, the paper possesses practical values for privacy-preseving meta-learning algorithms.\n\nThe proposed differential privacy seetings are well illustrated and presented in the paper. The differentially private parameter-transfer is also straightforward but has been twisted a little bit for theoretical guarantees. The theoretical results seem pretty reasonable to me, but I have not checked the proof in detail.\n\nThe experiments demonstrate the effectiveness of the proposed differentially private parameter-transfer. However, the experiments are also very toy-ish in some senses, which reduces the the pritical values. All the datasets the paper uses are very easy ones. It is highly recommended to perform experiments on more challenging meta-learning datasets, such as Mini-ImageNet, CUB, etc. See [A Closer Look at Few-shot Classification, ICLR 2019] as an example for conducting few-shot learning experiments."}