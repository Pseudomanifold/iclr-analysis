{"rating": "6: Weak Accept", "experience_assessment": "I do not know much about this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #4", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This is an interesting and very well-written paper. I read the paper carefully but I don\u2019t have sufficient expertise to determine whether all the proof steps are correct.\n\nThis paper builds on recent works giving generalization bounds on RNNs.\n\nThe primary contribution is that they are able to bound the generalization error for RNNs without a dependence on the network size parameters d and m.\n\nTheir proof is roughly as follows:\n1. They decompose the RNN + ReLU activation into the sum of a linear network and difference terms. This step is key because it lets you treat each term independently when estimating the Rademacher complexity.\n2. The linear network term can be bounded directly with their Fisher-Rao norm.\n3. They make a second decomposition: the difference term can be written as a sum of simpler terms\n4. For the simpler terms, their Rademacher complexity can be bounded independently using matrix-1 norm. Using the matrix-1 norm instead of the spectral norm means their bounds won\u2019t depend on the network size parameters.\n5. Then they combine these bounds to give the Rademacher complexity bounds for RNNs.\n6. Lastly, they combine the Rademacher complexity bound with Kuznetsov et al 2015\u2019s multiclass margin bound to give the generalization bound.\n\nThe downside to their generalization bound is that it requires the covariance matrix of the input data must be positive definitive, and it explodes when the smallest eigenvalue is close to zero.\n\nTheir second contribution attempts to address these downsides. They prove another generalization bound for RNNs when training with random noise, which has the effect of increasing the term containing the smallest eigenvalue of the input covariance matrix.\n\nThey remark on several empirical phenomena that are consistent with their results:\n- Correlation of features in the input data makes it harder for RNNs to generalize\n- Weight decay could help by decreasing the relevant gradient terms in their bounds\n- Gradient clipping could help when the smallest eigenvalue of the input covariance is very small\n\nTheir third contribution is a single experiment. This contribution is fairly weak and the practical value of their theoretical work would be much more convincing if they were to put more effort into this section.\n- They use IMDB data set (50k movie reviews + binary sentiment classification task)\n- They add Gaussian noise to the input data with four different values.\n- They plot the generalization error, which is the difference between the test error without noise and the training error with noise\n\nSpecific comments to improve their experiment section:\n- I\u2019m confused by the following sentence: \u201cgeneralization errors \u2026 for different combinations of L and \\sigma_epsilon are shown in Figure 1.\u201d However, in Figure 1 I only see different values of sigma. I don\u2019t see anything about using various values for L. This should be clarified.\n- Figure 1 draws linear interpolation between data points - there\u2019s no evidence for those interpolations. It should be reported as a scatter plot, preferably with error bars.\n- If space limitations prevent reporting the experiment results more rigorously, I would prefer to see the experiment results reported in an appendix, with a brief comment on their significance in the main paper."}