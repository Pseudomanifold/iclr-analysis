{"experience_assessment": "I do not know much about this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper is based on a prior work which proposed Splitting Steepest Descent to search better network structures via splitting existing neurons to multiple off-springs. As an improvement, the authors (1) incorporate the energy cost to better guide the splitting process and (2) reduce the time and space complexity by approximating the original computation process with Rayleigh-Quotient Gradient Descent. They conduct experiments on public image classification datasets using lightweight networks as backbones to show that their algorithm outperforms existing methods. The paper is well written and easy to follow. The experiments are comprehensive and the evaluation results shows good properties of proposed method.\n\nIn brief, this paper is an improvement to a splitting algorithm in a previous work, achieving good efficiency and enabling application on large datasets. However, the theory needs more justification and the experiments results are not sufficient to show the significance of their contribution. Therefore, this paper may not be accepted unless more experiment results are given.\n\nFor the theory & modeling, the following should be addressed.\n1.\tThe mathematical justification of the optimization on energy cost is not very sound, and the definition of optimal splitting set seems arbitrary.\n2.\tGiven that the experiments are conducted on convolutional networks, it would be more illustrative if the paper describe the process of applying the algorithm on common convolutional operators.\n3.\tThe novelty is limited by the prior work.\n\nFor the experiment, the following should be addressed.\n1.\tThe experiments are mainly conducted on MobileNet network. It would be more convincing if more experiment is done on other lightweight or normal convolutional networks.\n2.\tThis paper reduces time and space complexity of the algorithm in a previous work, but there is no running time or memory footprint statistics to support this argument.\n3.\tThe paper only lists one pruning-based method as comparison in the experiments. It would be more convincing if more pruning and splitting methods are presented.\n"}