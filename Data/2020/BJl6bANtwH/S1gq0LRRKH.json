{"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper focusses on underdetermination as being key to extrapolation. In the case of pretrained models, the model extrapolates on a test input if the prediction at this input is underdetermined or multiple predictions are equally consistent with models characterized by similar architecture and loss functions.\nThe underdetermination in the case of over-parameterized model classes as in deep neural networks is used here as a way of detecting extrapolation.\n\nThe authors define an extrapolation score for trained models on unlabelled test point by measuring variance of predictions across an ensemble selected from local perturbations on trained model parameters that fit the training data well or having similar training loss.\n\nThe score approximates the variance of predictions by estimating the norm of the component of the test point\u2019s gradient that aligns well with the low curvature directions of the Hessian, thus providing a tractable quantity in quantifying uncertainty in predictions. The motivation is that if the models have been trained to a local minimum or saddle point, then parameter perturbations in flat directions (small eigenvalues of the Hessian) do not change the training loss substantially.  These models with small perturbations on the flat regions then form the local ensemble for measuring the extrapolation and predicting on out of distribution samples, spurious correlated samples and for  active learning on uncertain data.\n\nThe authors prove that the extrapolation score is proportional to the standard deviations of predictions across a model ensemble with similar training loss. The math in the derivation checks out.\n\n \n\nOne of the novel contributions of the paper is in using computationally cheap post-hoc local ensembles over fully trained ensembles in the baselines that require complicated training procedure. The other key differentiation over baselines is their method leverages the ill conditioned Hessian where  the baselines struggle in requiring an inverse of that ill conditioned Hessian.\n\nThe limitations of their method is in the determination of sufficiently small eigenvalues from the ensemble subspace. Further, the sensitivity of the small set of eigenvalues towards overestimating the prediction\u2019s sensitivity to loss preserving perturbations and being less sensitive to some other under-constrained directions.\nBelow are the potential places where more clarity will help:\nIt would have been good to see a way of measuring the sensitivity in the set of small eigenvalues determination. I urge the authors to think of a way  of quantifying this sensitivity if possible especially since the model class is low dimensional.\n\nIn the experimental section with label, class prediction task, how correlated are the confounders Eyeglasses and Hat? What happens if the models are allowed to train for a longer; does the inconsistency in the behavior of AUC over more eigenvalues change?\n\nIn section 5.4, I think a comparison with the Resampling Under Uncertainty baselines is imperative. \nThere is a typo in E.4 label Attribute->Attractive.\n\nThere is lack of clarity in how similar the models are during training. Although, the ensemble is used post-hoc, its unclear if the models during training differ in initialization only? \n\nWhat are the implications of the method in the case of finetuning models especially is the training data available for fine-tuning is low. \n\nFurther, is there any notion of how the method scales with increasing depth in the neural network models? A comparison with larger test set and models trained on deeper architecture such as ResNet and the like will be interesting to see.\n\nWith noisier data and the inconsistencies in the expected behavior of the method, is there a way of quantifying the amount of noise and the extrapolation? I do see the empirical experiments demonstrating this but some more insight into this is perhaps important.\n\nOverall, its an extremely well written paper with great clarity. The method described by the authors is well differentiated from the baselines in making the clever use of the projection of the ill conditioned Hessian on the low curvature directions of the test point\u2019s gradient. \n"}