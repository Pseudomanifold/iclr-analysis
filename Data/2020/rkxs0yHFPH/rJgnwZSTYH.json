{"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review": "This paper shows how SNNs can integrate backpropagation with a second accumulation module that discretizes errors into spikes. In other words, the authors show how to translate event-based information propagation (used by SNNs) into a backpropagation method, which is the main contribution. The description of establishing the equivalence between an ANN and SNN in Section 3 is mostly well done. They perform empirical studies on MNIST and CIFAR-10 to demonstrate the effectiveness of SpikeGrad. \n\n\n= Main Concerns =\n\n1. It seems not clear to me why it is a good idea to introduce a second compartment with a threshold in each neuron as described in Eqn. 6. \n2. I very much like the idea of \"translating\" an SNN into an ANN. I'm a bit confused about the computational complexity estimation of the SNN. In particular, it is not clear to me what is the practical implication of {n-n_min}/n_min < 0.035. Furthermore, in https://openreview.net/forum?id=rkg6PhNKDr, for ANNs on CIFAR-10, freezing 80% of the VGG19 parameters from the third epoch onwards only results in 0.24% drop in accuracy. I wonder if the advantage of SNN over ANN is still huge in this case. \n3. I do not think experiments on MNIST are very useful, as the task is a toy task. I would suggest running at least one more experiment on CIFAR-100 or TinyImagenet. \n"}