{"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper proposes to learn affordance maps: a method to judge whether a certain location is accessible. This is done by distilling a series of \"trial and error\" runs and the relation of a pixel in the image/depth plane to a corrdinate into a model.\n\nI like the idea and think the paper should be accepted. The idea to use trial and error (something I prefer to self-supervision, which is used differently in many contexts, I believe) to obtain a data set for learning a model is nice and very practical.\n\nSome concerns that I think should be adressed.\n\n- The term information gain is used wrongly. The entropy of class labels is not infogain. Infogain is the expected KL of the model posterior from the model prior. Please correct this. See [1, 2].\n- *Learning* a model of the environment and using it for navigation/exploratin has also been tackled recently by [1]. I think the authors should draw connetions to that work.\n- Self-supervision has recently been proposed by Lecun as a subsitute (of sorts) for unsupervised learning. What he means is that a part of the data is used to predict another part of the data. I have no hard feelings about the term, personally preferring unsupervised, but the authors should be aware of the name clash.\n\nI wonder how the authors envision to extend this method to real scenarios. The \"trial and error\" method is clearly not viable for robotics setups, as hazards are costly. It would be nice if the authors could give there perspective on things.\n\n[1] Depeweg et al, \"Decomposition of Uncertainty in Bayesian Deep Learning for Efficient and Risk-sensitive Learning\", Proceedings of the 35th International Conference on Machine Learning\n[2] Mirchev et al, \"Approximate Bayesian Inference in Spatial Environments\" in proceedings of Robotics: Science and Systems XV."}