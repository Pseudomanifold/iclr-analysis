{"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "This paper proposes a new exploration algorithm by proposing a new way of generating intrinsic rewards. Specifically, the authors propose to maintain a \"novelty frontier\" which consists of states that have low-likelihood under some likelihood model trained on their replay buffer. The authors propose to sample from the novelty frontier using a scheme similar to a prior method called Skew-Fit, but replace the VAE with a kernel-based density model. To construct an exploration reward, the authors estimate the KL divergence between the resulting policy state distribution and the desired `state distribution, where the desire state distribution is a Gaussian centered around a point sampled from the novelty frontier.\n\nOverall, the paper tackles an important questions of exploration, and while the concept of a frontier set is not novel, the authors propose a concrete instantiation that has promising results on continuous state spaces. I'm skeptical that this exact algorithm would work on domains with complex state spaces (e.g. images), where adding Gaussian noise to your state won't produce reasonable nearby states. That said, the general idea of fitting a new model to the latest trajectory and using KL as reward seems like a promising principle that could on its own scale. However, the theory seems a bit off and there are a few experimental details that make me hesitant to increase my score.\n\nIn details:\n\nTheory:\nI found the proof surprisingly long given that it amounts to saying that if (1) S = Z + N and (2) Z and N are independent, then\n  H(S) >= H(N)\nand so\n  H(S | Z) - H(Z | S) = H(S) - H(Z) >= H(N) - H(Z)\nPerhaps more worrisome is the statement, \"we consider to maximize h(S|Z) - h(Z|S)\". Unless I misread the paper, the authors do not maximize this quantity. Instead, they *fix* this quantity by choosing a fixed entropy of N. Worse yet, this quantity is actually minimizes since, while h(N) is fixed for the duration of the experiment, h(Z) is maximized (\"To increase h(Z), we need to add...\"). It would be good for the authors to address this concern, given that the claim of the paper is that they are \"maximizing the entropy of the visited states.\" It seems like a simple answer is the following: given that S = Z + N, if N is fixed to some Gaussian distribution, then the authors simply need to maximize H(Z), which they are already doing. I'm not sure why the authors need to reason about H(S | Z) - H(Z | S).\n\nExperiments:\nCan Table 1 be replaced with the learning curves? The numbers 90% success and standard deviation of 3% seem like arbitrary numbers. It doesn't preclude the possibility that (e.g.) Skew-Fit or RND receives a 99% success rate with standard deviation of 3.1%. Figure 11 and 12 of the Appendix don't convince me that threshold at 90% and 3% is a particularly good choice.\n\nCan the authors summarize the difference between coverage and entropy in the main paper? It seems like an important distinction. Given that the authors did not use all 8 pages, it would be good to explain it there rather than in the Appendix.\nHow sensitive is the method to the hyperparameter alpha? How was it chosen? Is it the same alpha chosen for Skew-Fit?\nHow was N chosen for the door environment?\nIs Figure 7 (left) showing the performance on the simulated or real-world robot?\nIf it was done on the real-world robot, were there any important details in getting sim-to-real-world to work?\nIn Figure 5, why does there seem to be discrete jumps in the learning curves for \"DoorOpen Coverage\"?\n\nI would be inclined to raise my score if:\n1. The authors clarify why studying the quantity H(S | Z) - H(Z | S) is particularly important.\n2. Address the concerns raised over the experiments.\n3. Discuss more explicitly under what assumption they expect for this method (with a Gaussian KDE) to work well\n"}