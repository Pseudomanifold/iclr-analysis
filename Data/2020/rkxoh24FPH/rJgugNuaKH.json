{"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "In this paper, the authors studied the usage of the mutual information maximization principle in representation learning. They argue that the bias in the estimation of lower bound of MI may loosen the connection between InfoMax principle and representation learning. Specifically, they figure out the following phenomenon by experiments.\n    1. Large MI is not predictive of downstream performance.\n    2. Higher capacity critics can lead to worse downstream performance.\n    3. Encoder architecture can be more important than the specific estimator.\nFinally, the authors make a connection to deep metric learning.\n\nRecently, using the principles of mutual information in deep learning has been very hot. However, a lot of papers just use the concept of mutual information without deep thinking (why use MI? why not other metrics? what is the estimation bias and variance for MI?). Also, most paper do not have theoretical guarantees. In this paper, the authors think deeper about the InfoMax principle, and point out some weakness about the connection between InfoMax principle and the quality of representation learning. I think this paper can trigger some deep and calm thinking in this area.\n\nHowever, I think this paper is more critical then constructive. It is good to point out some weakness of the InfoMax principle, but what should we do next? How should we fix the InfoMax principle, or mutual information estimator, to make it more robustly useful for representation learning? Or does it mean that InfoMax principle is not a good tool for representation learning? I agree that this questions are out of the scope of this paper, but I would like to see the authors share more constructive thoughts in the discussion area, to make this paper more constructive.\n\nOverall, I would like to weakly accept this paper. I think this paper worth a strong accept if some constructive ideas are provided in the rebuttal. "}