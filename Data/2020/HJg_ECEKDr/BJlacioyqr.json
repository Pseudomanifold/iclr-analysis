{"experience_assessment": "I do not know much about this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "Summary:\nThe paper proposes Generative Teaching Networks, which aims to generate synthetic training data\nfor a given prediction problem. The authors demonstrate its use in an MNIST prediction task\nand a neural architecture search task on Cifar10.\nI do not find the idea compelling nor the empirical idea convincing enough to warrant acceptance at\nICLR.\n\n\nDetailed Comments:\n \nAt a high level, the motivation for data generation in order to improve a given prediction problem \nis not clear. From a statistical perspective, one can only do so well given a certain amount of\ntraining data, and being able to generate new data would suggest that one can do arbitrarily better\nby simply creating more data -- this is not true. \n\nWhile data augmentation techniques have improved accuracy in many cases, they have also relied\nheavily on domain knowledge about the problem, such as mirroring, cropping for images. The proposed\nGTN model does not seem to incorporate such priors and I would be surprised that one can do better\nwith such synthetically generated data. \nIndeed, the proposed approach does not do better than the best performing models on MNIST.\n \nThe authors use GTNs in a NAS problem where they use the accuracy on the generated images as a proxy\nfor the validation accuracy. As figure 4c illustrates there actually does not seem to be much\ncorrelation between the accuracies on the synthetic and real datasets. \nWhile Table 1 indicates that they outperform some baselines, I do not find them compelling. This\ncould simply be because random search is a coarse optimization method (and hence the proposed metric\nmay not do well on more sophisticated search techniques). \n    - On a side note, why is evaluating on the synthetic images cheaper than evaluating on the\n      original images? \n    - What is the rank-correlation metric used? Did you try more standard correlation metrics such\n      as Pearson's coefficient? \n"}