{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "title": "Official Blind Review #4", "review": "* Summary\nThis paper introduces architecture modifications for self-attention to stabilize transformers in reinforcement learning.\nThe new architecture, Gated Transformer-XL, replaces the order of the layer norm blocks to preserve an identity mapping.\nMultiple existing gating layers are proposed to replace the residual connections of transformer.\nThe new architecture is compared against MERLIN and LSTM on DMlab-30, and further ablation studies are done on Numpad and Memory Maze.\nIt is noted that they use the recent V-MPO objective to train LSTM and transformer.\nTheir results show that transformers are able to learn in memory-intensive environments, with some gating combinations surpassing LSTM.\n\n* Decision\nThis paper presents promising empirical results, however the experiments are limited, making it difficult to place in the broader work.\nIn addition, the contribution is incremental and not well-motivated.\nI would recommend a weak rejection.\nStill, I think the paper is well written and could be improved upon.\n\n* Reasons\nWhile the empirical results are impressive, they are not put into context.\nDMlab-30 is still a relatively new environment suite and it is difficult to place the result of this paper in the context of broader work.\nIn addition, the comparison is against LSTM on a new objective.\nWhile Transformer is able to beat LSTM on the same objective, it is unclear whether that is a success of the objective or the architecture.\nIn Numpad, the transformer architecture shows an improvement over LSTM, but no comparisons are made to any other memory-based agents.\nThe hyperparameter studies on Memory Maze also show improvements in memory-related tasks, but do not help in understanding of the proposed work.\n\nThe choice of architecture modification is also not well motivated.\nAs the paper mentions, initializing near identity has been shown to be important in the supervised learning literature.\nFor the topic of this paper however, I do not think this adequetly explains the instability of transformers in reinforcement learning.\nIn the related work section for example, the paper notes that gating mechanisms have been used to handle the vanishing gradients problem.\nThe paper also notes that vanishing gradients is not an issue in transformers.\nHence, it is unclear why gating would stabilize transformers for reinforcement learning.\n\nThe paper is overall well written and the ideas developed are clear.\nUnfortunately, the impressive results on DMlab are not sufficient for both the lack of deeper empirical study and better theoretical motivation for the architecture modifications.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A"}