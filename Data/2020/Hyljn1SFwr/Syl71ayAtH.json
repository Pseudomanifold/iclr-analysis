{"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "Summary\nThe paper follows up on some recent dispute, which centrally uses diagrams of the information plane to support claims with empirical evidence. These diagrams are essentially showing estimates of the mutual information between a neural network\u2019s input and a specific layer\u2019s activations (typically on the x-axis) and mutual information estimates between the true label and layer-activations (y-axis). Since these two terms are traded-off in the information bottleneck objective, one could easily draw visual conclusions about neural network training approximately following some information-bottleneck objective. This would be an interesting finding, since typically unregularized neural network training via \u201cplain\u201d stochastic gradient descent (SGD) is investigated, and it is not at all trivial how this would naturally induce an information-bottleneck objective. Unfortunately, as has been reported before, mutual information estimation methods typically employed strongly depend on the binning chosen (to estimate discrete probability mass functions). Additionally there is some conceptual criticism, essentially the issue that discrete, deterministic neural networks are invertible (especially with softmax, tanh or other sigmoid activations) - as such the quantities shown in the information plane should be constant, regardless of the layer.\nThis paper aims at shedding some more light on these issues, by performing a series of experiments where e.g. the bin-size, or the activation-composition across layers is varied. Additionally the paper investigates whether salient \u201ckinks\u201d in the information-plane trajectories can be related to early stopping, or \u201cperfect\u201d stopping. Finally, the paper performs some very exploratory experiment on pruning neural network layers, based on the information plane diagrams.\n\nContributions\ni) Information-plane diagrams for different bin-sizes and both tanh and ReLU activations, and combinations of the latter two, using datasets used in previous publication to allow for easy comparison (and reproduction of some results).\n\nii) Experiments to see whether points in training selected by early stopping (validation accuracy starts decreasing again?) or \u201cperfect\u201d stopping (validation loss starts increasing again) correspond to characteristic kinks in the information plane diagrams (which indicate the onset of the compression phase).\n\nQuality, Clarity, Novelty, Impact\nThe reasons why neural networks are able to learn representations that generalize well are currently not understood, but the question is receiving increasing attention in the recent literature. Several authors have proposed that SGD (in combination with neural networks) might have interesting, automatic regularization properties that favor weight-configurations that not only minimize training loss, but also generalize well. Showing that SGD dynamics \u201cnaturally\u201d optimize an information-bottleneck (IB) type objective would be a breakthrough result in understanding neural network training. As such, the topic is highly timely and of large potential impact. This paper aims at adding another piece to this puzzle by clarifying some of the issues with empirically verifying a connection between SGD dynamics and the IB objective. Unfortunately, I think that the current paper is not ready for publication. My main issue is that the large parts of the paper are very hard to follow, many parts are quite hand-wavy and sometimes plain wrong. Instead of clarifying and summarizing the recent dispute, the current paper causes more confusion and often simply re-iterates arguments that have been made earlier. There are some promising bits, but the paper currently looks fairly rushed and unfinished and I am convinced that it would benefit from some thorough polishing. If this were done properly, the paper could serve as a nice summary, and entry-point, to understand the scientific debate that spans several other publications. There is much that could be discussed/added to the arguments brought fore in previous publications and how to move forward with some of the findings / or how to try and alleviate issues with mutual information estimation, but this seems beyond the scope of the current paper.\n\n\nImprovements\na) The paper needs at least one or two more passes to de-clutter and clarify. Also sometimes the context (reported in previous papers on the issue) is completely missing - I think the introduction could be substantially improved. Other parts, for instance Section A in the appendix, are quite imprecise at best, sometimes borderline wrong (unless the reader familiar with the subject adds a lot of interpretation in favor of the paper).  See my comments below for some more specific sections and parts that need improvements.\n\nb) The paper would strongly benefit from a clear goal. Is it either to summarize the previously reported debate and reproduce all results in one publication? Or is the idea to propose better ways of estimating discrete mutual information from samples? Is the paper arguing in favor of using information plane diagrams as proposed by Schwartz-Ziv & Tishby and relating them to early stopping and/or some network compression algorithms, or is the paper arguing in favor of dismissing the trajectories in the information plane as (not very meaningful) artifacts of estimating discrete mutual information while it should actually be constant? Depending on the answer to each of these questions, the paper would need different kinds of (major) revision.\n\n\nComments\n\ni) P3, First paragraph, last sentence. I cannot follow the sentence, please clarify/rewrite.\n\nii) There are several occasions where the paper claims that smaller bins make mutual information estimation more reliable. I agree with this in the case of having infinitely many samples from a distribution (or the parametric form of a continuous PDF, as shown in the illustrations in the appendix). Under what conditions does this statement hold true when estimating discrete PMFs from a (small) number of samples?\n\niii) Page 4, first paragraph. What are the \u201c2 compression phases\u201d? Is there not only a single compression phase (after the \u201ckink\u201d when the mutual info with X decreases rapidly)?\n\niv) Page 4, first paragraph. When describing results shown in the figure please mention which particular trajectory is being referred. Otherwise the description is quite hard to follow.\n\nv) Section 2.3. The whole discussion in the section (and the experiments) should be fairly obvious to anyone vaguely familiar with (discrete) information theory - one important part is the criticism that tanh neural networks are essentially invertible, leading to constant MI. The other important part is that activations tend to cluster more and more strongly during training (Fig. 5), which explains the difficulty of choosing a good binning scheme. I personally think that the whole section can be significantly shortened (to about half a page, max. 1 page).\n\nvi) How was Figure 4 produced? What does it mean that the bins were \u201ctracked\u201d? Please explain this (to a degree where it can easily be reproduced). Also, what does it mean that \u201cit is from a different notebook\u201d?\n\nvii) Describe precisely what \u201cearly stopping\u201d and \u201cperfect stopping\u201d mean.\n\nviii) Figure 7 could be shown in a single panel (b, bottom right) where the time-points for early, and perfect stopping are marked with different vertical bars.\n\nix) The whole section A in the appendix needs improvement. E.g. entropy is not a measure of disorder, KL divergence is not really a distance measure (in the strict sense), the case where the info bottleneck produces a minimal sufficient statistic is for infinite beta (no capacity constraint), most of the framework is concerned with constraints that imply insufficient capacity (same is true for rate-distortion which is the basis for IB and THE framework for lossy compression, i.e. non-invertible channels).\n\nx) Figure 9, Appendix B. What is the difference between the two panels (and what\u2019s the difference to Fig 2a)?\n\nxi) Appendix G. The text description is currently hard to follow, but might be really important for readers who want to understand the dispute."}