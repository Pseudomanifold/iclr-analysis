{"rating": "3: Weak Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper proposes an end-to-end deep reinforcement learning-based algorithm for the 2D and 3D bin packing problems. Its main contribution is conditional query learning (CQL) which allows effective decision over mutually conditioned action spaces through policy expressed as a sequence of conditional distributions. Efficient neural architectures for modeling of such a policy is proposed. Experiments validate the effectiveness of the algorithm through comparisons with genetic algorithm and vanilla RL baselines. \n\nOverall, the paper provides a solid contribution by proposing a new RL-based algorithm for the bin packing problem. In particular, the dense reward design for the MDP is quite interesting. I also think solving the 2D and 3D bin packing problem via RL is already quite valuable as an application. \n\nHowever, I do not think the proposed method is novel enough. Most importantly, I perceive the concept of conditional query learning indifferent from the autoregressive modeling of the policy (with conditionally masked inputs). Although the authors divide the processing of each bin into three steps of MDP (not strictly), the steps can be merged into one without any change in the environment. Since other parts of the algorithm also come from the existing literature (except the reward design), I think this point is crucial for the paper to be published at the conference.\n\nMinor comment:\n- I think the genetic algorithm described in the experiments should be equipped with more details, i.e., the type of processor used and elapsed time. \n- In table 2, I think bold numbers for the lowest variance of performance is very confusing since it does not necessarily mean a better algorithm. "}