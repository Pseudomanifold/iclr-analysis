{"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "title": "Official Blind Review #4", "review": "This paper proposed a BERT based document summary model that has the capability of modeling arbitrarily long documents. Experiments on CNN/Daily dataset show the improvement of the proposed model compared with its baselines.\nThe advantage of this paper is that the time-consuming training process of BERT can be avoided.\n\nI think this paper is not good enough to be accepted. The model does not have the ability of understanding \u201cArbitrarily\u201d long documents, it just aggregates multiple (n_segment) BERT segments and extends the BERT capability from l_bert to n_segment*l_bert. It is not as flexible as the LSTM which can capture the real arbitrary long document. The model looks bloated and the performance is not persuasive. The authors reproduced the baseline BERTSUM but the reproduced performance is significantly lower than performance in the original BERTSUM paper. (without explanation) The proposed model can\u2019t beat the performance in the original BERTSUM paper. Even to their reproduced BERTSUM results, the proposed model gives very closed performances.\n\nBesides, this paper doesn\u2019t compare their model with other SOTA models and all the experiments are conducted in one dataset. The result analysis is not enough. As the main contribution in this paper is to understand the longer documents, the performance on long documents should be evaluated separated.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}