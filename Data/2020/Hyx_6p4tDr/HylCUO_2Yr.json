{"rating": "3: Weak Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "In this paper, a bilinear feature mapping based on random matrices is studied. The problem is to construct a map taking two vectors as inputs and outputting a single vector. Although a naive implementation requires some multiplication with a three order tensor, the proposed method avoids the expensive computation by inducing low-rank assumption. The proposed method is empirically evaluated with two action recognition tasks. \n\nAlthough the paper contains some interesting aspects, I find there are several critical limitations, especially (A) lack of motivation, (B) gap of theoretical results, and (C) insufficient experiments. \n\n(A) So the paper considers the setting that we have two different vectors x and y as input features. I think this is not a standard-setting in both supervised and unsupervised tasks. In particular, I couldn't find any necessity of limiting the pattern of second-order interaction in the form of Eq. (1). I mean, (1) only considers the interaction of (x, y), but it excludes the interaction of (x, x) and (y, y). So there needs to explain why we have to consider the interaction pattern (1). \n\n(B-1) I couldn't understand what Theorem 1 tries to convey. What we need to evaluate, if I understand correctly, is how the random projection preserves the interaction between x and y. However, Theorem 1 evaluates completely different thing (the inner products <x_1, x_2>, <y_1, y_2>). I really confused here; why we have to consider two x (x_1, x_2) and two y (y_1, y_2) while we only have single x and y in the learning setting? \n\n(B-2) Theorem 2 is also unsatisfactory because of the same reason above. Also, the implementation uses the linear approximation of sin and cos, which makes Theorem 2 unapplicable. \n\n(C) First, the proposed method is evaluated only by a single task, temporal action recognition. I feel it is not enough to show the validity as a general NN module. For example, what would happen for image classification tasks? Second, I don't see the proposed method is quite superior to the existing methods. For example, Hadamard is comparable in terms of runtime."}