{"experience_assessment": "I do not know much about this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I did not assess the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "Akin to previous work introducing tensor regression layers to leverage the tensor/multimodal structure of inputs [Kossaifi et al., 2017], this paper proposes a Kronecker structured attention operator for self attention models acting on tensor data. The proposed operators enforce various constraints on the query key and value matrices of the attention module, where some (or all) of these matrices are obtained as horizontal and lateral averages of the query matrix; in this context, the query matrix is actually the flattening of a 3rd order tensor, whose slices are referred to as \"feature maps\". A theoretical analysis investigates the properties of imposing a Kronecker structured covariance matrix on the feature maps. The main theorem provides a way to efficiently construct feature maps satisfying this covariance structure. Experiments on image classification and segmentation are given where the proposed approach shows competitive performances while maintaining a number of parameters on par with efficient architectures such as neural nets.\n\nI find this paper difficult to follow. In particular, I find it difficult to see the relevance of the theoretical analysis part. I think I got it in the end, but I believe the analysis could be better motivated/presented and the consequences of Theorem 1 on design choices or implementation could be clarified. Similarly, the description of the architecture in Sections 3.1 and 3.2 is sometimes given without much motivation, letting the reader wonder there are particular reasons for the choices made on the architecture. I acknowledge that this may be because I am not very familiar with attention networks (but I am familiar with the literature on tensorization of neural networks).\n\nI am not very confident in my assessment but I have the feeling that the paper could be greatly improved by some restructuring and giving more insights and motivations.\n\nI have a few questions and comments:\n- end of section 2.1: what is the purpose of the seperate linear transformation on each input matrix?\n- after Eq. (3) I don't think the notation [cross in diamond] has been introduced.\n- the reference (Gupta & Nagar 2018) does not seem appropriate (I don't believe the notion of vectorization requires a reference)\n- Some relevant literature may be missing, e.g.,\n[A Tensorized Transformer for Language Modeling]\n[Tensorized Self-Attention: Efficiently Modeling Pairwise and Global Dependencies Together]\n"}