{"rating": "3: Weak Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "The title of this paper is rather misleading that I thought it was an empirical study of learned priors in deep latent variable models. But in fact this is a methodology paper that proposes a new learning objective for these models. The objective is new in that I haven't seen it anywhere else but the contribution is quite incremental given a closely-related objective is studied in wasserstein autoencoders. Despite that it might look surprising to people familiar with variational autoencoders, removing the KL regularization term and match aggregated posterior and prior is already justified in the wasserstein ae paper.\n\nMore empirical evidences are needed to show the strengths of the proposed method over methods with similar motivations, such as WAE, resampled prior VAE (Baur & Mnih, 2018), 2-stage VAE (Dai & Wipf).\n\nMore concerns are summarized below\n* There are many claims in the main text that is unclear to me. For example, on page 4, \"in doing so it is easy to see that the issue of posterior overlap can be mitigated\", how?\n* FID is not a meaningful metric for generalization. There is no evaluation of test log likelihoods.\n* The learned deep generative model may generate pretty images. But I suspect it will be outperformed by WAEs in terms of representation learning (because no regularization ever happens in the objective).\n* Did you apply VGG19 perceptual loss to all models or only models using the proposed method?"}