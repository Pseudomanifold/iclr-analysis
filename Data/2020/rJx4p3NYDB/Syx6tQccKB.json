{"rating": "6: Weak Accept", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "The paper proposes an improvement to Counterfactual Regret Minimization, avoiding traversing the whole tree on each iteration. The idea is not to change the strategy in those infosets, where the reach probability of opponents is low. The strategy in such infosets is only updated once in several iterations, when the sum of reach probabilities over these iterations if higher than the threshold. The straightforward implementation of the idea still has the same running time as CFR. Therefore, the paper presents an efficient implementation, exploiting the structure of the game tree. However, this implementation comes at the cost of additional memory requirements. Overall, the paper proves the theoretical result of about O(sqrt(|I|)/D) times faster than CFR to achieve the same approximation error, while the memory requirements increase by a factor of O(|H|/|I|). Here |I| is the number of infosets, D is the depth of the game tree and |H| is the number of histories.\n\nThe idea of eliminating unnecessary computations for infosets with low probability is a valuable contribution. The presented theoretical analysis takes an important place in the series of works refining the regret upper bound of CFR and its variants. The experiment confirms performance of the idea. \n\nThat being said, I follow up with some questions/criticism.\n1.\tImplementation in Section 3.2.1 and Appendix E is rather hard to follow. Is there any intuition on how the segment [\\tau_t(h), t] is divided, i.e. what does t_1, t_2 and \\tau\u2019(h) mean? Also, clarity could be increased if these variables would be defined before they are used.\n2.\tHow is a segmentation rule for Lazy-RM in OLO designed in such a way, that equation \\sum_{i=1}^n \\max_a c\u2019_i(a)^2 \\approx \\sum_{j=1}^T \\max_a c_j(a)^2 holds?\n3.\tSection 3.2: \u201cfollowing step (1)\u201d. (1) is an equation for RM in OLO, probably some other reference was meant.\n4.\tRecently, Linear Cfr was introduced, which outperforms Cfr+. Thus, citation is needed Brown, Noam and Sandholm, Tuomas \u201cSolving Imperfect-Information Games via Discounted Regret Minimization\u201d. Worth to mention, LazyCfr is straightforwardly compatible with Linear Cfr.\n5.\tThe specified space requirements significantly limit the applicability of the presented Lazy-RM implementation. For example, in state-of-art approaches to solve/resolve No-Limit Holdem (Libratus, DeepStack, Pluribus), either the game tree is too large, making the space requirements unrealistic, or the game tree is small enough for getting a good equilibrium approximation fast even with CFR+.\n\n"}