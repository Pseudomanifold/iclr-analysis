{"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper presents a method for unsupervised domain adaptation. The problem is well known in literature and follows the setting of labeled source and unlabeled target set. This work proposes the \u201cbutterfly network\u201d suitable to train on noisy data (labels) and assign pseudo-labels to the target set. The butterfly network consists in two branches one for source+target and one for target only data. Both use the same optimization objective and a \u201cchecking\u201d mechanism has been devised for pseudo-labelling the data.\nDecision: weak reject\nMotivation: This paper has some merit but does not present the method in a clear way, it requires some additional effort to go through the method and retrieve from the appendix information useful for full understanding. For example algorithm 2 is a key component of the method and is in appendix, notation is not always clear nor explained (the loss in algorithm 2 is ), the networks F_1, F_2, F_t1, F_t2 could be added in figure 3 for more clear understanding and R(t) along with u_i could be more clearly defined (how to obtain u_i is still not clear to me after several re-reading of the paper). The introduced losses should be better justified. \nAnyway, as I said the paper has some merit, it provides many insights and extensive analysis on \u201cbutterfly\u201d method for unsupervised domain adaptation. The experimental section is extensive and demonstrates improvement in performance using this method compared to state-of-the-art, even though for some \"real world\" datasets (e.g. SUN, Caltech, ImageNet) the improvement is not so significant as in the case of MNIST-SYND. Could the authors provide results on MNIST-SVHN to help compare with other papers in literature? Did the authors observe the same evolution of the accuracy (decreasing and increasing after a few epochs) also on the \"real world\" datasets as in MNIST-SYND?\nReplicability: as I said the method is not really clearly explained and therefore I am not confident I could implement and replicate the results. This not because I think the method is complex but because some key components that I pointed out previously about the method are not clear and I strogly believe these are key components to replicate the results.\n"}