{"rating": "8: Accept", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This paper proposes a new problem setting in the domain adaptation field. Since it is impossible to obtain perfectly clean labeled source data in the real world, existing UDA methods cannot well handle real-world data. However, in wildly unsupervised domain adaptation (WUDA), we do not need a perfectly clean source data, which means that WUDA problem is a more general and realistic problem than existing ones. \n\nTo address WUDA problem, the authors proposed Butterfly framework (based on dual checking principle) to simultaneously reduce the 1) noise effects in source domain and 2) distributional discrepancy between source and target domains. They tested the proposed method on simulated and real-world WUDA tasks (35 tasks in total), and the accuracy of proposed method is higher than those of representative UDA methods. They claim that Butterfly can eliminate noise effect, which is strongly supported by Figures 2, 4 and 5. They also present the ablation study to show that each part in Butterfly is meaningful. \n\nIn general, this paper is easy to follow and clearly presents the main idea and learning procedures of Butterfly. Since WUDA, as a new problem, could lead a new research direction in the domain adaptation field, this paper should be presented in ICLR 2020. Detailed comments can be seen below.\n\nPros:\n\n+ WUDA, as a new problem, is very important for the domain adaptation field.\n+ Butterfly, as a solution to WUDA, outperforms representative UDA methods on simulated and real-world WUDA tasks.\n+ All claims are strongly supported by experimental results, and ablation study shows that each part in Butterfly is a necessary component.\n+ Following Ben-David's paper, this paper also presents an upper bound of the target domain risk. This is 1) the first WUDA bound and 2) probably the first DA bound related to pseudo labelling function. The conditions in Remark 3 are very interesting.\n+ It is very nice to use noise effect \\Delta to explain the abnormal phenomenon in experiments.\n\nCons:\n\n- The color scheme of figures is not friendly to color-blind people. The authors should do different line styles or marker styles.\n- The interaction between DIR and TSR happens via shared CNN, right? The authors should explain this in the caption of Figure 3.\n- When T = 1, you directly use source data as the pseudo-labeled target data since there are no pseudo-labeled target data in the first step (based on Algorithm 1). Is that correct? If yes, the authors should explain this in Figure 3 and the description of Algorithm 1. If no, please give a detailed explanation.\n"}