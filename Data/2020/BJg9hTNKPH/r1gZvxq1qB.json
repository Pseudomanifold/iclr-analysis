{"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper presents a framework for evaluating offline reinforcement learning (RL) algorithms.  Results from a  thorough series of experiments are presented which suggest that certain details of recently proposed RL methods are not necessary for achieving strong performance.  These results suggests that some of the complexity in RL design can be ignored.  \n\nI commend the authors for performing a valuable test and comparison of existing offline RL methodology.\n\nThis paper could be improved by providing more clear insight and intuition about the deeper meaning of these results regarding the \"unnecessary\" technical complexities.  Could the authors suggest why certain complexities are unnecessary?  Clearly the authors of those previous works thought they were needed.  To really help researchers design better algorithms, we need to be guided by some insight about not only what doesn't work but why it doesn't work.\n\nAlso, the paper could be improved by being more clear about the nature of the evaluations.  The authors provide extensive results; but it wasn't clear whether these were \"apples-to-apples\" comparisons with the previous results in the papers that proposed the \"unnecessary\" technical complexities.  For example, I didn't see the authors say that they reproduced the results of previous works, only that they tested previous methods in certain tests.  Does the BRAC framework reproduce the results for previous papers?  If so, this should be made more clear and stated prominently in the paper so that the reader knows that BRAC is, in this reproduction of previous results sense, reliable.  If not, how if the reader to know that the \"unnecessary\" technical complexities, are truly unneccessary?\n\nFinally, the paper presents lots of results, but I did not see any mention of the statistical significance of these results.\n\nMinor issue:  In the Conclusion Section, the authors say, \"Unfortunately, off-policy ... is an challenging open problem.\"  Unfortunately?!  A challenging open problem is a good thing!  And I think the authors did a good job addressing a difficult problem."}