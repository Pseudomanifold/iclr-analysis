{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This work proposes a new type of DropOut layer to regularize neural network training. The basic idea is to rotate the features using a random rotation matrix. The authors use Givens rotations to do this in linear time. The authors analyze their DropOut formulation for linear models and contrast it to Bernoulli DropOut. The further provide a probabilistic analysis of the effect on the co-adaption of their DropOut approach. Experimental results are shown on standard classification datasets, object detection, and speech recognition.\n\nPros: \n+ Interesting analysis that supports the idea. Both the analysis of linear models and the co-adaptation analysis help in building intuition about the method.\n+ Extensive experiments: The presented experiments cover different applications and are large-scale (e.g. ImageNet). The experiments indicate that there is a small, but consistent, improvement over the baselines.\n\nCons:\n- Parts of the paper are unclear:\n\n1) Equation 2: This equation mentions that the operator is normalized by the cosine of the rotation angle. While the text briefly mentions this and acknowledges that the resulting operator is not a rotation matrix anymore, this is not further mentioned in the text. It is not clear why this normalization was chosen and what would happen if one chooses a proper rotation. When looking at the actual operator that includes this normalization it seems that the term \"rotation\" is rather misleading. The proposed approach effectively applies a signed and uniformly scaled permutation matrix to the features and adds the results back onto the features.\n\n2) The analysis of the co-adaption is not completely clear to me. Can you elaborate more on the sentence \"We use L_1 distance but not L_2...\"? Why is it significant here that the variance is a second moment? Equation (15) states that RotationOut reduces co-adaption by a factor of p - (1-p)/(D-1). If we take the extreme case of only two neurons we have that this factor is negative when p < 0.5. More generally, the factor is negative whenever D < 1/p. What does negative co-adaption mean? What does this tell us about this analysis?\n\n3) Section 3.2 is completely disconnected from the rest of the paper. It examines the interdependence between dropout and batch norm, but I don't see how this specifically connects to the contribution at hand.\n\n- The improvement with respect to other DropOut variants is small. RotationOut incurs a higher computational overhead (even if the \"rotation\" can be done in linear time) in practice according to the authors.\n\nSummary: The authors introduce their idea together with interesting analysis, however, there are some problems with clarity. The practical gains that are afforded by the approach are small, and DropOut, in general, is less and less used (at least in image processing architectures) thus the impact is questionable."}