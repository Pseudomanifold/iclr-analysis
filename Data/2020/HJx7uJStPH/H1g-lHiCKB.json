{"experience_assessment": "I have published in this field for several years.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "The authors present modifications to the state of the art (waveform based) source separation model (Wave-U-Net) and improve the state of the art to be comparable to spectral masking based methods. They clearly outline all the architectural changes they make (GLU nonlinearities, strided upsampling, bidirectional RNN), perform thorough evaluations against strong baselines, and a complete ablation study to demonstrate the value of each component. The paper reads well and quickly informs newcomers to the field with proper motivation and context. For all these reasons I think it should be accepted.  One weakness of the paper is that the relative incremental nature of the study, but given the thoroughness and clarity of the experiments, and the non-triviality of the architecture search, I think this is a valuable contribution for the ICLR community.\n\nOne small suggestion, the language difference between \"upsampled\" convolution and \"transposed\" convolution is a bit confusing. I might suggest focusing on the striding of the convolution vs. bilinear upsampling, as a non-strided convolution can still be \"transposed\" from a standard API point of view in pytorch or tensorflow."}