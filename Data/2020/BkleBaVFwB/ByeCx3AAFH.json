{"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper presents a formulation of graph generative models based on graph attention aimed at scalability of these methods.\n\nThe paper is generally written well and I like the overall theme of the paper, however, there are a few key issues with this work and I don't think the paper as it stands is ready for publication:\n\n1) The main motivation expressed in the paper is that graph generative models are generally not scalable and they identify three main areas: (a) graph size (i.e. num nodes); (b) data scalability (i.e. num training samples); (c) label scalability (i.e. num of node or edge types). However, the paper doesn't follow on why the proposed method actually addresses these issues. The derivation doesn't talk about scale until we reach section 3.5 and then we find out that actually the proposed model is O(n^3) in reality. Then there are approximations to make it scale. So for me there is a massive disconnect between the main motivation of the paper and the suggested model. Why not study approximation methods for already existing graph generator models?\n\n2) Following on the theme of scale, the only experimental result discussing this is the time column reported for the training time. So that partially addresses the data scalability. Other baselines as well have reasonable training times specially when it comes to large datasets (e.g. ZINC is that the largest dataset studied with 250K samples and GraphRNN is 2x slower and GraphRNN-S only about 20%). What I was looking for was when you really can train on real-world datasets that other methods basically can't be trained. The datasets chosen all are small hence there's not much issue with scale there. The question about the scalability w.r.t. other aspects (i.e. num nodes and num labels) has not been studied or reported.\n\n3) The approximations suggested in section 3.5 also don't seem to have much impact on the training time. These approximations were motivated by the scale while looking at the training times they barely make any difference. However, they make a big difference in performance metrics specially in smaller datasets. So the question that comes to mind is that what is the role of these approximations w.r.t. the quality of the models? Again this question needs further study.\n\n4) Comparing GraphRNN and GraphRNN-S's modifications with the results from the original paper, it seems they are performing much worse (e.g. deg for the original GraphRNN-S is 0.057 while the reported num here is 0.523 for Protein dataset). The same is true for other metrics. Why is that?\n\n5) As pointed out by an observer, it seems that there are nuances to generation of the graph needing seeds of arbitrary size to be provided, explained deep down in the appendix. If this is the case for generation then it should be discussed in the main part of the paper and contrasted with methods that can start from scratch.\n\n6) In the training configuration part of the appendix, A.7.2 it seems there are discrepancies in number of GPUs as well kinds of GPUs used for each method. When reporting training times in the main section, do you normalise against these?\n\n7) It seems that many hyperparameters mentioned in A.7.2 are chosen in an ad-hoc manner without proper model selection and seem to vary across each different versions of GRAM for each different dataset. How sensitive is the model to these hyperparameters? I suspect if the model was insensitive, you could've fixed them for many of these experiments, but seems that is not the case. So without proper model selection routines, the results may not be representative of what the model discussed.\n\nMinor comment: The model suggested has some similarities to DEFactor model from Assouel et al 2019 in terms of formulation of the problem for labelled graphs (nodes as a matrix and adj as a tensor), though the underlying models are very different, that paper as well targets arbitrary size graph generation and efficiency w.r.t. model parameters."}