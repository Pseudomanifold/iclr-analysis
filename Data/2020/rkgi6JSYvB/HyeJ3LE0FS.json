{"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "This paper proposed an architecture to apply Graph Neural Networks (GNN) into the problem of conversational machine comprehension. The author argued that in conversational machine comprehension, question aware context representation can form a context graph. And a GNN can be used to encode the nearest neighbor version of that graph in order to capture context relevance. Experimental results show weak and mixed gain using the proposed approach. Although GNN might seem to be a reasonable approach to handle graph related structures, I am not convinced that the a context graph is necessary to be built in the first place.  One can build a context representation without the need to construct such a graph and there is no strong evidence to support building such a graph is necessary. Justification on why such a graph is important is critical to understand the motivations of the approach. "}