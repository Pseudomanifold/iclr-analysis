{"experience_assessment": "I have read many papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "## Summary\n\nThe authors propose a method for encoding time features using a sine function with learned phase and frequency. They apply this method to several synthetic and real-world datasets.\n\nTemporal and positional encoding is important to many applications, including NLP, sound understanding and time series modeling, so the topic is certainly of interest. However, the method they propose offers very little that is new when compared to e.g. Vaswani (https://arxiv.org/pdf/1706.03762.pdf, section 3.5) (the authors acknowledge this work several times). In addition, the authors compare to a baseline that seems to consist of passing time as a float. This seems like a very weak baseline---there are any number of other reasonable ways to encode this.\n\nDue to the incremental nature of the improvement and the weak baseline, I don't think this paper should be accepted to ICLR.\n\n\n## Specific Comments\n\n1. In Section 2, I find the sentence \"We follow a similar intuition but instead of decomposing a 1D signal of time into its components, we transform the time itself and feed its transformation into the model that is to consume the time information\" really unclear. Could you rephrase it?\n\n2. Often, positional encodings are used to encode ordering for a model architecture that is not inherently sequential. This is the case for the positional encodings in the transformer model. Did you try these encodings with non-recurrent architectures?\n\n3. In Section 5.2, did you mean 'fixing t2v(\\tau)[n] = sin(2\\pi n \\tau / 16)'? i.e. I think it's missing a 'tau'\n\n4. In Section 5.2 \"Fixed frequencies and phase shifts\" you compare Time2Vec to a fixed set of frequencies. Since positional encoding with Fourier transforms is well known, this seems like the relevant benchmark but it receives only a brief treatment. The authors compare these methods only on Event-MNIST and only for 16 frequencies. I would like to see this comparison expanded.\n\n5. Could you clarify exactly how time is encoded for LSTM + T? Are you, in fact, just passing a float value? How is this encoded for each data set? For example, the \"times\" for Event-MNIST is always [0, 783] while the SOF data has timestamps. What is the encoding scheme for each?"}