{"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper proposes an algorithm to generate boundary OOD positive/negative samples to train a classifier for OOD samples. The algorithm is based on the theoretical analysis on why confidence value could be high in unbounded polytopes. CVAE is used as a generative model to get new samples. Experiments are conducted on MNIST and Fashon-MNIST datasets, which are used as OOD and in-distribution, and vice versa. Other datasets are also used for OODs. Comparison are made with Confident-Classifier, ODIN, and Mahalanobis distance-based approach, and the proposed method outperforms the others.\nOverall the paper is well-written and well-organized. The proposed method is based on the idea from theoretical analysis, and is reasonable and valid. There are only a couple of things to point out: First, the methods to compare, such as Confident-Classifier and ODIN, are not so strong. Thus, I am not sure whether the performance of the proposed algorithm is dramatically better. Second, I would like to see the sensitivity analysis of the proposed method, because there are several hyper-parameters as mentioned in the paper.\nHowever, I like the method and could be accepted as an ICLR paper.\n"}