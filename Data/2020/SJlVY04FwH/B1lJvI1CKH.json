{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I did not assess the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "Summary:\nThe paper presents exact conditions for the convergence of several gradient based methods for solving bilinear games. In particular, the methods under study are Gradient Descent(GD), Extragradient (EG), Optimizatic Gradient descent (OGD) and Momentum methods. For these methods, the authors provide convergence rates (with optimal parameter setup) for both alternating (Gauss-Seidel) and simultaneous (Jacobi) updates.   \n\nComments:\nThe paper is well written and the main contributions are clear. \nI find the theoretical results of the paper interesting and promising, however i believe that the proposed analysis will be difficult to extend beyond bilinear games to more practical scenarios as the authors claim.  In particular, the proposed analysis is based on understanding the bilinear game dynamics using spectral analysis. This approach is not novel. It is well known for bilinear games (see for example [1] and the references therein) and is not easy to extent to general games.\n\nThe authors provide necessary and sufficient conditions under witch all previously mentioned algorithms (GD, EG, OGD,Momentum) converge for bilinear games. The convergence analysis  (Theorems 3.1 -3.4) is easy to follow and seems correct. \n\nMain issue: The authors mentioned in their abstract that \"... and understanding the dynamics of (stochastic ) gradient algorithms for solving ...\". In addition in their figures 4 and 5 they compare stochastic methods. However there is no convergence analysis on stochastic variants of the proposed methods. Note that in [2], it was shown that stochastic variants can prevent the convergence of standard game optimization methods, while their deterministic version converges. \nIf the goal of the last experiment is to show that the proposed methods and analysis can be extended to more interesting general settings then the algorithms analyzed in the paper should be used in the numerical evaluation and not their stochastic variants. The authors should be more clear (from the abstract) on what algorithms they study. The paper clearly focuses on deterministic (full gradient) methods. \n\nTo conclude I liked the paper and the theoretical analysis seems correct however i am not convinced that the results could be of interest for the ICLR community. It focuses only on simple bilinear zero-sum games and on deterministic methods for solving them. \n\nMinor Comments:\npage 2, bellow eq 2.2 biliner---> bilinear\npage 3 bellow eq. 2.6: Cesari---> Cesaro\nIn caption of figure 2: replace the x-axis and y-axis with horizontal axis and vertical axis respectively.\n\nReferences:\n[1] Gidel, Gauthier, Reyhane Askari Hemmat, Mohammad Pezeshki, Remi Lepriol, Gabriel Huang, Simon Lacoste-Julien, and Ioannis Mitliagkas. \"Negative momentum for improved game dynamics.\" arXiv preprint arXiv:1807.04740 (2018).\n\n[2] Chavdarova, Tatjana, Gauthier Gidel, Fran\u00e7ois Fleuret, and Simon Lacoste-Julien. \"Reducing noise in gan training with variance reduced extragradient.\" arXiv preprint arXiv:1904.08598 (2019).\n"}