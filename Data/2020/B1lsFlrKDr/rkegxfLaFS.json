{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This work proposes Local Auto-encoding Parser and a Global Auto-encoding Parser for semi-supervised graph-based dependency parsing. The experimental results show that the proposed methods are effective.\n\nThe novelty of this work is limited especially with unclear motivations.\n\n1. The methods proposed in this work are incremental. It seems some minor changes are make to VAE framework. Since the length of this paper is over 8 pages, the novelty in this work is not enough especially under higher standards.\n\n2. The motivation of using global and local auto-encoding parser is not clear to me. The authors proposed to encode each word in local auto-encoder and encode whole sentence in global auto-encoder. But why it takes two encoders is not well explained in the paper.\n\n3. The performance improvements shown in experimental parts (Table 1 and 2) are very marginal. It is hard to attribute the improvements to the proposed methods or training tricks. \n\nSuggestions:\n\n1. The motivations of the proposed methods should be well explained.\n\n2. Better experimental results will make it more convincing."}