{"rating": "1: Reject", "experience_assessment": "I do not know much about this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review": "The paper proposes an implicit function approach to learning the modes of multimodal regression. The basic idea is interesting, and is clearly related to density estimation, which the paper should have discussed. On the other hand the tackled problem is a weaker variant of the learning multimodal output distributions in regression. What is the benefit of tackling this simpler problem, when in reality we are interested in the output distributions? In Bayesian literature (BNNs, deep GPs, Bayesian regression) multimodal outputs are routinely produced, but the paper ignores these methods. The paper should compare to these, and demonstrate the benefit of just learning the modes instead of learning the full output distributions (perhaps the mode learning gives more accurate mode assignment?).\n\nThe paper should be more rigorous on what is the problem setting. Right now its unclear if g(.) is multimodal, if \\eta is multimodal, or if both are. This is an important distinction since it deals with whether the underlying system is modal or if the noise modal, and connects with aleatoric/epistemic characterisations. The earlier works could have been presented in more clear manner, currently the paper gives an impression that learning joint function over (x,y) is novel which it surely isn't. It was a bit hard to follow the earlier works, they should be more clearly categorised.\n\nThe artificial datasets raise more questions than they answer. Both of them are simple univariate cases, where one would expect even simple approaches work very well. But there are suddenly 40000 datapoints for the first case (why not eg 50?), optimisation seems to take hundreds of thousands of iterations, and the results are still quite bad all around (fig3). I suspect that there are coding issues, and overall the univariate examples are not very informative in general. The \"high-dimensional\" case is not really high-dimensional, and a real one should have been proposed instead. There are also no real competing methods in any experiments, except for very simple regression methods or baselines from the 90's (MDN). With no comparisons to competing methods the experiments are close to worthless. The two real dataset experiments are not enough, and even there the improvement seems to be modest with only trivial baselines included. I also don't understand why the bike classification problem is chosen for regression.\n\nThe paper proposes to combine the implicit function idea with output mode estimation, however the problem definition is vague, competing Bayesian methods and density estimation methods are ignored, the experiments are insufficient with little state-of-the-art comparisons, few datasets and clear problems in the learning. The results show only small improvements, which are not explicated sufficiently. The specific problem tackled is of minor importance for the wider ICLR community."}