{"experience_assessment": "I have published in this field for several years.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper proposed Graph Enhanced Transformer(GET) to combine the graphical and sequential representations of the molecule to improve the retrosynthesis prediction performance. Experiments indicated that the proposed model outperforms state-of-the-art Seq2Seq-based methods on USPTO-50K dataset, and showed ability in reducing invalid SMILES rate.\n\nTwo main comments: \n\n1. This paper provide no novelty with respect to deep learning method. It is just a combination of sequence transformer and graph neural network (using RDKit(Landrum, 2016) to transform a SMILES into the molecular graph). The decoder is the same as vanilla Transformer to generate SMILE string output. \n\n2. The writing can be improved. For instance, in the caption of Figure 1 - \"somehow to be transformed\" ...  plus a few other places have wording issues like this.  \n\n \n\n\n"}