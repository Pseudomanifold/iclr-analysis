{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "In this paper, the authors proposed to utilize variational lower bound of mutual information for learning representations in Reinforcement learning. To optimize the proposed variational lower bound with a more flexible encoding network, the author proposed to utilize stein variational gradient descent (or amortized svgd). Instead of learning the representation separately, the authors incorporate the framework into PPO or A2C, which yields a joint training framework for policy optimization.\n\nThe authors discussed the information bottleneck in the setting of RL thoroughly, and proposed a novel target Y (\\log P) in the scenario of policy optimization. Further the authors derive the variational lower bound under the setting of RL, and proposed to utilize amortized SVGD to learn the proposed variational lower bound. The authors also examine the mutual information using recent proposed MINE, which also indicates the effectiveness of the proposed method.\n\nUtilizing recent advanced techniques in representation learning and applying it to RL tasks which have high dimensional images state spaces can accelerate the training processing. Though the problem that the authors studied is important, the proposed method lacks novelty and has not been well evaluated comparing with other representation techniques. Specifically, I have several concerns about the paper.\n\n- Variational lower bound for RL. I admit the proposed \\log p(y|z) is novel (although heuristic), but the rest of the results can be easily derived from variational lower bound framework. I suggest the author clarify and discuss about the derivation of this part with techniques introduced in variational bounds of mutual information (Poole et al. 2019).\n\n- The derivation of updating of $\\phi$ (Equation 18). The derivation is totally unnecessary since it is exactly the same as the updating formulation of Amortized SVGD (Feng et. al 2017). See Sec 3 in Feng et. al 2017 for details. I think the author should motivate the usage of implicit models (the embedding function $\\phi(x, \\epsilon)$) and then show that we should optimize the implicit encoders using amortized SVGD.\n\n- The motivation of using amortized SVGD is unclear. If the authors parameterized the embedding function $\\phi(z)$ with a tractable density model such as Gaussian distributions, it is still possible to optimize the proposed lower bound. Ablation studies should be conducted to demonstrate why we can enjoy the benefits of implicit models in the setting of RL. \n\n- Baselines including other representation learning methods should be compared. The authors only compared with naive A2C or PPO, while there are many other methods which can be directly utilized to learn the representation during the policy optimization process. One example is  Contrastive Predicting Coding (Oord et. al 2018) (I noticed that the author mentioned MINE does not work well in this setting, but at least the variational lower bound using explicit models such as Gaussian encoders should be compared).\n\n- (Minor things) The plots in the figures are hard to read.  Figure (2) shows the advantages of the proposed methods which are really hard to read and distinguish several proposed methods. It would be nice to have a table to summarize the final performance (From the plots It is hard to conclude which one is the best). In addition, figure 1&3 is unreadable (Taking screenshots of tensorboard plots is really bad). \n\nOverall I think the paper studied an interesting problem while the motivation and the advantage of the proposed method are still unclear, which requires more discussion and comparison with other methods which can be utilized for representation learning. \n\n\nReference Papers: \n\nPoole, Ben, et al. \"On variational bounds of mutual information.\" arXiv preprint arXiv:1905.06922 (2019).\n\nFeng, Yihao, Dilin Wang, and Qiang Liu. \"Learning to draw samples with amortized stein variational gradient descent.\u201d UAI 2017.\n\nOord, Aaron van den, Yazhe Li, and Oriol Vinyals. \"Representation learning with contrastive predictive coding.\" arXiv preprint arXiv:1807.03748 (2018).\n\n"}