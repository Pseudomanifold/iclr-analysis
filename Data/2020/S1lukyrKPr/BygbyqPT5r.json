{"rating": "1: Reject", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "Three strengths:\n1. This paper has been well written and easy to follow. Adequate details have been provided to help easily reproduce the experimental results.\n2. The technical part is sound - the authors apply GAN for rumor detection and propose to use model-where and model-replace to extend conventional GAN models.\n3. Experiments are conducted on real-world data.\n\nWeaknesses:\n1. Contributions of novelty are limited. The idea of using GAN to detect misinformation such as rumors and fake news has been studied in the literature several times, and the proposed method does not differ from them significantly. The problem of explainable rumor and fake news detection has also been well studied. Therefore, this piece of work is more a marginal extension of existing solutions.\n2. The technical solution can be very limited. The generator can only manipulate content by replacing something from a true statement. The hidden assumption that misinformation is mostly generated by replacing some word definitely underestimates the complicated nature of fake news/rumor detection problem. If the assumption holds, the rumor detection problem can be easily done by collecting and comparing against true statements.\n3. The limited experimental results cannot resolve my concerns. The rumor dataset is very small for a typical deep learning model. I am also curious about how many rumors in the dataset are generated by replacing words.\n"}