{"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The contribution of the paper is a method of filtering and planning as joint probabilistic inference. For that, the duality of inference and control is used, such that an adversarial particle filtering approch can be employed. Several experiments that support the claim are presented.\n\nI recommend to reject the paper from publication. Main reasons are the sub-standard presentation of the idea as well as not justifying design decisions.\n\nI find the paper confusing. While the high-level idea is simple, the authors chose not to start the presentations from a reasonable point (i.e., the graphical model) and subsequently introduce the necessary approximations to make the problem tractable, several things are introduced ad hoc. \n\nE.g. what is the motivation to chose the mean state and the top-M particles? Why was that representation chosen? Were other representations tried? Under what conditions is this representation reasonable, when might it fail? The answers given are not sufficient. \nThe text and the algorithm boxes do not serve complementary purposes. Instead, the text merely reiterates what is in the algorithm box. \n\nFurther points for improvement.\n- Language. There are grammatical mistakes in the paper, e.g. missing pronouns, some sentences \"do not compile\", the language is sloppy (\"[...] had better be really sampling efficient [...]\")\n- Eq 1 has two expectations over s. Where does the first s come from? \n- \"Only requires a learned Q function\" does not seem very \"only\" to me. These are typically hard to obtain! Also, why is this better than using the true model (which can equally be required to be available) for Monte Carlo approximations?\n- When I started reading the paper, I was under the impression that it is about continous time POMDPs. Could be clearer.\n- For p(O_t = 1) \\propto exp(R) the assumption that R <= 0 is required.\n- page 2, paragraph 1: it reads as if the history grew exponentially. I assume the authors were referring to the policy, but that is an unnatural assessment, as policies in continuous spaces are typically continuous as well, making a cardinality argument cumbersome.\n- The literature on varitional particle filtering is not respected. Starting points are [1, 2, 3]\n- Regression does not imply root mean squared error. Counter example: logistic regression.\n\n\nReferences\n[1] Gu, Shixiang Shane, Zoubin Ghahramani, and Richard E. Turner. \"Neural adaptive sequential monte carlo.\" Advances in Neural Information Processing Systems. 2015.\n[2] Naesseth, Christian A., et al. \"Variational sequential monte carlo.\" arXiv preprint arXiv:1705.11140 (2017).\n[3] Maddison, Chris J., et al. \"Filtering variational objectives.\" Advances in Neural Information Processing Systems. 2017.\n\n\n"}