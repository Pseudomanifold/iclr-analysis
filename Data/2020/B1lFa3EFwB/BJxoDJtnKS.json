{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review": "*Summary*\n\nThe paper proposes a new method to learn data-driven representations, being invariant to some specific nuisance factors which are detrimental for the selected (supervised) classification task.\nAuthors build upon the existing probabilistic framework termed Adversarial Invariant Induction (AII) from (Xie et al., 2017). \n\nThey claim to explore it under a both theoretical and practical point of view, demonstrating the limitations of maximizing a variational upper bound on conditional entropy as a proxy to achieve invariance. \n\nLeveraging these observation, authors propose a novel method, called \u201cinvariance induction by discriminator matching\u201d (IIDM) that is based on a regularized classification loss, penalized by a Kullbach-Leibler divergence between conditional distributions of the nuisance factor.\n\nExtremely convincing experiments are carried out on a synthetic and a real benchmark in multi-source domain generalization (PACS).\n\n\n\n*Pros*\n1. The genesis of the proposed IIDM is extremely paced since smoothly derived from the AII framework.\n2. Experimental results on a synthetic benchmark (a version of rotated MNIST) and on a popular benchmark for domain generalization (PACS) proved the effectiveness of IIDM\n\n\n\n *Cons*\n1. The paper is hard to get, if the reader is not familiar with related literature\n2. It is not fully clear from the paper which parts are original and which are inherited from prior work.\n3. The structure of the paper needs to be improved (check my comments in the section beneath)\nSome of the proposed methodologies are not clear (IIDM+)\n\n\n\n\n*Detailed Comments*\n\nThe problem considered by authors is surely interesting and addressing a popular topic in computer vision and deep learning. \n\n1. Unfortunately, the paper, as it is is hard to get for scholars which are not expert of the AII formalism, which, in my opinion is not enough detailed. Therefore, in my opinion clarity is something that authors should try to work hard on: for instance, during the rebuttal time, authors can write from scratch an entire new Section in which they explain in plain terms the main outcomes of their paper, without entering too much into technical details.\n\n\n2. Additionally, the structure of the paper needs, in my opinion a major re-styling, still for the sake of better readability:\n2.a. A visualization of the proposed method (for instance, using flow-diagrams) in comparison with the existing AII should help in rapidly getting the factors of novelty of the proposed IIDM method. I would also encourage authors to add a pseudo-code\n2.b. Since authors claim two major contributions (understanding AII + IIDM), I would like to see those two contributions thoroughly presented and dissected in two separated sections of the paper. I am not fully convinced with the actual writing style in which the two contributions seem to be intertwined together.\n\n\n3. Although already convincing, the experimental part can be improved:\n3.a. Instead of a version of rotated-MNIST, authors can test on the \u201cdigits-five\u201d setting (MNIST, MNIST-M, SVHN, UPS, SYN) as done in several works like http://openaccess.thecvf.com/content_cvpr_2018/papers/Xu_Deep_Cocktail_Network_CVPR_2018_paper.pdf.\n3.b. In addition to multi-domain generalization, authors could also have tried more classical unsupervised domain adaptation settings or, even, single-source domain generalization as in https://papers.nips.cc/paper/7779-generalizing-to-unseen-domains-via-adversarial-data-augmentation.\n\n\n\n*Final Evaluation*\n\nI think that the main aspect that authors should face during the rebuttal is to make the paper more easy to read and better separate the two contributions (understanding AII and IIDM). What I am not convinced at all about the writing style of the authors since when reading the paper I am not always capable of understanding what is novel (since proposed by authors) and what is inherited from prior work. But, maybe, the reason for this is that I am not an expert of the specific related field - but, even so, I think that the paper needs to be understood from the broadest audience possible.\n\nInstead, I am familiar with multi-source/single-source domain generalization (and adaptation) and, after my careful analysis of the experiments, I see a lot of potential in the approach. I would me more than interested in checking the performance of the proposed method over some of the novel benchmarks that I have recommended. It would be nice if authors add more experiments, but I know that this is always a complicated request during a rebuttal period.\nGlobally, if I were asked to only rate the experimental part, I would have promoted for full acceptance. Unfortunately, the theoretical part of the paper is not fully clear to me and, therefore, I am not confident in calling for a full acceptance only based on the experiments. \n\nIn brief, I would go for a weak reject, looking forward to the authors\u2019 rebuttal and the opinion of the other Fellow Reviewers."}