{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "N/A", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "The paper proposes learning to add input-dependent noise to improve the generalization of MAML-style meta-learning algorithm. The proposed method is evaluated on OmniGlot and miniImageNet. The paper reports improvements upon MAML, MAML with meta-learned parameter-wise learning rates, as well as a few regularization methods that are based on input/hidden state perturbations (Mixup, Variational Information Bottleneck). An ablation study also compares the proposed meta-dropout algorithm with a number of modifications, such as a fixed noise, input-independent noise, etc. It is furthermore shown that meta-dropout somewhat improves the model\u2019s robustness against an adversarial attack. \n\nThe paper is somewhat incremental considering that Li et al, (2017) and Balaji et al, (2018) have already proposed meta-learning parameter-wise learning rates and parameter-wise regularization coefficient respectively. One difference from the methods above is that in the proposed method noise is controlled by the input. The ablation however shows that in 5-shot classification case simply adding non-trainable noise works quite well. \n\nIt seems like the choice of the particular method for adding the noise was performed using the test set. If it\u2019s true, this is methodologically wrong: model selection should be performed on a development set (or meta-development) set. Futhermore, Table 2 contains some results named \u201cAdd.\u201d, which I guess stands for additive noise. I did not find an explanation of what is the specific method for adding noise used in this case. Such additive noise is also missing from ablation experiments. \n\nOverall, it seems that paper falls short of clearly proving that back-propagating through MAML to the noise parameters is helpful. The \u201cDeterministic Meta-Dropout\u201d performs better than baseline MAML, and arguably, meaning that some part of the improvement upon MAML can be due to the architectural differences and not due to noise. \u201cIndependent Gaussian\u201d and \u201cWeight Gaussian\u201d baselines perform worse than non-trainable noise (\u201cFixed Gaussian\u201d). Learning the variance for the noise is shown to be detrimental. There is just too much confusion in the results, the improvements are not very robust. \n\nThe paper writing is okay, but there are serious issues. I am not sure I understand the argument in Section 3.2 that meta-dropout performs variational inference. It seems like Equation 7 is wrong because  y_i is missing from the second argument of the KL divergence term. The transition to Equation 8 is therefore also wrong, and as far as I can understand, the whole argument breaks down. Line 7 in Algorithm 1 in Appendix A (which by the way should really be in the main text) does not make sense.\n\nOther issues: \n- the second sentence of the abstract is not implied by the first, the usage of \u201cthus\u201d does not seem appropriate\n- the intro should probably mention L1 and L2 regularization as well\n- in Section 3.1 there is a forward reference to Equation 5, makes understanding the text quite hard\n- \u201cmeta-droput\u201d, \u201crobustenss\u201d: typos in many places\n- Figure 4 visualization is not clear. \n- the architectural change required to add noise is not explained in the paper (i.e. what is \\phi and how it\u2019s used) \n- no comparison to meta-learned L1 regularization \n- a baseline is missing in which \\phi is treated as a part of \\theta and trained with vanilla MAML\n"}