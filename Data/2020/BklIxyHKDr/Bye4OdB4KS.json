{"rating": "3: Weak Reject", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This paper provided \"an empirical study showing that a simple k-nearest neighbor-based filtering approach on the logit layer of a preliminary model can remove mislabeled training data and produce more accurate models than some recently proposed methods\". Even though it has many theoretical analysis and experiments, the paper itself is poorly written. There is no intuitive discussion on what is missing in existing methods, why the proposed method can be better, and when the proposed method may also fail.\n\nNote that an important related work is missing, namely \"Robust Inference via Generative Classifiers for Handling Noisy Labels\" from ICML 2019 (see https://arxiv.org/abs/1901.11300). The idea of that paper is also making use of the learned representations of ANY discriminative neural classifier, where the geometric information of the hidden feature spaces can help to distinguish correctly and incorrectly labeled training data. That paper was a 20-min long oral presentation at Hall A (i.e., one of the most crowded sessions), and the authors should really compare with it both conceptually and experimentally."}