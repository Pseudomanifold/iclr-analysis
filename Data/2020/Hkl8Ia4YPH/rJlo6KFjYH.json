{"rating": "3: Weak Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This paper explores the task of summary-to-article generation, the task of generating long articles given a short summary. Generating long text as output is challenging, since the seq2seq model often fall into degeneration of language models. To address this issue and have a better control on the long-form text generation, this paper proposes a hierarchical generation approach which first generates an intermediate sketch of the article and then generated the full article. This intermediate sketch can be noisy during inference because of the discrepancy between the training and inference strategies. To this end, this paper proposes a multi-agent reinforcement learning as well. \n\nFor the evaluation of such long-form text outputs (article), this paper also proposes to use a summarization model to summarize the generated article and measure the ROUGE score between the generated summary and ground-truth. The premise here is that if we can generate a good article, then the output summary generated based on this article as input will also be good. \n\nThey empirically evaluated the proposed hierarchical model with reinforcement learning, showing significant improvements over conventional seq2seq models. \n\nOverall, this paper is interesting with some new ideas, with caveat for some clarifications and missing some important experiments. \n\nArguments:\n\n\n1) It would be interesting to see how does a fine-tuned GPT-2 model on these summarization datasets perform on this article generation task. \n\n2) ROUGE-rec metric is weird in the sense that if the summary-to-article model just copies the summary with some junk non-related information which is fluent, the summarization model based on this article can still generate a good summary. However, this might not be the case as the human evaluation correlation is good with this metric. Anyway, I would suggest to further analyse this metric.\n\n3) By seeing the outputs generated by the conventional seq2seq model, I was wondering if the repetition can be fixed by simply blocking the n-gram repeats. Further, I would be interesting  to see if transformers are better baselines in such long-form text generation tasks. \n"}