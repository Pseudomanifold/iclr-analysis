{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "This paper explores generating articles from summaries--- the inverse problem of document summarization. Since directly generating a long article from summary results in degenerations such as repetitions (appendix), here the authors proposed to generate a \"sketch\" of an intermediate length (the geometric mean of summary length and article length), then generate the article based on both the sketch and the summary. The sketch supervision comes from extracting sentences in the article close to the summary in the embedding space (using BERT), and both generation problems (summary -> sketch, summary+sketch -> article) can be trained with MLE. Then the whole pipeline is finetuned using policy gradients, where the reward signal for the sketch generator is the log likelihood of the article generator. In terms of modeling, the authors use a gating mechanism to combine summary and sketch states in the article decoder.\n\nExperiments are conducted on two summarization datasets in the reverse direction (CNN/DM and BigPatent). To evaluate the generations' faithfulness, the authors proposed ROUGE-rec, which is based on another summarization system that summarizes the generated article, and use ROUGE-L as the score. To evaluate the generations' fluency, the authors used perplexity under GPT-2. The proposed method exhibits superior performance compared to normal seq2seq baselines, and human evaluations agree with ROUGE-rec and GPT-2 ppl.\n\nPros:\n1. Most long document generation problems are open-ended such as pure language modeling. A closed-ended task like summary-to-article opens an interesting research venue.\n2. The proposed model gets much better generations than the baselines, especially from the showed examples in the appendix.\n\nCons:\n1. The proposed model has much more parameters than the baseline. It is not a fair comparison unless the baseline seq2seq gets the same number of parameters.\n2. The proposed model relies on external models such as BERT for obtaining the sketches, which might give it an unfair advantage.\n3. It seems that the baseline seq2seq models produce many repetitions even with nucleus sampling (appendix). I suspect they are not well trained.\n4. With word/sentence perturbations, pretraining, and RL, there seem to be too many floating parts of the proposed approach.\n\nQuestions:\n1. why does ROUGE correlate so poorly with pairing accuracy? (table 5)\n2. what's the baseline reward R_t in Eq 2? Does that come from a neural network as well?\n3. after pretraining, is Eq 2 the only objective for the sketch generator? Or do you need to mix it with MLE?\n\nMinor\uff1a\n1. table 6, human evaluation, column pairing accuracy, should make 68.3 bold instead of 65.0.\n2. figure 2 is too small, hard to read\n\nOverall, this work considers a very interesting problem, and by using a two-phase generation approach, this work gets decent performance in terms of summary-to-document generation. However, I think the approach is not very novel and I am inclined to reject this paper."}