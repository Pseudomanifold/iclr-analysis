{"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "Comments:\nThe authors proposed a method based on self-ensembling and clustering for open-set domain adaptation. The proposed method steers category-agnostic clusters to learn the underlying structure of test samples, which is used as a constraint to learn better representation. Experiments are compared with different baseline methods and comprehensive analysis is carried out.    \n\nPros:\n1. The proposed method incorporates the clustering method into model training to get better representation to keep the original data structure in the target domain.\n\n2. Sufficient experiments are compared with different baseline methods on different datasets. The performance of the proposed method is good in most settings. Especially, on the close-set domain adaptation task, the method is also good compared with baseline methods. Besides, the authors also analyze the influence of different factors on the experimental results. For example, different distance metrics in the clustering branch and different branches in the MIM part.\n\nCons:\n1. The whole framework is complicated and seems a combined method with different existing components. The necessity and importance of different components are not clearly claimed. How to determine the choice of hyperparameters in the unsupervised domain adaptation setting? The performance would be very sensitive and unreliable. There is no sensitivity analysis for performance.\n\n2. For the concept of agnostic clustering, the author may have an incorrect understanding.  In the Probably Approximately Correct (or PAC) learning model, the assumption is that the data distribution over labeled examples is correctly classified by some fixed but unknown concept in some concept classes, e.g., by a linear separator. In the agnostic setting, however, the assumption is weakened to the hope that most of the data is correctly classified by some fixed but unknown concept in some concept space, and the goal is to compete with the best concept in the class by an efficient algorithm.  I suggest two papers involved with agnostic clustering for the authors:\n\nBalcan, M. F., R\u00f6glin, H., & Teng, S. H. (2009, October). Agnostic clustering. In International Conference on Algorithmic Learning Theory (pp. 384-398). Springer, Berlin, Heidelberg.\n\nKothari, P.K. and Steinhardt, J., 2017. Better agnostic clustering via relaxed tensor norms. arXiv preprint arXiv:1711.07465.\n\n3. Technically, I got lost on Eq. (3), which also is a very important step in the proposed SE-CC framework. How do the authors perform clustering? Why do the authors use such an update policy for centres? If it follows the k-means model, the centre update policy needs to be reproduced after you use a different metric function.  However, I found the authors still used the average value update policy. It is very strange and unclear.\n\n4. For the main technique equation (5), it is very sudden that the authors use KL to do minimization. If the number of $x_t$ is small, the L_KL may lead to a small value. There must be enough samples for the following optimization. However, the sample numbers of x_T^S and x_t is unclear.\n\n5. The writing may be improved and some parts are not clearly explained. For example, \n1) in the 'Summary' part of section 2, \"The structure preservation enables effective alignment of sample distributions within known and unknown classes\"; \n2) It would be better, if the A -> D, A -> W and others are explained in the caption of Table 1.\n\nQuestions:\n1. In the introduction part, the authors claimed the binary classifier cannot get good performance because of ambiguous semantic labels between known and unknown classes. Why is the clustering method able to tackle the samples with ambiguous semantic labels? Do the authors have any proof?\n\n2. In figure 2, 1) Is the MI maximization discriminator is necessary? The authors claimed that this constraint can enhance the learned feature representation. What does 'enhance' mean? 2) How can we understand the results (real or fake) of Mutual Information Maximization after the discriminator? 3) How can you choose the input image \\hat_{x}_t^S?  Why do you need the MI constraint between only one image and the input image, not between all the other images(excluding the input image only) and the input image? \n\n3. In MI optimization, a global and local strategy is applied. It is unclear why the authors use these steps and what are their convergence conditions and results?\n\n4. The authors claimed that \"Hence, the learned feature representations are enforced to be domain-invariant for known classes and meanwhile more discriminative for unknown and known classes in target domain\". How can you guarantee this? I can not see why the representations are more discriminative for unknown and known classes in the target domain.\n\n5. In table 2, 1) why is the performance of different classes so diverse? Some are around 90%, some are around 10%. 2) SE is better than the proposed method in many classes. Could you explain more?\n\n"}