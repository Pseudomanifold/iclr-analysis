{"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper introduces a new method of open-set domain adaptation, which exploits Self-Ensembling with the category-agnostic clusters in the target domain. Firstly, the proposed pipeline performs clustering to decompose all target samples into a set of category-agnostic clusters. Secondly, an additional clustering branch is integrated into the student model to estimate cluster assignment distribution. By aligning the cluster assignment distribution to the inherent cluster distribution via minimizing their KL-divergence, the feature representation is enforced to preserve the data structure of the target domain. Finally, the mutual information among the feature map, classification, and clustering assignment distribution is maximized to enhance the feature representation. \n\nAlthough the classification performance is better than the baseline methods, this paper should be rejected because (1) this paper is not well organized and a bit hard to read, (2) the proposed pipeline is ad -hod and complicated, and there are a lot of hyperparameters to tune. \n\nMany important terms and concepts are used without explanation in the first half of the paper, such as \"student model,\" \"assignment distribution.\" They can be understood if readers read all pages, but it would be better to write it reader-friendly. At least, a short introduction of Self-Ensenbleing is required in Sec.1. Also, motivation to use Self-Ensembling as a base model is not written. The authors should mention the reason why the authors integrate the cluster alignment into Self-Ensembling.\n\nThe proposed pipeline seems ad-hoc. The algorithm is not justified by theory. The authors should state the reason why the alignment of clusters works well for open-set problems more clearly. Mutual information maximization seems a sideshow of the main claim of this paper, and it makes the reviewer feel the proposed pipeline more ad-hoc.\n\nThis paper should cite some articles about prototypical networks and discuss the novelty of this paper referring to them.\nYingwei Pan, Ting Yao, Yehao Li, Yu Wang, Chong-Wah Ngo, Tao Mei. Transferrable Prototypical Networks for Unsupervised Domain Adaptation. CVPR, 2019."}