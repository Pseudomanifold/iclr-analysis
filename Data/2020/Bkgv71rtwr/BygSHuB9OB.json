{"rating": "3: Weak Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "The paper introduces a new approach to open set domain adaptation, where the source domain categories are contained in the target domain categories. The overall goal is to filter out outlier categories in the target domain and enable adaptation within the shared classes.\n\nThe paper employs the self-ensembling student-teacher model for the closed-set domain adaptation part. However, the paper does not explain how this part contributes to the open set domain adaptation part. It just copies the previous method without sufficient motivation. This should not be considered as a contribution of the paper.\n\nWhat distance measure is used in the K-means algorithm is not introduced. The similarity measure between data points and centroids is cosine distance. It should be consistent with the distance measure in the K-means algorithm.\n\nThe paper uses features from the pre-trained model on ImageNet for clustering. However, when the target domain deviated from the ImageNet much and there is no model pre-trained on large-scale data related to the target domain, the features are not reliable and may induce large clustering errors. Training the clustering branch on such wrong clustering assignments is sub-optimal. Could the authors provide a solution to such a situation?\n\nThe mutual information maximization part is the major contribution of the paper. It employs both global and local mutual information and uses adversarial learning to enforce each feature to match the class probability and cluster assignment. This part is novel to the open set domain adaptation problem.\n\nThe classification results on several datasets show that the proposed method outperforms previous methods. However, the method uses the self-ensembling technique, which is not used by previous papers and not the contribution of the proposed method. It should be better to compare with previous methods by modifying their closed-set part with the ensembling model.\n\nThe ablation study part is not that convincing. It cannot reveal the relationship between different parts of the method. From the results, we do not know how the CE, KL and MIM parts influence each other. For example, the MIM may rely on KL and CE since we need good P_{clu} and P_{cls}. It should be better to show when removing one part from the method, what is performance.\n"}