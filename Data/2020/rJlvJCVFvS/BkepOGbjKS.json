{"rating": "3: Weak Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This paper proposes to learn attention among pairs of input units (they call these entities) as a matrix of attention values. These when aggregated along a row gives a summary of related entities for each input entity, and when aggregated overall gives the 'soft' entity-pairs in an input.  They apply it on four image-related tasks: object detection, categorization, relation , and scene detection and one document classification task.  Direct supervision for learning the entity-pair attention is only available from the relation proposal task.  They also induce indirect supervision from the object detection task using co-occurrence of objects in an image.  For text they hypothesize attention pair supervision based on POS tags.  Their experiments show that only for the relation proposition task their method provides significant gains over existing methods, that too in the fully supervised mode.    For scene categorization their method is good only with supervision on attention relation. For object detection their gains are insignificant and for text classification they show gains only with the labeled data is small.\n\nI have the following concerns about this work:\n1.  Computing pairwise attention is computationally expensive, and the gains they obtain seem too small to justify.  The only significant gains are for the relation proposal task where such pairwise attention is expected to be the norm.\n\n2.  Their experiments do not perform a fair comparison over the number of parameters and running time.   The FAN module inserts lot more parameters and quadratically blows up the attention vector length.  If we normalize on the number of  parameters and running time, it is unclear if the gains of FAN over  baseline will continue to hold.  For example, in the document classification task, they concatenate the FAN descriptor with usual  word to sentence attention.  What if a multi-headed attention is  used on the word to sentence layer? It is unclear if FAN will score over multi-headed attention.\n\n3. Their coverage of related work and empirical comparison with existing work is sketchy.\nAuthors have not done justice to the multiple prior work that seek to\nsupervise attention or model the relationship between attention of\nmultiple entities.  Several papers on supervising attention but in the section \n\"Attention Networks \u2013 Limitations\" the authors do not mention these.  I list some of these:\n\nSyntax-Directed Attention for Neural Machine Translation\nKehai Chen, Rui Wang, Masao Utiyama, Eiichiro Sumita, Tiejun Zhao\nAAAI 2018.\n\nSiddhesh Khandelwal, Leonid Sigal: AttentionRNN: A Structured Spatial\nAttention Mechanism. CoRR abs/1905.09400 (2019)\n\nAttentive Relational Networks for Mapping Images to Scene Graphs\nMengshi Qi, Weijian Li, Zhengyuan Yang, Yunhong Wang, Jiebo Luo; The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2019, pp. 3957-3966\n\nSupervised Attentions for Neural Machine Translation\nHaitao Mi Zhiguo Wang Abe Ittycheriah\nhttps://www.aclweb.org/anthology/D16-1249.pdf\n\n\nQuestion for authors:\n---------------------------------\nPlease clarify the exact way in which the FAN module that provides word-pair\nattention is converted into a sentence descriptor. From Figure~3 it appears that you do row-wise\nmax-pooling but please  specify clearly in section 4.5,  preferably with a formula.\n\nThe form of Equation 3 needs more justification. Why this specific form?\n\nPresentation:\n------------------\nThe first section is hard to read and requires significant improvement in writing.  I give some suggestions:\n\nTypo in sentence:\n\"for the task of learning relationship attention weights between entities\"\n\n\"relation weights\" is an awkward construct.\n\nA citation is required on \"Relation Networks\" in their first mention in this sentence:\n\" Typical qualitative examples comparing Relation Networks with our\nFocused Attention Network are shown in Figure 1, with a quantitative\ncomparison reported in Section 5.\"\n\nThe sentences in the paper are often hard to parse.  Here is are some\nexamples:\n\n\"The scaled dot product attention module of Vaswani et al. (2017), for\nexample, uses learned pairwise attention weights between region\nproposal network (RPN) generated bounding boxes in images of natural\nscenes (Hu et al., 2018) to boost object detection.\"\n\n\"In fact, for a given reference object (region), relation networks (Hu\net al., 2018) tend to predict high attention weights with scaled or\nshifted bounding boxes surrounding the same object instance. This is\nlikely because including surrounding context, or simply restoring\nmissing parts of the reference object, boosts object detection\"\n\nThe illustration of attention in Figure 2 is not at all clear."}