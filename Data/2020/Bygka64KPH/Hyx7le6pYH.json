{"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper suggests a method for semi-supervised few-shot learning. It is based on prototypical network, but in addition to the supervised loss a regularisation term that encourages unlabelled sample to be closer to the prototypes. This regularisation term is adapted from Haeusser et al. (2017) and is encouraging a random walk on a graph (where nodes are prototypes and unlabelled samples) that begins at a certain prototype to end at the same prototype. \n\nThe SS-FSL is indeed interesting and worth exploring. I also find the random walk on a graph of samples appealing and can potentially give insights on the structure of the embedding space. However, I think the paper is lacking in innovation, it is Haeusser et al. (2017) method applied to SS-FSL. The only difference is the usage of prototypes instead of labeled samples, this difference is also only relevant for 5-shot and not for 1-shot (where the prototype is the labeled sample) so there is only a single experiment (5-shot mini-imagenet) that is truly testing PRWN. Also, the choice of using prototypes (unlike Haeusser et al.) is neither justified theoretically nor empirically. Additionally, it is strange that the reported SS-FSL results are lower than standard FSL SOTA, e.g MetaOptNet (Lee et. al, 2019). \n"}