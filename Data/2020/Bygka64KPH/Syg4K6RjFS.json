{"rating": "3: Weak Reject", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This submission introduces a version of the random-walk regularizer introduced in Haeusser et al. 2017, in the setting of a Prototypical Network for semi-supervised few-shot learning. The authors show that using this regularizer, SOTA results can be obtained, notably on the popular miniImageNet. They also show that the random-walk can be used to successfully tackle the case with distractors.\n\nI'm a bit on the fence for this submission. I could be convinced to accept, due to the impressive effectiveness of the method despite its simplicity. However, the submission is not without faults:\n\n1. There are no results reported on tieredImageNet, despite it being used in the original paper on semi-supervised few-shot learning (Ren et al. 2018).\n\n2. The proposed methods remains a fairly simple extension of the regularizer of Haeusser et al. 2017.\n\nIf the authors could address point 1 and add results on tieredImageNet, I would be willing to increase my rating.\n\nVery small note: in the 4th section paragraph, is it possible that p(x_i|p_j) = \\Gamma_{i,j}^{(p\\rightarrow x)}, should be p(x_i|p_j) = \\Gamma_{j,i}^{(p\\rightarrow x)}?"}