{"experience_assessment": "I do not know much about this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review": "The paper is concerned with few-shot classification, both its benchmarks and method used to tackle it. The scope of the few-shot classification problem can be set relatively widely, depending on what data is available at what stage. In general few-shot classification is an important ability of intelligent systems and arguably an area in which biological systems outperform current AI systems the most.\n\nThe paper makes a number of contributions. (1) It suggests an approach to do a specific type of clustering and compares it favorably to the existing literature. In a specific sense the approach does not use supervised labels (\u201cwithout labels at meta-evaluation time\u201d). (2) It applies that approach to currently existing datasets and achieves \u201csurprisingly high accuracies\u201d in that setting, with the implication that this shows a weakness in these datasets when used for benchmarking (\u201ctoo easy\u201d). (3) It further suggests a metric, dubbed \u201cclass semantics consistency criterion\u201d, that aims to quantify this shortcoming of current benchmarks on these datasets. (4) It assesses a specific meta-dataset using that metric, confirming it is harder in this sense, at least in specific settings.\n\nMy assessment of the paper is mildly negative; however this is an assessment with low confidence given that I am no expert on few-shot classification or related areas.\n\nWhile the authors first example (the \u201cMongolian\u201d alphabet of the Omniglot dataset and geometric shapes falling into different categories) illustrates the problem space well and is indeed quite intuitive, the same cannot be said about either the specific setting they consider nor the metric they propose. It\u2019s not immediately clear that the other approaches from the literature they compare their method to were conceived for the setting considered here, or indeed optimized for it. The authors do show good accuracy on clustering Omniglot characters without using labels and thus indeed demonstrate a high amount of class semantics consistency for that dataset. The results on miniImageNet are less clear-cut, and the results of the evaluation of the meta-dataset appear to depend on the specific setting considered. This makes it unclear to what extent the proposed metric is general and predictive. To their credit, the authors state that in future work they are looking to make their metric \u201cmore interpretable and less dependent on the backbone architectures\u201d.\n\nI believe the paper might benefit from being given additional attention. A streamlined and more accessible version might well be an important contribution in the future."}