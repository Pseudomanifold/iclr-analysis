{"experience_assessment": "I have read many papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "The aim of this work is to improve interpretability in time series prediction. To do so, they propose to use a relatively post-hoc procedure which learns a sparse representation informed by gradients of the prediction objective under a trained model. In particular, given a trained next-step classifier, they propose to train a sparse autoencoder with a combined objective of reconstruction and classification performance (while keeping the classifier fixed), so as to expose which features are useful for time series prediction.  Sparsity, and sparse auto-encoders, have been widely used for the end of interpretability. In this sense, the crux of the approach is very well motivated by the literature.\n\n* Pros\n\t* The work provides extensive comparison to a battery of other methods for model prediction interpretation. \n\t* The method is conceptually simple and is easy to implement. It is also general and can be applied to any prediction model (though this is more property of the sparse auto-encoder).\n\t* Despite its simplicity and generality, the method is shown to perform well on average, though it sometimes performs significantly worse than simple baselines.\n\n* Cons\n\t* The method itself is not explained very well. The authors use language such as \u201cattach the auto encoder to the classifier\u201d, which is a bit vague and could mean a number of things. It would be helpful if they provided either a formal definition of the model or a architectural diagram.\n\t* Though the quantitative evaluation is not entirely flattering, the authors should not be punished for providing experiments on many datasets. That said, if their contribution is then rather one of technical novelty, i.e. a sparse-autoencoder-based framework for time series interpretability, it would be helpful for them to \n\t\t* More formally define their framework / class of solutions\n\t\t* Provide a more in depth study of possible variants of the method (this is elaborated on in the \u201cQuestions\u201d section)\n\t\t* More strongly argue the novelty of their method\n\t* The authors provide a discussion on automatic hyper-parameter tuning that seems a bit out of place in the main method section, since it is not mentioned much thereafter and is claimed to not bring benefits.\n\t* The qualitative evaluation made by authors is rather vague:\n\t\t* \"Alongside the numbers, TSInsight was also able to produce the most plausible explanations\u201d\n\t\n* Additional Remarks\n\t* Why not train things jointly? Does this have to be done post-hoc? The authors state that they \u201cshould expect a drop in performance since the input distribution changes\u201d -> so why not at least try fine-tune and study the effect of training the classifier with sparse representations end-to-end? Exploring whether things can be trained jointly, or in other configurations, might allow the authors to frame their work as more of a general technical contribution.\n\t* It would be nice to have the simple baseline of a classifier with a sparsity constraint, i.e. \n\t\t* I.e. ablate the reconstruction loss\n\nI\u2019ve given a reject because 1) the explanation of the method is not very precise and could be greatly improved, 2) the quantitative evaluation is not sufficiently convincing, given the lack of technical novelty), and 3) the qualitative evaluation is hand-wavy. "}