{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper tackles the problem of solving a black-box optimization problem where only some samples have been observed. This task requires a good model that can be both expressive and generalizable. Instead of learning only a single forward model of x -> y, this paper proposes to additionally use a mapping from y -> x. Optimizing in the space of z instead of x can be much simpler, and this should also act as a strong regularizer during training. Specifically, the paper uses a GAN that transforms [y,z] -> x, where z is stochastically sampled. This paper further proposes a reweighting scheme that interpolates between a uniform weighting and weighting the best sample so far, as well as a sampling procedure that iteratively samples points and refits a second model, which was inspired by Thompson sampling.\n\nPros:\n - The proposed idea of using an inverse mapping is straightward but shown to be effective. The methods to make this work, namely reweighting and the randomized labeling procedure, seem to have some amount of theory behind them, though their presentation was confusing without multiple read-throughs. \n - There are plenty of experiments across a wide array of domains, including images, 2D and 6D functions, and proteins which have a discrete representation.\n - There are some comparisons to Spearmint and a scalable BO method (DNGO), though only on the 2D and 6D functions.\n\nCons:\n - The proposed pieces were often difficult to follow, and there doesn't seem to be sufficient information regarding the reweighting and randomized labeling for understanding and reproducing this work (see Questions). \n - Only a few ablation experiments were carried out, and the effect of reweighting seems to only appear as a visual comparison in Figure 1. As the method seems quite different from related approaches, having more systematic comparisons would give us a better understanding of the core sources of improvement and better instigate future works.\n\nQuestions:\n- After Theorem 3.1, what is g? A linear function can only change a pdf by its bias (as any multiplication only affects the normalization constant), so not sure how to interpret g. I wasn't able to find this in the Appendix either.\n- When creating the augmented dataset for defining & approximating some kind of posterior, can you be more concrete about how the y (and x) values are chosen? More specifically, is this procedure approximating some kind of meaningful posterior? If the y values are sampled randomly (from some fixed prior or perhaps from the p(y) described in the reweighting section?), what makes this procedure meaningful (does it rely on the learned GAN somehow)? Seeing a simple example in 1D would be a good visualization. \n- What are the different rows of Figure 1 (different initializations)? Why are the different rows so similar for MIN but not for F? Also, what were the original examples (are they closer to the F results, or the MIN results)?\n- For the protein task, how did you structure the output of f^-1(x) and how did you backpropagate through the discrete variables?\n- In the experiments, it wasn't explicitly clear what the \"MIN without inference\" setting referred to; I assume this is where a single sample from the inverse mapping GAN was used?\n\nAdditional Comments:\n- When discussing the reweighted objective, the notation is a little confusing. The variables (j,k) is a different parameterization of the index i, but initially I thought k was indexing features of x. Perhaps a brief explanation of the rearrangement would make this clearer at first glance, or even remove this from the main text? (Without going through the proof, it isn't clear why this rearrangement is discussed.)\n- After (1), it wasn't yet clear why this is called \"model-based\" optimization, as no model has been introduced yet.\n- Are BO methods truly not applicable to the static setting? The static setting seems to be just a single prediction, which seems like a single step (ie. special case) of the non-static case?\n- typo: \"method to solve perform optimization\"\n- typo: Figure 1 \"Obsere\""}