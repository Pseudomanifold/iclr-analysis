{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "In this work, the authors proposed a deep learning-based method for synthesizing the missing modality/features/domain in input images. The proposed method is based on generative adversarial networks utilizing several loss functions for generating accurate missing modalities. Moreover, they have extended the proposed method for an alternative task, image segmentation.\u00a0They validated the proposed method on natural images using RaFD dataset for generating the missing facial expressions, and biomedical images using BraTS and ProstateX datasets for generating missing sequences and implementing lesion segmentation.\nThe content of the paper is almost clear and it is well written. However, there are some major comments that I would like to mention.\u00a0\n\n1.\tThe paper provides very weak literature regarding the deep learning methods for synthesizing missing modality. For instance, one of the first multi-input, single-output (many-to-one) method was proposed by Jog et al. [1]. See more in [3, 4, 6], and especially recent benchmark methods [2, 5, 7].\n2.\tThe authors claim that the proposed method has start-of-the-art performance. However, we found that they did not compare the proposed method with state-of-the-art methods. Please check the latest state-of-the-art in MRI sequence synthesizing [2, 5, 7].\n3.\tEquation 7 is not the Dice loss function [8], instead, it shows Tversky loss function which is slickly different than Dice loss [9]\n4.\tIt is missing a clear justification for not using the weight parameter (lambda) for segmentation loss function. In particular, how they can control the trade-off between segmentation and image generation performances during the training.\u00a0\n5.\tIt is also missing information about which view of the 3D image is selected to extort 2D slices, as well as the reason for selecting the mentioned view. Moreover, most of the slices, especially in the brain images are without tumors lesions (BRATS). Therefore, when the proposed model is trained based on whole slices, it will have a bias. There is no mention nor justification for this issue.\n6.\tMulti-input multi-output (n-to-n) image translation is not new. See references above, which are related to the same idea [6, 7]\n7.\tIf your method supports n-to-n image translation, regarding the literature, you should show the performance of the proposed method for all possible scenarios as the literature provides. See table 3 in [7] that shows performance in the BRATS dataset.\n8.\tPeak signal-to-noise ratio (PSNR) is another important metric for measuring the performance in synthesizing missing sequences. This measure was not reported in the paper.\u00a0\n9.\tThe reported results in Table 1 are related to the single modality synthesizing (n-to-1). However, regarding the literature, for correct comparison, you should consider all possible options and then measure the mean value for all reported results. See table 4 in [7].\u00a0\n10.\tTo show that your method provides comparable performance in natural image segmentation, Dice measure could be enough. However, in medical image segmentation, having a good overlap between segmentation output and ground truth (Dice) does not imply that your method provides good segmentation performance. In medical image segmentation, specifically lesion like multiple sclerosis or brain tumors, we have to use other metrics like lesion-wise true positive rate, lesion-wise false positive rate, positive prediction value, etc to prove the validity of the proposed method. Such as the metrics mentioned in [10] for MS lesion segmentation.\u00a0\n11.\tThe results of the methods reported in segmentation parts for BraTS and ProstateX are not related to the state-of-the-art segmentation methods. They are related to some previously proposed methods which are not state-of-the-art. Even if the authors want to concentrate on methods with an initial generating step for missing modality, you should compare the proposed method with the other baseline methods like the ones proposed in [3] and [4].\n12.\tTable 8 (column 3) shows that synthesizing a missing modality and using the generated fake modality combined with all other available modalities for segmentation gives a better performance than using all real modalities in a network like U-net. However, there is not any justification for this strange performance. Why a set of modalities including fake/generated modality can give better segmentation performance than a set including all real modalities? May you need to measure the aforementioned metrics to see whether your method has over-segmented regions or not. If your method creates better Dice measure performance, it does not prove that you have better segmentation performance, instead, you may have very low true positive rate or very high false-positive rate)\u00a0\n13.\tAn ablation study is needed to prove the impact of the proposed loss functions.\n14.\tThe authors did not discuss the disadvantages of the proposed method.\n\n[1] A.Jog, A.Carass, D.L.Pham, and J.L.Prince, \u201cRandom forest FLAIR reconstruction from T1, T2, and Pd-weighted MRI,\u201d in\u00a0Proceedings - International Symposium on Biomedical Imaging. IEEE, 2014, pp. 1079\u20131082.\u00a0\n\u00a0[2] A. Chartsias, T. Joyce, M. V. Giuffrida, and S. A. Tsaftaris, \u201cMultimodal MR Synthesis via Modality-Invariant Latent Representation,\u201d\u00a0IEEE Transactions on Medical Imaging, vol. 37, no. 3, pp. 803\u2013814, Mar 2018.\u00a0\n[3] M. Havaei, N. Guizard, N. Chapados, and Y. Bengio, \u201cHeMIS: Hetero-Modal Image Segmentation,\u201d in\u00a0Medical Image Computing and Computer-AssistedIntervention\u2013MICCAI2016. SpringerInternational Publishing, 2016, pp. 469\u2013477.\u00a0\n[4] T. Varsavsky\u00a0et al., \u201cPIMMS: Permutation Invariant Multi-modal Segmentation,\u201d in\u00a0Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support. Springer International Publishing, 2018, pp. 201\u2013209.\u00a0\n[5] S. Ul\u00a0et al., \u201cImage Synthesis in Multi-Contrast MRI with Conditional Generative Adversarial Networks,\u201d\u00a0IEEE Transactions on Medical Imaging, pp. 1\u20131, 2019.\u00a0\n[6] R. Mehta and T. Arbel, \u201cRS-Net: Regression-Segmentation 3D CNN for Synthesis of Full Resolution Missing Brain MRI in the Presence of Tumours,\u201d in\u00a0International Workshop on Simulation and Synthesis in Medical Imaging. Springer, 2018, pp. 119\u2013129.\u00a0\n[7] A. sharma., G.Hamarneh, \u201cMissing MRI Pulse Sequence Synthesis using Multi-Modal Generative Adversarial Network\u201d, IEEE Transactions on Medical Imaging, 2019.\n\u00a0[8] Milletari, F., Navab,N., Ahmadi,S.-A., 2016. V-net: Fully convolutional neural networks for volumetric medical image segmentation. In: 3D Vision (3DV), 2016 Fourth International Conference on. IEEE, pp. 565\u2013571.\u00a0\n[9] Seyed Sadegh Mohseni Salehi, Deniz Erdogmus, and Ali Gholipour. Tversky loss function for image segmentation using 3d fully convolutional deep networks. In International Workshop on Machine Learning in Medical Imaging, pp. 379\u2013387. Springer, 2017.\n[10] Carass, A., Roy, S., Jog, A., Cuzzocreo, J. L., Magrath, E., Gherman, A., But- ton, J., Nguyen, J., Prados, F., Sudre, C. H., et al., 2017. Longitudinal mul- tiple sclerosis lesion segmentation: Resource and challenge. NeuroImage 148, 77\u2013102.\u00a0\n"}