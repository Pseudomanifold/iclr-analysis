{"rating": "3: Weak Reject", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "The authors present a randomization defense in the black-box threat model, where bounded l_2 norm perturbations are allowed. In the presented scheme, the defender adds Gaussian noise to every coordinate of the output probability vector before returning an inference result. \n\n\nThe paper suffers from an incomplete evaluation, and therefore I cannot recommend acceptance. \n\n\nDetails:\n* Completeness of evaluation. As shown by Ilyas et al [1] and Cheng et al [2] and Brendel et al [3], black-box attacks can succeed even when only information about the label is present. Thus, I suspect that an attacker can simply run any of these attack algorithms in order to fool the model. In addition, if we use enough samples in the NES-based \u201cQuery-Limited\u201d algorithm of Ilyas et al (that is, with enough samples per step) then we should be able to perfectly mimic the white-box attack, which as shown in Figure 2 is effective. \n* Potential flaw in evaluation. BAND performs worse than QL on the undefended classifier in Table 1, which should not occur. I would check to make sure that the attacks are applied correctly here.\n* Lacking details in evaluation. I could not find how many samples are used to perform the attacks in Table 1. It is hard to evaluate the defense without knowing how many samples are used in each algorithm.\n\n\n[1] https://arxiv.org/abs/1804.08598\n[2] https://arxiv.org/abs/1807.04457\n[3] https://arxiv.org/abs/1712.04248\n"}