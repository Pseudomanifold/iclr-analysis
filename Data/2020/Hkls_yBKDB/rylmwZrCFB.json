{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "review_assessment:_thoroughness_in_paper_reading": "N/A", "title": "Official Blind Review #3", "review": "[Summary] \nThis paper addresses the problem of synthesizing programs (x86 assembly code) from input/output (I/O) pairs. To this end, the paper proposes a framework (AutoAssemblet) that first learns a policy network and a value network using imitation learning (IL) and reinforcement learning (RL) and then leverages Monte Carlo Tree Search (MCTS) to infer programs. The experiments show that AutoAssemblet can synthesize assembly programs from I/O pairs to some extent. Ablation studies suggest the proposed IL and RL guided search is effective.\n\nSignificance: are the results significant? 2/5\nNovelty: are the problems or approaches novel? 2/5\nEvaluation: are claims well-supported by theoretical analysis or experimental results? 4/5\nClarity: is the paper well-organized and clearly written? 4/5\n\n[Strengths]\n\n*clarity*\nThe overall writing is clear. The authors utilize figures well to illustrate the ideas. Figure 1 clearly shows the proposed pipeline as well as the MCTS process. In general, the notations and formulations are well-explained. \n\n*technical contribution*\n- Optimizing both the imitation learning loss and the reinforcement learning loss yields better performance when more tasks are available and tasks are more difficult.\n- Leveraging a learned policy network and value network for improving the efficiency of the MCTS seems effective.\n\n*ablation study*\nAblation studies are comprehensive. The proposed framework first optimizes two losses (IL and RL) and leverages the learned policy network and the value network for improving MCTS. The provided ablation studies help analyze the effectiveness of each of them.\n\n*experimental results*\n- All the descriptions of the experiments and the presentations of the results are fairly clear. \n- The results demonstrate the effectiveness of the proposed RL guided MCTS.\n\n[Weaknesses]\n\n*novelty*\nOverall, I do not find enough novelty from any aspects while the overall effort of this paper is appreciated. The reasons are as follows.\n- This  \"self-learning\" framework is not entirely novel since it has been proposed in [1], where the model is trained on a large number of programs that were randomly generated and tested on a real-world dataset (FlashFill). \n- The hybrid objective (IL+RL) has been explored in neural program synthesis [2] (a supervised learning model is fine-tuned using RL), learning robot manipulation [2], character control [4], etc.\n- Utilizing Monte Carlo Tree Search for program synthesis has been studied in many works. [5] proposes to treat the network outputs as proposals for a sequential Monte Carlo sampling scheme and [6] presents an RL guided Monte Carlo tree search framework. \n- Program synthesis on assembly languages: RISC-V [6], etc.\n\n*related work*\nThe descriptions of the related work are not comprehensive. While many neural synthesis works [1, 5, 7-10] have explored a wide range of settings for learning to perform program synthesis, they are not mentioned in the paper. I suggest the authors conduct a comprehensive survey on this line of works. \n\n*baselines*\nIn my opinion, the baselines (imitation, REINFORCE, MCTS) presented in the paper are far from comprehensive. I believe the following baselines should also be considered:\n- As the proposed model optimizes a combination of the IL loss and the RL loss, it would make sense to also evaluate a model optimizing this hybrid loss.\n- Search-based program synthesis baseline (i.e. learning guided search vs heuristic search)\n- Comparing the proposed framework against some neural induction baselines would confirm the importance and effectiveness of explicitly synthesizing programs instead of directly predicting the outcome/output. This has been shown in [1, 7].\n\n*testing set*\nThe testing sets are extremely small (with only 50, 40, 40 programs), which makes the results less convincing. Also, how those testing sets were created is not mentioned anywhere in the paper. It only states \"we designed a set of human-designed tasks\".\n\n*number of given I/O pairs*\nIt is not mentioned anywhere how the authors split the observed I/O pairs and the assessment I/O pairs such as what has been done in most of the works [1, 2, 7, 8]. While the observed I/O pairs are input to the program synthesis framework, the assessment I/O pairs are used to evaluate the synthesized programs. By doing so, the more observed I/O pairs are given, the more accurate the synthesized programs should be (assuming the model can find programs that fit the observed I/O pairs). \n- The discovery (Figure 2d) in this paper is contradictory to what is mentioned above: the program synthesis accuracy decreases when more I/O pairs are given. I am assuming the authors do not split observed I/O pairs and assessment I/O pairs.\n- With the setup where the observed I/O pairs are separated from the assessment I/O pairs, a larger number of K (the number of the observed I/O pairs) should be used so that it is more likely that the program for each task is unique and the evaluation would make more sense.\n\n[1] \"RobustFill: Neural Program Learning under Noisy I/O\" in ICML 2017\n[2] \"Leveraging Grammar and Reinforcement Learning for Neural Program Synthesis\" in ICLR 2018\n[3] \"Reinforcement and Imitation Learning for Diverse Visuomotor Skills\" in RSS 2018\n[4] \"DeepMimic: Example-Guided Deep Reinforcement Learning of Physics-Based Character Skills\" in SIGGRAPH 2018\n[5] \"Learning to Infer Graphics Programs from Hand-Drawn Images\" in NeurIPS 2018\n[6] \"Program Synthesis Through Reinforcement Learning Guided Tree Search\" arXiv 2018\n[7] \"Neural Program Synthesis from Diverse Demonstration Videos\" in ICML 2019\n[8] \"Execution-Guided Neural Program Synthesis\" in ICLR 2019\n[9] \"Learning to Describe Scenes with Programs\" in ICLR 2019\n[10] \"Learning to Infer and Execute 3D Shape Programs\" in ICLR 2019", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A"}