{"rating": "6: Weak Accept", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This paper proposed \"self-ensemble label filtering\" for learning with noisy labels where the label noise is instance-independent (in fact, the noise model is the class-conditional noise). Among the existing directions in this area, it falls into the sample selection direction, but it also takes semi-supervised learning based on the likely noisy data into account.\n\nNovelty: borderline. As other sample selection methods, the proposed one would like to identify the training data with correct labels. What's new is that the authors \"form running averages of predictions over the entire training dataset using the network output at different training epochs\" and show that \"these ensemble estimates yield more accurate identification of inconsistent predictions throughout training than the single estimates of the network at the most recent training epoch\". This is the major contribution of the paper. Furthermore, the data likely to have incorrect labels are not thrown away but used in a semi-supervised manner. This is a minor contribution, because semi-supervised learning is orthogonal to label-noise learning and everybody in this area knows the combination of them can work better in practice. Note that this is an academic/scientific paper, not an industrial product, so you don't need to combine all things that might work.\n\nSignificance: high. The proposed method significantly outperformed all baseline methods. However, it's not completely fair to compare a label-noise + semi-supervised method with other label-noise only methods... As a matter of fact, you don't need to apply perturbation consistency (or other semi-supervised) regularization after identifying the training data with incorrect labels. Semi-supervised regularization such as virtual adversarial training can even improve supervised learning.\n\nIssues: It's known under class-conditional noise model, the backward loss correction is the unique way to estimate the classification risk (or equivalently, the classification accuracy) given noisy validation data. So how can the validation (i.e., hyperparameter tuning) be performed for the proposed and baseline methods in Table 1 given noisy validation data? "}