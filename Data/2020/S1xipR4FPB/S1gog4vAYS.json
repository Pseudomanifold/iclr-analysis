{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "In this manuscript, authors adopt GAN for data augmentation to improve the performance of knowledge distillation. My concerns are as follows.\n1.\tThe novelty is limited. Using GAN for data augmentation is not new and authors only introduce it for KD, which didn\u2019t address the essential problem of KD itself.\n2.\tThe experiments are not sufficient. For DNNs, authors only compare the performance on CIFAR-10 with the conventional KD. More data sets and benchmark algorithms are helpful to illustrate the effectiveness of GAN data.\n"}