{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #4", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper extends previous work on using a hyperspherical energy function for regularizing neural networks, an apporach called minimum hyperspherical energy (MHE). The authors point out several problems with optimizing the original MHE objective in high dimensions and propose the compressive minium hyperspherical energy (CoMHE) to address these problems. The main idea is to project the network weights to a lower-dimensional space and then apply the original MHE approach to the projected weights. The paper proposes numerous different ways to perform these projections, where the two main variants are based on random projects and angle preserving projections. The paper provides a number of theoretical results, showing that these projections approximately preserve the angles between pairs of weight vectors. The paper has a comprehensive experimental section, where the authors empirically evaluate the different variants of CoMHE, and they compare CoMHE based models to state-of-the-art models on CIFAR-10/100 and ImageNet. Most considerable, with a plain 9-layer CNN they obtain close to a 2 percentage point improvement over ResNet-1001 on CIFAR-100.\n\nOn the positive side, the paper is well written and easy to follow. The paper both investigates the theoretical aspects of the proposed methodology and has comprehensives empirical evaluation. In particular, many of the reported results are comparable to the state-of-the-art, showing that this is effective regularization approach that gives good generalization.\n\nThe main shortcoming of the papers is that while it contains many new methodological contributions, the paper appears to be somewhat incremental work. Furthermore, while the experimental results are comprehensive, it appears that only for figure 1, multiple training-runs have been performed. When standard deviation over multiple runs is not reported, it makes it hard to draw conclusions from the reported results. For instance, are there any significant differences between the results reported in table 2, or does the table show that the methods are not sensitive to the dimension of the projection?\n\nGiven these shortcomings, I recommend a weak reject of the paper.\n\nTo clarify my understanding of the paper, I would like the authors to answer the following questions:\n\n(1) How can you conclude that your empirical results do not show any noticeable performance gain with using multiple projects for AP-CoMHE when you only report the result for one project in table 3?\n\n(2) In table 4, I do not understand why you did not increase t even further.  When do you start to see overfitting? Could the baseline archive the same performance as the other models with a larger t?\n\n(3) On the top of page 2, you write \"Third, when the number of neurons is smaller than the dimension of the space (it is often the case in neural networks), MHE defines an ill-posed problem because the neurons can not even fully occupy the space.\" I do not understand which \"space\" you refer to here. Could you please clarify this?"}