{"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper applies the three-head neural network architecture as well as the corresponding training loss proposed in (Gao et al., 2018b) to alphazero style learning of the Hex game. The paper is mainly an empirical study, and shows that the architecture leads to faster and better learning results for Hex. The evaluation is done on two datasets, one with examples from near-optimal players produced by MoHex 2.0, and the other from randomly sampled but perfectly labelled examples generated by benzene. Performance improvement is evaluated from several different perspectives, including state-value errors, action-value errors and policy prediction accuracies. Finally, the match performance is also reported for competing with MoHex 2.0, one of the state-of-the-art agent for Hex.\n\nGenerally speaking, the paper does a good job in introducing and analyzing the structure of the alphazero learning scheme and the related alphago and alphago zero schemes, and the experiments within the scope of Hex is relatively thorough and the performance improvement is consistent and convincing. \n\nHowever, the description of the three-head neural network in Section 3 is too brief, and without looking at the original paper (Gao et al., 2018b), it is quite hard to understand the motivation of the objectives (especially the definitions and explanations of R1, R2 and R3). \n\nAdditionally, the challenge of applying three-head neural network architecture in the alphazero learning setting is almost not mentioned. In particular, what are the modifications needed compared to the original work (Gao et al., 2018b)? The authors may want to explain clearly how the training scheme is different, and clearly state what the detailed neural network architecture (at least in the appendix) used is, and how they are different from the original alphazero paper and (Gao et al., 2018b). Without these explanations, the significance of the paper would be largely limited to coding and engineering efforts (which are also valuable but not that much in the research sense).\n\nAnother related issue of this paper is that it is not clear (at least to me, who know little about the Hex game) how difficult it is to tackle Hex (compared to Go, Shogi and chess, etc.). The authors may want to elaborate more on this as well to further showcase the significance of the work.\n\nFinally, there are also some inconsistency in the hyper-parameter choices and architecture design. In particular, it is not clear why the authors choose the expansion threshold to 0 in the match performance part, whereas the authors use threshold 10 elsewhere. The turning on and off of the data augmentation in 3HNN in different experiments mentioned in the appendix are also not well explained. \n\nNevertheless, I still value the paper's effort and success in applying a newly proposed approach for a relatively challenging real-world game problem, despite the issues about experimental design and writing mentioned above.\n\nSome minor suggestions: the title of the rightmost plots should better be \"perfectly labelled examples\" instead of \"perfect examples\", and the authors may want to make it clearer which plot corresponds to dataset T1 and which corresponds to T2."}