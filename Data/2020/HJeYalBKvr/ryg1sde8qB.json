{"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "I think the paper needs a deep review in the English part. For example, in the abstract, they repeat \"In this paper\" a couple of time and it is complicated to understand the introduction and methodology. Also, I think the paper needs a better structure. The related work should be first in order to understand the relevance of this paper. \n\nFrom the experiment point of view, it is necessary a better explanation about the hyperparameters or the experiments which were carried out. In addition, the single database was used to evaluate the technology which is not enough to show the big different respect to the transformed paper. Also, the comparison is not really fair. In each \"layer\" of the proposed phrase transformer, it has actually two self-attention layers, but the baseline has only one self-attention layer. In addition more methodologies should be necessary to compare the results of the experiment. \n\nThe architecture part is complicated to follow and I don't understand the big contribution of this paper. \n\nFor that reason, I recommend a reject the paper and work more for the final version "}