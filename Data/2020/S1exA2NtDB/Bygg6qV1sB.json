{"experience_assessment": "I have read many papers in this area.", "rating": "8: Accept", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "title": "Official Blind Review #4", "review": "The authors propose a new method for model agnostic meta learning (MAML) based on evolution strategies (ES) rather than policy gradients (PG). The proposed method has clear advantages over prior work: it is conceptually much simpler, simpler to implement and is a zero-order method (while PG-MAML requires 2nd order derivatives and differentiation through the update steps).  Also, the method natively allows to incorporate methods from evolution strategies, e.g., to improve exploration. Empirical results are convincing: ES-MAML consistently outperforms PG-MAML (or is at least not worse) on various tasks. Also, ES-MAML seems to be much more robust compared to PG-MAML, which is known to be brittle. The paper is well motivated and well written. The mathematical formalism is precise.\n\n\nComment/questions:\n\n- PG-MAML is known to be very sensitive w.r.t. hyperparameters, is this also the case for ES-MAML? How were good hyperparameters found for ES-MAML?\n- While this work focuses on RL, it would be interesint to see if ES-MAML is also advantages over vanilla MAML for common few-shot learning image classification problems.\n- What\u2019s the efficiency of ES-MAML compared to PG-MAML in terms of wall-clock time?\n- (minor:) multiple times in the paper, \\citep{} and \\citept{} are used incorrectly.\n\n", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}