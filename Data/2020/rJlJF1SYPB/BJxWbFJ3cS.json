{"rating": "3: Weak Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "N/A", "title": "Official Blind Review #5", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This paper theoretically shows that data manifolds can be approximated by neural-network-based generative models including GANs. In particular, they prove that under mild assumptions neural networks can map a given latent space $M_z$ onto a set $M_theta$ which is close to the given data manifold $M$ within a small Hausdorff distance. There results hold for the case of both single data manifold (i.e. data generated from a single class) and multiple data manifolds (i.e. data generated from multiple classes). In the latter, they need to allow insignificant parts of the latent space to be mapped onto thin \u201ctunnels\u201d connecting the manifolds. The construction of the mapping from the latent space onto the data manifold provided in their proofs is only for shallow networks. Section 6 of the paper - Invariance Property of Deep Expanding Networks - characterizes the property of the manifold $M_theta$ computed by deep neural networks that expanding the dimensionality of the input. In particular, they show that $M_theta$ is a smooth embedded manifold and it is diffeomorphic to the latent manifold $M_z$, which shows that neural networks cannot significantly transform the latent space. The paper also extends the results for the geometric universality of generative models to cycle generative models including the CycleGANs or Pix2Pix architectures. In particular, they show that under mild conditions, there exists a pair of neural networks that can approximately map back and forth between two given data manifolds.\n\nPotentially, this paper could be an interesting contribution. However, some points in the theory need to be verified, and at least toy experiments should be provided to validate their theoretical claims. Furthermore, Section 6 - Invariance Property of Deep Expanding Networks - does not seem related to the main story of the paper and should be a separate paper itself. I weakly reject this paper, but given these clarifications in an author response, I would be willing to increase the score. \n\nMain arguments and questions:\n\n1. Theorem 5.1 and 5.2 - Geometric Universality of Generative Models for signal class and multiclass case - seem to be straight-forward applications of Lemma 5.1 and Theorem 4.2. Lemma 5.1 is a special case of the Brown\u2019s mapping theorem and Theorem 4.2 is the well-known theorem on the universal approximation power of neural networks. I, therefore, question the significance of  Theorem 5.1 and 5.2.\n\n2. Since this is clearly a theory paper, lack of experiments can be tolerated. However, the paper does not provide even a single toy simulation result to at least shed light on their theoretical claims. For example, the results from Theorem 6.1 which show that neural networks cannot significantly transform the latent space can be empirically justified.\n\n3. Will the results in Section 5 and 7 hold for Convolutional Neural Networks, or only for Fully Connected Networks? \n\n4. Theorem 6.1 shows that the manifold $M_theta$ computed by a neural network is diffeomorphic to the latent manifold $M_z$. However, the mappings by deep generative models like GANs, in most cases, are not invertible. It would be great if the authors can elaborate this point more. Otherwise, the results in Theorem 6.1 are questionable. \n\n5. The paper admits that according to theorem 6.1, \u201cit is impossible to approximate an arbitrary data manifold with latent space being R^{d}\u201d, but in practice, deep generative models like GANs can generate good-looking images. As mentioned in the paper, a precise theorem for this case is not provided. The authors, however, say they \u201chypothesize that it may be possible to approximate an arbitrary compact data manifold using expanding networks up to a subset of arbitrary small measure, and thus limitations imposed by Theorem 6.1 are negligible in practice.\u201d. However, I didn\u2019t see how this hypothesis is related to the results and discussion in Section 7. It would be great if the authors can provide more explanation for this hypothesis and its connection to the results in Section 7.\n\n6. Geometric universality does not guarantee that a good approximation to data manifolds can be found after training the generative model. The optimization, especially the objective losses used to train the model, plays an important role in understanding the manifold $M_theta$ represented by the trained model. As a result, I am not quite sure about the significance of this paper and would appreciate if the authors can discuss the relevance of their results.\n\nThings to improve the paper that did not impact the score:\n\n1. The paper should define what fully connected neural networks are.\n\n2. Some notations in the paper need to be defined such as the \u2243 in Theorem 6.1.\n\n3. More discussion on exponential map and the intuitions behind it should be provided.\n\nMinor comments:\n\nThere are some typos in the paper such as \u201ccontinuos\u201d in page 4, \u201can embedding is the following\u201d in Definition 6.1, \u201cmay possible\u201d in page 7, and \u201cis two train two neural networks\u201d in page 7."}