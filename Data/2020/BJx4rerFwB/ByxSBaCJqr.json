{"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "\nSummary:\nThis paper proposes a method for aligning an input text with the frames in a video that correspond to what the text describes in a weakly supervised way. The authors propose a combination of a \u201cFrame-By-Word\u201d (FBW) representation and a Word-Conditioned Visual Graph (WCVG). The proposed method outperforms the weakly supervised baseline presented in the paper in experiments by a large margin. In addition, it quantitatively performs close to previous strongly supervised methods.\n\n\nPros:\n+ New Word-Conditioned Visual Graph representation\n+ Outperforms weakly supervised baseline\n+ Ablation study of the moving parts\n+ Interesting use of positional embeddings for multi-modal learning\n\nWeaknesses / comments:\n- What is the processing speed of the method compared to the baseline?\nThe proposed method makes multiple comparisons while computing the attention weights over all words and frames. Does this cause the method to be slower than the baseline? If so, how much slower is it?\nAnswers to these questions can help readers to keep in mind the trade-off of the proposed method for achieving the accuracy presented in the paper.\n\n\n- Number of parameters comparison with baseline:\nDid the authors make sure to have similar number of model parameters for the baselines and the proposed method? Maybe I missed it, but I couldn\u2019t see a mention of this anywhere. It would be useful to state this so that readers are sure that it\u2019s not the number of parameters that is helping the method.\n\n\n- Assumption that sentences are only associated with its ground truth video:\nThe authors mention that they have the same assumption as Mithun et al., 2019. Can this assumption be detrimental if the dataset does not follow it? Say there are sentences in the dataset that could describe segments in multiple videos. Could this assumption lead to suboptimal representation learning / relationship learning for words / video frames?\n\n- Determining the size of the sliding window:\nFrom reading the paper, it looks like the sliding window used for computing the word / frame relationships has to be manually defined. This seems a bit suboptimal for the generalizability of this method. Do the authors have any comments on this?\n\n- Can this model be supervised? If so, how does it compare to the supervised baselines?\nThe authors point out that their weakly supervised method performs close to the strongly supervised previously proposed. This is a nice finding, however, have the authors try to answer the question of what would happen if the proposed model is supervised? Will the proposed model outperform the strongly supervised baselines? Or at least perform the same?\n\nConclusion:\nIn conclusion, the proposed method makes sense and it has been shown to empirically outperforms a previous weakly supervised baseline. The authors also provide an ablation study of the moving parts to show that the entire pipeline is important to achieve the highest performance in the hardest setting. It would be nice if the authors successfully answer / address the questions / concerns mentioned above in the rebuttal."}