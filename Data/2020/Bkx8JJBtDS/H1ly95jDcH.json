{"rating": "3: Weak Reject", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper suggests a measure for predicting the performance of deep networks by counting number of paths. Authors further evaluate this measure empirically and show that it is predictive of generalization.\n\nFinding a measure that predicts generalizability for a given architecture is very interesting and potentially impactful since it can be used to make design choices.\n\nOverall, I enjoyed reading this paper but I have some concerns and I hope authors can address them:\n\n1- Definition: I think the definition make sense for layered fully connected networks but it seems like the way authors extend it to convent is not elegant. In particular, we know that convnets generalize even without weight sharing in which case they can be presented as a simple feedforward network. Is it possible to generalize the definition to any feedforward network presented with a directed acyclic graph (including convnets)? Another reason that this definition for convnets bothers me is that we often observe that the number of channels increases after pooling which connects #channels in each layer to the size of the image in the layer. But this definition completely ignores size of the image in the layers. Another issue is that at least in the main text, the definition is provided for a layered networks and it is not obvious to me that how it can be extended to densenet and resnet.\n\n2- Experiments: Authors provide many experiments to support their claim which is great but they avoid the most direct way to evaluate the measure. I think the best way to evaluate the measure is to train many networks (layer fully connected to layered convnets) with different number of neurons and plot generalization vs #paths. This would be a very convincing experiments. Many experiments provided here do not directly evaluate the measure in a convincing way.\n\n\nI hope authors address above concerns in which case I will increase my score."}