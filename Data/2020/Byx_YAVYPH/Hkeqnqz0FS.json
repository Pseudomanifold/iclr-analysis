{"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "N/A", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "1. Summary\n\nThe authors introduce a simulator (JBW) with the goal of supporting continual learning. They demonstrate that RL agents struggle with a lot of the tasks in JBW. The majority of the paper describes the technical details of JBW, and show that RL agents can struggle to solve continually changing tasks in JBW.\n\n2. Decision (accept or reject) with one or two key reasons for this choice.\n\nI'm borderline. It is valuable to have environments that support continual learning, although the experimental investigation into different forms of non-stationarity would be more informative. \n\nRe new implementations: the continual learning setting is certainly important and interesting, but existing environments (see BabyAI, https://arxiv.org/abs/1810.08272 (focus on NLP)) do feature multiple tasks and it is not hard to augment these to run `forever'."}