{"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "Jelly Bean World: A Testbed for Never-Ending Learning\nThis work introduces a domain for evaluating and experimenting with algorithms for never-ending learning. These are variants of grid worlds which have multi-task, multi-modal, dynamic settings and can lead to interesting learning challenges. \n\nI\u2019m referring to never-ending learning as NEL throughout. \n\nIntroduction\nComment: It\u2019s good to tell the reader as early as possible why never ending learning is different than multi-task or continual or lifelong learning? Those are more commonly used terms in the community so it should be situated properly. All of this stuff about NEL seems very similar to continual learning/lifelong learning and we should really reference it and describe the difference?\n\nI didn\u2019t find \u201cIn order to more formally describe general intelligence, we posit that there is an underlying measure of complexity of the environment E such that: (i) highly specialized and non-general learning algorithms can perform well in environments with low complexity, but (ii) environments with high complexity require successful learning agents to possess more general learning capabilities\u201d to provide much clarity. Can we either remove it or stick to the later formalism?\n\nIn never-ending learning, we explicitly disallow the learning agent\u03c0from learning across multiple episodes or in multiple environments, which is closer to humanlearning. -> Is this just the same as saying you\u2019re reset free and in a single environment? This sentence is a bit confusing. \n\nOne potential criticism of using simplified simulated worlds like JBW is why should we believe that insights that we get from JBW would carry over to the real world natural environments that NEL ideally cares about. Why is this actually representative of the real world? Because that is really what we care about with NEL. There is merit to simulation in this setting but only if we believe that either insights, algorithms or policies also hold in the real world and we can representatively model the worlds complexity. Can we verify this somehow? \n\nDesign\nDoes the user have control over all the agents? Or how are they programmed\n\nI would move the details of procedural generation to the appendix, they\u2019re a bit distracting from the point. \n\nI would also tell the readers why things like scent, intensity, interaction etc are important early on, otherwise it\u2019s confusing what their purpose is. \n\nIn general I quite like the setup, it seems like it has the sufficient amount of complexity in modality, interaction and multi-agent systems to be useful. I wonder if it\u2019s also useful to introduce autonomous self-powered agents which move on their own in the environment and introduce dynamic non stationarities. \n\nA little more description of the multi-agent, multi-task, curriculum stuff would be useful in the design section. \n\nThe reward functions are all sparse? Or do they need guidance to get to objects as well?\n\nI\u2019m still a bit confused about the interactions functions. Could those be described a bit further?\n\nPerhaps a practical question is how does this relate to the work described in the BabyAI/Minigrid stuff from MILA and other simulated gridworld style environments with multiple agents and such. \n\nExperiments: \nIn the case studies, are things multi-agent?\nI wonder if in the reset-free experiment, if we just use dynamic agents in a multi-agent setup, would this just work?\n\nIs it a little odd that the without occlusion performance comes back down to around the same as with occlusions?\n\nIs the scent just perhaps misconfigured/too hard to learn from coz it never seems like it\u2019s doing well with scent?\n\nOverall, I like the paper and the introduced environment. I think it\u2019s important to study scenarios such as the ones described here and this provides a tractable way to start. I am however concerned that the environments are too simplistics and perhaps too far from the real world for the insights to carry over to more realistic scenarios. Some suggestions would be to try and make the environment a bit more realistic and less toy so that insights might also more easily transfer to real world scenarios. But I think with some of the clarifications above and a bit more description, this would be a valuable contribution on topics which are not thought about enough in RL. I also think that actual visuals and videos on an actually accessible website would make it easier for the reviewers/readers to understand the importance of this. I'm currently listing it as a weak accept but I would like the authors to better clarify some of the points mentioned above, discuss how realistic the setting is and also provide us with videos of the environment to better gauge things. "}