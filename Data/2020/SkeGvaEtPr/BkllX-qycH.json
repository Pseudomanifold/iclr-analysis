{"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "This paper presents Neural Markov Logic Networks  (NMLN), which is a generalization of Markov Logic Networks (MLN). Unlike MLN which relies on pre-specified first-order logic (FOL) rules, NMLN learns potential functions parameterized by neural networks on fragments of the graph. The potential function can possibly take into account the constants present using embeddings to better solve transductive problems\uff08otherwise the potential can only use relational structure). To make computation tractable, the size of local potential functions is constrained. Training of this MRF is performed by solving a min-max entropy problem: conditioned on an informative potential, the uncertainties shall be decreased. Experiments on a knowledge base completion task and a graph generation task show superior performance compared to baselines like neural theorem provers.\n\nPros:\n1. no need to specify FOL rules and can potentially discover subtle relations not evident to us.\n2. can be used for generation since the learned rules might be more fine-grained than what we can specify.\n3. it's interesting that on nations knowledge base completion problem even without constant embeddings it works fine, which shows the power of just using relational structure.\n\nCons:\n1. the computation complexity of the global potential function grows combinatorally with the clique size k and polynomially with graph size n, which is unrealistic to any larger graphs than the small molecules, if any higher order statistics matters (e.g. in molecules there are rings).\n\nQuestions:\n1. for training can we use MLE?\n\nOverall this is an interesting work. I think it is a natural generalization of Markov Logic Networks and works on two small problems. I am inclined to recommend this paper to the community."}