{"rating": "1: Reject", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "N/A", "title": "Official Blind Review #4", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper claims that convolutional filters in CNNs are not the result of fitting to the input data distribution but they are the optimal solution to a spectral decomposition of the convolutional operator. \n\nPositive things about this work:\n1) it is clearly written\n2) the fact that Gabor wavelets are the eigenfunctions of convolution is sound.\n3) it provides good food for thought about what needs to be learned and what comes from the pre- specified choice of architecture\n\nNegative things about this work:\n1) it misses references to relevant works. In particular, there is an article making essentially the same points:\nJoan Bruna, Soumith Chintala, Yann LeCun, Serkan Piantino, Arthur Szlam, and Mark Tygert, \"A mathematical motivation for complex-valued convolutional networks,\" Neural Computation, 28 (5): 815-825, 2016\nhttp://tygert.com/ccnet.pdf\nwhere these authors make the same conclusions and observe that learning reduces to figuring out the  windowing, number of scales, etc. but not the type of filters.\nThis prior work greatly reduces the impact of this contribution, unfortunately.\nThere are other references that are missing, but these are minor points compared to the above. For instance, I'd recommend to cite Hubel & Wiesel's seminal work on mapping the mammalian receptive fields, and older work by M. Lewicki about analyzing learned receptive fields by sparse coding algorithms, similarly to the cited B. Olshausen et al.  \n2) The Authors show that Gabor wavelets are eigenfunction of convolutions and they stop here to conclude that filters in CNNs are the way they are because of the architecture, but how about the effect of the non-linearities, depth and the type of cost used for training? The work is unfinished without a thorough analysis and discussion of these crucial aspects."}