{"rating": "8: Accept", "experience_assessment": "I do not know much about this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review": "This paper proposes an algorithm for explaining the move of the agents trained by reinforcement learning (RL) by generating a saliency map.\nThe authors proposed two desired properties for the saliency map, specificity and relevance.\nThe authors then pointed out that prior studies failed to capture one of the two properties.\nTo combine the two components into a single saliency map, the authors proposed using the harmonic mean.\n\nThe experimental results demonstrated that the proposed saliency map successfully focused only on important parts while the other method tend to highlight some irrelevant parts also.\nThe authors also did a great job for evaluating the goodness of the saliency maps, by preparing a human annotated chess puzzle dataset.\n\nI think the paper is well-written, and the basic idea look reasonable and promising.\nThe experimental evaluations are well designed and the results look convincing.\nSaliency map for RL is not yet mature, and I expect to see further improvements (especially, more theoretically principled ones) follow this study."}