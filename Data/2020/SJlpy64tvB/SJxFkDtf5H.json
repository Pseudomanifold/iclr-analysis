{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "General:\nThe paper first proposes an adversarial attack on the exemplar-based continual learning algorithm, A-GEM. The problem formulation is new and interesting, but I am not sure how practical or realistic the setting is. The attacker assumes to have access not only to the model but also to the episodic memory. I think that is quite a powerful assumption for the attacker and it is not very surprising that the attack would work. So, I am a bit torn with the judgments. \n\nSummary & Pro:\n1. First proposal of adversarial attack of continual learning algorithm. \n2. The conventional attack schemes are shown to not work well, and they devised new one (GREV) tailored for A-GEM. \n3. Experimental results show convincing results that their method works well. \n\nCon & Questions: \n1. It is not clear whether the proposed method will also work well for other exemplar-based methods like iCaRL or GEM (the simpler version than A-GEM), etc. I get that A-GEM can be attacked by their assumption and method, but how general is it?\n2. What exactly is the practical scenario of this method? How can the attacker get access to the model & memory? In the traditional adversarial attack literature, it is shown that white-box attack can also lead to the black-box attack. But, in this case, I am not sure about the practical implication of the proposed methods. \n3. It seems like the entire memory is under attack. What happens when only the memory is partially attacked, e.g., 10% of the data in the memory is attacked? \n4. Table 1/2 only shows the overall average accuracy. Can you also show the per-task average accuracy curves? It would be much better to see such curves to clearly see the effect of the attack rather than the overall average. \n"}