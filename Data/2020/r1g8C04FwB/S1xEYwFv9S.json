{"rating": "1: Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #4", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "Paper Summary:\n\nThis paper proposes an algorithm to generate synthetic handwriting data in order to train a handwriting recognition system in context where in domain training data is insufficient. The proposed algorithm relies on fitting splines on words rendered with handwriting like fonts. Such split allows to apply a motor model to generate variations of the word. The proposed method is compared with other methods of generating artificial training data on three datasets.\n\nReview Summary:\n\nThis paper is not making sufficient contribution in the domain of machine learning, learning representation and their applications as delineated by the conference call for paper. The main contributions are twofold: a dataset of handwritten fonts and a spline fitting algorithm that involves no machine learning. I would strongly advise the authors to consider an alternative venue for this contribution, e.g. International Conference on Document Analysis and Recognition ICDAR.\n\nDetailed Review:\n\nThe abstract and intro could state your objective more clearly: you should state that your objective is to create synthetic handwriting training data to improve a recognition system (i.e. generation is not the end goal). Abstract and introduction could be clearer if you used standard terminology (data augmentation and synthetic training data generation). \n\nThe experiments do not allow to assess the value of the system compared to simple baselines relying on the same data. One could consider training a model simply on the images of the words (i) generated with your font dataset, (ii) on distorted version of these images with simple distortion as discussed in paragraph 2 of Section 1. Also, no ablation allow to assess the impact of your different choices: could you report results varying the number of fonts, varying the number of training words? Same questions for the RNN systems, could improvement be obtained by simply generating more data from the RNN system?\n\nThe authors should cite more prior work on recovering pen trajectories from image of handwritten text alone (e.g. see below), and compare to such approaches. \n\nFinally, I am surprised about the experimental setup. The author compares with Graves RNN which is trained on recorded pen trajectories (online data). If such data is available, one can train a supervised model to map an image to the corresponding trajectory. One could even devise a forced decoding approach using Graves system to infer motor program from images, this would be a strong alternative to the proposed spline inference algorithm.\n\nMisc:\n\n- please define all acronyms (e.g. GAN, BPL, RNN...)\n- this document has been converted from a submission to a venue with a different style file which caused all the citations to wrongly mention the author name twice, please correct this. Proof reading a version of the submitted PDF could have prevented this.\n- on open sourcing your font dataset, even if you cannot redistribute the font themselves, you could consider distributing a list of their urls.\n\nReferences\n\nExtracting motion primitives from natural handwriting data\nBH Williams, M Toussaint, AJ Storkey - 2006\n\nInferring motor programs from images of handwritten digits\nV Nair, GE Hinton - NIPS 2006\n\nPervouchine, Vladimir, Graham Leedham, and Konstantin Melikhov. \"Three-stage handwriting stroke extraction method with hidden loop recovery.\" Eighth International Conference on Document Analysis and Recognition (ICDAR'05). IEEE, 2005.\n"}