{"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The authors propose a self-attention mechanism for rotation-equivariant neural nets. They show that introduction of this attention mechanisms improves classification performance over regular rotation-equivariant nets on a fully rotational dataset (rotated MNIST) and a regular non-rotational dataset (CIFAR-10).\n\nStrengths:\n+ States a clear hypothesis that is well motivated by Figs. 1 & 2\n+ Appears to accomplish what it claims as contributions\n+ Demonstrates a rotation-equivariant attention mechanism\n+ Shows that its introduction improves performance on some tasks\n\nWeaknesses:\n- Unclear how the proposed attention mechanism accomplishes the goal outlined in Fig. 2d\n- Performance of the authors' evaluations of the baselines is lower than reported in the original papers, casting some doubt on the performance evaluation\n- The notation is somewhat confusing and cumbersome, making it hard to understand what exactly the authors are doing\n- No visualisation or insights into the attention mechanism are provided\n\nThere are three main issues detailed below that I'd like to see addressed in the authors' response and/or a revised version of the paper. If the authors can address these concerns, I am willing to increase my score.\n\n1. The motivation for the attention mechanism (as discussed in the introduction and illustrated in Fig. 2) seems to be to find patterns of features which commonly get activated together (or often co-occur in the training set). However, according to Eq. (9), attention is applied separately to orientations of the same feature ($A_i$ is indexed by i, the channel dimension), and not across different features. Since the attention is applied at each spatial location separately, such mechanism only allows to detect patterns of relative orientations of the same feature appearing at the same spatial location. The motivation and utility of such formulation is unclear, as it appears to be unable to solve the toy problem laid out in Fig. 2. Please clarify how the proposed mechanism would solve the toy example in Fig. 2.\n\n2. The only real argument that the proposed mechanism is useful are the numbers in Table 1. However, the experimental results for CIFAR-10 are hard to compare to the baselines because of differences in reported and reproduced results. I would appreciate a clarification about the code used (was it published by the authors of other papers?) and discussion of why the relative improvement achieved by the proposed method is not an artefact of implementation or optimisation issues. \n\n3. The exposition and notation in section 3.1 is very hard to follow and requires substantial improvement. For instance, the sections \"Attention and self attention\" and \"Compact local self attention\" seem to abstract from the specific case and use x and y, but it is unclear to me what x and y map to specifically. Maybe also provide a visualization of how exactly attention is applied.\n\n\nMinor comments/questions:\n\n- If the attention is applied over the orientations of the same feature, why does it improve the performance on Rotated MNIST (which is rotation invariant)?\n\n- I assume the attention matrix $A_i$ is different for each layer, because the features in different layers are different and require different attention mechanisms. However, unlike F and K, A is not indexed by layer l.\n\n- It would be good to provide the standard deviation for the reported results on CIFAR-10 to see if the improvement is significant."}