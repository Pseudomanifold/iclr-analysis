{"experience_assessment": "I have published in this field for several years.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "Summary of the paper:\nThis paper proposes a method for feature augmentation, whose aim is to prevent overfitting and improve generalization.\nThe feature augmentation is done using the last feature vector of the CNN, which is the input to the fully connected layer. The method applies noise to the weights of the fully connected layer that contributes the most to the output.\nIt presents results on two datasets: SVHN and CIFAR-10.\n\nDecision: Reject\n\nArguments for the decision:\nThe paper is missing references to some important recent works in the field of semi-supervised learning. \nFor example, the following papers present results on the same datasets, and could be compared with: Label Propagation for Deep Semi-supervised Learning, Iscen et al., CVPR 2019; Tangent-Normal Adversarial Regularization for Semi-supervised Learning, Yu et al., CVPR 2019; Mutual Learning of Complementary Networks via Residual Correction for Improving Semi-Supervised Classification, Wu et al., CVPR 2019; \n\nMore importantly, in [Realistic Evaluation of Deep Semi-Supervised Learning Algorithms, A. Oliver et al. (NeurIPS 2018)], the authors raise a lot of questions on the current state of the art of the field and present a testbed to address the issues. These issues are related to the application of semi-supervised methods to realistic scenarios and could be taken into account in the next top-level publications in the field.\n\nIn addition, the method is not introduced to the reader in the most clear way.\nFor example, in the introduction, the authors talk about \u201cstable targets\u201d, but have never talked about \u201ctargets\u201d before. The objective function is not discussed conveniently, for example, the loss noise consistency is not well motivated. The ablation study should also assess the contribution of the different losses. \n\nRegarding the experiments, besides the lack of comparison to SOTA results, and comments on important questions raised by Oliver et al., there are important details missing, especially in the semi-supervised field. For example, how is the validation set built, and how are the optimal hyperparameters found?\n\nQuestions to authors:\nAt some point, the authors write \u201cAugmentation in the latent space is suitable for regularization as it can produce new data point that is more plausible and comprehensive.\u201d Why is it so? What means \u201cplausible and comprehensive\u201d in this sentence?\n\n\nAdditional feedback related to things that did not impact the score, typos, etc:\nOn abstract, typo: Filp - flip\nThe figure could use the same symbols used in the algorithm, so to facilitate the reading of both.\n\nOverall, I would recommend the authors to follow the recommendations of Oliver et al., mentioned above, in order to improve the paper and be in line with state-of-the-art works."}