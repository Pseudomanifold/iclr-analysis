{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper describes a new approach for semi-supervised learning, in which uniform noise is added to the last layer of a DNN, scaled according to the magnitude of the entries/features of this layer; this is phrased as 'data augmentation at the feature level'.  Several other loss terms are also used---a parallel ensembling step, a \"consistency\" loss term, and a \"noise consistency\" loss term.  The result is a semi-supervised algorithm that is empirically compared with several other recent state-of-the-art semi-supervised algorithms, and outperforms them on most benchmarks.\n\nThis paper achieves slightly better performances on some state-of-the-art baselines; but the overall presentation and writing of the paper is very confusing, and more importantly, it is very unclear to the reader (a) what exactly is done, (b) why, and (c) which parts are actually important.\n\nTo start, the paper motivates the idea in ways that largely ignore a lot of prior work- for example, ignoring past work that has applied feature-level data augmentation or noising, attributing the idea of adding noise to prevent overfitting (a very old one) to Goodfellow 2016, etc.  Overall, the idea of 'feature-level data augmentation' is not novel, though the particular approach used here may indeed be unique (it is slightly unclear).\n\nMore importantly: the actual approach used is unclear due to inconsistent and incomplete terminology and explanations.  For example, g is defined as the augmentation function, but then elsewhere \"Aug(g(...))\" is written; confusing set notation is used; etc.  More importantly, in Sec. 2.1, the feature augmentation & ensembling are introduced (again, both of which have been done before), but then several more terms are introduced in 2.2 and it is unclear what they are motivated by.  For example:\n- L_consistency is presented as the MSE of the sum of the summed feature vectors of the labeled and unlabeled datasets- what is this motivated by?  And surely it is at least normalized given different dataset sizes?\n\nMore importantly than somewhat unclear presentation, is the fact that there is no ablation study done to reveal exactly what each component contributes.  Which ones are actually necessary?  Since many of these individual terms have already been proposed, which one / what aspect of them are actually causing the results to be better?  Without this kind of analysis, it's hard to take any kind of conclusions away from the paper or understand the results.  In this case, the paper must be accepted purely because it beats some SOTA results, which seems hard to do."}