{"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "This paper proposes bounding the Wasserstein term in WGAN with an aim to stabilize training. The basic framework of the proposal, termed WBGAN, is presented in Section 3.1, and an instantiation using the Sinkhorn distance is described in Section 3.2.\n\nThe proposal is demonstrated to empirically improve stability over the baselines in the mid-resolution experiments presented in Section 4.2. On the other hand, in the high-resolution experiments in Section 4.3, the authors suggest that WBGAN with Sinkhorn does not scale well, and show some results with the bound determined on the basis of a separate run to investigate the converged value of the Wasserstein term, which is impractical. Moreover, the empirical performance seems comparable to the baselines in Figure 7. Because of these I would judge the contribution of this paper not strong, so that I would recommend weak acceptance.\n\nIn page 3, lines 20-21, the authors argue \"a possible reason,\" which I do not understand. Take WGAN as an example. With weight clipping taking place over the whole training process, the Lipschitz constraint should automatically be satisfied even in the initial training phase, which would invalidate the authors' argument here.\n\nIn Section 3.2.1, I do not understand why the authors assume that the relevant distributions are in P_p(X) without specifying the value of p. Is it meant to be P_1(X)?\n\nIn Appendix A, I do not understand the sentence \"Suppose \\hat{\\mathbb{P}}_{g_i} are the independent empirical measures drawn from \\hat{\\mathbb{P}}_g.\" It says as if samples from \\hat{\\mathbb{P}}_g were measures, but they are actually values in X.\n\nThose figures showing the FID (Figures 1, 2, 5, and 7) are drawn versus the \"epochs\", whereas those showing the Wasserstein terms (Figure 4) and the generator loss (Figure 5) are drawn versus the iterations, which makes comparison between them impossible.\n\nPage 1, line 43: which improve(s) the stability\nPage 2, equation (3): Here a vector \\Gamma 1_N is equated with an empirical distribution \\hat{\\mathbb{P}}, which does not make sense.\nPage 2, line 40: where 1_N is a(n) N-dimensional\nPage 3, line 8: Each \\alpha corresponds (to) a \\lambda\nPage 3, line 21: As shown in Fig. (2->1)\nPage 3, line 27: W should be italicized.\nPage 3, line 42: Si(n)khorn distance\nPage 6, caption of Figure 2: both each counterpart -> each of both counterparts\nPage 6, line 1: discriminator -> critic\nPage 6, line 24: both WGAN-div and WGAN-GPReal fail(s) to converge\n"}