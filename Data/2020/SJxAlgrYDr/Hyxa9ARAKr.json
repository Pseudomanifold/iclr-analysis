{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "Review of \u201cCity Metro Network Expansion with Reinforcement Learning\u201d\n\nIn this work, they investigate the use of RL (actor-critic) for planning the expansion of a metro subway network in a City. They formulate the problem of expanding the metro system as sequence of actions, hence a seq2seq+attn type architecture is used for the actor. The reward calculation is based on a combination of origin-to-destination and social equity metrics. They apply their method to plan the expansion of the current metro lines in a large city in China where they can leverage the mobility information information gathered from ~ 25M mobile phones in the city.\n\nI think this work has great potential, as they identify a data-driven approach that can have a high impact (i.e. design subway lines affecting 25M+ people in a real city). That being said, there are some issues that I feel needs to be addressed before the work can be published at a high quality conference, so I want to help the authors improve the work by highlighting important points that will make the work better:\n\nThe related work section on metro network design is only a paragraph. I think both the related work and experiments sections are missing many substantial contributions, as there is vast literature of work from Operations Research area about solving such problems through constraint optimization. Even a simple google scholar search brings many examples [1]. This is before discussing about existing ML and Genetic Algorithm approaches [2], or with Monte Carlo Tree Search [3].\n\nWithout discussing existing work and offering detailed comparisons and experiments, this paper essentially just shows that RL can be applied to such problems, but the reader wouldn't know whether it is the best tool, or simply if RL is the hammer that is used to treat every problem like a nail. The only baseline the paper compared against is another paper published in 2019 which IMO is not satisfactory.\n\nOn a related note, there are also a few projects doing similar network optimizations with slime mold (Physarum) and different variations using it for shortest path finding in mazes and all sorts of interesting problems [4].\n\nI'm reminded of a nice work called \u201cNeural Combinatorial Optimization with Reinforcement Learning\u201d [5] that proposed the use of neural nets to solve TSP problem, but ultimately needed to put in the work to compare with traditional approaches. I'm including the reference here so the authors can learn from that paper's experiences to help improve the work.\n\nRegarding the dataset: One of the most impressive points is that the work utilized a giant dataset of ~ 25M mobile phones. For an important dataset like this that is central to an impactful application of ML, would be nice to have a discussion (even in the Appendix) to describe how the data is collected, and what regulations / user privacy issues the research team might have to overcome, as these types of issues are becoming very important to the wider research community. Would also like to see a discussion about whether the large amount of data points can be reduced to a simpler 2D density map and achieve similar performance? Would there be any plans to release an anonymized version of the dataset for demonstration purpose?\n\n[1] https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=transportation+network+operations+research+constraint+optimization&btnG=\n\n[2] https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=transportation+network+design+machine+learning&btnG=\n\n[3] i.e. Link Prediction with Monte Carlo Tree Search (https://paperswithcode.com/paper/m-walk-learning-to-walk-over-graphs-using)\n\n[4] https://www.researchgate.net/publication/324791496_Physarum-Inspired_Solutions_to_Network_Optimization_Problems\n\n[5] https://openreview.net/forum?id=rJY3vK9eg"}