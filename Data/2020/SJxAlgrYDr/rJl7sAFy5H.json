{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "In this paper the authors train a seq2seq model through reinforcement learning to iteratively expand a city metro network. The authors show that different objectives can be satisfied with this approach, such as the accessibility to different areas (something the authors call social equity indicator) or maximising origin-destination trips. \n\nThe paper is interesting but could use a more extensive comparison to alternative approaches or ablated  version of the same approach. For example, what if the approach would only take into account the last metro station instead of the complete previous sequence? Would it work less well? Additionally, the baseline method the approach is compared against is not explained in enough detail. In addition to RL methods, method such as genetic algorithm have shown great promise in producing layouts, such as for wind turbines (e.g. Grady et al. \u201cPlacement of wind turbines using genetic algorithms\u201d). I wonder if such an approach would work equally well for designing metro lines and if RL is really the best technique here (which it might be but I\u2019m not convinced yet). Because of the mentioned shortcomings, I believe the paper should be improved before publication. \n\nAdditionally, the paper would benefit from a careful spell and grammar check. I found multiple typos, especially in the introduction.  "}