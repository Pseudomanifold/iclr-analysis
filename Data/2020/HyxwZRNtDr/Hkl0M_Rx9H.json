{"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper focuses on the problem of robust reinforcement learning and proposed a generic framework that is able to deal with both discrete and continuous state and action spaces. They formalized the robust reinforcement learning problem as a min-max game with Wasserstein constraints and put forward an efficient and scalable solver that is helpful to numerical optimization. Overall, this paper is of well-written with a clear illustration of the methodology and comprehensive experimental results. I still have a few concerns below, that prevent me from giving a direct acceptance: \n1.\tHowever, the proposed method seems to be somewhat incremental: In Yang (2017), it is clearly stated that it is viable to treat the robust reinforcement learning objective as a min-max game (in eq.(1)) with support belonging to a Wasserstein ball (in eq.(2)). The statement in the submission \u201c\u2026 a novel min-max game with a Wasserstein constraint \u2026\u201d seems overclaimed, namely, eq.(8) in the submission, is a combination of eq.(1) and (2) in Yang (2017), with the constraint in eq.(8) not exactly equal but just a relaxation of eq.(2) in Yang (2017).\n2.\tFurthermore, since a few papers have proposed methods to deal with both transition and reward dynamics, it would be nice and complete to also address (or hint on) the reward ambiguity problem.\n3.\tDoes the relaxation of the Wasserstein constraint in eq.(7) make the learned policy conservative? Some illustrations of this effect of \\epsilon would be interesting and complete.\n4.\tFor the experiments in section 5.1, it would be better to give an illustration of what the color means in Figure 1. \nInsoon Yang. A convex optimization approach to distributionally robust markov decision processes with Wasserstein distances. IEEE control systems letters, 1(1):164-169, 2017.\n"}