{"experience_assessment": "I do not know much about this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "Contribution\nIncorporates a mixture model on top of CenterNet for offset regression, and demonstrates improvements over the baseline (without refinement).\n \nOverall\nThe approach is well-motivated and the contribution is focused. The improvements on the test set seem significant but vanish after performing refinement. This is not a bad thing, as progress towards replacing the ad-hoc refinement procedure is valuable. However, I have questions about the conclusion of the paper: namely, whether viewpoint is actually the dominant mode.\n \nDecision\nMy current decision is weak reject. The work improved upon a baseline model of interest, and provided sufficient experimental analysis to demonstrate this. However, further analysis is warranted. I would be willing to improve this decision if further modeling extensions are implemented and analyzed.\n \nComments / Questions\nThe writing of most of the paper is clear, however I found section 4.1 confusing. Is the experiment here comparing whether conditioning on the input is better than using only the marginal distribution of mixture components (over all images)? Is a trained MDN model frozen, then you approximate the marginal distribution of mixture components via variational inference? Given that in the second model the mixture weights remain constant across images, it is surprising that this model does not do worse. I am also not sure what this experiment demonstrates beyond the importance of conditioning on given information.\n \nI would like to see experiments incorporating more structure. In the current model, each centerpoint is assigned a single mixture component. I am convinced by the current experiments that there are only marginal benefits to including more components in the given model. However, what if each offset was given its own latent variable, possibly with some interaction between nodes?\n \nI would like to see a fine-grained analysis of the differences between the means and variances of the mixture components. My hypothesis is that the mixture components are determined by \u201cviewpoint\u201d only because that determines whether the face is occluded by the back of the head. One could also check by sharing the means between mixture components. If this is true, then the means between the mixture components should be very similar, and only the variances would differ. This would also provide support for a more structured model, since various keypoints may be occluded independently.\n \nThe mixture model helps recover some of the gap between the baseline model and the post-refinement performance. What is needed to bridge the rest of the gap? Is the biggest problem dealing with occlusion?\n"}