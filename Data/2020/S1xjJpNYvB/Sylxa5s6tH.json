{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "In this paper, the authors proposed to extend meta learning for few-shot classification to the multi-domain setting. The problem looks interesting, but the proposed method is incremental. \n\nSpecifically, there are three main components of the proposed method in training: 1) a base network, 2) a model pool, and 3) a selection network. The base network is trained by simply combing training data from all the domains, which is the most common way to learn a shared model across different domains. The model pool is constructed highly based on existing works [Snell et al., 2017; Rebuffi et al., 2018], and thus is out of novelty. The main technical contribution should lie on the selection network, where a key research issue is how to represent different tasks. However, in this work, the authors just simply used the mean of outputs of the base network over all instances of a specific task to represent the task. Why is this strategy good for task representation? The authors failed to explain it. Neither theoretical nor empirical studies are provided. Therefore, the motivation behind this is unclear and not convincing. \n\nIn testing or inference, the authors proposed to use a class-prototype based approach or a weighted average of ensemble outputs to make predictions on the target-domain instances. Theses techniques are indeed widely used in the literature, which are again not novel.\n\nIn summary, though the problem studied in this paper is interesting, the proposed method is incremental, and has limited novelty contributions. "}