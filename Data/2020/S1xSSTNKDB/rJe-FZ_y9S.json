{"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review": "This manuscript introduces a new face dataset, FairFace, that is balanced in terms of race composition. The authors also performed extensive empirical validations on the new dataset as well as several existing face datasets to show that models trained on this new dataset do have better balance in terms of recognition error across different demographic subgroups. \n\nFirst of all, there is no doubt that, as a community, we all should work together to mitigate existing bias (unbalanced ratio in terms of race) in the dataset used to train automated recognition system. From this perspective, the manuscript does a good job in building and introducing the FairFace dataset and conducted a thorough comparison with existing face datasets. I appreciate the efforts the authors put in building it. My main concern is that the contributions of this paper are not well-aligned with the Call-For-Paper of ICLR. Specifically, although ICLR does have sub-field that aims at applications in vision, audio, speech, natural language processing and robotics, it more or less focuses on novel applications in these areas with techniques related to representation learning. On the other hand, the main contribution of this paper is not about any specific representation learning techniques or applications, but rather a novel dataset. Hence I believe it may find a better fit at other conferences/journals that have specific focus on this respect, e.g., CVPR or FAT*. "}