{"rating": "1: Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #4", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "\n\n## Summary\n\nThis paper address how self-imitation learning (SIL) can guide to find better solutions in multi-agent reinforcement learning (MARL) problems. The main contribution is to extend NFSP (Heinrich & Silver 2016) by SIL (Oh et al., 2016), which gives the proposed approach named NFSIP (Nerual Fictitious Self Imitation and Play). Since the problem being targetted is a multi-agent setting, the notion of \"good\" experience is slightly modified to take both of single agent's reward and global optimization objective denoted by social welfare into account. The proposed approach achieves a significant improvement over baseline MARL approaches in three multi-agent benchmark environments.\n\n## Decision\n\nFrom this reviewer's point of view, this paper is a clear reject. The paper is not clearly written and is incompletely written in its current form, hence not enough quality to be recommended to acceptance. Moreover, experimental results and analysis are limited and not enough. It is also difficult to say the novelty and significance are strong. I think this paper's perspective of applying efficient exploration techniques in a multi-agent RL setting is interesting, and it has some advantages and promising results of improvements, but a better execution of the idea would be required.\n\n## Supporting Arguments\n\nWriting and Clarity:\n\n* In general, the paper is not straightforward to follow. The paper is not structured very well, please see more comments below (i.e. feedback for improvement).\n* Figures are not clear, and very difficult to understand; besides, no caption or detailed explanation accompanying is provided. \n* No related work.\n\nMethods and Experiments:\n\n* The use of social welfare (the objective for the entire system) seems not well-motivated and principled. The main idea is that per-agent SIL objective is used, but only when the social welfare is above some threshold. A downside is that this threshold needs to be gradually tuned as training progresses, which can be hacky and would require a non-trivial tuning. It would be more preferrable to have more principled approach that takes both of per-agent and global objective into account in a self-imitation learning like fashion. In experiments, what is the effect of thresholding at global social welfareness? How was the schedule chosen?\n* Experimental analysis are quite limited, and the paper is lacking a detailed analysis; including ablative studies, a study of individual design choices, or qualitative examples/analyses of the learned behavior, to name a few.\n* Many details of the algorithm is missing. For example, what base RL learner (actor-critic) algorithms is used? How is sampling from prioritized experience replay buffer done?\n* AC-SIL and NFSIP outperform other baselines, which would indicate that the main benefit of tackling sparse-reward environments via exploration comes from SIL objectives. However, the details of AC-SIL and COMA-SIL are missing; how these algorithms were obtained? How are they different from the full approach (NF-SIP)? Also, it is questionable that they were fairly compared.\n\n## Feedback for Improvement\n\n* The authors should address the reviewer's concern about clarity and experiments. Besides, in terms of structure and organization of the paper, a vast majority of the paper should be improved.\n* Experimental results (learning curves) are difficult to parse as all lines are drawn in achromatic colors.\n* Citation was not placed properly; e.g. Ficitious play (FP) (Heinrich & Silver 2016), which is a very direct background work, is not clearly cited. (e.g. very first paragraph of Section 3, or the method description in Section 4).\n* The paper should have conclusion. Also, abstract should be written in the abstract, not as a section.\n* All equations should have numbers and the terms/concepts used in the paper should be introduced formally.\n* Finally, the title, which sounds too broad, seems not the best choice that summarizes this work's main idea and contribution.\n\n"}