{"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "In this paper, the authors proposed an asymmetric multi-task learning method on temporal data, and applied it to clinical risk prediction.\n\nOverall, the problem studied in this paper is interesting, the proposed method looks reasonable, and the application is also interesting. However, there are also some concerns.\n\n1. The details on how to construct F_\\theta to generate the hyper-parameter of a in (10) are missing. As the proposed MTL method is asymmetric, F_\\theta(f, g) is supposed to be different from F_\\theta(g, f), right? Otherwise, the transfer weight \\alpha from f to g would be the same as the one from g to f. What is the design of F_\\theta.  Moreover, the authors mentioned that \"the network F can learn a meaningful distribution of the transfer weight, such that it sets the value of \\alpha high when f and g are related, with low uncertainty on f and high uncertainty on g.\" However, only based on (8), (9) and (10), it is quite difficult to understand why the claim can be implemented. More details are needed.\n\n2. The complexity analysis is only focused on the relation to the number of timestamps T, without taking the number of tasks D into consideration. As the proposed method is asymmetric across tasks and across time, when the number of tasks is large, the scalability may be an issue. In real-world applications, e.g., in a big hospital, the number of patients can be very large. In this case, is the proposed method practical? \n\n3. Though the proposed method looks reasonable, it contains many components or networks. I guess to train such a composition network precisely needs a lot of tricks in practice.\n "}