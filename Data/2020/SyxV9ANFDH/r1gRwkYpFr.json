{"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper proposed to use SRU for inferring nonlinear granger causality. It also provided two extensions of SRU with regularization to alleviate the issue of overfitting.\n\nSRU was proposed in a previous paper. This paper extended this algorithm for inferring granger causality through applying group sparse regularization, which is a pretty smart design to me. Another major innovation comes from the two modifications to combat the possible overfitting when using very fine-grained scale parameters in SRU.\n\nThe paper was well-written in general. I can follow the paper without problem.\nThe effectiveness of the algorithm depends on the sparse regularization, which lacks theoretical guarantee for non-convex optimization. Based on the experimental results, it doesn't seem a big problem though. But I'd like to see some analysis of the actual sparsity of the weight with the proposed group sparse regularization.\n\nThe experiments seem convincing to me and I really appreciate the authors provided the tuned hyper-parameters in the appendix.\n"}