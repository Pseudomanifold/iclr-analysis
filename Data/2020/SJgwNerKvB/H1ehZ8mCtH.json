{"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper proposes to use hypernetwork to prevent catastrophic forgetting. In deep learning, the information of the samples are converted to parameters during the training process, however, future training process could interfere with the information from the previous tasks. One of the method to prevent forgetting is to use reheasal, which retrains the network with previous data. The mechanism of this work is to store the previous samples as a trained point in the parameter space, so that a set of points in the original space is stored and thus rehearsed as one point in the parameter space, this saves both the memory and computation.\n\nI give a weak accept of this paper due to the following reasons:\nPros:\n- The idea of converting a set of data points to one point and rehearse at a meta level is a smart and novel idea.\n- It shows significant improvement compared to baseline methods, especially for split CIFAR experiments.\n- The Appendix contains a fair amount of details and additional experiments on generative models.\n\nCons:\n- This works assumes a task incremental setting, during training process task is received one by one, within each task we could assume i.i.d shuffling of the data. During testing, the task boundary is optional. Although this setting has been taken by many other works in this field, it is also criticised that availability of task boundary is an unrealistic setting. A more realistic setting would be to continually learn with a continuous non-stationary stream of data, which indicates there's no split of train / test phase. Thus a general continual learning method should not require task boundary, which would be problematic for this work as it depends on task conditioning.\n- For the rehearsal objective in 2, L2 penalty is used. This could be a problem as minimizing the L2 distance in the parameter space does not necessarily minimize the task loss.\n\nQuestions I have that needs clarification:\n- Chunking: Are the chunking parameters shared/updated across tasks?"}