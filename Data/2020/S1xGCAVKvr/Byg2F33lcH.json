{"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This work suggests a host of  improvements and simplifications to the meta-learning approach of Andrychowicz et. al.  The authors have carefully analyzed weaknesses in previous work and I think their experiments do suggest that they have improved on them.  However, I would still recommend rejecting, as imo\n1: the  absolute state of these approaches seems unpromising, and \n2: the authors do not do a good job contextualizing how well the learned optimization performs compared to more standard methods.\n Each step used to train the meta-optimizer could be used instead to pick hyperparameters (choice of which \"classical\" optimizer, and its hyper-parameters, like lr etc.).  However, there is not really any discussion about the trade-offs between the time it takes to train the meta-optimizer and the results that would be obtained by hyper-parameter search.   Indeed, even with the tiny hyper-parameter search spaces the authors use, in most of their figures, one of ADAM or plain SGD does comparably or better than their method. \n\nIt is not clear if the figures represent train or test loss; the authors should report both.  Furthermore, imo, almost the figures are cut off too soon- the models all still seem to be learning.    What are the error rates at the cutoffs on test and train?\n\nFinally, I wonder at the choice of test problems.  Why not pick something where one naturally will need to run an optimization many times (e.g. style transfer) rather than a toy problem like mnist or cifar?  Note that there are already other approaches (not learning based on learning gradient descent) that have been successful there. \n  \n\n"}