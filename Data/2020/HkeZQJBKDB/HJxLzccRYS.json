{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "N/A", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review": "The paper proposes a universal approximator for functions equivariant to finite group action. The idea is to draw a bijection between such equivariant universal approximators and those for functions that are \u201cinvariant\u201d to the stabilizer subgroup of the output indices. Using existing results for designing universal invariant approximators, the paper then seems to suggest universal equivariant approximators in the form of neural networks. \n\nWhile this is an important topic and the paper -- to the extent that I could follow -- seems to be technically sound, I found the paper very hard to read in part due to numerous grammatical errors.\n\nAnother issue is that I don\u2019t see why the symmetric group is treated separately from the general finite groups. If in the end, the goal is to plug in \u201ca\u201d universal G-invariant function, the paper could leave those details out and focus on clarifying its proposed bijection. Could you please comment? Also is there a setting in which this setup leads to a practical architecture?\n"}