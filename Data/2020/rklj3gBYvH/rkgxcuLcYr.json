{"rating": "1: Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "- The paper targets the scalability issue of certain meta-learning frameworks, and is therefore addressing an important and interesting topic. \n\n- Theoretical and technical novelty is rather minimal. \n\n- The paper writing is well beyond the ICLR level, and is honestly beyond the level required by a scientific manuscript in general. Writing needs a massive overhaul.\n\n- There are way too many grammatical mistakes. In addition, there are citations written the wrong way -e.g. Rajeswaran (2019)-, and also the flow of the ideas has room for improvement. \n- For the aforementioned reference, the author ordering is wrong, and not consistent with the way it is cited in the text.\n\n- page 1: \"while the learner can learn a set of initial task parameters are easily optimized for a new task. \": Please fix and/or clarify. \n\n- page 2: \"where the classes contained in each meta-set is disjointed\". \n\n- page 3: \"The LSTM-based meta-learner proposed in this work, allow gradients to\" \n\n\n- \"Memory-based Under review as a conference paper at ICLR 2020 methods (Ravi & Larochelle (2017)) that use all of the learner\u2019s parameters as input to a meta-learner tend to break down when using a learner with a large number of parameters (Andrychowicz et al., 2016).\": Just to clarify: The latter paper, which is criticising the former category, is older than the paper representing the former category. Is that right? \n\n- page 2: \"superior parameter updates\". I see that the result has been based on classification accuracy. Notwithstanding the ablative study in the experiments secion, maybe superior parameter updates can be either replaced by a more unequivocal description of the mentioned comparison, or formally defined from there onwards. \n\n- At the ICLR level, I do not think that all this detailed description of backpropagation would be necessary. \n\n- Equation 1 and the description that follows: \"a_l is the layer\u2019s pre-activation output\". Is a_l the post-activation output as well? Equation 1 implies so, doesn't it?\n\n- page 3: \"This limits MAML to domains where a small amount of update steps are sufficient for learning.\": What do you mean by \"This\"? Is it to have inner loops consisting of multiple sequential updates, which is what was referred to as \"preferable\" in the beginning of the same paragraph? i.e. Is the MAML limitation noted in this paragraph a limitation of the vanilla MAML (plus the other versions) as well or solely due to the \"preferred, yet detrimental\" extension of adopting multiple sequential updates?\n\n\n\nMinor:\n- page 1: Supervised few-shot learning \"aims to challenge machine learning models to ...\": It does not challenge ML models; it is a specific ML paradigm. "}