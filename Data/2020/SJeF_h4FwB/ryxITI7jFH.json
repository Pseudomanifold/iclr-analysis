{"rating": "8: Accept", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I did not assess the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "Label noise widely exists in the large-scale data sets. This paper proposes a novel approach that directly cleans labels in order to train a high quality model. The proposed method leverages statistical principles to correct data labels and has a theoretical guarantee of the correctness. In particular, a likelihood ratio test (LRT) to flip the labels of training data is used, and it can prove that the LRT label correction algorithm is guaranteed to flip the label so it is consistent with the true Bayesian optimal classifier with high probability. The experimental results on several benchmark data sets show that the proposed method is promising. Overall, this paper could be a significant algorithmic contribution. But I also have some minor concerns:\n[1] The theoretical analysis and the experimental results are both well organized in the paper. How about the time complexity of the proposed method. If the authors can show the time cost in the paper, I will much more agree with the paper.\n[2] In the experimental parts, the convergence curve of the proposed method during the training epochs may be better to prove the theoretical analysis.\n[3]The details of the compared methods should be given, and it will be better to give the results without any noise labels. In this way, the confidence of the paper will be further improved.\n"}