{"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper proposes a label correction approach based on a likelihood ratio test, for robust training of deep neural networks against label noise. First, this paper introduces the LRT-Correction procedure, which is the main component of the proposed label correction approach. LRT-Correction uses the current model prediction to run a likelihood ratio test and flip labels when they are rejected. The decision is made by comparing the likelihood test results with a predefined value \\Delta. Then they introduce the full algorithm, AdaCorr, where the LRT-Correction procedure serves as an inner loop for the label correction. Lastly, there are experiments done on four datasets to conclude the superior performance of the proposed AdaCorr in contrast to several existing methods. \n\nOverall, this paper proposes a new label correction approach based on a likelihood ratio test. Standard experiments show that the proposed AdaCorr is superior to several existing methods. \n\nThe following questions are expected to be addressed during rebuttal:\n1.\tThe LRT-Correction procedure introduces additional computation costs. What is the difference in computation costs between Standard and the proposed label correction approach? Is the extra computation cost significant? \n\n2.\tThe LRT-Correction procedure is introduced based on a binary setting. The main theorem (Theorem 1) also only supports the binary setting. There is a statement in Corollary 1 that \u201cLRT-Correction can be generalized to multiclass classification tasks, by flipping \\tilde{y} to be the best prediction of f when the null hypothesis is rejected. Theorem 1 can be generalized to multiclass classification tasks, by considering all pairs of class values.\u201d How exactly did you do for that? Please provide more details.\n\n3.\tThis paper uses the ablation study to demonstrate that the proposed AdaCorr is robust to several important hyper-parameters, e.g. the number of epochs m for the burn-in stage, the predefined value \\Delta for likelihood ratio test. How did you exactly choose the optimal value for these hyper-parameters? These is a statement \u201cWe choose m=20 in this data set (CIFAR10) and \u201csimilarly\u201d in other datasets.\u201d Did you use the same m(=20) for all datasets? Does this also hold for the hyper-parameter \\Delta ?\n\n4.\tThe experiments are too standard. Any results on real-world datasets, e.g. Clothing1M [1]\uff1f\n\nMinor comments:\n1.\tThe summarization of the existing related work is not consistent throughout the paper. In Introduction section, this paper believes that the existing methods mainly follow two directions, i.e. probabilistic reasoning and data selecting; while in Related Work section, they are classified into three categories. Please clarify your arguments. \n\n2.\tPage 5: In Corollary 1, \u201cLRT-Correctioncan\u201d -> \u201cLRT-Correction can\u201d\n\n3.\tPage 7: In Table 2, MINIST -> MNIST. \n\n4.\tPage 7: In Experiment Setup, please provide more training details, e.g. learning rate. \n\n\n[1] Xiao, Tong, Tian Xia, Yi Yang, Chang Huang, and Xiaogang Wang. \"Learning from massive noisy labeled data for image classification.\" In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 2691-2699. 2015. \n\n"}