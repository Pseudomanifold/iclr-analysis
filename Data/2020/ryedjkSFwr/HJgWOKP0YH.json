{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review": "The author propose a method called global momentum compression for sparse communication setting. The contributtions can be summarized into 3 parts: switching DGC setting from local momentum to global momentumm, theortical proof of the convergence, empirical results showing performance. \n\nHowever there have several issues:\n\t1. No significant contribution. Although they theoretically prove a new version of DGC, it's just a minor modification and no significant performance improvement as shown from their empirical results.\n\t2. In the experiment session, as shown in the results,  their method seems more stable during training but there achieves minor improvement in terms of the test accurarcy. Second, they only compare with DGC and it's counterpart baseline. It's better to include more related algorithms for comparison (like quantization methond: QSGD or signSGD).\n\t3. Comparing with DGC, there is no improvement in saving communication as shown in their results. Since GMC only changes DGC setting from local momentum to global momentum, no modification is involved in the compression part of DGC. \n\nOverall, I appreciate the authors for their theoretical contribution for DGC and well written paper. However, it would be great to show a better improvement and include more related methods for comparison. "}