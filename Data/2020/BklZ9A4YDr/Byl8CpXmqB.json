{"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "Summary: The paper presents an approach to generate 3D training data to improve the performance. At the core of this work is the use of hybrid gradients, i.e., a combination of analytical gradients (task-specific network) and approximate gradients (graphics renderer). The benefits (computational and generalization) of the proposed approach is shown using three benchmarks for depth and surface-normal estimation: (1). MIT-Berkeley dataset; (2). NYU-v2 depth dataset; and (3). Basel Face. \n\nPros: \n\n+ well-done evaluation and comparisons with prior art! The authors demonstrate the various design decisions and improvements over existing works on different datasets.\n\n+ intuitive combination of analytical gradients and approximate renderers to combine the synthesizer and task-specific network.\n\n\nConcerns: \n\n- A goal for the use of synthetic data is to enable an extensively large amount of data to train parametric models, which may otherwise not be available because of the constraints on capturing and creating real data. It is, therefore, important as how we can automatically create a humungous diverse synthetic data. However, the proposed approach comes no-where close to do it. There is an upper bound to what we can achieve using the proposed method, and it by no-means come close to what we can make just by using a few samples from real data. Here are more specific instances for my reasoning: \n\n(1). Section-5.2 and Figure-6:  Only a little modification (camera position and object rotation) is possible in terms of placement of objects in a scene. This constraint does not enable us to create something far different from what already existed in synthetic data.\n\n(2). Table-2: The use of hybrid gradients enable smarter ways to do augmentation and leads to better performance than prior art. However, the performance is far lower than what one could achieve with few samples from real data (using only 750 training examples images from NYU-v2 dataset) even when trained from scratch. Here are the numbers of this setup: Mean: 21.2; Median: 13.4; <11.25: 44.2; <22.5: 66.6; and <30: 74. \n\nIt is by no means clear as to how the proposed approach can ever come close to this performance, and make the current plan unuseful for any practical purposes. It will be useful to understand what future directions can be pursued to close this gap. Additionally, the authors can add experiments that use the network trained on synthetic data as an initialization and fine-tune it for real data distribution. Does it lead to better performance?\n\n- Figure-4: please mention the delta difference at the time of convergence of hybrid gradient with other approaches. It gives a sense of how far do we get in terms of computational efficiency.\n\nMinor Concerns: \n\n-inconsistent citation for PCFG in Sec-1 and Sec-4.\n\n- typos and grammatical errors here and there."}