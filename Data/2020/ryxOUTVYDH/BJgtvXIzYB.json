{"rating": "3: Weak Reject", "experience_assessment": "I do not know much about this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "Caveat: I admit that I am not incredibly familiar with this particular research area, so I am probably not the best person to review this paper.  I am not certain what part of the matching and bidding process ended up with this paper assigned to me.\n\nThis paper presents a method for filtering out noisy training examples, assuming that there is a known percentage of label noise present in the data.  The gist of the method is to repeatedly perturb the weights in the network slightly, and only accept as training data examples that consistently get small loss across all perturbations.  The intuition is that the loss for noisily labeled examples will not be stable under these perturbations, so using an ensemble of perturbed models should find the label noise.  This intuition seems reasonable enough, and the method seems straightforward.\n\nThe reason I am giving a \"weak reject\" score is largely because the experiments seem weak to me.  It seems pretty unrealistic to randomly corrupt 20% or more of your data.  In what scenario will you actually have data that has 20%+ label noise?  If you actually have one, why not use that to show the effectiveness of your method, instead of an artificial setting?  You have shown that your method achieves better performance in a contrived setting, but in order for it to actually be _useful_, it needs to work on real data, which hasn't been shown.\n\nOne example of a real scenario where you might have a very high degree of label noise is in weakly-supervised semantic parsing.  This paper (https://openreview.net/forum?id=ryxjnREFwH), for example, uses confidence thresholding (though without an ensemble) to filter the training data.  It might be fruitful for you to try demonstrating the benefits of your method on this kind of task.\n\nMinor issues:\n\nSection 3.2 presents math suggesting that the perturbations are additive, with deltas drawn from some distribution.  Section 3.3 then presents the actual perturbation methods, which seem difficult to characterize as drawing a delta from a distribution.\n\nSection 4.3 - citations for the baseline methods should be in the main paper, not only in the appendix.\n\nSome things weren't explained well enough for the paper to be self-contained.  For example, the description of LSEC says that there are \"stochastic operations\", but these are not described anywhere, even with a simple sentence.  Instead the reader must refer to another paper."}