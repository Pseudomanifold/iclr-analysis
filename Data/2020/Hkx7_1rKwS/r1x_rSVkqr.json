{"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "In this paper, the authors introduce a new optimization algorithm for minimax problems, or finding equilibria in sequential \ntwo-player zero-sum games. Such problems are common in machine learning, including generative adversarial networks or primal-dual reinforcement learning. The commonly used gradient descent-ascent algorithm, corresponding to taking a gradient step for both players (or for both variables being minimized and maximized over), does not converge, in general, to local minimax points. Moreover, it can converges to fixed points which are not local minimax. To address these issues, the authors introduce the \"follow the ridge\" algorithm for minimax optimization problems. Given a minimax problem min_x max_y f(x, y), this algorithm consists in adding a correction term to the gradient corresponding to the y variable (corresponding to the max). This term is derived from the observation that minimax optimization should follow ridges (i.e. local maximum w.r.t. to y) of the function. Ridges can be defined as the implicit functions such that the gradient w.r.t. y is equal to zero, allowing to design an update that would stay \"close\" to the ridge. The correction term corresponding to the update thus involve the inverse of the Hessian w.r.t. y. The authors prove that all the fixed points of this algorithm are minimax, and that all local minimax are fixed points of the algorithm. The proof use first and second order conditions for local minimax points, which were recently derived in a paper by Jin et al. The proposed algorithm can also be used with momentum and preconditioning, and be generalized to Stackelberg games. Finally, the authors evaluate the follow the ridge algorithm on toy low dimensional GAN problems, as well as experiments on the MNIST dataset, showing better convergence that other methods used for minimax optimization problem.\n\nThe problem studied in this paper is an important one, as it arises in multiple area of machine learning such as adversarial \ntraining or reinforcement learning. It has also received significant attention from the community in the recent years. This paper propose a simple solution, which is well motivated, to the problem as well as a proof of convergence. A limitation of the proposed method is that it uses the Hessian of the problem, probably making it hard to apply on large  scale problems that are common in deep learning. I believe that it would make the paper stronger to discuss potential ways to mitigate this issue (e.g. inspired by L-BFGS), and their impact on theoretical guarantees. (Note that the authors briefly mention using the conjugate gradient algorithm in the experimental section).\n\nOverall, the paper is well written, and easy to follow (even for non-expert like me). I believe that it does a good job at introducing the problem and existing work on which it builds, and to motivate the proposed solution. I have not checked the proofs carefully, but they seem sensible. A small weakness of the paper is the experimental section: for example, I am not sure the MNIST experiments bring much to the paper, and would have preferred more convincing experiments. However, this is mostly a theoretical paper, and I do not think this is a big concern.\n\nTo summarize, I think the paper study an important problem, proposes a sound solution and is clearly written. For these reasons, I believe that the paper should be accepted to the ICLR conference. However, as I am not an expert on this area, my recommendation is a low confidence one.\n\n\nMinor comment: I believe that at the beginning of second paragraph of section 4, \"Suppose that y_t is a local minimum of f(x_t, .)\" should be \"maximum\"."}