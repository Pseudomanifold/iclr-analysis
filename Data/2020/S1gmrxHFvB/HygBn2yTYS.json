{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "The paper proposes a novel method called augMix, which creates synthetic samples by mixing multiple augmented images. Coupled with a Jensen-Shannon Divergence consistency loss, the proposed method has been experimentally, using CIFAR10, CIFAR100, and ImageNet, shown to be able to improve over some augmentation methods in terms of robustness and uncertainty.\n \nThe paper is very well written and easy to follow. The idea of the approach is simple, and should be easy to be implemented. The evaluation of the proposed method is currently based on experimental evidence. Nevertheless, the empirical studies in its current form could be further improved. Please see my detailed comments below.\n\n1. The proposed approach relies on a chain of augmented methods. In this sense, experimental studies on the sensitivity for how the augmentation methods in the chain (e.g., augmentation operations) and their chain structure (e.g., length of the chain) impact the performance of the augMix should be provided. This is in particular relevant because the authors did mention that \u201cadding even more mixing is not necessarily beneficial\u201d on page 8.\n\n2. Since the proposed method mixes multiple augmented images, a more appropriate comparison baseline would be a method involving creating synthetic data with multiple images. For example, the n-fold Mixup method as discussed in Guo AAAI2019 (Mixup as Locally Linear Out-Of-Manifold Regularization).\n\n3. Some experimental results/observations deserve further discussions. For example, on page 8, the authors mention that \u201capplying augMix on top of Mixup increases the error rate to 13.3%\u201d. I wonder if the authors could provide any insights or hypothesis on why the proposed model behaviors in this way? \n\n4. Would that be any manifold intrusion issue as discussed in Guo\u2019s AAAI2019 paper? That is, would it be possible to generate images that are very close to some real images but with different labels? For example, by looking at the bottom-center image in the Appendix B, the synthetic image created seems to be close to some birds with other categories. \n\n5. Does the method work for other network architectures such as DenseNet?\n"}