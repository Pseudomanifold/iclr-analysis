{"rating": "3: Weak Reject", "experience_assessment": "I do not know much about this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "The paper discusses a new  data augmentation method which improves the accuracy of the network for several specific shifted domain scenarios. The main goal of the paper is to increase the robustness of the deep model trained on the augmented data to generalize well beyond the data corruption like the  rotation, translation, noise,.... For each input, they apply  $k$ different operation of image shift and make the weighted combination of them. The weight vector is generated randomly from Dirichlet distribution with the parameter $\\alpha$.  The weighted combined images would be added to the original image in convex combination. The convex weights are generated from distribution Beta with parameter $\\beta$. Later they train the network with adding the Jensen-Shannon divergence for the posterior distributions of augmented images as the consistency regularizer.  They show this data augmentation will increase the accuracy of the model for shifted and non-shifted domains and also it leads to more calibrated model for domain shift problem.\n\nPros: \nthe paper is well-written with clear implementation details. The level of experiments are wide and cover different aspects. The experiments shows the significant improvement compared to several baselines. The authors conducted the experiments for a wide range of model-datasets to show the validity of their ideas. \n\nCons: \n1- The title of this work is a strong claim that is not supported in the paper. In this paper, it is mentioned that AugMix is a data augmentation method that generates data to add to the training set and after training with data augmentation, the method would be more robust to other distortions that can be added to the datasets. Generally, the definition of domain shift is wider than just adding perturbation to the dataset.  To support the claim, the paper should also report the results for similar tasks datasets such as CIFAT10-STL10- or MINIST-SVHN for different models and with different domain adaptation methods. The claim about the improvement of uncertainty also is not supported well by the experiments. The method should be tested for many model-datasets specifically, to support improving the  uncertainty under the domain shift idea like the paper [1].  \n\n2- The novelty of the work is limited. The generating method of distorted  images is the combination of previously proposed methods like [2] and [3].  The motivation of why the proposed method is working well is not clear. How this objective function can improve the robustness to the image perturbation but it does not lose the accuracy is not discussed. It would be better if the proposed method were supported by theory and also the intuition and explained why it should get better results than previous data augmentation methods such as AutoAugment [3].\n\n3-  Fine-tuning the parameters like $k$, $\\alpha$ and $\\beta$ is not discussed at all.\n\n4- To show the robustness of the proposed method to domain shift, the paper compares the proposed method to other data augmentation methods that are not designed for domain shift which seems unfair.  \n\nReferences:\n[1] Ovadia, Yaniv, et al. \"Can You Trust Your Model's Uncertainty? Evaluating Predictive Uncertainty Under Dataset Shift.\" arXiv preprint arXiv:1906.02530 (2019).\n[2] Zhang, Hongyi, et al. \"mixup: Beyond empirical risk minimization.\" arXiv preprint arXiv:1710.09412 (2017).\n[3] Cubuk, Ekin D., et al. \"Autoaugment: Learning augmentation policies from data.\" arXiv preprint arXiv:1805.09501 (2018).\n"}