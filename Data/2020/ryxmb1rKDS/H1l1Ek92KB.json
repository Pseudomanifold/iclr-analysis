{"rating": "6: Weak Accept", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "In this paper, the authors propose a framework for learning the dynamics of a system with underlying Hamiltonian structure subjected to external control. Based on the extended equations of motion, the authors suggest how to apply NeuralODE in a way that makes use of the prior information that the unconstrained system is Hamiltonian and subjected to a control term. For a range of tasks, the authors then demonstrate that the proposed SymODEN framework can learn the dynamics and recover the known analytical solution, and that they can derive a controller that allows them to drive the system to a target configuration. \n\nI find this paper very interesting and the formulation elegant. In particular, I appreciate that the paper is pretty much self-contained and that the authors derive the theory from first principles. However, there are a couple of points (listed below) that should be addressed prior to publication to improve the clarity of the paper, and to help the reader to fully appreciate the depth of the experimental section. If these points were addressed in sufficient detail, I would be willing to increase the score:\n\n1) Reading the abstract and the introduction, I got the impression that SymODEN can be applied to any physical system while the method is in fact only applicable to systems governed by Eq. (11). I think it\u2019s worth mentioning in the text that not every physical system follows (constrained) Hamiltonian Dynamics. \n\n2) You mention that a controller is designed based on the learned dynamics. For example, in the first sentence in Sec. 2.2: \u2018Once the dynamics of a system have been learned, it can be used to synthesize a controller to maneuver the system to a reference configuration q*\u2019. I think it is important to specify here which dynamics you are referring to, i.e. the constrained or unconstrained dynamics. Later on it becomes clear that you use constant-u training data and that u is part of the input to the model, so it has to be constrained dynamics, but at this stage it is still unclear to the reader.\n\n3) In Eq. (11), you set du/dt = 0 without motivating this restriction. Can you provide at least one sentence on why this is an interesting choice and back it up with a reference? Furthermore, the sentence above Eq. (11) is broken and needs fixing. \n\n4) Tasks (general): You consider a range of tasks and I appreciate that you start with a simple and intuitive system. However, I think a bit more guidance throughout the tasks section would be very helpful. In particular, I would suggest that you provide a short (one or two sentences) summary at the beginning of each task to say what exactly it is that you are trying to test or demonstrate. Furthermore, I would suggest showing the summary of  results, i.e. Sec. 4.2, after you introduce the individual tasks rather than before.\n\n5) Task 2: This task addresses multiple things in one go: Initially, you demonstrate that you can recover the results of Task 1 without access to the generalised momenta, and explain why this can only be done up to a constant scaling factor. This is very interesting and clear. However, then you jump straight into the controller and things become a little unclear because, at this stage, it still seems that the dynamics are the same as in Task 1, i.e. unconstrained. Please add a sentence or two for clarification. Another important aspect that is not commented on at all is the behaviour of u(t) in Eq. (27). In particular, isn\u2019t u(t) expected to satisfy du/dt = 0 based on Eq. (11)? The results in Fig. 6 suggest that this is not the case (see time interval [2, 6]). This seems like an interesting and surprising behaviour, especially because SymODEN was only trained with constant-u training data. I would appreciate if the authors could comment on this. I would also suggest to add horizontal lines to Fig. 6 to indicate the expected results.\n\n6) Task 4: Why did you not explain this task in a dedicated section like you did for all other tasks?\n\n7) Symplectic: Since both the method and the title of the paper contain the word \u2018symplectic\u2019, it would be good if you explained what the term actually means.\n\n8) \u2018Our results show that incorporation of such physics-based inductive bias can provide knowledge about relevant physical properties (mass, potential energy) and laws (conservation of energy)...\u2019. To me, this statement is slightly misleading. You did not demonstrate that SymODEN \u2018provides knowledge\u2019 of laws of the system; energy conservation (for u = 0) as a law is hard-coded into your network. The specific value of the energy can be inferred but that I would consider a physical property. I would suggest to change the wording to reflect this clearly.\n\n9) Introduce the acronym ODE much earlier than in Sec. 3.1.\n\n10) Model training: What happens if you use unseen initial conditions rather than the ones in the training data? Perhaps you could add a comment to clarify.\n\n11) There are many typos and grammar mistakes in the paper. Please revise it carefully. To give you a few examples:\n\u2018are both reformulation\u2019 -> \u2018are both reformulations\u2019\nSec 2.1: Decide on whether you use plural or singular for \u2018dynamics\u2019 and be consistent.\n\u2018on a equal footing\u2019 -> \u2018on an equal footing\u2019 \n\u2018beyond classical mechanics, the Hamiltonian\u2019 -> \u2018Beyond classical mechanics, Hamiltonian \u2026\u2019\n\u2018Hamiltonian is same as\u2019 -> \u2018Hamiltonian is the same as\u2019\n\u2018represents potential energy\u2019 -> \u2018represents the potential energy\u2019\n\u2018trajectory actually converge to\u2019 -> \u2018trajectory actually converges to\u2019\n\u2018a ODE solver -> \u2018an ODE solver\u2019.\n\u2018Lagrangian and Hamiltonian formulation\u2019 -> \u2018Lagrangian and Hamiltonian formulations\u2019\n\u2018assume that q and p evolves\u2019 -> \u2018assume that q and p evolve\u2019\n\u2018translational coordinate\u2019 -> \u2018translational coordinates\u2019\n\u2018naive baseline model approximate\u2019 -> \u2018naive baseline model approximates\u2019\netc.\n"}