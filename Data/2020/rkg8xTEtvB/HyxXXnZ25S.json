{"rating": "1: Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #4", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper proposed the hierarchical disentangle network (HDN) that leverages hierarchical characteristics of object categories to learn disentangled representation in multiple levels. Their coarse-to-fine manner approach allows each level to focus on learning specific representations in its granularity. This is achieved through supervised learning on each level where they train classifiers to distinguish each particular category from its \u2018sibling\u2019 categories which are close to each other. Experiments are conducted on four datasets to validate the method.  \n\nExploiting object hierarchy to learn disentangled representation is a promising direction but I lean towards rejecting this submission due to\n1. No results on commonly used disentanglement metrics (e.g. see [1])\n2. No comparison with existing supervised/unsupervised methods on disentangled representations (e.g. [2][3])\n3. The needs for full supervision on each level and manually designed fixed hierarchy require labels for the full hierarchy and make it not applicable to many existing data. This probably is why the proposed approach did not work well for more complex datasets like ImageNet.\n\n\nThese also should be addressed:\n1. The choice of adaptive instance normalization should be discussed. AdaIN could be used to account for small changes like color or local changes, but can it be used for larger and more global change (for example from animal category to human). If not, is it a limitation of this method?\n2. Justification for several choices made in the method, for example in the form of qualitative/quantitative ablation studies - usage of local \u2018brother\u2019 categories, image/feature reconstruction losses\n3. Can the metric in Table 1 prove disentanglement is achieved? What if E and G learned some way to fool the classifiers\n4. Authors use conditional generative adversarial networks but it seems that there is no noise.\n5. Discussion of failure cases. For example, the authors mentioned that the proposed approach did not work well for ImageNet. Why is this the case?\n\n\nMinor comments:\n- some citations are not properly formatted\n\n[1] Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations, Locatello et al.\n[2] Disentangled Sequential Autoencoder, Li and Mandt\n[3] Exploring Disentangled Feature Representation Beyond Face Identification, Liu et al.\n\n"}