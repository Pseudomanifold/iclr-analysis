{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "A variant of VAE, named Guided-VAE is presented in this paper. The basic idea is to add guidance in the learning of VAE by adding a sub-component. Unsupervised and unsupervised models are built to introduce guidance information (affine transformation in unsupervised model and meta-data/class labels in supervised model). Experimental results show that the idea does work well. Specifically, I have the following comments.\n\n1. I think the affine tranformations in Equation (3) is pre-specified, but it is unclear in the paper. Please clarify.  The affine transformation part in the first term of Equations (3) also needs more explanations. \n\n2. It is unclear how traversal of latent variables was conducted. \n\n3. In data types other than images, how is the unsupervised model guided? Can you give a specific example not in the image domain? \n\n4. In Figure 3, is the PCA basis interpretable?\n\n5. I was not surprised that the the proposed method works better than beta-VAE in Figure 4, because these factors are supervised imposed to representation learning. The interpretation of z^rst was not explore. It is important and interesting to investigate that whether these variables not enforced in supervision also produce disentangled representation. \n\n"}