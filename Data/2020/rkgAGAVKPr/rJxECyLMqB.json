{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The authors of this paper construct a new few-shot learning dataset. The whole dataset consists of several data from different sources. The authors test several representative meta-learning models (e.g., matching network, Prototype network, MAML) on this dataset and give the analysis. Furthermore, the authors combine MAML and Prototype network, which achieves the best performance on this new dataset.\n\nPros:\n+ Compared with previous datasets (e.g., miniimagenet, omniglot), the constructed meta-dataset is larger and more realistic, which contains several datasets collected from different sources\n+ Several competitive baselines are compared on this dataset under different scenarios (e.g., different number of shot) with reasonable analysis.\n\nCons:\n- I am familiar with meta-learning, however, it is my first time to review a paper whose main contribution is proposing a new benchmark. The proposed dataset may useful in further meta-learning research. However, I do not feel the construction way is quite difficult. The authors only propose several rules to construct the data set (see 3.2). \n- It would be better if the authors can explain more about Proto-MAML. My understanding of Proto-MAML is to apply the prototype on the last layer and keep the other layers.\n"}