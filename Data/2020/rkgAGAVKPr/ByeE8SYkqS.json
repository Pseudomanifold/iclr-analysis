{"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper proposed a really interesting direction for few-shot and meta-learning, the concept of a 'meta-dataset', which can be used for more realistic evaluation of algorithms. The main contributions are:\n\n1) A more realistic environment for training and testing few-shot learners. \n2) Experimental evaluation of popular models\n3) Analyses of whether different models benefit from more data,\n4) A new meta-learner\n\nI think this work is an interesting empirical paper which should be supported by solid experimental results. My concern about this paper in its current form is that the layout/structure of the paper needs to be improved, for example:\n\nConsidering putting some of the key results in the appendix section in the main text\nRemoval of repeating results from the main text by shortening the early sections"}