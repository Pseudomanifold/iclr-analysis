{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper presents a methodology to bring together lifelong learning with few shot learning, called Slow Thinking to Learn (STL). STL comprises of task-specific Fast Learners (FL) and a single Slow Predictors (SP). FL has a lookup memory, where learned embeddings of data and its label is stored. SP contains a single model which is trained on batches that comprises of datapoint from the lookup memory of FL and a meta-model trained using predictions from FL, in a way similar to MAML [Finn et al. ICML 2017]. The learned embedding function and the feedback term (in Equation 3) helps to extend the framework to sequential few-shot learning. The methodology is evaluated on standard lifelong learning benchmarks and a few-shot adaptation of CIFAR-100. \n\n+ves:\n- The overall idea to have an interplay between a quick learner and a slow predictor, inspired by the biological brain is novel. The proposed methodology is logical and draws inspiration from [Sprechmann et al. ICLR 2018].\n\n- The problem setting, which seeks to address concerns in existing lifelong learning methods, is relevant. Existing lifelong learning methods do have some limitations in their experimental settings, and this work seeks to address this concern.\n\n- The results for the experimental settings considered are promising.\n\nConcerns:\n- While the overall idea is interesting and relevant, the novelty is incremental in its originality to solve the identified concern, considering the paper mainly strings together existing ideas in terms of the methodologies (as summarized above). \n\n- It would have been nice if the paper motivated the work (and its setting) more strongly. While the paper states that knowledge of future tasks (even their quantity) is a strong assumption, examples of real-world applications (or problem settings) where one may not have access to this would have helped better motivate the proposed problem setting.\n\n- The premise of the work is not very clear: on Pg 1, the paper states \u201ccurrently, lifelong learning models are usually trained \u2026...for a sequence of tasks arriving at test time.\u201d The knowledge about future tasks is claimed to be a strong assumption. However, in the lifelong learning context, I am not sure if this is not considered \u201ctest time\u201d. The very premise of lifelong learning is that the model should continue to learn as newer tasks arrive over time, and that training is fair when newer tasks arrive.\n\n- The experiments don\u2019t seem to rigorously study the key objective/motivation of the work. If the assumption of knowing the number of tasks is considered strong (pg 1 of the paper), it would have been interesting to see the results of the proposed method against existing methods when this assumption is violated, for e.g, as the number of tasks increases (beyond 10 - to, say, 20 or 50). All experiments in this work are eventually on standard settings of lifelong learning followed by other papers, which the work initially questions. Datasets such as Permuted MNIST allow for an indeterminate number of tasks, and studying in a varying number of tasks setting would have helped study the problem setting more closely, and the relevance of this work.\n\n- The experiments in Section 4.1 use a memory size of 1000 (Figs 4a, 4b). According to the methodology, the Fast Learner uses one memory module per task (M^t). Would this require storing 10000 examples each of 10 tasks, or is the memory size fixed to 1000, irrespective of the number of tasks? This is not clear, and is perhaps an important detail considering the focus of this work.\n\n- In CIFAR-100 experiments, are 20 classes added as a single task? How is the growth of the final classification layer handled?\n\n- It would have been nice to see a formal treatment of \u201cslow\u201d and \u201cfast\u201d as used in the SP and FL of this work. The terms seem to be heuristic in the work, and a clear definition of when a model is \u201cfast\u201d vs \u201cslow\u201d, as required for the proposed methodology, would have helped generalize the proposed idea better.\n\n- An important component of the proposed method is the SP (slow predictor). In the SP methodology, why is the cosine distance most appropriate for similarity between embeddings? What distance metric is KNN based on in this methodology? If KNN uses Euclidean distance for finding h (in Eqns before Eqn 1), why is cosine similarity the best option for computing the similarity in the next step? Why not use Euclidean itself?\n\nThe paper builds on an interesting idea, but may benefit from a thorough revision with these concerns in mind. I will wait for the author's comments to decide further.\n\nOther minor comments:\n\n- Some of the important details of the methodology, including certain details of training used, are in the appendix and not the main paper. The paper could be organized better to ensure all relevant details to understand the methodology are in the main paper.\n- The notations should be consistent across the figures and text. In Fig 2(a), the average label is \\hat{y\\prime}_{FL} as per the text, while its marked \\hat{y\\prime} in the figure. \n- In Section 2, in line 3 of the subsection titled Problem 1., there seems to be a typo in the definition of D^{(t)}: {(x, y)}_i instead of {(x, y)}_*t*.\n"}