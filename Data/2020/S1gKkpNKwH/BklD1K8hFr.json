{"rating": "3: Weak Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "The authors propose to construct reinforcement learning policies with very few parameters. For this purpose, they force a feed-forward neural network to share most of its weights, reducing the total number of different weights to at most 23 and therefore compress the network. Instead of manually encoding which weights are shared, the authors propose to use a reinforcement learning method to learn this mapping. The values of all parameters are learned with a gradient-based method.\n\nThe paper is very well-written. The concepts are easy to follow, the related work covers a lot of different but related domains. The experimental section sheds light on some important aspects. However, I have few concerns regarding Table 2.\n\nTable 1 considers more tasks than Table 2. Why did you decide to use only a subset and why these tasks? The architecture of the FFNN is not part of your search space but you admit it is very important. For the experiments you chose a FFNN with one hidden layer. Furthermore, you manually adapted the number of partitions. Would fixing the architecture to one hidden layer work in general? How do you select the number of partitions? Both these choices seem crucial and to invalidate the automation aspect. You select the best run of 300. Do your baselines follow a comparable setup? What if you compare mean rewards? The discussion of random partitions is very important and it is nice to see that you discuss this in Section 4.3. As you mentioned, in NAS random search is a strong competitor. Therefore, this method deserves to be added to Table 2 as well.\nConcluding, this is an okay paper with limited innovation. The comparison to baseline need to be improved or at least justified."}