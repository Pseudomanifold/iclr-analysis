{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "This paper proposes a way to utilize the domain hierarchical structure information to help the general multimodal I2I (called joint multi-domain and multi-modal in the paper). The proposed method applies the hierarchy-regularized learning to learn the nested distributions which are reasonable for the data with a well-defined hierarchical structure.\n\nPros:\n1. The proposed method shows the ability to learn the nested distributions with the help of hierarchical structure information. It is a reasonable way to model the general multimodal I2I. I think the authors work in the correct direction.\n2. To model the partial order relation in the hierarchy, the authors borrow the thresholded divergence technique from the natural language processing field (Athiwaratkun & Wilson (2018)) and use the KL divergence considering its simple formulation for Gaussians. It sounds reasonable and may benefit other related CV tasks.\n\nCons:\n1. The detailed method description is very confusing to me. In section 3.1, it is mentioned that the proposed \u201cmethod only contains one pair of encoder and decoder for multi-domain X^l_i\u201d, which sounds like there are many pairs of encoder and decoder. While in the following description \u201cusing G to output the target image x^l_(i\u2192j) = G(c_i , s^l_j )\u201d, which sounds like use one shared generator.  I wonder if it is the case that there is one shared encoder, one shared decoder, but there are different branches for different sub-domains in the domain distributions modeling module?\n2. It is mentioned that the penalty between a negative pair should be greater than a margin m. While this important parameter as mentioned in A.2 is not described in the main paper.\n3. It is mentioned that \u201cIn the extreme case, every instance is a variation mode of the domain-specific information.\u201d It is the case in the ICLR19 paper \u201cExemplar guided unsupervised image-to-image translation with semantic consistency\u201d which uses one exemplar to achieve the general multi-modal I2I. I wonder what are the advantages and disadvantages of learning the distribution and using the exemplar directly. Besides, if there is no well-defined hierarchical structure, is there any way to apply the proposed method?\n4. As to the evaluation, although the authors provide quantitative results by different metrics, a user study evaluation would be good. \n5. As to the visualization results, there are still many noticeable artifacts in the results. Maybe the nested distributions are too complex to learn in this framework.\n\nMy initial rating is on the boardline."}