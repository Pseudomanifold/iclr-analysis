{"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "Thank you for your submission.\n\n- What is the specific question/problem tackled by the paper?\n\nThe paper proposes a VAE architecture to learn causal relations and allow for interventions. The architecture requires knowledge of the causal graph, and the direction of the causal arrows are inferred by comparing the log-likelihoods of generated images. The architecture may also require knowledge that an arrow exists between two vertices. This relies on the principle that \"low-capacity\" neural networks can predict better along the causal arrows (with the cause as input and the effect as the output) than in the opposite direction (with the effect as input and the cause as the output).\n\nThe paper focuses on the graph (A, B) where one wants to understand whether A causes B, or B causes A. The paper also discusses intervening in this graph.\n\nThe paper uses a new dataset for evaluating the approach, based on simple Newtonian systems. \n\n- Is the approach well motivated, including being well-placed in the literature?\n\nI think the motivation is adequate, but the review of the literature glosses over related work (or the absence thereof) in predicting the direction of arrows in causal graphs. The comparison of the proposed dataset against existing ones is missing.\n\n- Does the paper support the claims? This includes determining if results, whether theoretical or empirical, are correct and if they are scientifically rigorous.\n\nThe procedure for determining whether A causes B (or B causes A) is qualitative. The paper demonstrates that the performance gap between the correct and incorrect explanations is consistently distinguishable across multiple experiments.\n\nVisual inspection of the generated images is also used for assessing the quality of the models.\n\nBecause the results are qualitative, the support for the claims is not as strong as it could be (with quantitative results).\n\n- Summarize what the paper claims to do/contribute. Be positive and generous.\n\nThe paper has two main contributions:\n* Evidence to the Independent Mechanism principle (in a setting different from Bengio et al.'s transfer setup).\n* A new dataset for evaluating learning causal arrows (with accessible ground-truths).\n\nI think these are interesting contributions.\n\n- Is the paper clearly written?\n\nThe paper has a number of grammatical errors that should be fixed.\n\nThe explanation of how the latent interventions are made is important and should be included.\n\n- Clearly state your decision (accept or reject) with one or two key reasons for this choice.\n\nI vote for a weak accept.\n\n- Provide supporting arguments for the reasons for the decision.\n\nI trust that the writing issues will be addressed in due course, but I am also concerned about the fact that evaluations are qualitative. The qualitative results provide support for the contributions that could be strengthened. \n\nThe dataset is also an interesting contribution and it is a good idea to give it visibility. For this, though, it is important that the paper assess its strengths and limitations in comparison to alternative datasets.\n\n- Provide additional feedback with the aim to improve the paper. Make it clear that these points are here to help, and not necessarily part of your decision assessment.\n\nI am not convinced that mentioning Kolmogorov complexity is an efficient use of the space. I think the content could be improved by making the motivation section more concise and adding a few more experimental results or discussion.\n\nWhich discussions would be good to have? I think it should be noted that the intervention on effect should behave as demonstrated (creating implausible scenarios). Also some more development on the spring example: What is the right causal graph for it, and can the arrows in that graph be learned?\n\nQuantitative results would also improve the paper. Maybe decide between A->B or A<-B based on a statistical test?\n\nYou give an example about elephant-grassland association. Please cite a source for that.\n\nSuppose that both likelihoods for A->B and B<-A are about the same. How do you decide if your model is too rich, or if there's no relationship? (This is an important question to understand if the method requires knowledge that an (A,B) arrow exists or not.)\n\nThe panels in Figure 5 do not support the claim. The simple net gets better at the cause, but in some cases the rich representation does a better job at the effect.\n\nI think the physics dataset is also a contribution, so its originality & impact should be discussed in comparison to related work. Why is this an adequate benchmark? How does it address limitations of other benchmarks that could be used to evaluate proposed solutions for the problem in question?\n\nIn summary, my suggestions for improving the paper are:\n1) Make sure & demonstrate (by adequate discussion of related work) the originality of the contributions:\n1.1) The method for detecting the direction of causal arrows.\n1.2) The dataset as a benchmark for the problem being studied.\n2) Report quantitative results across the dataset and maybe across multiple setups for each name/physical law, with good coverage. You may consider a test set where the parameters are within the sampling range of your training set, and also outside the sampling range (where success of the method would be even more interesting). "}