{"rating": "3: Weak Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "The paper proposes a new intensity-free model for temporal point processes based on continuous normalizing flows and VAEs. Intensity-free methods are an interesting alternative to standard approaches for TPPs and fit well into ICLR.\n\nThe paper is written well and is mostly good to follow (although it would be good to integrate Appendix A.1 into the main text). The paper proposes interesting ideas to learn non-parametric distributions over event sequences using CNFs and the initial experimental results are indeed promising. However, I found the presentation of the new framework and the associated contributions somewhat insufficient.\n\nThe proposed approach seems to consist mostly of applications of existing techniques and of only few technical contributions. There is also no real theoretical analysis of the advantages of the new approach beyond general statements. In addition, the experimental analysis is missing comparisons to\n- other intensity-free methods (e.g., [1, 2]) \n- other NeuralODE based methods (e.g, [3, 4]) \nand would also benefit from a closer analysis of the models advantages and/or additional tasks. While each of these points on its own would not be very severe, I found that the combination of all of them is problematic in the current version of the paper. I hope that the authors can address this in their response or future revision.\n\nFurther comments:\nThe results on Breakfast of the competing methods seem quite lower than the results published in (Mehrasa 2019). What is the cause for the differences here? For instance, APP-VAE in (Mehsara 2019) would outperform the results of PPF-P both in terms of LL and MAE (142.7 vs 204.9)?\n\n[1] Xiao et al: Wasserstein Learning of deep generative point process models, 2017. \n[2] Xiao et al: Learning conditional generative models of temporal points processes, 2018. \n[3] Chen et al: Neural Ordinary Differential Equations. \n[4] Jia et al: Neural Jump Stochastic Differential Equations"}