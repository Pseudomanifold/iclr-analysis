{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This paper studies the forgetting problem in the pretrain-finetune framework, specifically in the dialogue response generation task. It proposes a mix-review strategy to alleviate the forgetting issue. The paper makes three major claims:\n(1) In the finetuning stage, the model forgets part of the language generation skills acquired during pretraining. \n(2) The proposed mix-review strategy effectively alleviates the forgetting problem.\n(3) The proposed method performs better in terms of context-sensitivity and knowledge transfer.\n\nAlthough the forgetting problem pointed out by this paper is interesting and worth studying,  the proposed method (1) lacks novelty and (2) does not perform well empirically.  The writing of the paper also needs to be improved.\n\nThe proposed mix-review strategy is very straightforward and lacks novelty. To prevent catastrophic forgetting, the simplest way is to sample some data from the historical task and jointly train with the new task, which is exactly the proposed method. It is not surprising using this strategy alleviates the forgetting problem, but the question is whether it can make the model generalize better. Empirically, it does not perform better compared with the commonly-used weight decay regularizer. In Table 2, we can see the proposed method didn\u2019t improve much in terms of either perplexity or human evaluation.\n\nThe two analyses are also not convincing to show mix-review performs better. For example, in terms of context-sensitivity, the increase in perplexity after distort the context does not necessarily mean the model\u2019s generation is more context-related.  Overall, the contribution made by this paper is not yet enough for an ICLR publication."}