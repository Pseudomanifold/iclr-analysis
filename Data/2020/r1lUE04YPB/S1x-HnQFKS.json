{"rating": "3: Weak Reject", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "The paper studies the forgetting problem in the pretraining-finetuning framework common to neural language generation models. It makes two main contributions: (1) it analyzes the forgetting problem from the perspective of \u201ccontext sensitivity\u201d and \u201cknowledge transfer\u201d. (2) In light of these analyzes, it proposes the Mix-Review fine-tuning strategy, which slightly outperforms the Weight Decay (WD) method of [Wiese et al., 2017].\n\nStrengths:\n\n(1) The paper addresses an important problem, as a very large body recent work relies on BERT, GPT-2, and related approaches to improve their models on specific tasks. The problem with these pre-trained approaches is that they bring challenges similar to those pertaining to continuous learning that have been studied for many years, e.g., (catastrophic) forgetting. There is a need to study the forgetting problem specifically in the context of the pretraining-finetuning framework and compare it approaches borrowed from the continuous learning literature, which the paper does to a certain extent (the WD method).\n\n(2) The paper shows some nice empirical gains (though results are mitigated by weakness 2 below) and a better ability to \u201ctransfer knowledge\u201d between the pretrained model and its application to the downstream task. \n\nWeaknesses:\n\n(1) The approach of the paper (Mix-Review) is very similar to methods that have been proposed already, and the papers doesn\u2019t acknowledge the huge body of prior work already existing on (catastrophic) forgetting. See [Kemker et al., 2017] for a comprehensive overview on the subject. There are multiple families of methods to mitigate the forgetting problem, including regularization methods, rehearsal (and pseudo-rehearsal) methods, ensemble methods, etc. Mix-Review belongs to the rehearsal category, as it reintroduces instances learned long ago (in the case of the paper, pretraining instances) to the current training regime. There is also a large body of work on rehearsal/pseudo-rehearsal going back to [Robins, 1995]. Robins\u2019 method that seems the closest is \u201crandom rehearsal\u201d, which as in the paper mixes randomly selected instances of the older data. See my detailed for other weaknesses in related work.\n\n(2) Experimental results are not convincing. First, results of Figure 1 mainly show that Mix-Review is less prone to \u201cforgetting\u201d than WD, but I find that unsurprising. At the risk of sounding obvious: The notion of forgetting only makes sense in the context of information (here, pretraining instances) that has been seen in the *past*, but those instances continue to be shown to mix-review in the *present*. Contrasting rehearsal methods to non-rehearsal in this manner is akin to comparing training-set perplexity with validation-set perplexity (i.e., in one of the two cases, we compute perplexity on what we are currently training on). So, to me, figure 1 doesn\u2019t tell us very much, and approaches should be mainly evaluated on a downstream task (which the authors do in table 2). \n\nUnfortunately, in the case of table 2, mix-review doesn\u2019t show much gain when compared to the standard WD (aka EWC) method. There is a small gain that seems to be within the confidence intervals (assuming that is what is shown in parentheses). Now, my problem with these results of table 2 is this quote from the paper: \u201cAlthough the perplexity is still improving, we stop the pre-training for practical reasons to control the duration of the experiments.\u201d  The difference between the baseline and the other systems shows that pretraining is very useful to all 3 downstream tasks, but this performance of the various models could be highly dependent of when the authors applied early stopping. Now, the actual issue is that early stopping is NOT applied consistently between WD and mix-review, as the WD approach has seen the pretraining data only 20 times (\u201cwe stop the pre-training after the CCNEWS data is swept 20 time\u201d), but mix-review continues to be shown CCNEWS data even after 20 epochs, so there is effectively no early stopping for mix-review.\n\nConclusion:\n\nOverall, I think the paper has merits in showing that rehearsal methods should probably be explored in the context of pretraining/finetuning architectures, but problematic experimentation and lack of comparison with previous work (there is only one baseline, WD, which is not enough to me given all the prior work on the subject of forgetting mitigation) make me recommend rejection for now. \n\nDetailed comments:\n\nThe reference to WD is [Wiese et al., 2017] is not the right one. Wiese et al. give credit to Kirkpatrick [2017] for their Elastic Weight Consolidation (EWC) method as WD is a special case of EWC. EWC has been widely used to mitigate the forgetting problem and is not mentioned in the submission. \n\nThe mix-review training objective contains a mix-decay parameter, which is unclear as it doesn\u2019t seem to appear in any of the equations (was it meant to be in Eq. 2?). In any case, for the paper to be of practical importance, I think it should show the effect of pre-training data percentage over time. It seems it starts with a high proportion of pre-training data, which could be wasteful as fine-tuning starts off by utilizing mostly pre-training instances. This gets fixed over time thanks to the mix-decay parameter, but as repetitive decaying of the pre-training data occurs, that pre-training data essentially vanishes to ultimately be empty. What prevents catastrophic forgetting in that case, after many epochs? Other methods borrowed from the catastrophic-forgetting literature wouldn\u2019t have this problem. It seems the choice of how long we let the model train could have a significant impact on how much the model forgets. \n\n[Kemker et al., 2017]: Measuring Catastrophic Forgetting in Neural Networks\t\nRonald Kemker, Marc McClure, Angelina Abitino, Tyler Hayes, Christopher Kanan\t\nhttps://arxiv.org/abs/1708.02072\n\n[Kirkpatrick, 2016]: Overcoming catastrophic forgetting in neural networks\nJames Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A. Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska, Demis Hassabis, Claudia Clopath, Dharshan Kumaran, Raia Hadsell\nhttps://arxiv.org/abs/1612.00796 \n\nPlease refer to Kemker et al. for other references mentioned in my review, as they sum up some of the large body of work done in that space.\n"}