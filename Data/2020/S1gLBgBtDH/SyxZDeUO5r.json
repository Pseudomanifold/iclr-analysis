{"rating": "3: Weak Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #4", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review": "Summary:\n\nThe paper provides a description of a new framework for reproducible and efficient RL experiments, as well as benchmarks of many algorithms on popular environments, such as `Atari and Roboschool. \n\nPros:\n- I agree that reproducibility is an extremely important question for the RL research, and thus such a code library is very beneficial for the community.\n- The library is well designed, and allows for creating extensions rather easily in the future.\n- Benchmarks are quite extensive and instructive.\n\nCons:\n-  Comparison with the library [1] is missing (see also [2] for description and benchmarks). As both libraries are focused on reproducibility and flexible implementations of algorithms, such a comparison would support authors claims.\n- I am not sure that ICLR is the right venue for such paper. Perhaps a more specialized conference of a workshop would be better.\n- Anonymity violation\n\nQuestions:\n- How difficult it is to implement distributional algorithms in your framework?\n- What about different exploration strategies? (Boltzmann, epsilon-greedy, parameter noise etc.). I guess it should be quite easy to make it configurable as well\n\n\n[1] https://github.com/catalyst-team/catalyst\n[2] https://arxiv.org/pdf/1903.00027.pdf\n"}