{"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "Authors suggest a novel method for pairwise text classification, hand engineered for a patent inventor match system. The idea is that each pixel is assigned to a character. Then for every bi-gram of a word color the pixels connecting those two pixels with a fixed color (green for one author, red for the other). color the first bigram in blue. Then add these two together. train a cnn on top. They achieve results in the ballpark of ther random forest or rule based methods.\n\nOne immediate question is that why is this a sensible idea?! The use case of convolutions in image processing is based on the fact that a shape happening in one location of the image is the same as if happening in the other part. Essentially image processing should be translation invariant (a ball is a ball no matter where in the image). Where as in here your grid position have specific meanings. So a green line in the top of the image has a very different meaning than a green line in the bottom.\n\nThere is no explanation for why not using a text based classifier as in the models used in GLUE tasks rather than transforming the text into an image. What is wrong with using a text based classifier? Why images?\n\nWhy stacking the two images as different color channels rather than using a siamese network? No justification is provided in the paper. When you stack them together the channels get compared and smashed together with each other at the first  CNN level. Where as typically one uses a CNN to get some level of abstraction and feature extraction. So makes sense to process each image separately for some layers then merge them together when comparing two images.\n\nHow exactly the bigrams are connected is not well defined. It is only mentioned with a straight line. For example, in the \"EN\" image of Fig. 1, why U is colored and not B? There are several shortest paths in each image. \n\nThe numbers reported in the experiments are close to each other. STD of the experiments has to be reported.\n\nTable 2 is not clear why \"Ours\" does not have the dataset name? Other methods are reported on IS or E&S. Which one is Ours reported on?\n\nThe paper does not provide justification for the main idea and several design choices. Experiments are also limited to one patent inventor classification. It would be more of an interest to report on a GLUE text classification task (https://gluebenchmark.com/tasks)"}