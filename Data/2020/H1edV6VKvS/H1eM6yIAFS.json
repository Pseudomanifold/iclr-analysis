{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The authors of this paper introduce the concept of proximal mapping from sparse representation  to supervised and unsupervised structures, aiming at learning structured representations. It generalize dropout and invariant kernel warping, and applied in multiview learning and sequence modelling. Generally speaking, without sufficient background knowledge, it is difficult for a reader to understand the major contributions of this paper, due to unexplained terms and notations. For example in the second paragraph of Section 2, I think x in activation functions should correspond to z in Equation (1) in some places. Thus, the authors are suggested to improve writing to clearly show the idea without too much mingling with specific techniques. Visual examples, such as Figure 2, do help.  Moreover, it is unclear how structured representation is defined, and how structured representation is learned by prox-map.  Finally, experimental results do support that the introducing prox-map in various neural networks improves performance. "}