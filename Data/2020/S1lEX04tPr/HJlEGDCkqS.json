{"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review": "This paper presents a method for adding credit assignment\nto multi-agent RL and proposes a way of adding a curriculum\nto the training process.\nThe best heuristics and structures to incorporate in the\nmodeling, learning, and exploration parts of multi-agent\nRL are still largely unknown and this paper explores some\nreasonable new ones.\nIn most of the tasks this is evaluated on in Figure 5\nthis approach adds a slight improvement to the SOTA\nand I think an exciting direction of future work is\nto continue pushing on multi-agent RL in even more\ncomplex envirnoments where the SOTA break down in\neven worse ways.\n"}