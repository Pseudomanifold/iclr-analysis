{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "The main idea of the paper can  be totally described in one line: perform adversarial\nperturbation of the query image rather than the 'k-shot' example\nimages. (Algorithm 3 of their paper.)\nThe paper first nicely motivates the need for robustness in the few-shot learning setup and why existing robust training methods are inadequate.  In the context of four existing meta-learning algorithms, they present evaluation of adversarial fine-tuning on robustness.  They conclude that adversarially perturbing only the input images used during fine-tuning is not effective as perturbing the query images used in the outer meta-learning loop.  Experiments all throughout are on two datasets Omniglot and mini-imagenet.\n\nStrengths:\n      - Systematically layout of  experiments on what kind of perturbations are most relevant for robustness\n      - One of the first papers to take on the problem of robustness in few-shot learning.\n      -  Clear writing.\n\nWeakness:\n      - The depth and extent of contribution falls short of the requirements of the main ICLR conference track.  The layout of the paper so that adversarial querying is brought out as a contribution of the paper was a bit surprising.   The natural 'porting' of adversarial training to meta-learning would include adversarially perturbing all the input instances: the ones used for fine-tuning and the ones used in the outer loop of a meta-learning algorithm.  The paper differentiates these, and calls the later  as query images.   Subsequently, it first decides to dwell on methods that do not perturb the inputs of the outer-loop.  I find that an artificial distinction.  \n\n     -  For a paper that is primarily about empirical comparison of different options,  more ablations across dataset, architectures, and training sizes are required.\n\n"}