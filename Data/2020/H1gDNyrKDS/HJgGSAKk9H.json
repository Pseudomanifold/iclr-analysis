{"experience_assessment": "I do not know much about this area.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "N/A", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This paper seeks to understand why Differential Architecture Search (DAS) might fail to find neural net architectures that perform well. The authors perform a series of experiments using different kinds of search spaces and datasets, and concluded that a major culprit is the discretization/pruning step at the end of DARTS. To avoid this, the authors propose early stopping based on measuring the eigenvalue of the Hessian of the validation loss. The results look promising (though as someone who is not familiar with the datasets, I don't have a sense of the significance of improvements.)\n\nIn general, this is a strong paper. I enjoyed reading it. It describes the problem clearly and performs a set of convincing experiments to support the claims. I especially like how different constrained search spaces are investigated, as this makes the results easier to interpret. I think the analysis in this paper will benefit researchers who work on similar problems. \n\n"}