{"experience_assessment": "I do not know much about this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper describes an approach to detect and localize anomalies in images. A VAE based architecture is used with some fittings to \n\n1) Sharpen blurry output of VAE (with an adversarial loss)\n2) Detect and localize anomalies with what they call the guided attention loss (this is the principal novelty it appears)\n\nThe guided attention loss is obtained from an externally trained network (Grad-CAM, Selvaraju et al). They consider two cases, one with 'normal' (non anomalous) images, which is totally unsupervised, while the other case is weakly supervised with some images with anomalies in them, where the attention loss is designed appropriately to handle the two cases. \n\nComparisons are made using 4 different datasets and metrics (e.g. IoU, accuracy of correctly classified anomalous images), and it is shown that their attention based model outperforms the state of the art. \n\nMy thoughts:\nIt makes sense, loosely speaking, that an attention based model would perform better than one without, enabling it to focus on regions of interest. The paper generally makes this point clear with results. However, I feel that the prior work is not very well described, and the basic idea that an AE architectures are usable for the anomaly detection task because its performance would be worse on images it has not seen (anomalies) is not immediately obvious. \n\nI am ambivalent about accepting this paper until we have a better coverage of related work. "}