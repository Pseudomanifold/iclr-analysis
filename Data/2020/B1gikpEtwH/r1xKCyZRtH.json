{"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "This work proposes a convolutional adversarial variational autoencoder trainable end-to-end, which employes attention to localize non-normal regions on the images (i.e., anomalies). Authors propose two different frameworks: unsupervised and weakly supervised. For the first one, authors build upon existing techniques (VAE + an adversarial loss to avoid the generation of blurry images), and incorporate an attention loss to encourage the attention maps to cover all the image regions (assuming that training is done only with normal images). For the weakly-supervised setting, authors employ few non-normal images and normal images to train a classifier that will trigger the activation maps on those images, depending on normal vs anomaly detection. Authors compare to some state of the art methods and show improvements with respect them. \n\nStrengths:\n- The paper is well written and easy to follow.\n- The methodology is sound.\n- Results seem to be competitive\n\nWeaknesses:\n- Technical contribution is rather limited, particularly in the unsupervised regime (authors basically add an attention loss term)\n- I feel comparison with some other related works is needed. Authors employ the same table as in Bergmann et al, CVR 2019. But what about comparing to Myronenko, 2018, for example, since this work seems to be related?\n\n\nPlease find below my comments.\n\n- As I mentioned, the contribution is incremental wrt previous works in the unsupervised setting.\n- How class imbalance is handled in the weakly supervised setting? It is weakly supervised for detection of anomalous regions but semi-supervised for classification at image-level.\n- Please cite Kingma and Welling, 2013 correctly: \u2018Diederik P Kingma and Max Welling. Auto-encoding variational bayes. International Conference on Learning Representations (ICLR), 2014.\u2019\n- Please include mean values in all the Tables to better compare to other methods.\n- Ablation study (e.g. Table 5) needs to be improved. In addition to include mean values for better interpretability, if I understood correctly the first column is the baseline model, while the he third is the proposed model. Nevertheless, it is not very clear what authors want to show in the second column. Which is the difference of the second model wrt to the first one? Does it have also attention (second column)? Authors need to extend a bit the ablation studies to: 1) make more clear each model and 2) show the impact of each element on the final performance. Same thing for the second part of Table 6.  Which is the impact of adding only adversarial reconstruction loss? And if only SGB is used? \n- I think that showing also visual examples of the models with and without the attention loss and SGB will be very helpful to understand the real impact/performance of each of them. Looking at the visual examples it seems that the proposed methods greatly outperform others (from sparse areas to compact ones). However, it is not clear to me from where this improvement is coming from.\n- Does the selective gradient back propagation technique simply consists on not back-propagating when the prediction is wrong? "}