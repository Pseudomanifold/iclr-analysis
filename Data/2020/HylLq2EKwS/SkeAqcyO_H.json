{"rating": "6: Weak Accept", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review": "The paper is essentially an attempt to incorporate a form of reinforcement learning into recommender systems, via the use of a synthetic feedback loop and a \"virtual user\".\n\nOverall this seems like a nice attempt to combine Inverse Reinforcement Learning frameworks with collaborative filtering algorithms.\n\nWithout a background in reinforcement learning, it was difficult for me to assess exactly how this compares to similar reinforcement learning work, or exactly how \"obvious\" the technical contribution is.\n\nNevertheless combining reinforcement learning with recommender systems is a topic of growing interest, and it is nice to see a paper in this space that makes a contribution with strong quantitative experiments, i.e., it is able to compete with (reasonably) strong baselines.\n\nThe experiments mostly look good, with a few representative, and quite large, datasets. The baselines are perhaps not state-of-the-art but represent reasonable points of comparison and are enough for a proof-of-concept. The paper is quite thorough in terms of experimental comparisons.\n\nOverall this seems like an interesting approach and a reasonably timely paper, making what seems like a compelling contribution to a current hot topic, and passes the bar in terms of experiments. Regarding the merits of the technical contribution, I'll perhaps have to defer to other reviewers, but overall the contribution seems above the bar."}