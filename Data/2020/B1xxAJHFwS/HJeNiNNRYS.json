{"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "N/A", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper introduces a finite time analysis of Q-learning with neural network function approximators across multiple layers and no iid assumption. \n\n[Pros]\n+ Provides a novel way to analyze Q learning with nn function approximators that can be applied to other algorithms (notably in my mind, TD in actor critic where iid assumptions are often violated). \n\n[Cons]\n+ The novelty is a bit unclear other than the non-iid assumption. We note that modern Q-learning tends to use batching so doesn't require much of an iid assumption anyways, but this allows for more robust proofs in TD settings with non-iid training.\n+ The paper was a bit dense and hard to follow, we suggest reducing p.8 to have more discussion with references to proofs in the Appendix as in Chen2019. \n+ As the authors admit in open commentary, there is a mistake to be fixed which needs to be reviewed before acceptance. I think there is value to this work, however, would require seeing the change to assess a revision.\n"}