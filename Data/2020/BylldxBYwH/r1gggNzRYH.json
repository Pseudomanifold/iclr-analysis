{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "Summary:\nThis paper proposes a physics-aware variant of a U-Net network for completing missing flow field data. Most notably, the loss functions are motivated by fluid dynamics, which forces the network to remain more consistent with the governing laws.\n\nDecision:\nI found the paper and the idea very exciting. Injecting domain knowledge by forcing the output (or differentiable transformations thereof) to be consistent with the physics is a quite relevant and appealing idea, for which this paper constitutes a nice proof-of-concept. Framing the problem of completing missing flow data as an inpainting task is also original. However, the evaluation of the method does not study important aspects regarding its generalization. The description of the experimental protocol is also missing important information.\n\nFurther arguments:\n- I found the discussion in Section 4.2 around method (b) not convincing. I do not understand why the network should be penalized if it does not reproduce the mistakes of the original simulator/solver. Since `div u` should be 0, why not simply penalizing ||div u|| instead of having the loss of Eqn. 8? Isn't approach (b) the approach which is most 'physics-aware' and correct from a physics point of view?\n- The experiments do not highlight whether the network actually just learn the training distribution or generalize by \"understanding\" the physics of the problem. A compelling experiment would have been to evaluate whether a network trained on a prior family of obstacles transfer properly to a different family (e.g., training on 6 spherical and 6 rectangle obstacles, but testing on fewer/more obstacles with other shapes).\n- Similarly, could the network generalize to larger/smaller inputs? Once trained, can it work on grids smaller/larger than 128x96? If not, what do you recommend to do in practice?\n- The description of the experimental protocol does not specify whether the method was evaluated on independent test data. More worrisome, section 4.2 even states that the MAE for Figure 2 is computed \"over the whole dataset\".\n- The method is not compared against any domain specific baseline. \n- While quite exciting, I am not confident the contribution is original enough from an ML point of view for ICLR, although it is certainly novel for fluid dynamics.\n\nAdditional feedback:\n- Some results reported in Table 1 are quite close of each other. It would have made the experiments much stronger if uncertainties were also reported and discussed.\n- Fig 3: I would have liked seeing the error maps of the methods. This would have been quite helpful to better tell them apart.\n- Given my comments above, I am confident an 8th page could be put to good use.\n"}