{"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "Authors combine different adv detection schemes to detect adv examples. In cases that their approach has failed they perform a human study and conclude that those examples are misclassified by humans as well thus deflecting adv attacks. \n\nAlthough combining existing adversarial detection methods are interesting but I think the paper lacks novelty. Also the work is motivated by stating that stronger attacks can break the defenses that are not certified. But isn't it the approach taken in this paper? How do we know other attacks would lead to the same empirical results as reported in the paper?  "}