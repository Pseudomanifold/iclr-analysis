{"rating": "3: Weak Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This paper does an in-depth evaluation of the notion of rewinding pruned networks to the weights at a previous point in training, and then re-training the pruned network from then on. This is in comparison with fine-tuning a pruned network, where the retraining continues from the network's current weights. The authors focused on vision networks and unstructured magnitude pruning in their evaluation.\n\nThe paper is well-written and easy to follow, and the authors have done a good job of empirically comparing rewinding against fine-tuning in a number of different scenarios.\n\nMy main concern with the paper is that it seems too incremental to stand on its own. Rewinding is a notion that was already explored in the Lotter Ticket Hypothesis (Frankle et al., 2019), so this paper seems to be more of an extension of that work. The take-away message from this paper (stated by authors in their conclusion) is that practicioners \"should explore rewinding as an alternative to fine-tuning for neural network pruning\", but that's a case that was already made by the LTH paper. The current work certainly gives more weight to that claim, but I don't feel the contributions are strong enough on their own to justify a full conference publication.\n\nI encourage the authors to continue working on this, as it is very interesting and can be very useful. Some ideas to make the paper stronger:\n- Given that this is a purely empirical paper, it'd be better to not limit the experiments as much. Can you run on non-vision networks? What about mobile-net? Can you try different pruning techniques? etc.\n- How do the different methods compare in terms of accuracy/sparsity versus FLOPs?\n\nFinally, two minor comments to improve the writing:\n- First sentence of 3.1: s/that meet that the accuracy/that match the accuracy/\n- First sentence of 3.1: s/than fine-tuning can/compared to fine tuning"}