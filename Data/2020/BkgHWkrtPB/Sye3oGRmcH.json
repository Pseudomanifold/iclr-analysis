{"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "Summary of the paper:\nThis is a theoretical paper that builds on top of Achille and Soatto (2018), Achille et al. (2019), McAllester (2013), and Berglund (2011),. The paper attempts to answer the relationship between the inductive bias of SGD, generalization of DNNs, and the invariance of learned representation from an information theoretical point of view. \nThe paper mentioned many interesting links. In my opinion, the contributions are the following:\n1. Invoking the theoretical result of Berglund (2011) to justify why Fisher information is relevant -- SGD tends to avoid local minima with high Fisher information. \n2. Relating the Fisher information and the stability of SGD to I(w; D).\n3. Introducing the definition of effective information in the activation, and show that which is closely related to the Fisher information. \n\nAbout the rating:\nThis is basically a good paper but I have a few concerns: \n1. A large fraction of this paper are taken from Achille and Soatto (2018), Achille et al. (2019).  \n2. In terms of impact, the paper is somehow incomplete -- it only demonstrates that the Fisher information is important, but the insights didn't lead to any substantial improvement over the current deep learning framework. \n\nDetailed comments:\n1. In my opinion, defining \"information in the weights for the task D\" by KL(Q||P) is inaccurate. \nThe weights themselves are information, which form a representation or a lossy compression of the data (which is also an information). \nAccording to the rate-distortion theory, what we care about is the amount of information the representation attains rather than \"where\" the information are. Therefore, we should talk about \"rate\" or \"amount of information\" or \"mutual information\" rather than \"information\" itself.\nA missing reference regarding this point: \nHu et al. \"\u03b2-BNN: A Rate-Distortion Perspective on Bayesian Neural Networks.\" 2018,\nwhich derives the information Lagrangian directly from rate-distortion theory. \n2. More discussions on Xu and Raginsky (2017) is expected, since it proposes to use I(w; D) as a generalization bound. It seems, in terms of generalization, minimizing I(w; D) is a sufficient condition while minimizing Fisher is a necessary condition.  \n3. There are in fact 4 key aspects: sufficiency, minimality, invariance and generalization. It would be great to have a theorem to summarize the relationships between them.  \n4. Could you elaborate on the footnote 3? "}