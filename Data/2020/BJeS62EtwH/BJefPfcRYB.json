{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "The goal of this paper is to analyze knowledge consistency between pretrained deep neural nets. In order to do so the paper trains neural networks to predict a hidden layer of one DNN using a hidden layer of another DNN. The model is interesting in that it is multi layer but it also allows decomposing its prediction as the sum of outputs of neural nets with different numbers of hidden layers. The prediction is dubbed \"consistent features\", which are further decomposed in consistent features of different complexity levels, while the error is dubbed \"inconsistent features\".\n\nThe paper then attempts to use this decomposition in \"consistent\" and \"inconsistent\" features in a number of ways. Assuming hidden layers of DNN A are being used to predict layer of DNN B, if A is stronger than B then the inconsistent features of B are claimed to be \"unreliable features\". If A is weaker, then the inconsistent features of B are claimed to be \"blind spots\". A figure is given to support this intuition, but I think some real evidence would have to be collected to support a claim like this.\n\nSimilarly the authors analyze model compression and distillation with their technique. They are able to show a decrease in the variance of inconsistent features as a models get progressively compressed or as a models get better during generations of distillation. Again the evidence that of the usefulness of this analysis seems very limited. The visualizations of consistent and inconsistent components don't seem to give any clear evidence.\n\nThe most interesting part of the paper shows experiments from boosting performance of a model by finetuning on features consistent with another model. None of the improvements seem close to state of the art though, and might just be some byproduct of model ensembling.\n\nOverall the paper is very interesting, but more convincing experimental results would have to be collected to prove that the method is actually useful."}