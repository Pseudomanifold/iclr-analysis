{"experience_assessment": "I have published in this field for several years.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "Distributed averaging algorithms (a.k.a. average consensus) have been thoroughly studied in the control and distributed systems communities. This paper proposes to learn a sequence of weight matrices for distributed averaging, by leveraging differentiable programming and stochastic gradient descent. The idea is natural to investigate, and the findings suggest that the proposed approach can indeed learn useful sequences of weight matrices, converging faster than repeatedly applying the same matrix (the more common \"static\" approach).\n\n1. That allowing to use a sequence of weight matrices leads, in general, to overall faster convergence is not so surprising. After all, the additional matrices provide additional degrees of freedom. The real challenge is how to design a sequence of weight matrices which, as rightly pointed in the paper, does not have a clean, convex formulation. However, there are two papers that have explored related a question:\n\nA Sandryhaila, S Kar, and JMF Moura, \"Finite-time distributed consensus through graph filters,\" ICASSP 2014.\n\nS Segarra, AG Marques, and A Ribeiro, \"Optimal graph-filter design and applications to distributed linear network operators,\" IEEE Trans Signal Processing, 2017.\n\nIt would be good to mention the relationship to these and possibly to also compare to the design approaches proposed there.\n\n\n2. There are some aspects of the experimental evaluation that could be improved.\n\n2a. Experiments are reported for Zachary's Karate network, a 2-d grid, and two families of random graphs, Barabasi-Albert and Watts-Strogatz. It would be interesting to try learning weights for graphs that are known to be harder for consensus. (See, e.g., A Olshevsky and JN Tsitsiklis, \"Convergence speed in distributed consensus and averaging,\" for examples)\n\n2b. Training and testing with the case where nodes are initialized with iid signals is not very interesting for this application. In a sense, all nodes are initialized close to the average. It also follows from the law of large numbers that each node only needs to average with a few number of neighbors to have a good estimate of the average. In the case of a \"static\" weight matrix, the worst-case initialization is given by the eigenvector associated to the second largest eigenvalue (in magnitude) of W. Have you tried using an initialization more like this, for training and/or testing? More generally, what happens if the initialization at test time is different from that used for training?\n\n\n3. I was happy to see that periodic extensions are investigated in Sec 3. Have you studied the impact of T? For the networks considered, I would guess that T=10 is not far from the diameter of the network (maybe it's even larger). What happens if larger or smaller T is used?\n\n\nBased on the above concerns, I recommend that this paper be rejected. The initial results are promising, but additional work is needed to strengthen the results. Even more compelling would be to \n\n\n\nMinor: \n- The paper mentions that \"It was recently shown by Kempton et al. (2018)...\". I believe the well-cited paper on \"Randomized gossip algorithms\" by Boyd, Ghosh, Prabhakar, and Shah also proposes a decentralized algorithm for solving the semi-definite program formulation of optimal weight design.\n\n- Why constrain/force the network weights to be symmetric? Other work has shown that using non-symmetric mixing weights can lead to faster consensus (but the design problem also becomes non-convex, and thus more challenging).\n\n- Why train in the incremental, layer-wise manner described in Sec 2.2? Did end-to-end training not work as well?\n\n- Why add the Frobenius norm regularizer? Why is any regularization needed at all here? Also, is the optimization process constrained to learn stochastic matrices?\n\n- Sec 3 mentions that \"the number of data-set per learning is set to 10000\". Is this the number of optimizer steps taken? Or are are multiple epochs performed over this data set? Is this the number of steps per layer, or total?\n\n- How are the weights W initialized in the experiments? Have you examined if the proposed approach finds very different solutions if started from different initializations, or if trained with different random seeds?\n\n- What value of \\lambda (regularization parameter) was used in the experiments? How sensitive is the performance to this choice?\n\n\n"}