{"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper proposes a novel way of reconstructing Granger causal structures using a differentiable neural network architecture that contains attention modules that are proportional to the Granger causality of the input layers. Furthermore, the architecture blends individual-specific induced causal structures and cross-population prototypical causal structures. The paper has an extensive experimental section on which the proposed method shows impressive improvements in causal discovery performance and predictive performance on par with state-of-the-art.\n\nAs main contributions the paper:\n* proposes a novel architecture \n* shows its values using extensive experiments\n\nOverall, I find the paper well-written with a clear description of the proposed architecture and clear experiments showing the importance of the architectural choices. A possible downside is the relative lack of novelty, since the method seems like a reasonable extension of the existing work. However, I think this counterbalanced by the excellent results on the causal discovery task and the extensive nature of the experiments.\n \nIn terms of suggestions, I think an illustrative example of the granger attention on an artificial / toy example would help a lot to give an intuitive understanding on how the method works and how the causal structure is being built.\n"}