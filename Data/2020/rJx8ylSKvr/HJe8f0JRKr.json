{"experience_assessment": "I have read many papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "In this paper, a method for leveraging entanglement entropy for understanding attention matrices is proposed. Specifically, the paper aims at solving two problems: 1) to study the theoretical analysis of entanglement entropy for the matching of two objects (question-answering pairs), and (2) to qualitatively calculate the matching matrix. The introduced approach is based on fundamental connections between the entanglement entropy and the attention matrix. The main goal of the paper is to show that a low-dimensional attention matrix can be derived from a high-dimensional matching matrix. Results are shown for a text matching task on two datasets (TREC-QA, YAHOO-QA). \n\nMy main concerns with this paper are that the approach is not well described and that the proposed contribution appears quite narrow. Overall it is not clear what the actual contribution of this work really is. Several sections of the paper appear convoluted and could be more concise; the text is often written unnecessarily complicated which makes it hard to follow and to comprehend details. While the experiments seem sound the overall improvement of 2.9% compared to SOTA work appear rather shallow. Therefore, in its current state I cannot recommend accepting this paper. \n\nDetailed comments: \n\n- The abstract of the paper is very cryptic and the motivation for the proposed approach is not sufficiently described. \n- The paper is not well-written and difficult to follow. Several sentences and sections are left too unclear. E.g. in the introduction sentences like \"... but such an indicator only reflects the intricate correlation structures of each single input object (e.g., an image or a text)\" or \"This is due to the fact that the tensor product occurs in the quantum many-body function for representing the image and text \" are confusing as they come without much context. \n- It is not clear what is meant by \"matching problem\".\n- A few sentences in the introduction are exact copies of the abstract, which makes the text appear redundant. It would help to clearly state what the contribution of this work is, instead of repeating sentences. \n- It is not clear what is meant by \"relatively-deeper\" and \"relatively-shallower\" layers.\n- The text shows several spelling and grammar issues (such as \"for the more complex the inputs\"). \n- Several sentences don't make sense and are difficult to read (e.g. \"Since our work is mainly for the text matching task of a sentence pair, we briefly introduce a recent Quantum Many-body Wave Function inspired Language Modeling\").\n- The notation and equations in Section 2 are mostly common knowledge and could be moved to the appendix. \n- In Section 3.1. what is meant by \"subsystem in deep neural networks\"? Later in the text in becomes more clear. So it would be helpful to rearrange the text. \n- \"probability amplitude distributions \" is not clear. \n- Sentences like \"which often correspond to the important information hidden in the matrix\" should be accompanied with a reference. \n- Section 3.2 is titled \"Network Design Based on Entanglement Entropy\", but the section does not actually describe a network architecture, but instead just describes how to obtain the attention matrix and the sample differences. \n- Section 4.1 (first paragraph): it would help to discuss the connection of many-body wave functions to represent questions and answer sentences as two subsystems more clearly and earlier in the text. \n- Section 4.2 (second paragraph) appears quite repetitive. Many sentences have been used in previous sections of the text. \n- The results and discussions shown in Sections 4.4 and 4.5 are interesting and seem sound. However, it is not clear what exactly are the \"adaptive settings for kernels\" (e.g. in Figure 2) \n- Limitations of the approach are not sufficiently discussed. \n- It is not clear what is meant by \"we will investigate the entanglement entropy under high-order conditions\" in the conclusion."}