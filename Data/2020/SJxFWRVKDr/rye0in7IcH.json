{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The authors consider gradients of some loss as a feature representation. The intro starts describing a form of classification loss, but this is switched to a GAE unsupervised loss in Eq. 1. In that section the authors somewhat show that a naive gradient representation does not work well, but at the same time show that it /may/ work with their method, introduced right after, and which consists in an \"orthogonality\" regularizer, introduced with any arbitrary loss later in Eq.3, and back to GAE in Eq.4. The authors evaluate whether this regularizer hurst reconstruction error \n\nI have found this paper interesting, but confusingly presented and still in a development phase (i.e. good idea, but not properly exploited yet). The premise on which the paper builds is that gradient information is more relevant than activations. Yet, this is only shown to be true if that gradient information is \"bent\" to follow a given orthogonality constraint in a fairly heuristic way (Eq. 4). Many choices are going under the hood:\n\n\"We train CAEs by setting \u03b1 = 0.03 and \u2126(z; \u03b8, \u03c6) = 0 in (4). This loss utilized for training is utilized as an anomaly score during testing but with the increased \u03b1 of 0.12\" \n\nThe sentence above is quite mysterious. The framework is tested with an anomaly detection task, which is a bit underwhelming, and to be frank, the results in Tables 3 or 4 (MNIST / CIFAR10) are not particularly convincing, specially when one factors the fact that \u03b1 has been strangely changed.\n\nBecause of this, I feel that overall the paper starts with a nice idea but has not reached yet the state in which it deserves being published.\n\nother comments:\n- I think it would help to formalize from the introduction what kind of gradient you are specifically referring to. Is it the gradient of the loss XE of the classifier w.r.t. an arbitrary label? although this is clarified later in the paper, the introduction is not informative enough (Fig. 1 is nice, but a proper statement is needed). In particular, gradients is presented as an alternative to Jacobians, but shouldn't it be some form of Jacobian (or collection of gradients)\n- in Eq. 1, why use *both* z and f_theta(x) in the same line, since they are equal? \n- Around Eq. 1, \"The training is performed by minimizing the loss function, J(x; \u03b8, \u03c6), defined as follows\". This is inacurate, J is not minimized to compute theta and phi: the sum over J(x_i; ...) is minimized. J is just an examplar loss. You minimize the expectation of J.\n- \"can be calculated through the backpropagation\" --> remove \"the\"\n- Your narrative in bottom of p.3 from \"We visualize the\" is a bit flawed: one could imagine an example where x_out ~= \\hat{x}_out, i.e. for which the loss L is small but the regularizer is large, or inversely one in which J is dominated by a small regularizer loss but where the loss L is large. So associating the size of the gradient of J to the departure from the manifold is misleading. It seems however that this is corrected later in p.5, in which you now allude only to d \\mathcal{L}\n- aren't there analogies with these gradients and Fisher score vectors in parametric stats? i.e. d log p_theta(x) / d theta ?\n- add more caption to Fig.3 describing what's going on, or at the very least a direct reference on the section / location in which the experiments are described.\n- \"with our proposed method which will be described in the following section\" : I would avoid this kind of \"movie\" narrative which tries to create a \"cinematic buildup\". Stick to scientific order, i.e. describe first method, test and experiment with it next.\n- \"is the primal loss for a given task\" --> supervised or unsupervised task?"}