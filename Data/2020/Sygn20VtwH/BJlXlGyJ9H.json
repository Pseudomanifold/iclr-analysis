{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "Summary\nThis papers proposes a recursive parameterization of gates in a recurrent model. Instead of directly conditioning gates on the input and previous hidden representation, the proposed model recursively calls itself to parameterize the gate. The recursion depth is dynamically determined (up to a predefined maximum recursion depth). The approach shows slight improvements over baselines on a range of tasks.\n\nStrengths\nSlight improvements on a wide range of downstream tasks\nQualitative analysis of dynamic recursion highlighting the adaptability of the method to different task properties\n\nWeaknesses\nFrom the equations in Section 2, I understand that a gate is conditioned not only on the input and previous hidden representation, but also the input and hidden representations from repeated application of the RNN cell for the given time step. As far as I understand, this is very closely related to ACT by Graves, Alex. \"Adaptive computation time for recurrent neural networks.\" 2016. They also have a dynamic way of determining how many recursive RNN cell applications per step should be performed.\nI am missing a clear description of differences of the proposed approach to the baselines tested in Section 3. At some point it is mentioned that a different optimizer was used (R-Adam). Are there any other confounding factors? I believe it is important to get clarity on these given that the difference between the model and baselines are very small.\nResults in Table 1 are highlighted in a misleading way. For example, stacked BiLSTM do as well for tree traversal (EM, n=5 and EM, n=10). For logical inference, there is a more recent paper investigating the limits of RNNs and I believe comparisons on that dataset could strengthen the paper: Evans, Richard, et al. \"Can Neural Networks Understand Logical Entailment?.\" ICLR 2018.\n\nMinor Comments\np1: \"the ability to reason deeply\" \u2013 I understand you mean literally \"deep\", but also \"reason\" is a loaded term.\np1: \"bears a totally different meaning\" should be made concrete\np3: I am a bit confused by the fact that Metagross is used to extend Transformers here given that you called it a recurrent (and recursive) model on the previous slide.\np4: What is the number of layers used in he stacked BiLSTM and is this the same as the maximum depth used in Metagross? I believe for a fair comparison they should be the same. I am also missing stacked LSTM in experiments on logical inference (Table 2).\nQuestions to Authors"}