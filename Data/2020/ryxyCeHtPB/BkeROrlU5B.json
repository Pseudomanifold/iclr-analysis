{"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "In general, I think it is a good paper and I like the contribution of the author. I think they explain in detail the methodology. The results compare the new methodologies with different databases which increase the credibility of the results. However, there is a couple of additional question that is important to manage:  \n\n1) The paper presents three different contributions. However, it is so clear how this work helps for \"By changing the fraction of channel neurons to skip for each convolution, AFDS can further accelerate the transfer learned models while minimizing the impact on task accuracy\" I think a better explanation of this part it would be necessary. \n\n2) The comparison of the results are very focused on AFDS, Did you compare the results with different transfer learning approach? \n\n3) During the training procedure. We need a better explanation of why \"we found that in residual networks with greater depths, AFS could become notably challenging to train to high accuracies\". Also, the results of the empirical test it would be useful to understand the challenges to train the network. \n\n4) I think it would be useful to have the code available for the final version. "}