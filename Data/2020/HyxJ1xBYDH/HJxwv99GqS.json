{"experience_assessment": "I do not know much about this area.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review": "Algorithms for Streaming data using a machine learning oracle is analyzed theoretically and empirically.\n\nThe idea is to build on some recent work (Hsu 19) which used RNNs to predict heavy hitters in streaming data. The purpose of this paper is to analyze whether such an oracle can help streaming algorithms to obtain improved bounds. I am not very familiar with this line of research so my comments will be more general in this case. The idea of improved bounds for streaming algorithms using machine learning oracle seems to be very appealing to me. The authors present novel theoretical results supporting this.\n\nExperiments are performed on real as well as synthetic datasets using Hsu et al.\u2019s method as an oracle.  Two real-world problems are selected, i.e., distinct packets in a network flow, Number of occurrences of each type of search query, and it is shown that using a oracle improves performance as compared to methods that do not use the oracle. Overall, I think the paper seems to be  an interesting direction which has both formal guarantees and experiments validating them in real-world datasets. One issue is perhaps, very little in terms of related work. I am not sure if this is the first work in this direction of proving bounds assuming an oracle or if there is some background work that the authors could provide to put this into context."}