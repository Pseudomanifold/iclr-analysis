{"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "** Paper summary **\nIn this paper, the authors propose a new re-ranking mechanism leveraging document-level information. Let X and Y denote two languages for ease of reference. The authors focus on X->Y translation and Y->X is a model used for re-ranking. Specifically,\n(1)\tTwo translation models X->Y and Y->X are trained, where X->Y is a document Transformer and Y->X is a sentence transformer.\n(2)\tTrain a language model P(Y) on document-level corpus (rather than sentence-level LM).\n(3)\tGiven a document with $I$ sentences (x^1, \u2026, x^I), translate each source sentence $x^i$ to K candidates.\n(4)\tUsing beam search guided by Eqn.(4) to find optimal translation paths, which is a combination of X->Y translation, Y->X translation, document-level language model and the number of words.\nThe authors work on NIST Chinese-to-English translation and WMT\u201919 Zh->En translation to verify the proposed algorithm.\n\n** Novelty **\nThe novelty is limited. Compared to the paper \u201cthe Neural Noisy Channel\u201d (Yu et. al, 2017), the authors use document Transformer and document-level LM for re-ranking, which is of limited novelty. \n\n** Details **\n1.\tSome baselines are missing from this paper: (A) dual inference baseline [ref1]; (B) X->Y is sentence-level transformer and LM is sentence-level LM, i.e., (Yu et. al, 2017), where P(Y|X) and P(X|Y) are sentence-level translation models.\n2.\tIn Table 1, the improvement of doc-reranker is not very significant compared to sent-reranker, ranging from 0.21 to 0.66. \n3.  In Table 4, \u201cChannel + LM\u201d and \"Proposal + Channel + LM\" achieved almost the same results. Does it mean that the \"proposal\" component do not work?\n4.\tMany models are used in this framework. I am not sure whether simple re-ranking or ensemble can outperform this baseline, e.g., 2 Zh->En + 1 En->Zh\n\n[ref1] Dual Inference for Machine Learning, Yingce Xia, Jiang Bian, Tao Qin, Nenghai Yu, Tie-Yan Liu, IJCAI\u201917"}