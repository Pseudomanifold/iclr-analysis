{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This paper provides a technique to solve match prediction problem -- the problem of estimating likelihood of preference between a pair of M-sized sets. The paper replaces the previously proposed conventional statistical models with a deep learning architecture and achieve superior performance than some of the baselines. The experiments show the efficacy of the proposed methods.\n\nI have some major concerns with this paper. These are described below:\n\n1.  The paper presentation is not very clear. The paper contains many imprecise statements. The problem is not setup very well. \n(a) The abstract and the introduction  contains vague statements with no proper description of what the technique is about. \n(b) In introduction, the authors start with discussing 1-sized pairwise comparisons, and then suddenly are discussing in-group items effects at the end of the third paragraph, so that means they are talking about M-sized comparisons with M > 1. This adds to the confusion.\n(c) The same things holds true for the first paragraph in \"Main Contribution\". Since the authors are using deep learning frameworks, this does not mean the authors \"can infer the underlying models accurately.\" I am not sure what the authors wanted to convey with this statement. \n(d) The reason I am being very stringent with impreciseness of the statements is majorly after reading the first statement in the Motivation section. It says, \"Our decision to incorporate two modules R and P into our architecture has been inspired by SOME state-of-the-art algorithms developed under CERTAIN statistical models, which have been shown\ntherein to be OPTIMAL.\" Please avoid using some, certain, optimal when they are not defined properly in the paper yet.\n \n 2. The paper mentions multiple times that it does not use statistical models tailored for a dataset or application but instead use deep neural networks. In my opinion, NN is just another form of statistical model that captures statistical patterns of comparisons and in-group interaction.  They are not following the same modeling assumptions as others but have created their own in some sense. The authors may want to rephrase those statements.\n\n3. The evaluation metric for the datasets that author consider is the prediction accuracy. I am not sure why the authors evaluate on cross entropy as well in Table 1, since both are closely related (CE is a consistent surrogate of accuracy). Can you please explain? However, I liked that they compared the methods with other metrics in Table 2. \n\n4. In problem setup, please mention M > 1. For M = 1, the problem is similar to [1] and many solutions have been proposed for that. \n\n5. I am not sure how the R and P modules capture what the authors want them to capture. I would suggest the authors to include that when they first discuss R and P modules.\n\n6. In equations 7, it is not clear how the function R(.,.,.,) and P(.,.,.) defined? Is it similar to what is described in equation 5?\n\n7. The training procedure contains the standard details; however, it is not clear to me how the modules R, P, and G interact during training.\n\nOverall, I believe the paper has a descent idea and contains satisfactory experimental results; however, the presentation of the paper is very weak at this moment. \n\n[1] Joachims, Thorsten. \"Optimizing search engines using clickthrough data.\" Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 2002."}