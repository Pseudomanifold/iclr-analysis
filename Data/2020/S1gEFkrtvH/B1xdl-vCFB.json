{"experience_assessment": "I have published in this field for several years.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper proposes a modification of the usual parameterization of the encoder in VAEs, to more allow representing an embedding $z$ through an explicit basis $M_B$, which will be pushed to be orthogonal (and hence could correspond to a fully factorised disentangled representation). It is however possible for different samples $x$ to use different dimensions in the basis if that is beneficial (i.e. x is mapped to $z = f(x) \\cdot M_B$, where f(x) = (c_1, ... , c_n) which sums to 1.). This stretches the usual definition of what a \u201cdisentangled representation\u201d means, as this disentanglement is usually assumed to be globally consistent, but this is a fair extension.\nThey show that this formulation can be expressed as a different ELBO which can be maximized as for usual VAEs.\n\nI found this paper interesting, but I have one clarification that may modify my assessment quite strongly (hence I am tentatively putting it on the accept side). Some implementation details seem missing as well. Otherwise the presentation is fair, there are several results on different datasets which demonstrate the model's behaviour appropriately.\n\n1.\tThe main question I have, which may be rather trivial, is \u201care the c_i supervised in any way?\u201d.\u2028When I first read the paper, and looking at the losses in equations 9-11, I thought that this wasn\u2019t the case (also considering this paper is about unsupervised representation learning), but some sentences and figures make this quite unclear:\n\ta.\tIn Section 3.2, you say \u201cWe train the encoder so that c_i = 1 and c_j = 0 if the input data has i-feature and no j-feature\u201d. Do you?\n\tb.\tHow are the features in Figure 6 attached to each b_i?\u2028I.e. how was \u201c5_o_clock_shadow\u201d attached to that particular image at the top-left?\n\tIf the c_i are supervised, this paper is about a completely different type of generative modeling than what it compares against (it would be more comparable to VQ-VAE or other nearest-neighbor conditional density models).\n2.\tThere is not enough details about the architecture, hyperparameter and baselines in the current version of the paper.\n\ta.\tWhat n_x (i.e. dimensionality of the basis) do you use? How does this affect the results?\n\tb.\tHow exactly are f(x), \\Sigma_f(x) parametrized? They mention the architecture of the \u201cencoder\u201d in Section 4.1, but this could be much clearer.\n\tc.\tHow do you train M_B? I assume they are just a fixed set of embeddings that are back-propagated through?\n\td.\tWhat are the details about the architecture of the baselines, and their hyperparameters? E.g. what is the beta you used for Beta-VAE?\n3.\tThe reconstructions seem only partially related to their target inputs (e.g. see Figure 4). This seems to indicate that instead of really reconstructing x, the model chooses to reconstruct \u201ca close-by related \\tilde{x}\u201d, or even perhaps a b_i. This would make it behave closer to VQ-VAE, which explicitly does that. How related are reconstructions/samples to the b_i?\n4.\tCould you show the distribution of c_i that the model learns, and how much they vary for several example images? \u2028How \u201cpeaky\u201d is this distribution for a given image (this feeds into to the previous question as well)?\u2028The promise of the proposed model is that different images pick and choose different combinations of b_i, which hopefully one should see reflected in the distributions of c_i per sample, across clusters, or across the whole dataset.\n5.\tWhat happens when L_B is removed? I.e. what is the effect of removing the constraint on M_B being a basis, and instead allow it to be anything? This seems to make it closer to a continuous approximation to VQ-VAE?\n6.\tIs Equation 10 correct? Should the KL use N(f(x) \\cdot M_B, \\Sigma_f(x)), as in equation 9 above?\n7.\tSimilarly, in Section 4.2.3, did you mean \u201cc_i = 1 and c_j = 0 for i != j\u201d?\n\nIf the model happens to be fully unsupervised, I think that these results are quite interesting, and provide a good modification to the usual VAE framework, I find that having access to the M_B basis explicitly could be very valuable.\n\nThere is still an interesting philosophical discussion to be had about when one would like to obtain a \u201cglobal basis\u201d for the latent space (i.e. Figure 3 (b)), or when one would prefer more local ones. I can see clear advantages for a non-local basis, in terms of generalisation and compositionality, which your choice (i.e. Figure 3 (c) ) would prohibit.\n\nReferences:\n[1] VQ-VAE: Aaron van den Oord, Oriol Vinyals, Koray Kavukcuoglu, \u201cNeural Discrete Representation Learning\u201d, https://arxiv.org/abs/1711.00937"}