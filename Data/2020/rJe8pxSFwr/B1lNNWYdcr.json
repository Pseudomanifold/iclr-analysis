{"rating": "1: Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #4", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper discusses various approaches to predict missing values in the input (filling/inpainting task).\nThey define an energy function equal to the squared L2 distance between the input and its reconstruction by various kinds of neural nets. They show slightly better performance compared to a PCA-based baseline.\n\nPositive things about this work\n- the topic is interesting\n- the last application is interesting (water temperature prediction) \n\nNegative things about this work\n- this work is very poorly  written and lacks sufficient clarity. This work needs a major rewrite. I do not even know where to start, but to give an example:\n1st sentence  of the abstract reads:  \u201cFor numerous domains, including for instance earth observation, medical imaging, astrophysics,..., available image and signal datasets often irregular spacetime sampling patterns and large missing data rates.\u201d, a sentence that misses the verb.\n2nd sentence of the abstract reads: \"These sampling properties is\u201d which is not grammatically correct\nAnd so on so forth. Speaking of which, the Authors make excessive use of \"....\".\n- because of the lack of clarity throughout the paper, I have had hard time figuring out what exactly the authors do. From the limited understanding I got after reading this draft twice, I think they consider a few different variants of auto-encoder and a \"log-prior\"/energy function equal to the squared L2 distance between input and its reconstruction. However, this formulation has barely any novelty. For instance, see old work like:\nS. Roth and M. J. Black, \u201cFields of experts: A framework for learning image priors,\u201d in Proc. of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), vol. 2, San Diego, California, June 2005, pp. 860\u2013867\nwhere they used a different log-prior, but essentially the same optimization process. If the novelty is the use of auto-encoders, then the comparison should be against methods that do not auto-encode (like the above or more modern versions of it).\n- several choices made by the Authors seem not well motivated. For instance, it's written that computing gradients is too expensive and therefore these are replaced by the G network. However, doesn't the G network also need gradients to be updated?\n- the terminology is not standard and confusing. Hidden state usually refers to the encoder output, not to the decoder output.\n- the Authors never introduce the metrics they use, reconstruction and interpolation scores.\n- in general, the motivation is unclear. Why is it a problem if the data does not come from a grid? In vision, inpainting on unconstrained masks has been standard for decades. \nMore recently, transformer architectures and GNNs seem quite good at representing sets and graph structured data.\nSo considering this context, the current motivation provided by the authors needs some refinement. In fact, the authors could consider building on top of these other more modern approaches."}