{"rating": "3: Weak Reject", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This paper proposes a method for generalized few-shot learning (GFSL) where the test data set contains samples of both base and novel classes. This is a natural extension of the dominant conventional FSL setting, under which the test data comes only from the novel classes. The proposed method, termed CASTLE follows a very similar pipeline as the method of Gidaris & Komodakis (2018). Specifically, the synthesized classifier weight vector is a combination of both class prototype (mean of the few shots)  and a weighted sum of some basis vectors. The difference is that in Gidaris & Komodakis (2018), the bases are the base class weight vectors, and in this work, the bases are learned from the data. These bases or neural dictionary of classifiers are based on the models in (Changpinyo et al., 2016; 2018) developed for zero-shot learning. \n\nGFSL clearly should be the next focus for few-shot learning and this paper does advance the state-of-the-art under this setting. However, I can\u2019t help but notice the similarity between this work and that in Gidaris & Komodakis (2018). The changes are based on borrowing ideas from existing zero-shot learning works in (Changpinyo et al., 2016; 2018). So the contribution is incremental. There are indeed some improvements on performance over Gidaris & Komodakis (2018). However, the multi-classifier learning brings 1-2% from the Appendix. The residual formation in Eq. (5) also helps. So one would expect that adding these two tricks to Gidaris & Komodakis (2018) would bring the performance closer. \n\nSection 3.2 is unclear to me: is the base class classifier parameter \\thetha_S updated during the episodic training process? Eq. (7) suggests it is, but the text suggests otherwise. \n\nAny reason for not using the commonly used low-shot imagenet dataset and CUB for the GFSL experiments? It would also be useful to examine different CNN backbones including the less powerful conv-4-64 and more powerful wide ResNet based architectures. It is well known that it makes a big difference. \n"}