{"rating": "3: Weak Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #4", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "Summary:\nThis paper tackles the generalized few-shot learning (GFSL) problem [1-2], that learns (few-shot) novel classes while not forgetting original classes. Built upon [1], the authors propose a different form of the weight generator for novel classes.\n\nPros:\n- The proposed method outperforms the prior work, in both GFSL and the standard few-shot setting.\n- The authors suggest the harmonic mean as an evaluation metric for GFSL.\n\nCons:\n\n1. Limited novelty & Prior works are not properly cited.\n\nThe problem of generalized few-shot learning (GFSL) is proposed in [1-2]. Hence, the authors should cite [1-2] in the last paragraph on page 1, where they introduce the GFSL problem. Also, many parts of the method are from [1], that [1] proposes an attention-based weight generator and this work only differs from the detailed attention mechanism. However, the authors do not cite [1] in the method section but only shortly mentions it on the last page. I strongly believe that the authors should clarify their contributions, as newcomers may misunderstand contributions and give wrong credits.\n\n2. The source of the improvements?\n\nThe authors should explain why the proposed method is better than [1]. One possible reason is that [1] uses a dictionary of size |S| (the size of the seen dataset S), but the proposed method uses 2-3 times of them, as stated in Appendix C.1 and Figure A8. Other reasons, e.g., the attention coefficients (Eq. (7) of [1] vs Eq. (4) of this paper), the combination weights (Eq. (8) of [1] vs Eq. (5) of this paper), or the classifier form (cosine similarity of [1] and linear of this paper) could also be a candidate. The authors should identify the source of improvements.\n\n3. Results in the standard few-shot setting.\n\nThe authors should clarify if the results are reproduced or copied from prior work. It seems that they are copied since the numbers are identical, e.g., see Table 1 of [3] and Table 1 of [4]. If so, the authors should specify where the numbers are from. Also, the caption of Table 4 and Table 5 seems to be wrong, as LEO [3] uses WRN-28-10 backbone instead of ResNet-12. Finally, the source of the gain also should be investigated. If the joint learning of many-shot and few-shot is the reason, DFSL [1] also should outperform other methods.\n\nMinor comments:\n- In Table 1, the authors state the reference for IFSL but not for L2ML' and DFSL'. For consistency, the authors should state all references or none.\n- Why DFSL' has a quotation mark? L2ML' is an inductive version of L2ML, but DFSL is already designed for the inductive setting.\n- OptNet in Table 4 and Table 5 should be changed to MetaOptNet [4].\n\n\n[1] Gidaris and Komodakis. Dynamic Few-Shot Visual Learning without Forgetting. CVPR 2018.\n[2] Ren et al. Incremental Few-Shot Learning with Attention Attractor Networks. NeurIPS 2019.\n[3] Rusu et al. Meta-Learning with Latent Embedding Optimization. ICLR 2019.\n[4] Lee et al. Meta-Learning with Differentiable Convex Optimization. CVPR 2019."}