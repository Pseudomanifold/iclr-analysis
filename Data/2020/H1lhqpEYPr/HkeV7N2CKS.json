{"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "N/A", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "Summary\nThe present work is concerned with providing a provably convergent algorithm for linear-quadratic mean field games. Here, for a given average behavior of the (large number of) players, the optimal strategy is given by an LQR with drift and the solution of the mean field game consists in finding a pair of (\u03c0 , \u03bc ) such that \u03c0 = \u03c0(\u03bc) is an optimal strategy under the mean field (the average behavior) \u03bc and \u03bc = \u03bc(\u03c0, \u03bc) is the mean field obtained if all players use the strategy \u03c0, under the mean field \u03bc. First, the authors show that under \"standard\" assumptions the map \u03bc \u21a6 \u03bc(\u03c0(\u03bc)), \u03bc) is contractive and hence, by the Banach fixed point theorem, has a unique solution, resulting in a unique Nash equilibrium of the mean-field game. Second, they show that by using an actor-critic method to approximate \u03c0(\u03bc) for a given \u03bc, this argument can be turned into an algorithm with provably linear convergence rate. The authors prove a natural result that seems to be technically nontrivial (I did not have the time to follow their proof in detail). Thus, I believe the paper should be accepted.\n\nQuestions/Suggestions to the author\n(1) It might be helpful for the reader to include a rough sketch of the proof and algorithm earlier in the paper\n\n(2) Since, as you mention, Assumption 3.1 (ii) \"is standard in the literature\", I would assume that it has been used before in order to prove existence of Nash equilibria using the Banach fixed point theorem? If so, I would suggest pointing this out to the reader and briefly mentioning the differences (if any) to the existing proofs in the literature.\n\n(3) On the bottom of page 4 you argue that the expectation of the state converges to a constant vector in the limit of large time, \"since the Markov vhain of states ... admits a stationary distribution\". In general, the existence of a stationary distribution does not imply convergence to the stationary distribution. Could please explain?"}