{"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review": "This paper frames and contextualizes CycleGAN as a stochastic generalization of penalized least squares for inverse problems, providing several unifying theorems, rederiving some modern CycleGAN architectures within the optimal transport framework, and also demonstrating the practical use of modified architectures derived using this framework for accelerated MRI and microscopy. \n\nWhile I did not check the proofs in detail, the additional generalization of a well-known, working architecture and additional variants used practically seem significant to me. Demonstrating the deep relationships in the proofs and propositions shown here, followed by two clear and concise derivations *and their practical application* is compelling, making this paper broadly applicable to both practitioners of compressed sensing and generative modeling. Frankly, it will take me some time to digest the proofs and overall relationships shown in the Propositions here, as I am not deeply familiar with optimal transport. The applied sections are direct, with Figure 5 being especially meaningful.\n\nThere are a few small grammatical issues in the text - a careful re-read and edit with particular focus on grammar and style would be beneficial, though as it stands these small flaws didn't meaningfully detract from the paper.\n\nThe primary thing the authors could do in order to raise my score, would be to take an additional pass at grammatical clarity for the paper. More experiments are always beneficial, and I would encourage the authors to release source code to replicate some form of their experiments if possible.\n\nSome additional references which may be useful additions, primarily for interested readers to gain further background on the use of deep models for compressed sensing:\nCompressed Sensing with Deep Image Prior and Learned Regularization https://arxiv.org/abs/1806.06438\nCompressed Sensing using Generative Models https://arxiv.org/abs/1703.03208\nDeep Compressed Sensing http://proceedings.mlr.press/v97/wu19d/wu19d.pdf"}