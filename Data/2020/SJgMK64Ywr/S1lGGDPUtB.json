{"rating": "8: Accept", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This submission proposes a way to do multi-stream neural architecture search for video classification. I give an initial rating of accept because (1) there are not many work on video architecture search yet (2) the paper is well written (3) experiments are complete and results are strong. I have a few comments as below. \n\n1. Most work in video action recognition tend not to use optical flow. Many people believe that if 3D conv or (2+1)D conv can be trained well, there is no point in using optical flow. What is the motivation of using flow in this work? I'm interested to know. \n\n2. As shown in Figure 5 of the appendix, the search space is quite large. For each block, it seems that authors search with r=1/2/4/8. However, the best searched network seems to only has r=1, 2 or 4. This is kind of counter-intuitive because longer sequences should in general give better results. Is there an explanation or insight that why r=8 does not show up? \n\n3. The learning rate for both datasets are very high, one is 3.2, the other is 25.6. This is quite unusual. Although many NAS literature show that large learning rate can help to achieve better performance, but 25.6 is really high. Did the authors do learning rate search as well? And what is the search space for learning rate? \n\n4. I understand that this paper focus on learning the connectivity pattern from difference inputs, like rgb and flow. Have the authors tried using RGB alone and searching the architecture? \n\n"}