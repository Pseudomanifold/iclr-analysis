{"rating": "3: Weak Reject", "experience_assessment": "I do not know much about this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper introduces a parameter tying scheme to express permutation equivariance in entity-relationship networks that are ubiquitous in relational databases. Results on the generality of the tying scheme are presented, as well as some experimental validation.\n\nThe paper extends several previously-proposed lines of work in statistical relational learning, including the work of Hartford et al. (2018) to multiple relations. In contrast to this earlier paper, which builds its argument step by step with great clarity (helped by illustrations), the current paper would prove hard to read to an ICLR audience, since most of its language and methods borrow more from the database theory literature. Since the proposed tying scheme is quite close to that of Hartford et al. (2018), one way to present the paper could be to construct the argument in such a way as to emphasize the difference with the previously-proposed scheme, thereby far better outlining the current contribution.\n\nIn addition, the experimental validation leaves much to be desired. In the synthetic data experiments (e.g. Figure 3), there is no guidance as to how to judge the quality of the resulting embedding. Also, it would be helpful to contrast the performance of the proposed approach against alternatives on a wider variety of datasets, such as MovieLens, Flixster, Netflix. (See the methodology followed by Hartford et al., 2018).\n\nAll in all, even though the proposed approach could usefully extend the state of the literature, the paper in its current form would need additional work before recommending acceptance at ICLR.\n"}