{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "Contributions:\n1. The paper modifies InfoGAN by replacing the uniform categorical distribution with a Gumbel-Softmax to adapt imbalanced class distribution.\n2. The paper proposes a data augmentation method to learn object identities invariant of predefined transformations.\n3. The paper evaluates its method on two datasets to demonstrates its effectiveness.\n\nThis paper fixes some shortcomings in InfoGAN, but it is hard for me to categorize it into an unsupervised method. Besides, its contribution seems incremental to me so I will vote for a reject.\n\nDetailed comments:\n1. The first concern to me is the data augmentation since the data augmentation itself seems to incorporate human supervision regarding the pre-defined transformations. Since traditional disentanglement methods barely rely on observations, it is hard to categories this method as an \"unsupervised method\". In Sec. 4.6 in the experiment, the proposed method seems \"re-learned\" the transformed data, which against the unsupervised setup. Moreover, this supervision could be unavailable for more complicated datasets, and the data augmentation scheme may bias the true data distribution.\n\n2. I compared the interpolation result in Figure 6 with a similar experiment in InfoGAN. But I found the interpolation quality in this paper is even worse than the one shown in InfoGAN. For example, I cannot see a salient stroke width change in RHS. of Figure 6, while InfoGAN learns a much more significant pattern change.\n\n3. I think this paper makes some modifications to InfoGAN, but I cannot see significant novelty since all modules presented are existing in the machine learning literature. I do think the imbalanced adjustment will work in this case, but I do not think this is an urgent problem to solve base on InfoGAN."}