{"experience_assessment": "I do not know much about this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I did not assess the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The work explores the problem of robustness and adversarial\nattacks in NN. In a multiclass prediction setting the idea\nis to use a taylor expansion of a loss coined CCKL which\nis the KL divergence between predictions for pairs of samples\nfrom different classes.\n\nThe papers seems to find a convoluted route to arrive\nto something like this: when the Fisher information matrix\nhas a strong eigenvalue the model is not robust. In other words\nit says that if the landscape close to convergence has\nvalleys, or fast changes, the model is not robust.\nThis appears quite obvious and related to previous similar\nstudies.\n\nThis statement is then empirically evaluated on CIFAR-10.\n\nThe mathematical derivations should be made more rigorous.\nFor example the paragraph on Cramer-Rao bound is very handwavy.\n\nTypos\n\n-  is found these  ->  is found that these "}