{"rating": "3: Weak Reject", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "In this paper, a new network architecture called EVPNet was proposed to improve robustness of CNNs to adversarial perturbations. To this end, EVPNet employs three methods to leverage scale invariant properties of SIFT features in CNNs.\n\nThe proposed network and the methods are interesting, and provide promising results in the experiments. However, there are several issues with the paper:\n\n- The authors claim that Gaussian kernels are replaced by convolution kernels to mimic DoGs. However, it is not clear (1) how this replacement, or employment of convolution kernels can mimic DoGs, or (2) more precisely, how the corresponding learned convolution kernels approximate Gaussian kernels. In order to verify and justify this claim, please provide detailed theoretical and experimental analyses.\n\n- It is also claimed that \u201ca 1 \u00d7 1 conv-layer, can be viewed as a PCA with learnable projection matrix\u201d. However, this statements is not clear. How do you assure that a 1x1 conv layer  employs a PCA operation or the corresponding projection?\n\n- What does \\| \\|_p denote? Does it denote \\ell_p norm?\n\n- What does x denote in d = w x h? Previously, it was used to denote matrix size.\n\n- Why do you compute \\ell_2 norm for row vectors instead of column vectors? How do the results change when they are calculated for column vectors?\n\n- According to the notation, s_0 and s_1 are vectors. Then, what does max denote in (14)? That is, how do you compute max(s_0, s_1), more precisely?\n\n- In the statement \u201cPNL produces a hyper-ball in the manifold space\u201d, what do you mean by the \u201cmanifold space\u201d? What are the structures (e.g. geometry, metrics etc.) and members of this space?\n\n- Please conceptually and theoretically compare the proposed method with state-of-the-art methods following similar motivation, such as the following:\n\nWeng et al., Evaluating the Robustness of Neural Networks: An Extreme Value Theory Approach, ICLR 2018.\n"}