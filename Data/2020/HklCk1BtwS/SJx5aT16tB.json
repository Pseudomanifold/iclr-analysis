{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "\nSummary:\n=======\nThis paper provides a closer look at the well-studied problem of learning word embeddings. In particular, it looks at the set of embedding methods that explicitly or implicitly perform a matrix factorization and tries to understand why the word embeddings exhibit analogy structure and why words that are semantically similar get embedded close together. The mechanism it comes up with has to do with the alpha parameter that represents the powers of singular values of the matrix that was factorized to estimate the embeddings. It turns out that alpha controls the distance between the words in the embedding transformation process. Next the paper discusses how to choose/estimate alpha to get better quality embeddings. Results are shown on several word similarity tasks. \n\n\nComments:\n=======\nThe paper offers fresh insights into the well studied problem of learning word embeddings. The impact of the alpha parameter is definitely interesting w.r.t the quality of embeddings learned. That said, the paper does have a few problems. First, though the paper is well motivated and puts itself nicely in context of previous work, it needs a copy-editor as there are many language/grammar issues some of which I highlight below. \n\n\nSecond, and the main problem with the paper, is that the properties of the alpha parameter are intriguing but the experimental evaluation is underwhelming. The paper also needs to show the impact of the alpha parameter on the quality of embeddings learned for some downstream task e.g. NER, POS Tagging. Just showing results on word similarity tasks and computing correlations is not very insightful or useful. \n\n\nGrammar issues (subset):\n\nPage 1: \"Word embedding is a very important task\"\n\nPage 1 : \"...which value should alpha be?\"\n\nPage 1: \"..has an important influence to the...\"\n\nPage 6: \"The first is to verify....\"\n"}