{"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "\nPros: \n(1) The proposed model makes sense to me, which tries to have two attention layers to extract the information related to the questions. It seems to have the ability to deal with \"and\"/\"or\" logical relationships as well. \n\n(2) Fig. 4 is impressive. It is clear and well-designed. \n\n(3) The results in Table 2 are convincing. They show that both the proposed dual-attention method and multi-task learning would contribute to the performance. \n\nCons:\n(1) It seems that the two main contributions are related to the language. Thus the synthetic language might not be proper to study. For example, in Eqn. 2, the first GA multiplies the BOW vector with the vision feature map, which could filter out unrelated instruction. This method could not be directly transferred to a real setup where natural language and natural images are involved.\n\n(2) The designed attention modules is lack of generalizability. It implements a two-step attention module, while the first step selects the related visual regions w.r.t the words and the second step gathers the information regarding these attended regions. However, it might not be aware of the spatial relationships and thus be limited to simple questions. For example, if the question is \"What is the object on top of the apple?\". To my understanding, the current module would not explicitly handle this one-hop spatial relationship. \n\nComments:\n(1) According to Sec. 3, 70 instructions and 29 questions are involved in this task. Using GRU to encoder these questions seems to be redundant. A simple one-hot embedding for these instructions might already be enough to encode the information.\n\n(2) I am not sure why the visual attention map x_S could be used as the state of the module.\n\n(3) After Eqn. 3, the paper says that \"ReLU activations ... make all elements positive, ensuring ...\". I am confused about the intuition behind this argument because of the softmax activation. Softmax will projects 0 to 1. So the sum of the all-zero vector would still be non-zero after softmax. \n\nTypo:\n- In Sec. 4, X_{BoW} \\in \\{0, 1\\}^V.\n- In Sec. 4.1, \"this matrix is multiplied ...\" --> this tensor."}