{"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "The paper presents a method for video activity understanding. The paper needs revisions to the method section as it is currently unclear. At a high level, it seems that the proposed method is using weights to generate weights that are used on the input. This is what is meant by \"higher-order.\" The method is evaluated on many datasets, however the state-of-the-art comparisons are missing several works, and the claim of outperforming state-of-the-art is not correct.\n\n\nComments:\n\nThe claim in the introduction that \"It would be difficult for conventional convolutions which recognize fixed patterns...\" does not seem to be supported with any evidence. I'm not sure that this is true, and no experimental or theoretical support is given for this claim.\n\nThe writing of Section 3 (Method) could use significant revision. It is quite hard to follow currently, and I'm not sure I fully understand all the details the method. At a high level, it seems to use weights to generate weights that are applied to the video input.\n\nIf my understanding is correct, then this paper is missing related works on neural networks generating weights (currently none are cited). \n\nI'm not sure that calling this second-order, or higher-order, is an appropriate name. Higher/second-order has a well-defined meaning in mathematics, and implies that this method is taking second-order derivatives, which from the writing, this method does not seem to be doing.\n\nThere is no discussion on the runtime or computational cost of this approach. It seems that it would be more expensive in inference and training. How much more expensive is the proposed H-block compared to a standard convolutional layer?\n\nExperiments:\nTable 2, something-something, is missing state-of-the-art results:\n\"Rethinking spatiotemporal feature learning: Speed-accuracy trade-offs in video classification\", ECCV'18 (48.2)\n\"MARS: Motion-Augmented RGB Stream for Action Recognition\", CVPR'19 (53.0)\n\nTable 3, Kinetics-400, is missing some state-of-the-art numbers:\n\"Representation Flow for Action Recognition\", CVPR'19 (77.9)\n\n\nTable 5, Charades:\n\"Evolving Space-Time Neural Architectures for Videos\", arXiv: 1811.10636 (38.1)\nSlowFast: 45.2\n\n\n\nMinor comments:\n\n\"It is more complicated to classify pull and push since it is an XOR operation on the relative positions of the hand and the object resulting from the hand\u2019s movements.\" What is meant by \"an XOR operation\"? I think there is a better way to describe that push/pull depend on the motion direction and hand/object relative location.\n\nThe notation is not standard, e.g., conv is f(X;theta). A more standard form would be X * theta. \n\nx_p'' is undefined (middle of page 2)\n\nPage 4: \"d by the simple convolutional model of . \" Of what?\n"}