{"experience_assessment": "I have published in this field for several years.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "\nPaper Summary: The goal of the paper is to analyze what information is encoded in the representation learned using RL for a specific game. The paper shows that the activations are sparse and the activation patterns are distinct and shows that the conceptually similar images are clustered together in t-sne visualization.\n\nPaper Strengths:\n\nThe paper starts with a nice introduction that embodiment is useful for perception. However, the main content of the paper is very different from the introduction.\n\nPaper Weaknesses:\n\nThe conclusions of the paper are either already known or very trivial. So there is nothing new for the community to benefit from. Please refer to my comments below for more information.\n\nThe conclusion of section 3.3 is that \"the agent learns to use sparse activation patterns and even leaves some of the available neurons completely unused\". This has nothing to do with embodiment. The same patterns are observed in non-dynamic tasks such as image classification. The CNNs are usually over-parameterized.\n\nThe conclusion of section 3.4 is that \"When comparing this with the encodings of a random untrained agent one can see that there is a clear association between the learned image encoding and the actions\". That is the whole point of training. We train the models to find correlations between actions and observations. It is obvious that there is more correlation compared to a random agent.\n\nIt is shown in section 3.5 that similar images will be next to each other in the t-sne visualization. It is obvious that this happens.\n\nDue to the issues mentioned above, I do not think there is anything new in the paper and I vote for rejection.\n\n"}