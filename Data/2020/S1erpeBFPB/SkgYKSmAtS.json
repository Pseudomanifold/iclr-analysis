{"experience_assessment": "I do not know much about this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "Summary\n---\nThis paper proposes to use a computer security method, \"Flush+Reload\" to infer the DNN architecture of a victim in the setting where both the attacker and the victim share the same machine in a cloud computing scenario. This does not require any physical access to the machine, however it does require that a CPU is shared, and the inference of the architectural details is based on the time it takes to reload computations from cache. \nThe paper is overall clear and well written.\n\nMotivations of the paper\n---\nHowever, concerning the motivations of the paper, I'd like some clarifications. As far as I know, in the deep learning community, the most effective architectures are published and public (VGG, Inception, ResNet, Transformer...).\nI am a bit confused by the sentence \"As a result, in the industry such novel DL systems are kept as trade secrets or\nintellectual property as they give their owners a competitive edge (Christian & Vanhoucke, 2017).\" which justifies that architectures are kept secret and thus may be prone being stolen.\nThis US patent is public and explains the method. As far as I know, it has never been enforced. Furthermore, this patent is associated with the paper \"Going deep with convolutions\", Szegedy et al. which introduced the Inception architecture, is public, very well-known, and thus I do not believe anyone would have any commercial interest in stealing it. \nFurthermore, I do have the impression that the edge many companies have over their competitors is the private datasets they own much more than the architectural details.\n\nMethod and applicability\n---\nWhile the method Flush+Reload itself is not novel, its application to the DNNs case and the way to reconstruct the architecture (generating the candidates, pruning) is.\nHowever, I do have some practical concerns about the applicability of the method.\n\nAs far as I understand, it can only work on one CPU. Most DNNs, even for inference, are run on (one or multiple) GPUs. Can the method be extended to work on GPUs?\n\nAlso, while the assumption that both the attacker and the victim use the same framework is realistic to me, I believe, they should also both use the same version of the said library, no? Otherwise some operations might be faster in some versions and slower in others, this is thus an additional and much stronger assumption to make.\n\nAt last, this would require the victim to use a public cloud service. However, as far as I know, many of the companies who could potentially design new architectures have their own private cloud. I am not certain that someone disposing of a new, private, and powerful architecture would use it on a public cloud service. \n\nExperiments\n---\nThe experimental section seems very limited to me. The authors show that they are able to reconstruct perfectly 2 architectures. While this is encouraging, I would like to see the limits of the proposed method.\nWhy not generate N random (or not so random) architectures and try to reconstruct them? Where does the method fail, where does it succeed?\nWhat if the victim used a custom layer that the method could not recover? Does it still recover a similar architecture?\n\n\nConclusion\n---\nWhile the paper, proposed to use Flush+Reload for recovering DNNs architectures and succeeds for at least 2 non trivial architectures, I do not recommend acceptance.\nFirst I am concerned by the problem this paper is tackling. Can this realistically happen in a real-life scenario?\nSecond, I am worried that the method suffers from very strong limitations in practice (eg the usage of a CPU for both victim and attacker).\nFinally, and importantly, while the experiments show some interesting first results, they are limited, I am not able to judge the strengths and weaknesses of the method, and thus I cannot assess the usefulness of the proposed method.\n\nNote: I have to say that this paper is definitely out of my area of expertise, even though I am confident in my understanding of the paper, it may be that some of my concerns are unfounded. If this is the case I will adjust my score accordingly."}