{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper proposes to use siamese convolutional network to generate a metric for images. The authors use both PDE generated simulated data and some real-world set to evaluate the proposed metric. \n\nWhile it seems to be a legit metric I have some concerns listed below:\n\n1. Need a proof why the cnn-based evaluation metric is a metric. In particular, the triangle inequality.\n\n2. Instead of using traditional metrics, I can first do a feature transform and then try a metric on top of the transformed feature space. Intuitively I do not quite see how the proposed metric is better than this naive feature+distance design.\n\n3. The paper spend one and a half page describing the data generation process. The authors claim using PDEs to generate data can have some special control of the data de-similarity, on the other hand, the performance on the simulated data does not indicate how practical the designed \u201cmetric\u201d is for real-world data which is possibly the main interest of most of the audience. \n\n4. The evaluation on the real-world data set is very limited. How does the proposed metric perform on image datasets such as CIFAR, ImageNet, MNIST? For example we may design experiment comparing inter/intra-class metric comparisons. And how that metric can be used to improve the sota results on the data sets?\n\n5. The metric construction section is not quite self-contained. For example, could the authors states in details how the feature map normalization and aggregations are actually done in the algorithm instead of just citing some related works?\n\n6. The loss function used in the training seems weird. I am worried how those two terms balance. Also it is a batch-dependent loss given the \\bar{c} and \\bar{d}. As the batch size gets changed the estimation accuracy of the Pearson coefficient may change in a different way as your first squared loss.\n\n7. Pearson coefficient only captures the linear correlation. I would suggest looking into something like mutual information instead.\n"}