{"experience_assessment": "I have read many papers in this area.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "The paper improves anomaly detection by augmenting generative models (VAE, etc) by iteratively projecting the anomalous data onto the learned manifold, using gradient descent of the autoencoder reconstruction term relative to the image input. The work seems related to AnoGAN, only instead of iterating over the latent space, the iteration is over the more expressive input space. The method is intuitive and a good parallel to Adversarial projections is made in the paper. To the best of my knowledge, the idea is novel, although I am not completely sure. \nThe second idea in the paper is to scale the losses by the reconstruction accuracy, which also is intuitive and shown to significantly speeds up the model convergence. \n\nThe experimental results are pretty convincing, showing both quantitatively and qualitatively that the method improves consistently over using the underlying vanilla generative models (AE/DSAE/2 VAEs). One desirable improvement is to get error bounds on the results, those are currently missing. Also, based on the inpainting results in Fig 7, it's not really clear if the method generates better results than Ivanov et al. \n\n\n\n\n"}