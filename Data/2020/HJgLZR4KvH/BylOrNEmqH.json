{"experience_assessment": "I do not know much about this area.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The authors try to incorporate intermediate-level skills into model-based RL, which is an essential problem in the RL field. The algorithm works well even in the case of high-dimensional state and action spaces. Their contributions are in four aspects:\n(1)they propose an unsupervised RL framework for learning intermediate-level representations, i.e. skills, based on maximizing the mutual information between the future state and current skill given the current state. This procedure is well-motivated and the mathematics is easy to follow.\n(2)they reformulate model predictive control (MPC) in the latent skill space.\n(3)their method is compatible with the idea of continuous skill spaces, which seems to give rise to more diverse trajectories and hence offers greater utility.\n(4)their method yields low-variance behavior while maintaining enough diversity.\n\nIt\u2019s an accept for me. On one hand, using model-free unsupervised RL methods to learn intermediate-level skills is not a new idea. on the other, approaching this problem via mutual information is, as far as I know, new to this field. Although, the novelty of this approach remains undecided, this method seems to work well enough compared to model-based, model-free and hierarchical RL methods. Their analysis from the perspectives of continuous skill space and skill variance also seem to hold.\n\nNevertheless, the study would benefit from more comparison with other methods using intermediate-level primitives (apart from DIAYN). Moreover it would be interesting to show this method works in scenarios apart from locomotion. I wonder how well the approximation p(z|s) \\approx p(z) works in non-locomotion tasks. Otherwise, the authors should mention this method is somewhat limited to locomotion tasks in the main text. \n\nOthers:\nTypo:\n1.Page 3: \u201cmaximally informative about about \u2026\u201d remove the redundant \u201cabout\u201d;\n2.Page 8, first line in section 6.3 \u201cis to be enable use of planning algorithms\u2026\u201d may be changed to \u201cis to take advantage of planning algorithms\u201d."}