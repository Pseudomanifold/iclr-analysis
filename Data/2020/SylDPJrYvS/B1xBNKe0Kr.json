{"experience_assessment": "I have published in this field for several years.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "The authors propose an ensemble model with deep networks. The authors suggest its relevance for incremental learning. The proposed model is evaluated appropriately. There are many issues with the work. The presentation and description needs a lot of improvement. \n\nWhat exactly do the authors mean by rehearsal? It is confusing term. \"... architecture contains two layers of neural networks and only the neural network in final layer is exposed to rehearsal ...\". Networks themselves have layers, so what does layers of networks mean here? The language needs a lot of improvement. \nAssuming that rehearsal means re-training or tuning or some sorts, the authors propose to split the network into two parts and retrain the second set of layers. How is this fundamentally different from retraining last few layers which is what most state of the art methods do? Further, architecture wise how is the proposal different from learning a layer of length C with softmax activation output for each class-specific index? What are we gaining in terms of learnability here?\n\nAs per description only a fraction of points from the rest of the classes are utilized as negative examples for learning a given class? This fraction seems very important/sensitive? What is its influence in evaluations? When a new class comes in in the form of incremental learning, one needs to retrain all the class specific models! Unlike claimed in the introduction, how is this small rehearsal or how is this different from retraining like in the conventional case?\n\nIn section 3.1, we still have a vector space, and nothing really special. Not need to tag them this separately!\n\nFor tables 2 and 3 we need confidence intervals for better interpreting the performance. "}