{"rating": "6: Weak Accept", "experience_assessment": "I do not know much about this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper proposes a framework for training machine learning models that simultaneously estimates depth of objects and poses of a single camera in a sequence of images from a single camera, in others words, a video.\nIn a video, to estimate depth of objects, which is a main objective of this paper, we need to know the relative position and rotation information of a single camera in a sequence of images in a video (motional information). However, to estimate the relative position and rotation information of the camera, we need to know a ground truth depth information of each objects in each image.\nThe main idea works just like EM or alternating optimization. The depth module estimates depth of objects in a sequence of images assuming the relative position and rotation information of a single camera is given. The motion module estimates motional information of a camera assuming the depth of each object is given.\nThe authors formulate the aforementioned two modules as neural networks, so that they can be trained end-to-end, and proposes various way of initializing the two modules.\n\nWhile the idea is simple, I think the paper is well-written and the experiments show a superior performance over existing approaches.\n"}