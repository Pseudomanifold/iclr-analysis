{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "\nThe premise of this paper is to propose \u201cadaptive dilation\u201d this allows convolutional kernels to \u201cflexibly adjust based on different contents.\u201d What precisely this mean should be clearer even at the abstract.\n\nThe authors are motivated by the observation that \" two obvious problems, which universally reside in most of existing dilated CNN structures, need to be properly tackled\u201d\n\nThese are \n1. \u201cAll weights\u201d share a single dilution value across all pixels\u201d\n2. Dilution selecton is data-independent\n\nThe first problem is unclear.  The latter is not exactly true, the dilutions are hyperparameter values chosen based on datasets just as much as any other ML architecture choices.\n\nThe authors propose to incorporate dilation selection into a \u201cunified data-driven framework\u201d.\nThe premise here is to learn a distribution over dilation values. \nThese are then sampled from during training from properties \nthat rely on \"content-related hidden priors\u201d.\nThe sampling approach relies on the popular Gumbel softmax.\n\nThe paper makes many fuzzy claims, for example:\n\u201cdilation inference grants a manageable way to partially understand the feature hierarchy\u201d\n\nThe paper has a number of qualitative experiments aimed at interpretation \nof the new receptive fields in the hopes that they via weak supervision\nreveal some significant structure in the images.\n\nThe experiments show some improvements on semsantic segmentation tasks\nover vanillar versions of various models \nincluding ResNet101, Xception, VGG, and DRN-D.\n\nThe authors also report some very slight improvements on image classification,\nbut these are built on weak models, the strongest of which is a ResNet50\nand all results are far from passable numbers on the task today.\nThe bes result here has 76.9% accuracy, while ResNext gets 84.5 %.\nEven the vanilla ResNet-101 from the original paper in 2014 gets 78% accuracy,\nbetter than the best reported  number here.\n\nIn the end I think this is an interesting heuristic but it\u2019s not clear what is gained\nand the results are promising but I am not quite convinced that a significant contribution\nhas been presented.\n\nMinor:\n\n\u201cThe power of prestigious Convolutional Neural Nets (CNN)\u201d\n>>>\tWrong adjective. \n\n\u201cGumbol-softmax\u201d  ==> \u201cGumbel-softmax\u201d\n>>> \tMisspelled throughout the paper\n\n\"To model inter-layer pattern smarter,\u201d\n>>>\t\u201csmarter\u201d ==> \u201cmore effectively\u201d\n\n\u201c3.3 discussion\u201d\n>>>\tIt\u2019s poor style to have a \u201cDiscussion\u201d section that is not the actual discussion section\n"}