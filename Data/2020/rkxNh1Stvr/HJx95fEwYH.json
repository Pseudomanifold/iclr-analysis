{"rating": "3: Weak Reject", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper proposes a new framework (RIO) to estimate uncertainty in pretrained neural networks. For this purpose, RIO employs Gaussian Processes whose kernels are calculated by kernel functions of input and output samples and the corresponding target values.\n\n- The proposed approach is interesting and the initial results are promising. However, there are various major and minor problems with the paper:\n\n- The proposed method can be applied to any machine learning algorithm. It is not clear why you focus on employment of the proposed method for vanilla NNs. \n\n- Have you applied RIO for other learning algorithms as well? \n\n- Could you please explain more precisely, how you utilize which particular properties of NNs in RIO, and/or how RIO helps quantification and improvement of uncertainty of NNs particularly?\n\n- Following equation (7), you claim that \u201cIn other words, RIO not only adds uncertainty estimation to a standard NN\u2014it also makes its predictions more accurate, without any modification to its architecture or training\u201d. Could you please verify and justify how RIO makes predictions of NNs more accurate? In this statement, I guess that you consider the results given in Theorem 2.6. However, you should not that the error functions given in Theorem 2.6 are calculated in a cascaded manner, i.e., by applying a GP at the output of a NN.\n\n- The main proposal of the paper is that RIO makes it possible to estimate uncertainty in any pretrained standard NN. In order to verify that proposal, you should improve the experiments, esp. using larger datasets with larger neural networks, including deep neural networks.\n\n"}