{"rating": "6: Weak Accept", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "The paper presents a Neural Network based method for learning ordinal embeddings only from triplet comparisons. \nA nice, easy to read paper, with an original idea.\n\nStill, there are some issues the authors should address:\n\n- for the experiment with Imagenet images, it is not very clear how many pictures are used. Is this number 2500? \n- the authors state that they use \"the power of DNNs\" while they are experimenting with a neural network with only 4 layers. While there is no clear line between shallow and deep neural networks, I would argue that a 4 layer NN is rather shallow.\n- the authors fix the number of layers of the used network based on \"our experience\". For the sake of completeness, more experiments in this area would be nice. \n- for Figure 6, there is not a clear conclusion. While, it supports that \" that logarithmic growth of the layer width respect to n is enough to obtain desirable performance.\"  I don't see a clear conclusion of how to pick the width of hidden layers, maybe a better representation could be used.\n- I don't see a discussion about the downsides of the method (for example, the large number of triplet comparison examples needed for training; and possible methods to overcome this problem).\n- in section 4.4 when comparing the proposed approach with another methods why not use more complex datasets (like those used in section 4.3)\n- in section 4.3, there is no guarantee that the intersection between the training set and test set is empty. \n- in section 4.3 how is the reconstruction built (Figure 3b)?\n\nA few typos found:\n- In figure 3 (c) \"number |T of input\" should be  \"number |T| of input\"\n- In figure 5 (a) \"cencept\" should be \"concept\"\n- In figure 8 \"Each column corresponds to ...\" should be \"Each row corresponds to ...\".\n- In the last paragraph of A1 \"growth of the layer width respect\" should be \"growth of the layer width with respect\"\n- In the second paragraph of A2 \"hypothesize the that relation\" should be \"hypothesize that the relation\".\n- In section 4.3 last paragraph, first sentence: \"with the maximunm number\" should be \"with the maximum number\"\n"}