{"experience_assessment": "I have published one or two papers in this area.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper presents a new approach for solving Constrained MDPs. Because the cost constraint is cumulative, the best action depends on the cumulative cost so far. They address this issue by learning a backward value function of the estimated cumulative cost so far. Their theoretical results show that the same properties for forward value functions hold here for backwards ones. They are then able to use the forward and backward cost estimates to constraint the actions selection, by adding a safety layer to the algorithm. The results show that the method does a better job of meeting safety constraints than the Lyapunov based method.\n\nThe backward value function idea is a nice novel way of addressing the cumulative cost constraint problem. \n\nThe paper is clearly written and the results are nice.\n\nThe biggest issue with this paper is that too much material has been pushed to the appendix. I think at the least some of the details of the actual implementation with PPO or A2C should be moved into the main text. \n\nFor the empirical results, it would be great to see something about the computation or wall clock time required. Does this method run more quickly than the Lyapunov based method? "}