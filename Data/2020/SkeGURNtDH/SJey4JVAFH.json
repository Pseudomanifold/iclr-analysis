{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "The paper proposes to jointy train a deep neural net for image classification, instance and copy recognition. This is achieved by i) combining a classification (cross-entropy) loss with a retrieval loss based on multiple copies/augmentations of the training image, and ii) a generalized mean pooling (GeM) layer allowing to interpolate between average and max pooling. The network obtains improved image classification accuracy on ImageNet over the same model trained without additional losses, and retrieval results competitive with the state of the art.\n\nThe paper is well-written and the different components are well explained. The improvements obtained on ImageNet are considerable, and I like the idea of using the GeM layer pooling exponent to adapt the network to higher resolutions. Also, it is desirable to have models that work well on multiple tasks e.g. for deployment on mobile devices.\n\nI have several questions and concerns:\n\n- Repeated augmentation together with a retrieval loss as the one presented in (2) is a known supervised learning technique called exemplar [1], which was originally proposed with a classification loss but recently extended to a to a triplet loss as the one in (2) in [2]. The same loss was also used together with labels for semi-supervised learning in [3], and similar improvements in image classification accuracy as in the proposed paper were observed for training a rotation-based self-supervised loss with all labels (the MOAM model in [3]). I think the paper would benefit from a review of recent work on self-supervised learning.\n\n- It was previously observed that increasing the resolution can improve image classification accuracy, see, e.g. in [5, 4]. It is also to be expected that adding AutoAugment to the mix will help.\n\n- It would be interesting to see a simple ImageNet pretrained retrieval baseline without bells and whistles in the retrieval experiments. I\u2019m not a retrieval expert, but it seems that retrieval networks are typically trained on other data sets and do additional tricks than just using a pretrained ImageNet embedding.\n\nAll in all I think the paper is solid and presents good results, but a very similar method was previously proposed by [3]. I\u2019m therefore not convinced that the paper presents enough novelty.\n\nMinor comment:\n-Using a different letter for the supervised labels y_j and the pairwise labels y_ij might improve readability.\n\n\n[1] Dosovitskiy A, Springenberg JT, Riedmiller M, Brox T. Discriminative unsupervised feature learning with convolutional neural networks. In Advances in Neural Information Processing Systems 2014 (pp. 766-774).\n[2] Kolesnikov A, Zhai X, Beyer L. Revisiting Self-Supervised Visual Representation Learning. InProceedings of the IEEE Conference on Computer Vision and Pattern Recognition 2019 (pp. 1920-1929).\n[3] Zhai X, Oliver A, Kolesnikov A, Beyer L. S4L: Self-Supervised Semi-Supervised Learning. arXiv preprint arXiv:1905.03670. 2019 May 9.\n[4] Tan M, Le QV. EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks. arXiv preprint arXiv:1905.11946. 2019 May 28.\n[5] Touvron H, Vedaldi A, Douze M, J\u00e9gou H. Fixing the train-test resolution discrepancy. arXiv preprint arXiv:1906.06423. 2019 Jun 14.\n"}