{"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review": "Summary: This paper describes an attention-based method to encode trees with constant parallel-time complexity maintaining scalability, uses this model to encode constituency parses of input sentences for the tasks of machine translation and text classification, and shows improved accuracy/bleu over models that do not encode the parses. \n\nStrengths:\n\nThe method proposed by the authors is scalable despite encoding tree structures. The models give considerable improvements on various machine translation datasets and the authors also show that the model is more sample efficient. I appreciate the charts showing training and inference time with sentence length, and the tables showing the ablations and attention distributions. \n\nWeaknesses\n\nThe authors do not use pre-trained embeddings for any of the classification models, but using these embeddings boost performance to much more than what they authors have achieved here. My main question is, if we use pre-trained embeddings, do encoding constituency parses add anything over and above them? I would like to see this method improve results over some state of the art classification models and not just over the tree-LSTM. In other words, how much classification performance does this method yield over current SOTA models, because the SST results are quite a bit below the current SOTA.\n\nThe authors achieve an accuracy of 98.2 on the IMDB dataset. Is this actually the case or is this a bug? Even models using BERT barely achieve an accuracy of 96% (http://nlpprogress.com/english/sentiment_analysis.html). Or am I looking at the wrong dataset here? Can the authors clarify?\n"}