{"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The authors propose a novel word embedding post-processing method that maximizes the similarity between the estimated Gram matrix of word vectors and its oracle matrix. To find the optimal Gram matrix, they adopt the shrink method to make Gram matrix K' to target matrix T on semi-Riemannian space. The authors use the shrinkage method to find optimal K' and formulate the maximization on CKA problem as finding the optimal shrinkage parameter that maximizes the lower bound of the CKA between the estimated Gram matrix and oracle. By applying the proposed method to various word embedding methods, the authors show the performance of their post-processing method on word analogy/similarity task, word translation task, and sentence similarity task.\n\nStrengths\n* This paper provides a novel post-processing method that can relieve isotropy condition and shows experimental support that solving isotropy condition on word embedding vectors can improve its performance.\n* Large set of experiments on various word embedding benchmark tasks. \n\nWeaknesses\n* It would be nice if the authors show the performance of the post-processed word vectors on other NLP benchmark: text classification, NER, ... etc.\n\nQuestion\n* \"Neural Word Embedding as Implicit Matrix Factorization\" and \"Analogies Explained: Towards Understanding Word Embeddings\" show that PMI is the global optimum point of the previous word embedding model's problem space and prove word analogy can be explained from the PMI characteristics of word embedding models. How can this paper be related to the two papers mentioned above?"}