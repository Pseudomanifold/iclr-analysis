{"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "Summary\nThe paper proposes a method for continuous learning called Functional Regularization of Memorable Past (FROMP) which maintains the output distribution of models on memory samples. FROMP uses the Laplace approximation and Gaussian process with neural tangent kernel (NTK) to approximate the output distribution. According to the leverage score strategy, the sample to be stored is selected. The leverage score strategy tends to select the sample of highest variances. \n \nStrengths\nTo some extent, I think the proposed method is novel, although there is a similar work named as Functional Regularisation for Continual Learning (FRCL). FROMP first uses NTK in Gaussian process for continual learning and proposes a new strategy of selecting memory samples.\nThe strategy of selecting samples to be stored is simple and effective.\nThe method achieves a good performance.\nThe paper is clearly written and easy to follow.\n \nWeaknesses\nIt needs more experimental comparisons between FROMP and FRCL, like adding comparison results of FROMP and FRCL for Split-Cifar. Currently, this paper only shows the performance on Permuted MNIST and Split MNIST but those two benchmark are quite simple and also the improvement is limited.  \nThe experimental section needs more detailed analysis. At least, in current version, it is not clear how many tasks in Permuted MNIST. The setting of hype-parameters for dropout are not provided.\n \nOther comments \nIn this paper, for Split MNIST experiment with multi-head, it shows that the method of EWC achieves worse results than SI. However, in my experiment, the precision of EWC is at least larger than 97%. In theory, I think they should have the similar performance and at least the discrepancy of accuracy between them is not as big as shown in this paper. I expect authors could explain this point."}