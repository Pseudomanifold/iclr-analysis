{"experience_assessment": "I have read many papers in this area.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper develops a framework for for audio generation using oscillators with differentiable neural network type learning. They showcase the usefulness and effectiveness of the approach with several examples such as timbre transfer, dereverberation, changing the room impulse response, pitch extrapolation and so on. I can imagine the proposed learnable oscillator based autoencoders in a variety of applications. \n\nI think that this suggested software library can be useful for a wide range of audio researchers, and I commend the authors for this contribution. It is very nice to see an example of research where we make use of our physical understanding of the sound medium rather than blindly throwing a neural network at the problem. \n\nI have one important question though: how susceptible do you think the system is robust with respect to f0 and loudness encoders? Have you experimented with situations where the f0 and the loudness encoders might fail (such as more non-periodic and noisy signals)? \n"}