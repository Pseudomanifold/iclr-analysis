{"rating": "3: Weak Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "The paper presented a mono-net which has only positive weights and monotonically increasing functions in between layers except for the first layer, and it can be shown that the proposed mono-net is capable of modelling any continuous functions. The modified Direct Feedback Alignment (DFA) is applied where only signs are used to update the weights. There are several issues and concerns that leads me to the following comments and concerns:\n\n(A) Why is it necessary to construct a monotonic layer which is constrained to only be able to approximate monotonic functions? Please elaborate. If the concern is about the gradient update, then there is better way of constructing such a network with limiting it being only capable of modelling monotonic functions.\n\n(B) If, given the proof in appendix, that the proposed mono-net is indeed a universal function approximator, then why do all the layers on top of the first layer have to contain only positive weights?\n\nFollowing the proof, given a neural network with only one hidden layer and hyperbolic tanh activation functions, as long as the weights in the layer that is after the tanh functions are all non-negative or non-positive, the neural network is also a universal function approximator.\n\nSince the chosen activation function monotonically increases in the input domain, the sign of the update calculated by DFA is the same as the gradient calculated by the chain rule. \n\nThe aforementioned way of constructing a neural network allows it to be able to model to change the monotonicity of the function in between layers when the two sets of weights in consecutive two layers have opposite signs. Also, the update gives the sign of the gradient calculated by backpropagation.   \n\n(C) What is the different between the proposed network along with the update rule and a network with only non-negative weights in the layers above the first layer trained with RPROP? They look exactly the same to me. \n\nIf so, another perspective of the story is that the paper emposes a non-negative constraint on the weights in a neural network, and this could be used as a baseline.\n\n(D) The proof that gives the universal approximation theorem explicitly defines the squashing function/the activation function to be bounded and this paper follows the setting, which is reflected in the experiments where the proposed network with ReLU activation functions don't work well. \n\nHowever, the expressiveness of ReLU networks has been shown to be strong and they are also universal approximators. I'd believe that with (B), it might lift the constraints brought by ReLU in the settings proposed by the paper.\n\n(E) I am not sure why for now the number of output units matters that much. The training algorithm can easily ignore other output units when samples of a specific class is presented, then after learning, the algorithm can rank the output units to make predictions. "}