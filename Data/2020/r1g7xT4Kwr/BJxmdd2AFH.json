{"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper proposes a hierarchical policy consisting of a planner and an executor policy for solving navigation tasks. A planner policy consumes the desired target goal and a ELI context from the executor to propose subgoals for the executor. The executor consumes these subgoals to output actions that the agent should execute, and returns the ELI context to the planner policy.\n\nStrengths:\n1. Decomposing the problem hierarchically makes a lot of sense for the given task.\n2. The design of the ELI vector that passes information seen by the executor during the intermediate steps back to the planner seems novel, and has been shown to experimentally help with performance.\n3. Paper conducts experiments in visually realistic environments and presents comparisons against methods from recent papers.\n\nShortcomings:\n1. Limited novelty: Hierarchical decomposition is extremely specific to the task of pointgoal navigation. The proposed decomposition employs use of pointgoal targets for the executor. While this works for navigation, it is unclear how this can be made to work for other robotic tasks such as manipulation, or for other long-horizon problems like montezuma revenge. In fact, such a decomposition of the problem have been investigated in past works for navigation [A,B].\n\n2. Experimental evaluations:\na) Lack of use of standard metrics. Paper uses tasks in Habitat for evaluation, but doesn't use the metrics that come along with it. It is fine to point out problems with standard metrics, but it will really help if the original metrics were included (possibly in addition to other metrics that will address the shortcomings like #collisions, etc as mentioned).\n\nb) Additionally, there was a challenge https://aihabitat.org/challenge/2019/ at CVPR 2019, and there is a leaderboard with results: https://evalai.cloudcv.org/web/challenges/challenge-page/254/leaderboard/839 The paper should include these previous results on this task on the dataset. While I agree that details for some of these methods may not be available, making meaningful comparisons and discussions difficult, details about some of these methods are in fact available, and these methods should be included in the paper.\n\nc) Following up on point b), the paper is tackling the RGBD version of this problem and details about a very strong baseline `Map and Plan Baseline` is available along with code. I am not sure if success rates presented in Table 1 are directly comparable to these publicly available numbers, but it seems like this baseline outperforms the methods proposed in this paper by a healthy margin (81 vs SPL of 89, which means success rate would be even higher). This is striking as this baseline does not need any training at all. This being said, I can imagine that the proposed method can work with RGB images alone (while such a baseline may not), but this should be experimentally demonstrated. Even then, paper should compare to other methods for this task as available on the leaderboard.\n\nThus, while I like the hierarchical decomposition and the exchange of information between the executor and the planner via the ELI. However, I believe the contribution is limited, in that it is not clear how generally applicable the framework is, and the experimental validation for the problem where it is indeed applicable is weak.\n\n[A] Combining Optimal Control and Learning for Visual Navigation in Novel Environments\nSomil Bansal, Varun Tolani, Saurabh Gupta, Jitendra Malik, Claire Tomlin\n\n[B] M. M\u00fcller, A. Dosovitskiy, B. Ghanem, and V. Koltun. Driving policy transfer via modularity\nand abstraction. arXiv preprint arXiv:1804.09364, 2018."}