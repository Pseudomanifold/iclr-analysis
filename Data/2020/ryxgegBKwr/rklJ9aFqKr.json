{"rating": "6: Weak Accept", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "Paper Summary:\n\nThis paper proposes a contextualized sparse vectors, called CoSPR, for encoding phrase with in open-domain question answering. It is different from existing static sparse vectors such as tf-idf in that CoSPR dynamically computes the weight of each n-gram that depends on the context.  The authors argument the baseline model DenSPI (Seo et al., 2019) that uses tf-idf with their contextualized sparse representations (DenSPI+CoSPR). Experiments with SQuADOpen and CuratedTREC show the effectiveness of CoSPR.\n\nStrengths:\n\n\u2014The model that uses contextualized encoding by BERT and the training strategy that leverages a kernelization is simple but effective.\n\n\u2014DenSPI+CoSPR achieves 97x speedup in inference compared to a state-of-the-art pipeline approach, BERTserini (Yang et al., 2019). Also, the inference speed of DenSPI+CoSPR is comparable to that of the original DenSPI.\n\n\u2014The paper is well written and well organized.\n\nWeaknesses:\n\n\u2014This study is based on DenSPI (Seo et al., 2019). There is no novelty in the dense representation part, since the focus of this study is on improvement of sparse representation.\n\n\u2014Multi-passage BERT (Wang et al., 2019) clearly outperforms DenSPI+CoSPR in terms of question answering accuracy. However, it is quite slower than DenSPI+CoSPR.\n\nQuestions:\n\n\u2014Can we use CoSPR as a passage ranker to find the passages that contain answer-phrase candidates?  How well the pipeline method of CoSPR (as a passage ranker) and BERT (as a passage reader) work?\n\nReview Summary:\n\nThe paper is well motivated, and the proposed model is simple but effective. I think this paper can be accepted.\n"}