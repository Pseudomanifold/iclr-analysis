{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper defines the quantity of \"gradient SNR\" (GSNR), shows that larger GSNR leads to better generalization, and shows that SGD training of deep networks has large GSNR. It tells a great story on why SGD-trained DNNs have good generalization.\n\nThis topic is highly relevant to this conference.\n\nHowever, I struggle to rate this paper, since I feel swamped with math. It is hard work to read this paper, and I can honestly say that I could semi-confidently follow until about Eq. (8). To even get there, I had to scroll back and forth to remember the definitions of the various symbols. The math may be very well correct, but it is infeasible to verify (or follow) it fully. It does not make it easier that one cannot really search a PDF for greek symbols with indices etc. Someone who reads theoretical papers all day long might do better here.\n\nThis is the reason I rate the paper Weak Reject.\n\nSome feedback points:\n\nSection 2.1:\n\nEq. (1): It seems the common definition of SNR is the ratio of mean standard deviation. Your SNR is its square. This should be explained.\n\nI think it would help the reader a lot to give some intuitive meaning to the GSNR value. Can you, in Section 2.1, explain with examples what typical (or extreme) values would be?\n\nAssumption 2.3.1:\n\nThis is dropped on the reader without any motivation. It is also confusing: \"we will make our derivation under the non-overfitting limit approximation\" conflicts with \"In the early training stage,...\" So is this whole derivation only true in the early stages?\n\nAssumption 2.3.1 seems to address a thought I had when reading this: At the end of the training, I would expect mu_q(theta) to be zero (the definition of convergence). At the start, it is arbitrary as it entirely depends on the initial values. So this paper must look at some part between the two extremes to make sense. Is it? Is this assumption related?\n\nWhat is the difference between \\sigma and \\rho? Seems one is on the data distribution and one on a sampled set. But then why is \\mu the same in both cases (Eq. (1) vs. Eq. (5))?\n\nAll plots:\n\nThe plot labels are far too small to be readable."}