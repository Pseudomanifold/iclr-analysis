{"experience_assessment": "I do not know much about this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review": "The authors propose a new training method for learning parameters of NNs, describing a method that combines gradients at different observation points. They also provide theoretical analysis of the convergence of the algorithm.\n\nThe paper is not very readable, and the authors do not help the reader understand and appreciate their work. This is clear from the beginning, where not even the algorithm acronym is explained. This continues throughout the paper, where there is very little sensible explanations. Detailed comments are given below:\n- Please introduce the methods and notation better. There are a number of works that are just thrown out there without proper explanation (e.g., acronyms HB, ASGD, and others are not even explained).\n- Notation could be improved as well, as matrices, scalars, and vectors are all denoted the same now.\n- Algorithm 1 is quite different from the actual text. E.g., where did line 5 appear from, it was never mentioned in the text. This adds to a lot of confusion. Similarly with several other aspects of the method (such as line 8).\n- \"if the vector operations are run by pipelines\", not sure what this refers to.\n- Typos: mu instead of \\mu, stand -> standard, ...\n- The intuition behind the theorems and what they actually tell us should be discussed. Currently they are just given.\n- \"roughly 1 times faster\", so not faster at all?\n- The experiments are also not very convincing. In fact, the proposed method doesn't really outperform the competing method in nearly any experiments. Discussion on what are the added benefits would be welcome.\nPlease note that I am not an expert on the topic (as I indicated below in my self-assessment). However, the paper is nevertheless poorly written, and the empirical evaluation is weak. I am quite interested in seeing other reviews by more qualified researchers."}