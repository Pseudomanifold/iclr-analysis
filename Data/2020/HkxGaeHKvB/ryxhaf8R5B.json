{"rating": "1: Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper proposes new optimization method called NAMSG by combining AMSGRAD and NAS and introducing more parameters. There are two regret bounds in convex and strongly-convex settings and some experimental validation on MNIST and CIFAR compared to various previous methods.\n\nThe purpose of the paper is unclear, and should be rejected. \n\nIf the NAMSG is the next best optimization method for neural nets, then any regret bounds on convex functions is irrelevant, and the authors should focus on rigorous experimental comparisons. Currently it is not clear at all how parameters for each optimization method is set, and that the previous optimization methods were given a fair chance. There is not enough information about the experimental design to convince people that the authors were careful to rule out alternative explanations. For example, it definitely should say how the various hyperparameters are picked in various methods.\n\nOn the other hand, if any of the analysis is novel, it would be good if the author can emphasize it and say what is the innovation in analysis and its significance. Right now it seems that the new parameters are plugged into a standard recipe to derive a very complicated formula, which is not helpful. I am not familiar enough with the area to tell if there is any interesting novelties in the analysis.\n"}