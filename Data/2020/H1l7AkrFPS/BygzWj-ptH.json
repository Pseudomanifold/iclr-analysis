{"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "\n=== Summary ===\nThe authors study the importance of spatial information in (later layers of) CNNs for Image Classification. Specifically, they propose to remove spatial information by either 1) shuffling the input to a convolution, 2) average pooling and replacing convolutions by fully connected layers or 3) replacing spatial convolution by pointwise (1x1) convolutions.\nThey find that removing spatial information in the last layers of CNNs at training time doesn't impact image classification performance while removing parameters (and potentially FLOPs) for VGG16, ResNet50.\n\n=== Recommendation ===\nThe presented study contains a few experimental flaws. The choice of method for removing spatial information is rather arbitrary and it seems the authors confuse spatial information (being aware of the relative spatial position between pixels) and spatial processing (processing nearby spatial positions). Specifically:\n- For shuffling, it makes more sense to keep spatial consistency by applying the same shuffling operation to all feature maps. Shuffling independently for each feature map does more than destroy spatial information, it also destroys spatial consistency which probably hinders training more than it needs to.\n- The authors should have tried 3x3 convolutions where the weights are the same for each relative position (ie C^2 parameters instead of 9C^2 parameters, but the same amount of FLOPS). This allows to still increase the receptive field size in the last layer but without using spatial information.\n\nExperimental improvements of accuracy with respect to the number of parameters are shown on very suboptimal architectures such as VGG16 and ResNet50. The improvements on better architectures (from a parameter efficiency perspective) are negligible. In particular, the rule of thumb provided by the authors is already applied in today's most efficient models such as MnasNet and EfficientNet.\n\nThe small importance of spatial information for image classification, especially in later layers, is relatively well known and has already been mentioned by other work such as Approximating CNNs with bag-of-local-features models works surprisingly well on imagenet. This also relates to the \"Picasso problem\" and the motivation for capsule networks.\nAdditionally, work on applying self-attention for vision is also concerned with adding spatial information to the self-attention operation (As such, it could have been interesting to replace the 3x3 convolutions with local self-attention layers without spatial information).\nThe additional questions raised by this work are rather non-conclusive (e.g: relationship with receptive field size, removing spatial information as regularization)\n\nIn summary, the presented study, while interesting, contains a few flaws, is of limited scientific novelty and experimental results are rather underwhelming.  The current draft doesn't warrant for ICLR acceptance."}