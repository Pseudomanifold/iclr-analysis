{"rating": "8: Accept", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This is a theory heavy paper. My only concern is relevance for this conference, but other than that the results are interesting and useful. \n\nIt seems the authors have focused on a particular case of folded convex penalty (Minimax Concave Penalty or MCP --- the authors should provide the full form of the abbreviation before using it). The major contribution of this work is the analysis, while the algorithmic setup can be borrowed from previous works (e.g. Liu/Ye 2019). \n\nRemark 10 is not clear to me. Why is the assumption that \\beta^\\star has a lower value than \\beta^{Lasso} reasonable ? Also, the assumption is to hold almost surely, which I am assuming is over possible instantiation of the randomized scheme ? In that case, this assumption seems very strong in general, unless I am missing something. \n\nI would suggest authors expand the paper to be self-sufficient, instead of referring to other works (e.g. Algorithm 1 in Liu/Ye 2019, and proof of Lemma 9 ). Please proof read e.g. above equation 62. \n\nIt would be nice if the authors also provide discussions on how just the sample complexity being large enough is sufficient for assumptions of Theorem 1. I had to spend a lot of time to understand the relationship and intuition wrt \\Gamma implying from sample complexity. That should add to the readability of the paper.\n\n\n\n"}