{"experience_assessment": "I have published in this field for several years.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This work proposes the problem of fact verification with semi-structured data source such as tables. Specifically, the authors created a new dataset TabFact and evaluated two baseline models with different variations. They applied two criteria and different rewards for workers to collect two subsets of different levels (\u201csimple\u201d and \u201ccomplex\u201d). They also applied a negative rewriting strategy to avoid exploitable cues or patterns in the annotations. They evaluated two baselines models: (1) latent program algorithm (LPA), which makes use of simple string match entity linking and systematic search and trains a neural network discriminator, and (2) Table-BERT, which linearize the table into a sequence through concatenation or template, and treat it as a classfication problem. Both showed reasonable accuracy (~68%), but still below human performance (92.1%) on a held out test set.\n\nI would like to see the paper accepted because:\n(1) it proposes an interesting task (table fact verification) with a clean dataset, and the experiments evaluated the ability of the current neural network models, such as BERT, or hybrid models, such as the LPA baseline, to perform (symbolic) reasoning;\n(2) special care is done to ensure the dataset doesn't contain simple cues or patterns, which is a common pitfall in dataset collection, and the dataset is also validated through two reasonable baseline models. \n\nSome weakness and concerns are:\n(1) some error analysis of the baseline models are missing. For example, what types questions are hard/simple for table-BERT and what are hard/simple for LPA, and some comparison between them. This helps point out where the difficulty come from, for example, whether the difficulty is language understanding or symbolic reasoning.\n(2) \"To focus on statement verification against the table, we do not feed the caption to the model and simply mask the phrases in the statements which links to the caption with placeholders.\"\nI am not sure this is the right thing to do since even the human annotators requires the caption to understand the context, why not also feed the caption into the model? \n(3) Although the Figure 2 showed that the higher order operations are indeed used in a majority of questions, which measures the breadth of the reasoning, it is unclear about the depths of the required reasoning, i.e., how many operations / steps are required to achieve the correct answer. It would help if the average number of steps / operations required for answering the questions are shown. \n\nIf the above concerns are addressed, I will be willing to raise my score.\n\n\nMinor comments:\n\nThe paper, especially the Appendix, requires some proof reading, for example, I believe the caption for Figure 5 in Appendix A is misplaced.\n\n\"... they are explicitly banned bring ...\" -> \"banned from bringing\"\n\n\u201cAs illustrated in Figure 6, the title only acts as a placeholder in the statements to make it sound more natural.\u201d -> From the example, it seems the name of the player is kept unchanged in the sentence, which is different from a placeholder.\n\nSuggestions:\n\nI understand this might require some works, but it would be really helpful to add more comments and maybe examples for the functions shown in Figure 5 (you might need to split the table into two pages or have another table for examples), so that it can be used by works that follows the LPA approach.\n\n\u201cDuring the annotation, the workers are explicitly guided to modify the words, phrases or sentence structures but retain the sentence style/length to prevent from artificial cues\u201d\nAvoiding simple cues or patterns are important, so it will be good if more details can be shared (for example, the instructions/guidelines you showed to the workers). \n"}