{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This paper proposes a framework to learn correlated drug-drug interaction based on structured prediction energy networks (SPEN). The core idea is to model the dependency structure of the labels (multi-label) by minimizing a designed energy function. The graph energy is designed as MLP over the mean of all nodes embeddings, where the nodes embeddings are obtained through a graph convolutional network. The edge information is included in the node embedding when aggregating neighborhood information. The proposed method also introduces an additional test inference network to jointly train with the cost-augmented training network under the semi-supervised setting. The authors tested on two DDI datasets and the result shows improvement compared to several baseline methods.\n\nStrengths\n- motivation: the authors consider the correlations between DDI labels (multi-label) which could potentially improve prediction of DDI. The proposed method uses structure prediction energy networks to model such dependency.\n\n- method: the proposed method introduce an additional test inference network to fit the energy minimization framework into a semi-supervised setting.\n\nWeakness\n- The core part of the proposed method which differs from previous works needs to be elaborated more.\n- The performance improvement seems to be marginal, especially on the second dataset.\n\nDetailed comments\n- The work is based on structured prediction energy networks (SPEN, Belanger, et al. 2016) and its follow-up works (eg., Belanger et al. 2016, Lifu Tu et al. 2018), the overall framework is very similar with previous work, where the feature extraction part is replaced by a graph convolutional network module. The core difference lies in the additional testing inference network which is jointly trained for adapting supervised SPEN into a semi-supervised setting. This part actually differs from all previous works and needs to be elaborated more. Why does such design make sense and what benefit can be brought through such design? The formulation for semi-supervised SPEN could be defined more clearly and worth elaboration.\n\n- The experiments are run on 3 different random splits, based on the mean(std) of the evaluation metric, the performance of the proposed method does not vary much compared to baselines, especially on the second dataset, eg., GNN 0.25 +/- 0.02 compared with GENN 0.26. Also, GLENN < GNN seems to imply including energy is not the most important part for helping the task, but rather the semi-supervised joint training truly improves the performance. "}