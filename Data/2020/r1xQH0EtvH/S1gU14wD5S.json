{"rating": "3: Weak Reject", "experience_assessment": "I do not know much about this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "In this paper the authors aim to develop an intuition for why neural networks (NNs) generalize so well, despite often being overparametrized for the given problem.\n\nThe paper is well written exploring a very interesting issue. It provides a good discussion of why generalization is puzzling, related work on the attempts to improve generalization bounds for NNs, and qualitative discussion of possibly answers to this problem. Despite this, we feel that a much more experimentation should be done to address some of the hypothesis in the paper. Also, it would have been helpful, if some of the results and figures were presented much earlier in the paper. What follows are the pros and cons / discussion points / styling suggestions the authors could choose to address:\n\n[pros]\n-\tWell-written\n-\tA good survey of related literature and concepts\n-\tInteresting visualizations\n\n[cons / points / styling]\n-\tThe placement of Figure 1 seems arbitrary as you refer to it for the first time on Page 3. This would not be such a big problem; however, it divides the paragraph in two without need to. Could you perhaps place the figure and caption on the bottom of the page?\n-\tIs there a reference for \u201cimplicit regularization\u201d?\n-\tOn page 4, it would have been helpful to provide examples of \u201clinking the intuitive arguments back to theory\u201d\n-\tIt would be helpful to provide more details on the filter-normalization scheme.\n-\tOn page 4, could you explain what you mean by \u201cwide margin classification is replaced with an implicit regulation (regularization - ?) that promotes the closely related notion of \u2018flatness\u2019 \u201c. How is \u201cflatness\u201d encouraged as a prior? Through the choice of an appropriate loss function?\n\nWould it be perhaps more suited for a longer format, e.g. Journal of Machine Leaning Research?\n"}