{"rating": "3: Weak Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This paper addresses to prune networks by evaluating candidate pruned networks using the adaptive batch normalization (ABN). While existing methods utilizes pretrained BN parameters for evaluating pruned candidates, ABN utilizes updated BN parameters by simply forwarding a subset of training data to update the BN statistics given some pruned structure. The authors observed that the evaluation metric based on ABN is more correlated with the fine-tuned accuracy compared to that of PBN. Finally, the authors present experiments for MobileNet and ResNet.\n\nOverall, I doubt the methodological contribution of ABN. I think that the main idea is quite similar to that of Liu et al., 2019b (the right figure of Figure 3). The proposed algorithm `fine-tunes\u2019 only BN parameters while the algorithm in Liu et al., 2019b fine-tunes the whole parameters. Pruning entire one epoch as done in Liu et al., 2019b might be expensive, however, I believe that the training iteration could be adjusted given any computational budget. This is the main reason why my decision toward rejection.\n\nOther comments are listed below:\n-I am not clear about introducing a new correlation measure (5). Explicitly noting why the correlation based on accuracies as done in Figure 3 is not enough for the evaluation would be helpful.\n\n-For justifying (5), the authors mentioned that searching the top-1 model is NP-hard but the top-k model is not. I could not fully understand this statement due to the following reason: If the top-1 model refers the model generating the best test accuracy given pruned architecture, searching it is NP-hard but searching one of the top k best models would be also NP-hard. If the top-1 model refers to the top-1 accuracy (or class) of the fine-tuned model (i.e., Y[1]), then it would be easily computed (i.e., not NP-hard). More explanation on NP-hardness would be helpful.\n\n-In Section 3, there is a repeated argument `Figure 3 and Figure 3 respectively\u2019.\n\n- In the second paragraph of Section 4.2, Figure 4.2 is referred but there is no Figure 4.2\n\n"}