{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "Overview\n\nIn this paper, the authors proposed a new version of graph convolutional network for visual question answering. To enable the \u201creasoning\u201d ability for visual question answering model, the authors proposed a new module called reasoning-awere GCN (RA-GCN). In RA-GCN module, it has a graph learner to learn the connections for visual graph extracted from the image. Then, a conditional graph convolution is performed to modulate the node features in the visual graph based on the question and then update the feature for each node specifically based on the edge context. Based on this RA-GCN module,  the authors further perform an iterative process to perform visual question answering. In the experiments, the authors worked on three datasets, VQA-CP, GQA and CLEVR. On these three datasets, the proposed method achieves better or comparable results to previous SOTA. A detailed ablation study further helps to understand the RA-GCN model more closely.\n\nPros:\n\n1. The authors proposed a new module called RA-GCN for visual question answering. In this new module, the authors used a graph learner to learn the structure of the visual graph, and then used a conditioned convolution to update the node features in the graph.\n2. In the experiments, the authors evaluated the proposed model and previous model on three datasets and achieved better or comparable performance compared. The ablation studies further helped to understand the model more clearly\n\nCons:\n\n\n1. It is not very clear why the proposed model is called reasoning-aware GCN. Though the proposed RA-GCN module perform message passing across graph conditioned on language, i do not think it has learned to perform reasoning for visual question answering. In this sense, the claimed contribution is a bit exaggerated.\n\n2. The difference between the proposed model and other graph-based visual question answering model is not very clear to me. The graph learner in RA-GCN is similar to the dynamic connections learned in LCGCN, while the conditioned convolution is also used on LCGCN.\n\n3. The motivation for RA-GCN is not clear to me. First, why the authors used a graph learner to prune the edges in the graph. Pruning the graph seems not reliable without any supervision on the connections. Second, why the authors used a node-specific updating by introducing a edge tensor. As it is in GCN, a straightforward way is directly regard the edges as nodes in the graph and then perform graph convolution to propagate the context from edges to object nodes. Also, the description of RA-GCN module is vague at some points. First, it is not clear what the Fuse function is in graph learner. Second, it is also not clear how to get the tensor P for node-specific graph convolution. \n\n4. In experiment, it is shown that the proposed model either outperforms or underperforms previous methods. On VQA-CP v2, all models achieved close performance. On GQA and CLEVR, the proposed model is worse than state-of-the-art. Based on the above comments and the experimental results, it is hard to justify the novelty and significant contributions behind the proposed model. What are the main merits in the proposed model is not clear to me.\n\n5. Finally, it would be great if the authors can present some visualization results for the proposed model, showing how the graph is pruned and how the node feature updating is modulated. These would help the reader to understand the \u201creasoning\u201d process behind the model.\n\nConclusion:\n\nIn this paper, the authors proposed a new module called reasoning-aware GCN for visual question answering. It is reasonable to use question to modulate the graph convolution. However, from the method description and the experimental results, it is hard to verify the novelty and significant contributions behind the proposed model. I would suggest the authors explain the motivations behind the model and explain it more clearly. Also, the authors should present some visualization results for the VQA task.\n"}