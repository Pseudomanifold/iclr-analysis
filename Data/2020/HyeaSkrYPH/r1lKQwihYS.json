{"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "The paper proposes a certified defense for adversarial patch attacks.\nTechnically, the authors use the well developed IBP based methods (Gowal et\nal., 2018, Mirman et al., 2018, Zhang et al. 2019).  The technique is simple\nbut effective. Since the number of possible patches are quadratic w.r.t image\ndimension, to reduce the number of bounds to propagate, the authors propose a\nU-Net based NN to predict the worst case scenario, and only propagate \"worst\ncase\" bounds predicted by the U-net.\n\nEmpirically, the proposed method gets good results, with certified accuracy\nsometimes even higher than empirical accuracy by previous methods.  The authors\nalso provide results for transferring robustness properties to shapes that are\nnot included during training.\n\nOverall, the contribution of this paper is novel, and results are promising,\nbut it still has some missing components, especially the idea of combining\nmultiple IBP bounds into one, which can be very effective for adversarial\npatches, as I will elaborate below.\n\nSuggestions and Questions:\n\nThe core idea behind IBP is that for whatever input perturbation is given (any\nLp norm or semi-norm, or non-norm based perturbations like patches at arbitrary\nlocations), it converts them to per-neuron lower and upper bounds after the\nfirst linear/conv layer.  For example, if the input perturbation is *two* patches\nB_1 and B_2, after propagating them through the first layer of the network, we\ngot two lower bounds l_{i,1}, l_{i,2} and two upper bounds u_{i,1}, u_{i,2} for\nthe i-th neuron. We then take the worst case bound, l_i = min(l_{i,1},\nl_{i,2}), u_i = max(u_{i,1}, u_{i,2}) and propagate only one set of bounds l_i\nand u_i to the next layer. The authors should explore on this direction, as\ndetailed below:\n\n1. For the exhaustive patch enumeration in (11), we can actually greatly reduce\nthe computation cost by combining the bounds of different patches after the\nfirst layer of the network, as I mentioned above. At the input layer, the\nnumber of bounds (each for one possible location of patch) are large; but after\nthe first linear/conv layer, we can compress them to one or a small group of\nbounds by taking the worst cast of them, like l_i = min(l_{i,1}, ...,\nl_{i,|L|}), u_i = max(u_{i,1}, ..., u_{i,2}). The patches close with each other\nshould also produces similar lower and upper bounds, so taking min or max over\nthem will not make the combined bounds much worse. This is better than U-net\nprediction since we are guaranteed to include the worst case scenario.\n\n2. Considering multiple patches (at different locations) on a single input. In\nthe simplest case, consider multiple 1x1 patches (in fact, this is equivalent\nto bounded L0 norm threat model); since each patch is 1x1 (only changing one\npixel), the bounds should be relatively tight after the first layer, and after\nthe first linear/conv layer we got 28*28 or 32*32 bounds which will be combined\ninto one or very few sets of lower and upper bounds that will be propagate into\nlater layers.  Multiple larger patches (2x2, 5x5) can be difficult since bounds\nare looser; multiple 1x1 in my opinion is both technically feasible and\npractically important, and should definitely be included in this paper.\n\n\nMinor issues:\n\n1. Eq. (5) and (6) are incorrect; the second term should be \\overline{z} -\n\\underline{z}. Also it is missing the bias term.\n\n2. In related works (section 4.1, page 3), (Weng et al., 2018) is not a defense\nmethod (it is a certification method, and no training is involved).\n\n3. In Table 3, it is better if the authors can provide empirical adversarial\naccuracy to IBP defended networks as well.\n\nOverall, I think it is a good paper but the authors should explore more to\nstrengthen their contributions. I gave a weak reject but I will not hesitate\nto recommend an accept as long as the authors can provide additional results\nmentioned above.\n"}