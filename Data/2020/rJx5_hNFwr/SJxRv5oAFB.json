{"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This paper introduces a new algorithm for learning to detect objects in two domains (eg. sunny and night images), in which one domain is labelled (object categories and bounding boxes) and the other domain does not have labels. To do so, the paper introduces a neural network trained with multiple loss functions and a modified gradient update similar to (Arpit et al., 2019). The method achieves few percentage better accuracy than state-of-the-art methods.\n\nThe problem of domain adaptation is of crucial importance and seeing improvements is exciting. Yet, I find the following points not convincing: \n\n-Novelty: The algorithm in the paper is strongly based on the network introduced by (Ren et al., 2015) with the domain adaptation strategy of (Chen et al., 2018; Saito et al., 2019). The novelty of adding additional loss functions and adapting the gradient update of (Arpit et al., 2019) seems prima facie incremental. \n\n-Analysis of the approach: It is unclear from where the effectiveness of the approach comes from. Figure 1 visualizes the features in the two domains with tSNE, and the features from this paper and from (Saito et al., 2019) have the same properties. From the figure it can not be concluded that \"our feature embedding results are consistently much better than previous approaches\" as the caption says. The ablation study in Table 1 seems to indicate that the gradient update almost does not bring any improvement and it is unclear what else can be learnt from this analysis. In the text of the paper nothing is mentioned. Finally, the attention maps in Figure 6 show no differences with or without detached gradients, but the description of this figure in the text is not in accordance to what is shown in Figure 6.\n\n-Incremental accuracy improvements: Also, when looking closely to the final accuracies, they are  ~3% larger than the best published results which contradicts one of the conclusions \"Our experimental results outperform the state-of-the-art approaches by a large margin on a variety of benchmarks\u201d (ie. 3% is not a large margin). \n\n-Generality of the approach: The algorithmic improvements presented in this paper are specific for object detection and it is unclear if these ideas would transfer to other domains and how.  In fact, the algorithmic choices are described but not derived from some principles, ie. the paper justifies the algorithmic choices because they are \"simple yet effective\u201d and presents them as a series of steps to follow. This obscures how the approach is connected to previous works and how to use it in new works.\n\nIn summary, the paper tackles an important problem and shows few percentage improvements over state-of-the-art accuracy but the method is based on modifications of previous works that are not well justified.\n\n "}