{"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "In this paper authors study one possible incarnation of more biologically plausible learning scheme, akin to (direct) feedback alignment methods, where the error signal is linearly mapped onto the update direction, without reusing forward weight (so to break the weight sharing issue, that currently is believed to be impossible for brains). \nAuthors approach can be summarised as a mixture of synthetic gradients with a noise-enriched estimation, rather than direct empirical risk minimisation.\nContributions are two fold, first, authors provide some theoretical analysis of the convergence of gradient estimator in a simplified setup, second, the noise-based estimator is empirically evaluated on 2 simple classification tasks.\n\nPaper is well written, and easy to read, with relatively easy to follow notation (which is quite a tricky task for non-gradient based learning methods that require abandoning typical concept of loss minimisation and talking about dynamical systems instead).\n\nI have a few critical comments, that I hope authors can address in the revised manuscript:\n- first, high level thing, that seems to be missing from the manuscript is use of baselines that are actually co-adapted, rather than random (e.g. DFA and FA). To be more specific, in papers like \"Sobolev Training for Neural Networks\" (NeurIPS  2017, https://papers.nips.cc/paper/7015-sobolev-training-for-neural-networks.pdf) one can find 3 basic methods (all requiring one implementation, and differ only in terms of which loss is applied): at each layer h, the gradient predictor g(h, e, B) is composed of (d/dh) CE[softmax(Bh + c), y], which has an analytical form, is biologically plausible (as boils down to a simple affine transformation if h and y. This model can now be supervised in 3 ways: \na) one can put supervision only on the gradient (and bootstrap from higher layers, if needed, as in FA or \"fully decoupled\" synthetic gradient model in Jaderberg et al.) [this is essentially \"pure\" SG from Jaderberg et al. but constrained to the conservative vector fields, so to guarantee convergence]\nb) one can put supervision on loss itself matching the \"topmost loss\" (reminescent of DFA, where error propagation skips entire network) [called Critic Training, Critic Network etc. depending on the source]\nc) twe two above can be used jointly (which leads to the full Sobolev training)\nNeither of these methods have been compared, and in reviewer's opinion it is critical, as approaches are very similar, and while Czarnecki et al. was not analysing biological plausibility, the models proposed do satisfy the same constraints requested by authors of this paper. Note, that with critic learning on MNIST, one can easily get results matching backpropagation (which, in the current manuscript is claimed as an important property of the introduced method). It might also be important to show that well tuned linear model on MNIST can reach 95% test accuracy too.\n- similarly, authors are not disentangling noise-induction, from the overall setup. Which of these two is the actual source of good results? Many previous works would rely on empirical risk minimisation, if one uses noised versions and train \"regular\" fully decoupled affine synthetic gradients, will the results be analogous? Will this improve the Sobolev training (if implemented and verified)? Given, that both methods are known object in the literature, providing understanding of which components are actually important (maybe it is only the combination that works?) would strengthen the claims.\n- Analogously, to further decouple mixed effects, when authors claim that noise-based estimator performs better than adam in the autoencoding case, having an adam with artifically added same amount of noise to gradient estimates would be helpful for the reader to see if the difference lies in the \"second order estimates\" of Adam, or in simply regularising effects of adding noise.  In particular, note, that this is a well established result, that noising inputs to the neural network is equivalent (up to first order terms) to Tikhonov regularisation.\n- the theoretical claim of Thm 1 is quite trivial, and while I really admire authors effort to provide theoretical grounding, it feels a bit overstated in the current form. What authors are showing, is that in the simple setup, where network is not learning, and all the errors are in the sense, independent, the linear predictor is consistent. This property is well known, and both assumptions used - never met in practise, consequently I would strongly suggest downplaying the claim, and stating these results in sentence or two, with proof moved to the appendix, as in the current version of the manuscript section 3 is presented as major contribution, rather than an interesting side note.\n\n\nMinor comments:\n- can authors provide some error intervals for results in Table 1? Results are so close, that claiming that 48 is even \"marginally better\" than 47 seems odd, unless many repeated runs were conducted and some confidence intervals can be provided?\n- it is odd to say \"using backpropagation OR Adam\". Adam is just an optimiser, it still uses backpropagation (aka chain rule). Could the notation be unified so that when talking about comparing optimisers, authors state Adam and SGD (assuming that this is what is currently called backpropagation?) and when talking about chain rule, the name of backpropagation is there?\n\n\nOverall I believe it is an interesting study, however, currently missing important baselines and ablations to be a good ICLR contribution. If authors are willing to add these, I will be happy to revise the score assigned."}