{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "---- Problem setting and contribution summary ----\nThe paper considers the problem of graph node classification in a semi-supervised learning setting. When classifying a node, the decision is based on the node\u2019s features, as well as by a weighted combination of its neighbors (where the weights are computed using a learnt attention mechanism). The authors extend upon the recent Graph Attention Networks (GAT) paper by proposing a different way of computing the attention over the neighboring nodes. This new attention mechanism takes into account not just their feature similarity, but also extra structure information, which also enables their method to attend not only over direct neighbors, but also up to k-hop neighbors.\n\n---- Overall opinion ----\nWhile I believe the general idea indeed has merit and empirically shows great promise, I believe the paper in its current state is not ready for publication. However, I believe that a more thorough revision can lead to an a publication with potential impact on the applications side.\n\n---- Pros ----\n1. The paper is easy to read.\n2. I really appreciated the good visualizations (Figures 2,3,4) that indeed help in understanding the method.\n3. Really good empirical results on the 3 datasets that were presented.\n\n---- Major issues ----\n1. Motivation:  \nI believe the paper is not well motivated from an applications perspective. In section 2.1., the authors did a good job explaining the limitations of current approaches on a generic graph structure, but this is only under the main assumption that a node should attend more to neighbors in its denser community than other neighbors that not connected so strongly (Fig 1). The issue that I have with this is that:\n      a) Why should we take this assumption for granted? What are some concrete practical node classification problems where it is indeed better if a node attends to its neighbors in this way (as opposed to the GAT approach)?\n      b) Even if the above is proven true, suppose node A in Fig. 1(a) attends with equal weights to all its 4 neighbors. That means node C (which is outside its densest community) gets 1/4, while the nodes inside the dense community get a total of \u00be. That means node A puts most of its attention to the dense community anyway. In what conditions is it necessary to bias this attention even further?\n\n2. Experiments: \nWhile the reported accuracies for the three datasets look good and also the authors have provided a link to their code (great to see that!), I believe the experimental section is missing an important amount of details for reproducibility purposes and also for explaining how certain parameters have been chosen:\n    a) There are no details on the model size and training procedure (hidden units, optimizer, learning rate schedule). \n    b) Maybe I am missing this, but I don\u2019t see any reference on what alpha and beta from equation (6) were used in the experiments. \n    c) What is the value of k in Table 2? How did you choose it? I believe Figure 5 shows test accuracies for different k, but I hope the authors did not choose k based on the test set performance. \n    d) How did you select the structural fingerprint to be 3?\n     e) \u201c...optimizing c through the learning process also gives very similar choice\u201d \u2192 how did you optimize c exactly?\n     f) Fig 5 a) Why does increasing the number of hops to 3 or 4 decrease the performance so much? Shouldn\u2019t the attention weights learn to ignore the further neighbors, if they are not useful?  \n\n\tAnother important question regarding experiments: since the ablation study shows that the optimal neighbor range is actually 2, a natural baseline to compare with would be something similar to GAT, where an attention weight is applied to all neighbors within two hops (basically skip the fingerprint step, and assume s_{ij} is 1 for all neighbors within 2 hops, and 0 otherwise).\n\n\tAlso regarding experiments, these 3 datasets, although common across many recent graph node classification papers, they are known to be quite limited (small in size and not very representative of real world). Since GAT is your main competitor, why not also show experiments on the PPI dataset they also test?\n\n3. Writing quality: \nWhile the language is clear and easy to follow, there are many grammatical mistakes throughout the paper (e.g. \u201cbenefitial\u201d, subject-verb agreement).\n\n---- More minor issues ----\n    a) Section 2.1: One could argue that GAT also contains longer range node dependencies through the node embeddings it learns. Since the node embeddings is trained through gradient descent, and at each iteration the embedding of a node changes according to its neighbors, you could say that information does get propagated from the neighbor\u2019s neighbors.\n     b) Why do you need a LeakyRelu in Equation (5) ? Also, aren\u2019t e_{ij} non-negative anyway (in which case LeakyRelu doesn\u2019t change anything)?\n     c) Why would a Sigmoid be a good choice for alpha and beta in Eq. (6)?\n     d) Section 3: A bag of words is typically represented as a binary vector, which is also categorical.\n     e) Please use \\citet when specifically referring to the authors of a paper as part of your sentence (e.g. \u201cFollowing Velickovic et. al., 2017 we\u2026.\u201d as opposed to \u201cFollowing (Velickovic et al., 2017), we....\u201d).\n"}