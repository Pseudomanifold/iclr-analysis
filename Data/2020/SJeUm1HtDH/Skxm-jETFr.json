{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper studies the role of audio in object and action perception, as well as how auditory information can help learning forward and inverse dynamics models. To do this, the authors built a 'tilt-bot', which tilts a box and the object within to collect data (sound & vision) of object interactions. The authors then tested how audio embeddings help object recognition and forward model prediction. \n\nThe idea presented in this paper is quite interesting. However, there are no significant technical innovations, the experimental evaluations are quite limited, and the writing can be improved. My overall recommendation is weak reject.\n\nThe problem of integrating audio for perception is interesting and has been quite widely explored; however, this paper extends the setup to also explore the effect of audios on dynamics modeling. This is relatively new and may lead to many potential future developments in this direction.\n\nTechnically, however, this paper mostly builds on existing technicals on learning forward and inverse models, except that the input is now audio in addition to video. The experimental results are also very limited. They are restricted to a single domain, a fixed collection of objects, and there are no comparisons with published, SOTA algorithms. There are also no results on downstream tasks such as robot manipulation.\n\nI also wonder how the authors think of the related work from Zhang et al: http://sound.csail.mit.edu/ , as they've also studied the effect of auditory and visual data in shape and material recognition.\n\nThe writing can be improved. Currently, the model and results are in the same section and mixed together. It'd prefer to separate them. There are a number of typos (incorrect spacing, etc.), especially in Section 3.4. Please double check.\n"}