{"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "1.\tPlease number the equations for better readability.\n2.\tThe usage of smooth kernel regularization, R(w) and logit pairing equation seems disjoint, what is the natural flow here?\n3.\tThe notation <X, Y> is misleading, do not use inner product notation to denote tuple!\n4.\tI do not see any justification of using KL\n5.\tThe contribution in terms of designing R(w) and the logit pair loss function is trivial.\n6.\tThe argmax to get x\u2019 how practically you ensure the solutions are inside the closed ball? The authors mentioned about robustness without any justification. Why related to TV norm? The usage of Pinsker\u2019s inequality to get upper bound is meaningful but that doesn\u2019t prove the robustness. Please explain, also why not state this as a theorem. I suggest prove the robustness in a concrete manner, maybe using influence functions.\n7.\tWhat is the loss function l(.,.) supposed to be?\n8.\tIn R(w) the second part supposed to minimize the norm of convolution kernel I presume, then why there is a negative sign!\n9.\tThe title of Section 4.1 is pretty strange, you don\u2019t have to say \u201c\u2026 for sanity checking\u201d.\n10.\tThe synthetic experiment is very immature and inconclusive. What can we get from Table 1? Also please justify the choices of hyperparameters used.\n11.\tAgain, looking at Fig. 4, I really can\u2019t see the usefulness.\n12.\tSection 4.3 is meaningless and seems redundant. Why not have a single story rather than so many branching, the experiments are not convincing at all.\n13.\tIn Fig. 5, authors argued AR is better than A, I don\u2019t see why, e.g., for horse A looks uch better than AR, same for insect. \n14.\tThe regularization seems not that useful, to me this work tries to justify using a regularization which by the choice of experiments is not well grounded.\n"}