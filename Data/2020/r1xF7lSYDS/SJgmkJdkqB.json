{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The goal in this work is to improve machine interpretability of images.\nThe authors main claims are:\n-\tTheir proposed approach improves image recognition accuracy even without knowing subsequent recognition tasks and recognition models used to perform them (transferable model to different recognition models/tasks).\n-\tFor this they propose what they call \u201cRecognition-Aware\u201d processing that combines image processing loss and recognition loss.\n-\tThe approach is evaluated on three image processing tasks with two downstream recognition tasks:\no\tImage super-resolution, de-noising, and JPEG-de-blocking processing tasks, with \no\tImage classification and object detection recognition tasks.\n\nThe paper is well written and organized, experiments carried are extensive but the reuse of known neural networks, many simplifications (shortcuts), a not clear enough methodology (see below), limited processing & recognition tasks used to support it, do not justify in our opinion the main (over-arching) work\u2019s claim:\n-\tIn 3.2 optimizing recognition loss/Last paragraph:  \u201cInterestingly, we find that image processing models trained with the loss of one recognition model R1, can also boost the performance when evaluated using recognition model R2, even if model R2 has a different architecture, recognizes a different set of categories or even is trained for a different task.\u201d.\n\nThe paper would greatly benefit (to understand the context of the work or the explanations provided) from clarification of the many under-defined, not clearly introduced concepts it carries:\n-\tMeaning of \u201cNetwork\u201d is not clearly defined:\no\tAbstract: \u201cimage processing network\u201d.\no\tIntroduction: \u201cthe network maps an image to a semantic label\u201d\no\tLater in the paper only networks introduced are deep neural networks. That should be clear from beginning of the paper.\n-\t\u201cRetraining/Adaptation\u201d  in 1st paragraph page 2.\n-\tIn 1. Introduction/Paragraph 1: You use \u201c.. techniques .. have been proposed for making the output images look natural to human\u201d:\no\tNoise is part of nature. A de-noised (smoothed) image is not \u201cmore natural\u201d.\no\tEnhanced (processed) images are not necessarily \u201cmore\u201d natural, rather they take advantage of the human visual perception characteristics to enhance recognition for example.\n-\tIn 1. Introduction/Paragraph 3:\no\t\u201c.. of great importance that the processed images be recognizable\u201d  Should explain the concept of image recognition! Because it could be related to contained objects, overall description (for captioning for example) etc. \n-\t\u201cImage processing\u201d in the context of the paper is intended only as \u201cimage enhancement for recognition\u201d. Pattern detection, segmentation, object extraction etc. are not included in this restrictive definition. Should specify for example: image enhancement and restoration. \n-\tFigure 1: As an illustration, it\u2019s completely counterproductive for your discourse as many simple image recognition algorithms would recognize the bird even in the noisy image.\n-\tIn 3. Unsupervised optimization of recognition loss: The \u201cunsupervised RA\u201d process is not  clear enough to us especially the statement:\no\t\u201c.. only \u201cunsupervised\u201d for training model P, but the target pre-trained model R can still be trained in full supervision.\u201d.\n\n\n-\t\u201cWe may not know what network architectures (e.g. ResNet or VGG) will be used for inference, what object categories the downstream model recognizes (e.g. animals or scenes), or even what task will be performed on the processed image (e.g. classification or detection)\u201d. \no\tIs your goal a universal \u201crecognition model\u201d applicable to anything?\n-\tI also have some trouble with the terminology:  \no\tIn 1. Introduction/Paragraph 4: \u201cIt is also important that the enhanced machine semantics is not specific to any concrete recognition model\u201d: \u201cenhanced machine semantics\u201d!\no\tIn 1. Introduction/Paragraph 4: \u201c..transferable among different recognition architectures..\u201d. Does \u201carchitectures\u201d refer to deep neural networks (DNN)? If yes, is recognition performed only by DNN? What about the preceding bullet (\u201cis not specific to any concrete recognition model\u201d)?\n-\tIn 1. Introduction/Paragraph 3: \no\t \u201c.. we argue that image processing systems should maintain/enhance machine semantics\u201d. Do not see what\u2019s to argue here?\no\t\u201cRecognition-Aware Image Processing\u201d is it simply put Image Processing techniques for recognition enhancement (\u201cRecognition\u201d still needs to be defined)?\n-\tIn 2 Related work :\no\t \u201c .. we assume we do not have the control on the recognition model, as it might be on the cloud or decided in the future, thus we advocate adapting the image processing model only. This also ensures the recognition model is not harmed on natural images.\u201d Care to explain?\no\t: \u201cto achieve better recover the face identity from low-resolution images\u201d, Typo?\n-\tIn 1. Introduction/Paragraph 1:\no\t\u201c .. might not look \u201cnatural\u201d to machines\u201d: Care to explain this concept? \n\uf0a7\tWould advise to just keep the second part of the sentence.\n-\tIn 1. Introduction/Paragraph 2: \u201cOne could specifically train a recognition model only on these output images produced by the de-noising model to achieve better performance on such images, but the performance on natural images can be harmed.\u201d  Care to explain?. \no\tMore complicated images (noisier, multiple obstructions etc.) are recognized nowadays and true to actual applications.\n\n-\t3.4 using an intermediate transformer/Last paragraph:\no\t\u201c .. that there are two instances for each image (the output of model P and T), one is \u201cfor human\u201d and the other is \u201cfor machines\u201d.\u201d:\n\uf0a7\tThe \u201cTransformer\u201d characteristics are not clearly defined for the intended output (For machines?).\n\uf0a7\tWhy is output of model T not represented in Figure 2 (Right)?"}