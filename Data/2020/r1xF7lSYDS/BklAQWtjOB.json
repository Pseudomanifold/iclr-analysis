{"rating": "8: Accept", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "Claims: \n\nThe paper presents a concept of \"recognition-aware (RA) image processing\": when one enhances image in a some way, not only human judjement should be taken into account, but also performance of various computer vision application using that image.\n\nAs an example of processing tasks, authors take super-resolution, denoising and JPEG-artifacts removal. Downstream applications covered are image classification and object detection. \n\nAuthors propose a several training schemas to solve this problem and discuss a limitations of each one: \n - \"simple\" preprocessing, when the only image enhancement loss is optimized\n - \"RA\" joint optimization of recognition and enhancement loss (supervised and unsupervised)\n - a variant when two images are created: one for human and one for machine.\n \n****\n\nRecommendation: strong accept\n\n****\nComments: \n\n Experiments are vast and performed on a variety of CNN architectures: ResNets, DenseNet ant VGGNet.\n Because one cannot predict, which computer vision tasks will be needed in the future, the natural question arise: how the results got for one set of tasks, architectures and image enhancement types transfer to another. Paper carefully studies this aspect as well.\n  \n Overall paper is well written and is pleasure to read. While reading, I made notes to ask in review - just to see the my questions answered in a next section.\nAuthors also provide source code for training. I haven`t run them though, but glanced through them.\n \n Weaknesses: I cannot really find a significant one. As a minor points:\n  - I would recommend to cite not the last papers for image enhancement porblems themselves like super-resolution and denoising: these are old problems with rich history, e.g.\n \n L. Rudin, S. Osher, and E. Fatemi, Nonlinear total variation based noise removal algorithms Physica D, 60 (1992), pp. 259\u2013268.\n \n - \"Transformer\" is probably bad name for deep learning component, as it is already widely used for a specific seq2seq architecture \n"}