{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "This paper proposes a variant of the use of Frechet Inception Distance (FID) for the evaluation and benchmarking of conditional GAN models. FID is a popular measure for comparing image distributions in the Inception v3 feature space, in terms of the means and variances of multivariate Gaussians fit to data samples from each distribution. The authors argue that FID is ill-suited for use with cGANs, in that they do not explicitly take into account conditional consistency or intra-conditioning diversity. The main contribution and basic idea of this paper is to create joint image-conditioning distributions from the image embedding and the conditioning embedding in the Inception embedding, and then to combine them (by default, through vector concatenation). These joint image-conditioning distributions are then fed to FID as per standard usage on image distributions alone. The authors refer to their approach as FJD (Frechet Joint Distance).\n\nAlthough the authors propose FJD as a new technique, it should more properly be regarded as the direct use of FID on joint distributions. The main practical contribution of the paper thus reduces to the notion of concatenating the learned conditioning representation with the image representation. As a research contribution, this is in itself not very substantial. However, in their experimentation the authors do take care to show through examples the effect of their joint image-conditioning approach in assessing image quality, conditional consistency, and intra-conditioning diversity, under a variety of conditionings.\n\nThere are some issues that are not adequately addressed:\n\n1) In all experimental cases FJD scores and FID scores correlate well, which undercuts the argument that FJD is superior to FID in assessing the performance of cGAN models. Can situations be experimentally demonstrated where that is not the case? In particular, what happens when the fit in image representation is dramatically better / worse than that of the conditioning representation? This situation is interesting, but not considered in this paper.\n\n2) The effect of the dimensionality of the learned representations is not addressed. When concatenating vectors to produce a joint image-conditioning representation, the dimensionality increases, which would tend to produce larger FJD values than their corresponding FID values. The experimental results of this paper seem to confirm this. However, is\nit really valid then to declare FJD as being somehow more sensitive to the conditioning simply by virtue of obtaining larger values and larger spreads than FID? It should be remembered that FID and FJD are *not* unitless measures.\n\nOverall, in its current state the paper appears to be below the acceptance threshold.\n"}