{"rating": "1: Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review": "Summary\nThis paper mention that there are some critical drawbacks existing in IS (Inception Score) and FID (Fr\u00e9chet Inception Distance) which are two popular metrics to measure image generation quality. However, IS and FID scores are initially designed for measuring unconditional distribution, which fails to capture the conditional consistency of conditional distribution. Thus, the authors propose to concatenate conditioned embedding h(y) with image feature vector f(x) to extend the FID metric. The authors also implement the method on a toy dataset to show the sensitivity of FJD on conditional consistency and several popular cGAN models to show the efficiency of FJD on real data.\nPaper Strengths\n  1. The method is intuitive and easy to implement.\n\nPaper Weaknesses\n1. Although this paper shows the problem of FID for capturing the conditional consistency sprightly with the toy dataset, however, this problem does not obviously show up on real data. Basically, FID can also give a good comparison of the different model as FJD"}