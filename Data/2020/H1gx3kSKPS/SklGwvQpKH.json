{"experience_assessment": "I have published in this field for several years.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "Summary of the paper: \n\nThe paper proposes to train implicit  model such as gan and an explicit model (Energy Based ) jointly . The GAN is trained using WGAN-GP objective or the original JS objective (we have a discriminator D and Generator G). The energy based model (E) is trained using Stein Divergence with a fixed kernel k or a learned critic who's parameters are denoted pi in the paper. Note that the critic of the stein divergence is vector valued. This paper propose to add a regularization loss on the stein divergence between the generator G (implicit model ) and the explicit model (E). This gives a training objective \n\n$\\min_{G,E} W(P_r, G) + \\lambda_1 S(P_r, P_E)+ \\lambda_2 S(P_{G}, P_{E})$\n\nIn the paper the stein critic is shared between the two stein divergence which means that the authors are rather considering : $S(\\lambda_1 P_r + \\lambda_ 2P_{G}, P_{E})$\n\nPaper shows the effect of this additional coupling between the two models as a regularization on the Discriminator D and on the critic of the stein divergence. \n\nThen  the effect of the regularization is also show in terms of convergence in the optimization on a bilinear game, and in the convex concave case. \n\nExperiments are given showing the benefits of the joint training. \n\nReview: \n\nThe paper has a lot of typos and needs a lot of proofreading and is not in shape for being reviewed. \nThere are too many concerns with this papers:\n\n1- The first one was mentioned above if the critic is shared then you better be considering :  $S(\\lambda_1 P_r + \\lambda_ 2P_{G}, P_{E})$\n\n2- In equation 4,  the problem is $\\min_{G} \\max_{D}$ it is swapped.\n\n3- There a lot of gaps in the proofs of Theorems 1 and 2. The transition from equation 14 to the $\\inf_{\\mathbb{P}}...$ is not explained and seems flawed. In theorem 2 , the proof is too short and swapping of $\\min$ and $\\mathbb{E}$ is not backed rigoursly. \n\n4- Again in Equation 8, it is not clear how the Stein terms were computed , the appendix does not give the derivations either.\n\n5 - Authors say that the Stein critic have similar architecture to the GAN critic , which indicates an error in the implementation in the neural case for stein critic. Stein critic has to be vector valued, after checking the code of this paper on GitHub, stein critic maps to a real value in the code , which is flawed. The critic of stein needs to map the image to an image , which actually quite expensive. \n\nTypos: \nabstract : without explicitly defines -> defining \nmultimodal data . has been -> have \nwithout explicit defines -> defining \n"}