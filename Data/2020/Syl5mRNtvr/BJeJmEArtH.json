{"rating": "1: Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "Summary: \nThe paper introduces a probabilistic grammar formulation for the task of predicting labels of future timesteps. The grammar is simplified to only contain productions of the form A -> Bc with nonterminals A and B and terminal c. The current nonterminal encodes the current \u2018state\u2019 and the current terminal encodes the label of the current timestep. The production encodes the transition from one state to the next as time proceeds. The grammar is formulated using a number of neural feed-forward networks in order to make the rules, nonterminals, and terminals all differentiable and thus learnable via backpropagation. Since the grammar can generate samples, it can be (and is) trained in a generative adversarial framework where a learned discriminator D must determine if a pair of sequences of nonterminals and terminals are generated by the model or from the data. The model is evaluated against baselines on two activity-forecasting / -recognition datasets and outperforms all baselines. It is also evaluated on a pose forecasting dataset and outperforms a number of prior works here, particularly at longer time horizons.\n\nOverall:\nReject. While I think there are merits to the approach, the explanation of the model was opaque and did not sufficiently compare and contrast to existing work both in the model definition and in the experimental evaluation. In particular, from my understanding of this model (made challenging by the explanation) and the limited probabilistic grammar that it encodes (only A -> Bc), it seems nearly identical to a (neural) hidden Markov model (i.e., a hidden Markov model that uses deep networks to parameterize the conditional distributions, e.g., [1]). Second, empirically, from a quick google search, other papers have published results on both the MultiTHUMOS (e.g., [2]) and Charades datasets (for the latter, there was even a competition [3]), none of which are mentioned here. \n\nClarity: Well written but not particularly clear. Model section is somewhat confusing and needs clarification, and the experiment section is missing details on the variants of the proposed model. It was also difficult to determine the specific way that adversarial training was performed; the explanation given was of high-level adversarial training but lacking sufficient specifics to reimplement.\nSignificance: Potentially useful but quite limited by the above-mentioned issues. I am not an expert in this application domain, however.\n\nDetailed comments:\nSection 1.\nThe introduction should better clarify what is meant by \u2018adversarial sampling\u2019. I was uncertain whether this meant a GAN-like training procedure or something else entirely until later sections.\n\nSection 3.\n- The model, as far as I can tell, does not learn transition between continuous events in time. It is given a sequence of discrete timesteps and learns discrete labels for those. Specifying \u2018continuous events in time\u2019 is misleading.\n\nSection 3.1.\n- It would be helpful to include an example of a nonterminal, terminal, and production at the beginning when the grammar is defined.\n- The grammar defined is non-probabilistic; however, the grammar used later is probabilistic. The definition should match the actual model.\n- Is a nonterminal a vector in R^D? And a terminal a vector in R^|\\Sigma|? This should be said explicitly.\n- r is used to denote both a \u201cset of rules\u201d and later \u201ca specific rule\u201d. Please use different notation or at least boldface to distinguish these.\n- Further, r is said to be a \u201cset of rules\u201d but then said to be a vector whose elements specify the probability of a set of rules. It is one or the other, not both. Does the latter mean that there\u2019s a learned matrix (or tensor) of rule vectors that the probability vector indexes? Or are the rules themselves just indicators in a vector and this is the probability of each one? Please make this more clear.\n- The notation G(A) = { (f_N(f_R(A)), f_T(f_R(A))) } produces a set containing one pair containing two lists, which does not match the prior notation of {(B_i, t_i)} = G(A).\n- This whole section would be made much more clear by explicitly defining the vectors as members of R and the mappings defined by the functions. Currently, it is quite confusing and I had to go over it many times to try to understand what exactly was being proposed.\n- Does the model not take in images after the encoding of the initial frames? Is it simply used to roll out future labels? This seems like a missed opportunity for a more useful model. \n\nSection 3.2.\n- This reads as a high-level description of applying GAN-style training to the proposed approach but does not provide the reader with enough information to know how this was actually done. For example, were sequences subsampled? What lengths of sequences were used? Was anything done to prevent overfitting, which can be quite problematic in these setups (e.g., [4])? This is unfortunate because I think that this training approach could be a useful contribution, as previous methods for training these styles of model rely on variational inference or other complex methods. \n\nSection 4.\n- I was glad to see some minor ablations of the grammar without the adversarial training in the experiments. However, I could not find an explanation of how it was trained if not using an adversarial method. A better description of the variants of the proposed approach should be added.\n\n\n[1] Structured Inference Networks for Nonlinear State Space Models. Krishnan, Shalit, and Sontag (2016).\n[2] https://paperswithcode.com/sota/action-detection-on-multi-thumos\n[3] http://vuchallenge.org/charades.html\n[4] Task-Relevant Adversarial Imitation Learning. Zolna et al. (2019).\n"}