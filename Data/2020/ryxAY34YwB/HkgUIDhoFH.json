{"rating": "1: Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper suggests generating a large news summarization dataset by taking advantage of the fact that in news articles it is often the case that first few sentences contain the most important information. I have the following criticisms of this paper:\n- the idea is not novel. The XSUM dataset cited had used this to create a large dataset based on BBC articles as the editorial guidelines are such that the first sentence is a summary of the article. The lead1 baseline doesn't make sense, as it is the actual reference of the dataset. As implemented, it actually picks the second sentence of the original article, and unsurprisingly works worse than the lead-X for the other two datasets.\n- the filtering based on word overlap between the initial sentences and the rest of the document means that the training dataset will encourage models copying words; good summaries don't have high word overlap necessarily.\n- no human evaluation is not conducted; ROUGE indicates small differences, but it can't be trusted without confirmation by human evaluation\n- I don't agree that using positional information is bad for the models. The point is that we need to do better than that, but we should still take it into account"}