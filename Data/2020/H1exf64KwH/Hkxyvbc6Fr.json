{"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper presents POPLIN, a novel model-based reinforcement learning algorithm, which trains a policy network to improve model-prediction control. The paper studies extensively how to utilize the policy, by planning in action space or planning in parameter space and how to train the policy, by behavioral cloning, by GAN or by averaging the results of CEM. The experiments show that the proposed algorithm can perform very well in MuJoCo tasks. \n\nOverall, the paper is well-written and the method is novel. The extensive experiments make the paper more convincing. \n\nQuestions:\n1. In the example of arm in the first paragraph of Section 4.2, although the mean is 0, the randomness in sampling will be the tie breaker. So \"failing\" is probably not the best word here. \n2. It seems that the policy network is deterministic. Why?\n3. Reparametrizable policy often requires fewer (noise) parameters to be optimized over. For example, suppose the policy outputs a multi-variate Gaussian distribution with diagonal covariance in R^10, then we only need to optimize over 10 parameters (the Gaussian noise).  Why optimize all parameters in the policy network, which makes optimization more difficult? \n4. Sec 5.1 Para 2: To my knowledge, the state-of-the-art model-based RL algorithm in MuJoCo environments is MBPO (https://arxiv.org/abs/1906.08253, NeurIPS 2019). \n5. What's the architecture of policy network? More importantly, how many parameters does the policy network have? It's really interesting to see that CEM works for such a high dimensional space. In an environment where a larger network is required, the optimization seems to be more difficult. \n6. In Ablation Study, what does \"imaginary data\" mean? \n7. I'm also curious to see how the objective of CEM improves. \n\nMinor comments:\n\n1. Sec 5.1 Para 2 L11: efficient -> efficiently. \n2. Are you talking about Figure 3 at Sec 5.2? If so, could you please add a link to the figure? \n3. A lot of default values need to be specified: What's the policy distillation method used in POPLIN-A/P in Table 1? Does POPLIN-A mean POPLIN-A-Replan or POPLIN-A-init? Does POPLIN-P mean POPLIN-P-Sep or POPLIN-P-Uni? \n4. Sec 4.1 Eq (2): \\delta_0...\\delta_\\xi are \\xi+1 sequences. \n5. Sec 5.3 Para 3: multi-model -> multi-modal. "}