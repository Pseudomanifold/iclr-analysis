{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "This paper proposes a layer-flexible adaptive computation time model which enables learning with a different number of layers at each time step.  It proposed a set of mechanisms to make the variable layer possible. It uses attention to re-arrange the hidden states in different layers into a different number of hidden states, thus allowing the hidden layers to be variable between different time steps. It also augmented the RNN to have a transmission state that transmits layer information to the next time step. \n\nIn the LFACT model equation after Eq.4 on Page 4, the lower layer hidden states are incorporated with the previous time step hidden states through the function g, before they were sent into the RNN cell f. This makes it different than a more straight forward setting in stacked RNN where the lower layer outputs are sent to the upper layer cell directly. I am wondering why this indirect way of stacking? will it work well if the layers are stacked as the normal stacked RNNs do (i.e., u_t^n takes the lower layer hidden state u_t^{n-1} as input)?\n\nIn the experiments, it seems that the N_t is very stable through time steps. Most of them are 1 or 2 layers. Although the LFACT outperforms the RNN and ACT significantly, that could be a factor of hyperparameter tuning or model structure advantage. Have the authors tried to fix N_t as a constant (let\u2019s say 2), and then perform the whole thing on the same setting again? I highly doubt that it will yield worse results. \n\nFor the N_t, is there any implication on what kinds of time steps should have more pondering steps and how does the model\u2019s choice match with the expected pondering time steps? Or  at least, if we are in an unsupervised setting so that we don\u2019t really have the \u201cexpected pondering time steps\u201d to check the quality of adaptive layers, we should run multiple replicas of the model with different parameter initializations and show that the distribution of N_t on each of the time steps are not uniform. If the \u201cpondering time\u201d (N_t\u2019s) are playing a role in processing the data, they should at least show some patterns that are related to the corresponding input, either decipherable or not. \n\nLearning through a different number of layers between different time steps is not a novel idea. For example, the TARDIS model (https://arxiv.org/abs/1701.08718) has set the number of hidden layers variable. \n\nIn general, I think the authors have provided an interesting idea and the experiments are well performed. I\u2019d expect the authors to isolate more factors from the model in order to show the effectiveness of the adaptive layer mechanism.\n"}