{"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "Summary:\nThe paper proposes the use of a hierarchical model for a generative modeling task. They propose a framework of introducing an intermediate latent variable to enforce the independence of the control and noise variable. \nThe paper report extensive experimental results to validate the proposed hierarchical model. \nThe authors also provide the anonymized code to observe the exact implementation in TensorFlow to visualize the latent variable traversals.\n\nComments:\nThe paper proposes the use of a hierarchical model for a generative modeling task by introducing an intermediate latent variable to enforce the independence of the control and noise variable. \nThe paper report extensive experimental results to validate the proposed hierarchical model. \nThis type of framework of crude to fine hierarchical generative model has already been successfully introduced by StackGAN and it's recent variants.\nOn the unsupervised disentangled feature learning, the framework provides incremental advancement by using beta-VAE in conjunction with GAN to use the best of both the worlds. \nEven though the proposed approach is similar to StackGAN, the experiments and the results mentioned in the paper are noteworthy.\n\nQuestions to Authors:\nThere are 2 main claims of novelty made in the paper.\n1. Architectural Biases: \nHow is the approach different in comparison to the StackGAN and it's variable which also use multiple levels of crude to fine image generation?\n2. Unsupervised control variable discovery:\nThis part is just the use of existing disentanglement VAEs to extract the control variables. So how does the paper try to make contributions to improve the disentangled features with the proposed method?\nApart from combining these to existing ideas, what can be considered as an added novelty to improve the quality of the disentangled features?\n\nIn summary, I find there is no novelty involved apart from combining the already existing SOTA model in disentangled feature learning (beta-VAE) and image generation (StackGAN).\n"}