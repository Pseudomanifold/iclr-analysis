{"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This work proves seval binary quantization guarantee for the 1 or 2 bit cases, and shows some empirical error analysis. \n\nI am not an expert on neural network compression so I am not quite sure how the proposed method compares with the state-of-the-art algorithms. On the other hand, I checked several proofs provided by the authors for the 1-bit and 2-bit quantization cases. The proofs look good to me.\n\nSome minor comments:\n1. For the definition (9) can the authors make it clear that it is for all v_j s.t. v_1>= v_2>=.... instead of \\exits v_j?\n2. Can authors provide some explanation why in (8) we want to have v1>=v2>=vk in the constraint? I understand we need that in the proof, but is there any reason this is also the case in empirical evaluation? To me we may also have cases such that v1 < v2, is there any guarantee for those cases?\n3. Feels like the draft can be compressed into 8 pages, even if the work looks nice.\n"}