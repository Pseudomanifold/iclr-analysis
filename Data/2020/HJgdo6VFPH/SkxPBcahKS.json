{"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper proposes a unified architecture in the context of multi-task learning where they demonstrate that training four tasks (with a variety of modalities like image, text, and videos) together results in about three times compressed model, while maintaining the performance similar to their respective individually trained models. The major components of this archtiecutre are (1) peripheral networks: used to encode the domain specific input into feature representations. (2) central neural processor: a fully attention based encoder-decoder model similar to the Transformer networks which encodes the spatio-temporal information. Further, this paper suggests that their unified architecture enables to perform decent on unseen tasks during its training. In this paper they test such scenarios on video captioning and video question answering. \n\nOverall, the paper is clear to read and thorough in its experiments, with the caveat that its missing many multi-task paper references and the ideas are not much novel. However, I would say the setup is well engineered. \n\nArguments:\n\n1) There are many works in multi-task learning after Luong et al., 2016, please refer them in the related work section (this section is very short!) and discuss on the differences of your model w.r.t. previous work (this is completely missing in the paper). I am pointing to some references below. \n\n2) Statistical significance tests are missing to show that MULT-3 or MULT-4 are able to \u201cmaintain\u201d the performance w.r.t. IND. \n\n\n[1] Latent Multi-task Architecture Learning, Ruder et al., 2019\n[2] A Joint Many-Task Model: Growing a Neural Network for Multiple NLP Tasks, Hashimoto et al., 2017\n[3] Multi-Task Video Captioning with Video and Entailment Generation, Pasunuru & Bansal, 2017\n"}