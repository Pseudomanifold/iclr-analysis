{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "The authors propose an extended and unifying learning architecture \u2013 OmniNet- based on transformer, which tackles tasks with various modalities such as images, text and videos. This is attained with a spatio-temporal cache mechanism, that can both capture and store temporal information and spatial information. In addition, this proposed framework supports asynchronous multi-task learning with pre-trained neural networks on different modalities. OmiNet\u2019s generalization capability is illustrated and demonstrated with experiments. The proposed model has multiple peripheral networks each majoring on one unique modality of data. These peripheral networks project input data into the same shared format/space that can be uniformly processed in a central neural processor working like a CPU. The central neural processor uses self-attention and RNN for temporal encoding and spatial encoding. The output of the encoding components are stored in temporal and spatial caches respectively. The two caches are then used as input to the spatial temporal decoder for different tasks. \n\n\nOverall, this paper is well-written, and technically sounds, with comprehensive experimental results. However, I still have two concerns below that prevent me from giving a direct acceptance.\n\n\n1.\tHowever, considering the proposed model attempts to solve the multi-task learning problem, there seems no multi-task learning methods compared as baselines, making it hard to justify the performance.\n\n2.\tFurthermore, in Table 1, the Omin-Net results are not as good as SOTA, without clear explanation. The parameter settings for SOTA are also missing. \n"}