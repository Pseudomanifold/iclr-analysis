{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This paper discusses the many shortcomings of existing adversarial attacks for NLP models. It is extending the work of (Gilmer et al., 2018) --mostly about attacks for CV models-- to NLP. It proposes 5 types of constraints that should be made explicit by algorithms generating adversarial examples: morphology-preserving (e.g., character substitutions), semantics-preserving (anything as long as semantics are unchanged), semantics-constrained (anything as long as the semantics chosen by the attacker are expressed), syntactically-constrained (anything that is grammatically correct) and non-suspicious (appearing human written). It goes on to show that two recent algorithms relying on synonym-substitution, namely (Alzanto et al., 2018) and (Jin et al., 2019), fall short on 3 of these constraints, sometimes despite claims of the contrary.\n\nOverall, the paper introduces interesting ideas, with a noble goal: making the categorization and evaluation of adversarial generation algorithms both more rigorous, more fair. But I feel the organization of the paper makes its exact contribution somewhat unclear and drawing conclusions is difficult.\n\nSection 3: Constraints\n- It would be helpful to relate the constraints with the existing adversarial NLP literature. What is new? How much of it is just a review of the existing body of work? Are you uncovering blind spots in the classification of attacks, that researchers have not previously considered? Could you make explicit where the novelty lies?\n- It would be interesting to discuss how comprehensive the provided list of constraints is (or is expected to be), especially since the conclusion hints at future work that may \"expand [the] hierarchy\".\n\nSection 4: Experiments\n- Why not do a more comprehensive evaluation of the literature? This section only chooses two similar algorithms. A general framework is introduced but only a narrow slice of the literature is evaluated.\n- Only three constraints are studied, because some are considered mutually exclusive. It would be nice to state this explicitly in this section, as well as keep the terminology consistent (e.g., syntactic constraint vs grammatical correctness).\n- I don't find the evaluation methods very convincing in the way they are presented:\n      - How good is LanguageTool to evaluate grammaticality? Could it have biases that make it more likely to detect errors in adversarial examples? Are there other tools not relying on hand-curated rules available? This could be discussed.\n      - On preservation of semantics, what fraction of ratings are \"Not sure\"? Does the average score change if \"Not sure\" ratings are discarded? Neutral, noncommittal ratings can be an issue with human evals. Also, why not use the \\epsilon=2 rule advocated for in Section 3.2?\n\nOverall this paper raises important issues, but its current organization makes it feel incomplete. Both section 3 and 4 could further expanded with additional analyses to make a much stronger statement. Perhaps it could even be worth splitting this paper into two?\n\nI would suggest the authors make more explicit or consider:\n- How do they want this paper to impact the field? What conclusions should the readers get to?\n- Could they provide a set of tools that benefits the evaluation of algorithms generating adversarial examples? Without such tools, what prevents future researchers to come up with evaluation methods that have the same shortcomings that you try to address?\n- What research is needed to further automate the evaluation process and ensure consistent evaluations? Can this paper encourage such research?\n\nOther minor details:\n- Why are the first three constraints mutually exclusive? One and two don't seem to be, as one can modify a few characters while maintaining semantics. Making these adversarial might be hard, but wouldn't these also be some of the most interesting adversarial examples?\n- Page 1: typo - vulnerable\n- Page 6: typo - far more often\n\n"}