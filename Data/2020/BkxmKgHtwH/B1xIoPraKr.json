{"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "\nSummary\nThe authors survey and categorize recent work in adversarial examples in natural language. The authors further quantitatively disprove previous synonym-based substitutions preserve semantic and grammatical correctness.\n\nDecision\nOverall, the paper is well written and formally categorize many recently work in adversarial examples in natural language. The quantitative study using LanguageTool and human eval is quite important for the community.\n\nSupporting argument\n1. The paper is clearly organized and formally categorize the perturbation in natural language. \n2. The findings that adversarial examples diverge in semantic meaning or do not appear to be human-written are important.\n3. It might be good to show some qualitative examples for the grammatically, semantically incorrect cases.\n\n\nAdditional feedback:\n1. Missing reference: https://arxiv.org/abs/1904.12004v1 is another relevant adversarial attack to machine translation, image caption models. It might not fit into the current categories. \n2. Huang et al. 2019 uses IBP not only for synonym attacks, but also for morphology preserving perturbations (typos). \n3. I disagree with the problematic statement for training IBP. The drop of nominal test accuracy is not limited IBP, but is related to the tradeoff between robustness and nominal test accuracy (https://arxiv.org/abs/1805.12152)\n"}