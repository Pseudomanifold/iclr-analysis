{"experience_assessment": "I have published in this field for several years.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper proposes a new task/dataset for language-based abductive reasoning in narrative texts.\n\nPros: \n\n-\tThe proposed task is interesting and well motivated. The paper contributes a dataset (20,000 commonsense narratives and 200,000 explanatory hypotheses). The construction of the dataset was performed carefully (e.g., avoiding annotation artifacts).  \n\n-\tThe paper established many reasonable baselines.\n\n-\tThe paper conducted detailed analysis, which invites more research on this task: despite the strong performance of many existing systems on NLI/RTE, there are larger gaps between the performance of these models and human performance on the proposed task. The experiments well support the conclusions made in the paper.\n\n-\tThe paper is well structured and easy to follow. It is well written.\n\nCons/comments: \n\n-\tWhile this is a new and interesting task, the contribution (as discussed above in \u201cpros\u201d above) is somewhat limited. I also suggest the paper discusses e-SNLI a bit more. \n\n-\tThe paper has a specific form of formulation for abductive reasoning, where there are exactly two observations and one proceeds the other; the explanation happens in between. I can see this helps collect and annotate data, but also limit the form of abductive reasoning and how models should be developed. \n\n-\tShould the title of the paper specify the paper is about \u201clanguage-based\u201d abductive reasoning. \n\n-\tA minor one: \u201cTable 7 reports results on the \u03b1NLI task.\u201d Should it be \u201cTable 2\u201d?\n"}