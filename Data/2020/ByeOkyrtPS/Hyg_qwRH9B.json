{"experience_assessment": "I do not know much about this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #4", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper addresses the problem of visual plan completion in the presence of noisy observations. The heart of the authors' approach is to learn embeddings of actions given distributions over actions (which correspond to steps in an uncertain plan), using various proposed \"affinity models.\" These affinity models are used to generate affinity scores (roughly, given a set of previous distributions over actions, how likely is each possible next action?).\n\nI think that the problem being studied is well-motivated by the authors, and I especially appreciated the introductory material on the importance of a system that reasons about distributions over actions, rather than simply assuming maximum likelihood ones.\n\n--Main Comments--\n\nMy main concern with the current version of the paper is the lack of clarity as to what is being done, and what (formally) the core contribution is. Even after reading through a couple of times, I only have a vague understanding of exactly what a \"affinity model\" is, mathematically. From what I gather, it seems an affinity model is a distribution P(Distr(a_{t+j}) | Distr(a_t))? How do the encodings \"enc\" factor into this definition? Is computing an encoding a necessary characteristic of any affinity model? Without these details, I am unable to understand precisely how the methods proposed in Section 4 (Distr2Vec and RS2Vec) fit into the problem formulation described in Section 3.1. I believe the text could be strongly improved with a clear mathematical definition of what an affinity model is, since this term is used so frequently, and a reframing of Section 4 around this definition.\n\nMy other major concerns lie in the experimental results. The experiments as a whole are rather opaque (some sort of visualization would have been very nice to see; for instance, could you maybe show a plan completion found by your method in one of the domains you experimented in?) Looking at the results in Section 5.3, I found Figure 9 rather unconvincing. The authors state that when PER is high, Distr2Vec \"clearly performs the best,\" when in fact the improved accuracy is only around 5%. I fully appreciate that in some benchmarks, 5% can be a major improvement, but I am unable to place the experimental results provided in this paper in comparison to other state-of-the-art plan recognition methods; only a naive affinity-model-based baseline (GM) is compared against.\n\nOn a similar note, Figure 10 seems to show little to no accuracy gains by using the proposed methods over GM, especially in light of the increase in training times.\n\nFinally, Figure 8 seems to suggest that LSTM and Algorithm 1 perform similarly. In the text, the authors state that \"LSTM requires 29.5 Secs to train and 0.02 Secs to recognize one action in testing phase\" while \"Algorithm 1 requires 8.0 Secs and 0.80 Secs respectively\" -- this, to me, indicates a tradeoff of faster training and slower inference vs. slower training and faster inference; it's not quite clear that one should be preferred over the other, and in fact it probably depends on the application in general.\n\nDue to the issues of clarity as to what is being done, and the unclear experimental significance of the work, I cannot recommend acceptance at this time, but I look forward to hearing the authors' responses in the rebuttal phase.\n\n--Other Comments--\n- Could you give some intuition on why anything useful should be learned when PER is 100%? My intuition would be that your proposed methods will not \"rule out\" the correct actions like GM does; is this correct?\n- The experimental results suggest that Distr2Vec performs mostly comparably to RS2Vec, while only requiring a tiny fraction of the training time. Is there any practical reason to ever prefer RS2Vec?\n- There are also other places where the exposition are unclear. For instance, in the Introduction, Distr2Vec is written to seem like an improvement over RS2Vec, but counter-intuitively, Distr2Vec is described before RS2Vec in Section 4. Making the story and relationship between the two consistent throughout the document would help improve the clarity.\n\n--Minor Points--\n- Make colors in plots consistent, e.g. in Figure 6 the colors for RS2Vec and Distr2Vec are swapped in the rightmost plot compared to the other three.\n- The colors in Figure 10 (left) are too similar, I cannot tell the data apart."}