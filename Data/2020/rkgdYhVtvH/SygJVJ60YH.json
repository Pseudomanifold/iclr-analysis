{"experience_assessment": "I do not know much about this area.", "rating": "3: Weak Reject", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "title": "Official Blind Review #3", "review": "The paper proposed an unified model for Label Propagation (LPA) and Graph Convolutional Neural Networks (GCN). It is shown how it is possible to infer the relationship between LPA and GCN in terms of label or feature smoothing (how label/feature does propagate over the neighbors) and label or feature influence over the other nodes. The results are given in terms of two theorems (whose proofs are in an appendix) which essentially state that the total label influence of nodes with a particular label \u201cl\u201d on a specific node is proportional to the probability that node is labelled as \u201cl\u201d by LPA. In practice, LPA acts as a regularizer to learn transformation matrices and edge weights simultaneously in GCN. By means of a simple joint loss (eq.8), the regularized training show that transductive learning with the joint model surpasses GCN/GNN baselines. \nWhile the proof of the first theorem is reasonable and seems correct (Taylor+ Schwarz inequality + L-Lip), the second left me a little puzzled, in particular wrt eq 16 and 17. Is it possible to add a graphical explanation or idea of the proof? Why \u201cy\u201d has to be reset at each iteration?\nUnfortunately, the improvement brought by the framework is marginal, even if it seems general. \nThe other limitation is that we have transductive training, but the authors are well aware about this.\n", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}