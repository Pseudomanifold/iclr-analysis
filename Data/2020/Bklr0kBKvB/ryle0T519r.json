{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper looks at the task of (adversarially or cooperatively) perturbing a point cloud in context of a classification task. It follows the prevailing paradigm of changing the original input in the direction of a high positive/negative gradient while staying \u2018close\u2019 to the original input, and the key contribution here is to define a different notion of \u2018closeness\u2019.\n\nWhile previous work (Xiang et. al., at least for \u2018point addition attack\u2019) used a combination of chamfer and Hausdorff distance as the notion of closeness, this paper additionally includes change in curvature (which is an intuitive term to include) when computing the adversarial/cooperative updates to the point cloud. The obtained results do visually look less perturbed compared to the previous approach, and the obtained adversarial shapes are more robust against two defenses studied.\n\nConcerns/Questions:\n\n1) If a point cloud P\u2019 is only a (small) perturbation of a point cloud P, then the Chamfer distance / Hausdorff distance is essentially the  L_2 / L_infinity norm of their difference. While the use of curvature terms is different, I feel the claims of importance of using \u2018distance metric of point clouds\u2019 is not very well justified (as I\u2019d expect essentially same results if these two terms were replaced by L2 and L_infinity norms instead). I think the use of these terms was more necessary in the work of Xiang et. al., as they allowed point addition, so the \u2018norm of difference of point clouds\u2019 is not well defined.\n\n2) This paper uses a different (more aggressive) adversarial term (in Eqn. 8) compared to Xiang et. al., so it is not surprising that the results in Table 1 indicate more robustness to defenses.\n\n3) In addition to the above comments about specifics, I feel this work\u2019s contribution over prior work is not significant. While Xiang et. al. did use L2 norm for their perturbation case, they did investigate the Chamfer/Hausdorff distances for another scenario, and therefore the main contribution here is an additional loss term.\n\n4) This is perhaps a hard concern to address, but simply showing some qualitative results to highlight that the changes are \u2018imperceptible\u2019 is not sufficient. Ideally, one should report a curve on \u2018change perceptibility\u2019 vs \u2018attack success rate\u2019 (though this would require some notion of perceptibility that was not used in optimization). Alternately, one could compare methods via A/B testing on mechanical turk, asking \u2018Which are these two shapes are closer to the original one?\u2019, and ablate for a certain level of confidence on the wrong class, which approach led to less changes. The current results simply show some examples, but provide no empirical way of judging which approach actually leads to more imperceptible changes.\n\nOverall, though the results are perceptually encouraging, I have slight concerns the empirical results reported. However, the primary issue is that the contribution regarding the additional term, while intuitive, is not a significant one in its own right.\n\nWhile the rating here only allows me to give a \u20183\u2019 as a weak reject, I am perhaps a bit more towards borderline (though leaning towards reject) than that indicates.\n"}