{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper proposes to compare the recognition performance of hyperbolic representations (learned with hyperbolic network layers) with other types of representations in Euclidean or spherical geometry. The comparison is performed in several computer vision contexts: image classification, one/few-shot learning and person re-identification.\nThe paper experimentally shows that hyperbolic representations can (sometimes) obtain better performance than Euclidean or spherical embeddings.\n\nThe paper is well-written, the context and background are very clear.\n\nAlthough the reported results show that there exist contexts where hyperbolic representations perform better than Euclidean representations, I vote for reject for the following reasons:\n\n- There is a lack of novelty in terms of machine learning methodology: the paper only applies existing ML approaches on different computer vision tasks. Therefore, since it is an experimental paper, I would expect more insight on the results. In the current version, the only insight provided that the paper is that representations pretrained with VGG have good hyperbolicity scores (see end of Section 4). \nIf I understand correctly, VGG16 representations were pretrained with a standard classification framework without exploiting hyperbolic geometry. Since the datasets have hyperbolicity score close to 0, this means that hyperbolic representations are appropriate. This is an interesting result. However, that part could still be improved by studying the hierarchies that can be extracted from the different datasets (CUB/miniImageNet/omniglot). Maybe there could be some insight about the hierarchies intrinsically learned by the VGG model.\n \n- In Section 5.1, it is mentioned that images difficult to classify are close to the origin whereas easy images are more far away. This seems natural since hyperbolic distances tend to grow exponentially as points get further from the origin. Therefore, difficult images (i.e. close to the origin) are close to the decision boundaries of the different categories. On the other hand, easy images are very close to only one decision boundary (w.r.t. some hyperbolic distance) by having a larger Euclidean norm. \n\n- The results in Section 5.2 are not really significant: the advantage of hyperbolic representations seems significant only in the 1-shot 5-way scenario. However, Euclidean representations seem better in the 5-shot 20-way, this kind of scenario is less prone to randomness since there are more examples to represent each category (i.e. the test accuracy is less dependent on how the support set is sampled since there is less randomness to represent a category at test time). This experiment should include standard deviation to have a better understanding of the statistical significance.\n\n- The results in Table 4 (which correspond to Section 5.3 and 5.4) are fishy. The hyperparameter c is related to the curvature of the space. It was for instance already observed in ref [A] that the curvature of the space has an impact on recognition performance. \nWhy do you report results only for c in {0.05,0.0007} on MiniImageNet and in {0.05,0.0005} for CUB (respectively best scores for 1-shot and 5-show)? Why do you not report results for other values of c (e.g. c=1)? How was c cross-validated? That value of c=0.0007 on miniImageNet does not seem conventional. The paper should provide more insight on the choice of c since it seems like an important hyperparameter. \n\n\n\n\nI also have a question: \nThe method proposes to replace the average vector of ProtoNets (Snell et al., 2017) by the gyrocentroid [B] (Eq. (2) of the submission, also called Einstein (gyro)midpoint). However, the choice of the average vector in (Snell et al., 2017) is motivated by the formulation of ProtoNet which is a special case of ref [C], the average vector is then the minimizer of some expected distortion (see Section 3.1 of [C]) called Bregman information. \nAs explained in [B], the gyrocentroid preserves left gyrotranslation. Is the Einstein gyromidpoint is not a minimizer of some expected distortion for more than 2 points?\n\n\n\nIn conclusion, the paper shows that hyperbolic representation can outperform Euclidean or spherical representations in some computer vision contexts. However, the paper lacks some insight, and some choices (e.g. the value of the hyperparameter c and the choice of midpoint) need clarification.\n\n\n\nReferences:\n[A] Law et al., Lorentzian distance learning for Hyperbolic representations, ICML 2019\n[B] Ungar, Analytic Hyperbolic Geometry in n dimensions: an introduction, 2014\n[C] Banerjee et al., Clustering with Bregman divergences, JMLR 2005"}