{"rating": "3: Weak Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review": "The authors show that changing the Euclidean geometry to the hyperbolic one in the final layers of neural networks *sometimes* benefits the computer vision tasks.\n\nStrengths:\n1. The paper is well-written.\n2. This is a reasonable attempt to transfer the success of hyperbolic language embeddings to vision tasks.\n\nWeaknesses:\n1. The second part of the motivation (Fig. 2, right) about blurred images being more generic than those with higher resolution sounds far-fetched. If this is a by-product of training, then maybe it's better to present it as such.\n2. There're experiments on a variety of datasets, but there is no proper analysis of the obtained results - why it works in some cases but does not work in the other. The authors defer this to future work, but I believe that for the paper to be complete this should be done here so that future work concentrates on weaknesses of the approach.\n\nQuestions:\n1. The last paragraph of Sec. 2 (p. 3) says that \"The hybrid nature of our setups makes the origin a special point ... This leads to the useful tendency of the learned embeddings to place more generic/ambiguous objects closer to the origin while moving more specific objects towards the boundary\". But wasn't this the case for purely hyperbolic embeddings as in the work of Nickel and Kiela (2017)?\n2. Since we already know that embedding graphs and words into a product of hyperbolic spaces is more beneficial than embedding them into a single hyperbolic space (Gu et al., 2019), why not trying the same for vision?\n\nReferences\n- Gu, A., Sala, F., Gunel, B. and R\u00e9, C., 2019. Learning Mixed-Curvature Representations in Product Spaces. In Proceedings of ICLR\n- Nickel, M. and Kiela, D., 2017. Poincar\u00e9 embeddings for learning hierarchical representations. In Proceedings of NeurIPS."}