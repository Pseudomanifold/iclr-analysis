{"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "The authors propose a learning strategy to fit predictive models on data separated across nodes, and for which different set of features are available within each node.  \nThis concept is developed by introducing the concept of two degree separation across horizontal (nodes) and vertical (feature) axis. The proposed approach consists in an iterative scheme where i)  models at independentently trained at each site, and ii) models' parameters are subsequently averaged and redistributed for the next optimisation round.  \n\nThe problem tackled in this work is interesting, with an important application on medical records from > 100,000 individuals followed  over time. Unfortunately the paper is not clear in several aspects, and presents methodological issues. Here my main comments on this work:\n\n- The authors should definitely refer to the concept of meta-learning [1], which addresses modelling problems very close to the one presented in this work: training a meta-model by aggregating information from different learning tasks.  The paper should definitely compare the proposed methodology with respect to this paradigm. \n\n- The fact that the parameters can be averaged across nodes implies that they must be of same dimension. This is counterintuitive, as the dimension of the data represented at each site may significantly differ depending on the kind of considered feature. This aspect points to some methodological inconsistency.\n\n- There is no comparison with any other federated method, neither with any classification method besides a NN, at least with the aggregated data. Also it could have been possible to reduce the number of input features using simple dimensionality reduction previous to the NN, such as PCA. \n\n- Vertical separation importance: At the end it looks like diagnosis is the main driver for the classification, showing results that are comparable to the ones obtained with the aggregated data. It is therefore not clear whether the proposed application allows to clearly illustrate the benefit of using this method with regard to vertical separation.\n  \n- All in all, the paper appears in a draft form, and the text is often inconsistent. For example, there is often inconsistency in the number of branches, or types of data considered, figures are not self-explanatory and present notation and symbols not defined anywhere. The bibliography is given in a non-standard format. \n\n[1] Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks. Finn, C., Abbeel, P., & Levine, S.  Proceedings of the 34th International Conference on Machine Learning-Volume 70 (pp. 1126-1135). "}