{"experience_assessment": "I have published in this field for several years.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper proposes to provide a novel gradient-based meta-learning framework (Meta-Graph) for a few shot link prediction task. More specifically, they generate an effective parameter initialization for a local link prediction model for any unseen graph by leveraging higher-order gradients and introducing graph signature function into graph neural network framework. The authors validate the proposed model through several experiments.\n\nThis paper reads well and the results appear sound. I personally find the idea of incorporating the structural signature for input graphs into the GCN to modulate the parameters of the inference model very interesting. Moreover, the provided experiments support the authors\u2019 intuition and arguments.\n\nAs for the drawbacks, I find the relationship to the prior works partly unclear. Moreover, it would be nice if the authors could also provide some ideas for future research directions, such as the prospects of using their approach for improving link prediction models and incorporating Meta-Graph in other domains like molecules structure. My concerns are as follows:\n\n\u2022    I am wondering if you can adopt R-GCN [1] instead of the GCN model for extending the Meta-Graph to multi-relational graphs? \n\u2022    I suggest considering ranking metrics such as MRR and HITS@ to further evaluate the performance of Meta-Graph. \n\u2022    Comparing the performance of Meta-Graph and MAML in Table 2, I am wondering about the reason behind the fact that the distance between these models\u2019 performance decreases by increasing the number of edges in PPI and FirstMMDB, but increases in Ego-AMINER? Further, I am wondering why Meta-Graph performance drops in Ego-AMINER after increasing the number of edges from 10% to 20% (Table 3)?\n\u2022    I suggest providing a comparison of computational complexity between Meta-Graph and the baselines.\n\n[1] Schlichtkrull, Michael, et al. \"Modeling relational data with graph convolutional networks\".\n"}