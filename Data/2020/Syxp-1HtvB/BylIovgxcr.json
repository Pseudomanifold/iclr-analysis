{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper investigates the aspects encoded by the latent variables input to different layers in StyleGAN (Karras et. al.), and demonstrates that these correspond to encoding different aspects of the scene across layers e.g. initial ones correspond to layout, final ones to lighting.\n\nThe \u2019StyleGAN\u2019 work first-generates a per-layer latent code y_l (from a global latent variable w), and uses these in a generative model. This paper investigates which layer\u2019s latent codes best explain certain variations in scenes. To formalize the notion of how a latent vector is causally related to a scene property, the approach here is to use an off-the-shelf classifier for the property, and a) find a linear decision boundary in the latent space, and b) quantifying whether changing the latent code indeed affects the predicted score.\n\nPositives:\n1. The analysis presented in the work is thorough and results interesting. The paper analyzes the relation of various scene properties w.r.t the latent variables across layers, and does convincingly show that aspects like layout, category, attribute etc, are related to different layers.\n\n2. The visual results depicting manipulation of specific properties of scenes by changing specific variables in the latent space, and the ones in Sec 3.2 studying transitions across scene types, are also impressive and interesting.\n\n3. The proposed way of measuring the \u2018manipulability\u2019 of an aspect of a scene w.r.t a latent variable is simple and elegant, thought I have some concerns regarding its general applicability (see below).\n\nDespite these positives, I am not sure about accepting the paper because I feel the investigation methods and the results are both very specific to a particular sort of GAN, and the writing (introduction, abstract, related work etc.) pitch the paper as being more general than it is, and claim the insights to be more applicable. More specifically:\n\n1) The text claims the approach \u2018probes the layer-wise representations\u2019. However, what is actually investigated is the layer-wise latent code (NOT \u2018representation\u2019 which is typically defined to mean the responses of filters/outputs of each layer). In fact, I do not think this work is directly applicable to probing \u2018representations\u2019 as the term is normally used because it may be too high-dimensional to infer meaningful linear decision boundaries, or directly manipulate it.\n \n2) All the initial text in the paper\u2019s abstract, introduction etc. leads the reader to believe that the findings here are generally applicable e.g. the sentence \u201cthe generative representations learned by GAN are specialized to synthesize different hierarchical semantics\u201d should actually be something like \u201cthe per-layer latent variables for StyleGAN affect different levels of scene semantics\u201c. Independent of any other concerns, I would be hesitant to accept the paper with the current writing given the very general nature of assertions made despite experiments in far more specific settings.\n\n3) In Sec 4, this paper only shows some sample results other models e.g. BIGGAN, but no \u2019semantic hierarchy in deep generative representation\u2019 is shown (not surprising given only a global latent code).  As the discussion also alludes to, I do not think this approach would yield any insights if a GAN does not have a multi-layered latent code.\n\n4) Finally, while the results obtained for StyleGAN do convincingly show the causal relations claimed, these results are essentially backing up the insights that led to the design of StyleGAN i.e. having a single-level latent variable capture all source of variation is sub-optimal.\n\n5) This is not a really weakness, but perhaps an ablation that may help. The results showing scene property manipulation e.g. in Fig 4 are obtained by varying a certain y_l, and it\u2019d help to also show the results if the initial latent code w was modified directly (therefore affecting all layers!). It would be interesting to know if this adversely affects constancy of some aspects e.g. maybe objects also change in addition to layout.\n\nOverall, while the results are interesting, they are only in context of a specific GAN, and using an approach that is applicable to generative models having a multi-layer code. I feel the paper should also be written better to be more precise regarding the claims. While the rating here only allows me to give a \u20183\u2019 as a weak reject, I am perhaps a bit more towards borderline (though leaning towards reject) than that indicates."}