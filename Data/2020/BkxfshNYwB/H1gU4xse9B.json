{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "The authors propose a differentiable pooling method for graph data, known as minCUTpool. It learns a clustering assignment matrix using MLPs and then add regularization terms to encourage the clustering results close to the minCUT. The experimental results show that the regularization terms can help improve the performance.\n\nCons:\n1. The novelty is limited. Compared with existing work DiffPool, the proposed method is improving the Diffpool by adding two regularization terms. In addition, the main regularization $L_c$ is already proposed in previous studies. \n2. The motivation is not clear. Why should we apply minCut for graph pooling? Intuitively, how is the minCUT related to graph representation learning? The minCut can identify dense graph components but why these dense components should be different clusters in graph pooling? In addition, the author claim \u201ccluster together nodes which have similar features\u201d. How could minCut terms lead to such conclusion? \n3.  Important baselines are missing, such as Sortpool (Zhang et al, An end-to-end deep learning architecture for graph classification, AAAI 2018), Self-attention pool (Lee et al, Self-Attention Graph Pooling, ICML 2019). \n4. The graph classification results are not convincing enough. In the original Top-K paper (Gao et al , Graph U-Net, ICML2019), the reported results for Proteins and DD datasets are 77.68%, 82.43%, which are significantly better than the results reported in this paper. "}