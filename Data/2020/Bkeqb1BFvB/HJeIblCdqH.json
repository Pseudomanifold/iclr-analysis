{"rating": "3: Weak Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "\nSummary\n\nThe authors propose the use of graph Laplacian spectrum (GLS) for learning graph-based feature representation. A perturbation-based framework was built to provide a theoretical analysis of the representation capacity of GLS. The experiments show marginal and sometimes decrease in performance when using GLS compare to other methods. \n\nStrength\n\nThe idea of using GLS is certainly good and well-motivated. It\u2019s clear that robust structural information can be extracted from GLS while preserving the isomorphism-invariant. The technical content of the paper appears to be correct and well-presented. The paper is generally well-written and structured clearly.\n\nWeakness\n\nThe experimental results are not convincing enough. Some intuitions as well as analysis of why the model underperforms the previous works are desirable. Furthermore, since the paper somewhat addresses the trade-off between expressiveness, consistency, and efficiency, results on the efficiency of the model (e.g. runtime, resources, etc.) should be included."}