{"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "#Summary\n\nThis paper proposes a generalised self-training framework to build a Graph Neural Network to label graphs.  Of importance is the dynamic nature of the self-training. The authors do not change the GCN but extend the self-training portion as per the prior GCN paper by introducing Dynamic Self-Training that keeps a confidence score of labels predicted for unlabelled nodes.\n\n# Comments\n\nThis is a very interesting paper in terms of looking at the effects of changing the self-training framework to better utilise the underlying structure. As such we can exploit information from other nodes that are yet to be labelled.\n\n1. As the self-training is going on, are there different computational costs or are they about the same?\n2. For CiteSeer 20 and 50, why does \\beta = 0.45 switch from the other experiments?\n3. Will such self-training be useful for general NN self-training procedures\n4. If we had soft-labelling or uncertainty on which label each node has, how would the dynamic self-training be changed?\n\n#Other notes\nPlease remove the \n\nAn appendix\nYou may include other additional sections here"}