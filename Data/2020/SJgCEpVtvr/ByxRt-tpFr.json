{"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "This paper propose to modify the existing work [1] of self-training framework for graph convolutional networks. It tracks three limitations of [1] and propose three\u00a0 use a threshold-based rule to insert new pseudo-labels and dynamic change the pseudo-label set. Moreover personalized weight are assigned to each activate\u00a0pseudo-label proportional to its current classification margin.\u00a0Evaluation of the proposed framework is performed on four networks for semi-supervised node classification task with varying label rates.\nPros:\n1. This work tracks and addresses the limitations of existing work.\n2. Authors conduct experiments on multiple dataset with varying 2-hop coverage ratio.\u00a0\n3.\u00a0The overall paper is well written, except some typos, e.g. in page 6, section 5.1 \"Each of three dataset is ......\". Should \"three\" be \"four\".\u00a0\u00a0\nCons:\n1. The proposed framework makes modification on the existing work, which is a good extension but the novelty is limited.\n2. The gap of the experiment results between the proposed method and the baseline methods are quite small.\n3. Only GCN\u00a0instantiation\u00a0are provided, it is suggested to evaluate the effectiveness on the other GNN variants, such as GraphSage, GAT and MoNet.\n[1]\u00a0Li et al. Deeper insights into graph convolutional networks for semi-supervised learning."}