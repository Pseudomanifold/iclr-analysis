{"rating": "6: Weak Accept", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "Adversarial Policies: Attacking Deep Reinforcement Learning\n\nIn this paper, the authors tackle the problem of adversarial attack by controlling the adversarial policy in reinforcement learning.\nI tend to vote for acceptance for this paper, but I also want to point out there is a lot of room for a better experiment section.\n\nPros: \n- In general, the proposed attacking scenarios is novel and missing from the current adversarial attack research, which mostly attack by adding constraint noise in the image space, instead of directly train a new adversarial controlling policy.\n\n- The problem is well formulated and the experiments are also sufficient to support the claim (could be better though, see Cons below).\nThe visualization provides useful insight for us to deepen understanding of the policy attack.\n\n\nCons:\n\n- Experiments limited in sumo cases.\nThe sumo experiment is quite difficult to train by itself and does not cover the board range of difficulty in multi-agent reinforcement learning tasks.\nTo be more specific, it will help the generalization of the paper by including\n1) Low-dimensional multi-agent environments. It will be even better if the input space is image and the output space is discrete.\n2) The study does not consider cooperative multi-agent games. It is also a very important and natural extension to the paper to consider the malicious attack in cooperative games, which can be equally common in real life.\n\n- No solution is given to the problem to combat policy attack.\nSome of the results of easy baselines such as iteratively playing attack and defense should be included in the current version of the paper.\nIt doesn\u2019t have to be successful, but should be quite necessary to increase the research value of the paper.\n"}