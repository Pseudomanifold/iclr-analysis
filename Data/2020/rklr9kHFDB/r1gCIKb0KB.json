{"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The authors present a rotation-invariant representation of a CNN modeling the V1 neurons and a pipeline to cluster these neurons to find cell types that are rotation-invariant. Experimental validation is performed on a 6K neuron dataset with promising results. \nThe paper is well postulated.\n\nBelow are comments about the work:\n\n1. In Figure 2, what does 1 x feature + 2 x another_feature mean?\n2. In Equation 3, why was the \u2018square\u2019 of error differences not used? \n3. In the clustering approach, how is the number of mixtures set for the GMM? How stable is the model to different number of mixtures?\n4. In Figure 6: are Blocks 5 and 13 the same clusters (since they are of the same color) or is it that the colourmap use did not have 100 colors? \n5. In the \u2018network learned redundant features\u2019, Sentence 1: why do the authors say \u2018similar MEIs\u2019. The 16 neurons rendered in both blocks look different. \n6. It will be informative to know how the number of clusters vary based on the correlation threshold used to collapse 100 clusters to a lower number. Are the clusters still functionally distinct for varying thresholds? Further why is MEI confusion matrix only shown for 13 groups?"}