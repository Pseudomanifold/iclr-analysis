{"rating": "3: Weak Reject", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "Contributions: This submission proposes a video instant embedding (VIE) framework for self-supervised video representation learning. It applies the training objectives from (Wu et al 2018b) and (Zhuang et al 2019), and studies the impact of different CNN architectures and sampling strategies, which are specific to videos. When using the same CNN backbone, the proposed method achieves higher performance than previous approaches, such as rotation.\n\nAssessment:\n- The proposed method achieves state-of-the-art performance on self-supervised video classification benchmarks (UCF and HMDB), and compares different video CNN backbones and data augmentation strategies, the empirical evaluations are very useful for researchers working on this topic.\n- The proposed method is an application of previous published methods (Wu et al 2018b; Zhuang et al 2019), using instance retrieval and local aggregation objectives (the latter shows little empirical gain) on videos. The implementation details, such as the use of memory bank, and different data augmentation strategies are useful, but has very limited novelty.\n- Despite the state-of-the-art performance, the empirical evaluations can be improved. For example, the impact of different training objectives could be studied further, and apple-to-apple comparison with many recently closely related work, such as CMC, CPC, DeepInfoMax, could be provided (the only such comparison is between ST-puzzle and VIE, when using 3DResNet, so it is hard to understand where the performance gain comes from).\n\nOverall, the submission proposes an interesting and state-of-the-art method for self-supervised video representation learning, but its technical contribution and empirical evaluation are limited. I therefore recommend weak reject."}