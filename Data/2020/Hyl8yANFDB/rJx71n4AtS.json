{"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "The manuscript is analyzing the \"generalization\" in TD(lambda) methods. It includes supervised learning from trajectories, on-policy imitation learning, and basic RL setting. Moreover, memoization performance has also been measured. Main conclusion is the fact that TD(0) performs very similar to tabular learning failing to transfer inductive biases between states. There are also additional surprising results about optimization.\n\nThe empirical study is rather complete and significant. It raises interesting questions for the community and states some clear open problems. \n\nResults are conclusive and interesting. I believe it is a study which a practitioner using TD-based method should be aware of. Hence, I believe it is impactful.\n\nOn the other hand, the manuscript has some significant issues which need to be resolved as follows:\n\n- One major issue is calling the analyzed metric \"generalization\". Generalization by definition requires something beyond what is seen. I believe the quantity defined in (9) is generalization. However, it can not be computed. Hence, calling its empirical version, \"generalization\" is confusing and a clear misuse of the term. I strongly urge authors to call the observed quantity something else. \"Empirical expected improvement\", \"gradient regularity\", \"expected gain\", etc. are some candidates come to my mind. \n\n- The optimization aspect is very interesting; however, it confuses the exposition significantly. I think it is better to give all results using adam first, and then showing the comparisons between adam and rmsprop later would be much more readable and easier to understand.\n\n- There are some clarity issues in the explanation of the experiments. Figure 3 is very confusing and it requires multiple reading to be understandable. A clearer visualization or a better explanation would improve the paper.\n\n- I am puzzled about why the authors did not use Q_MC in policy evaluation experiments (Section 3.3). I think it can very well be used in a straightforward manner. It would be an interesting addition to the experiments.\n\nMinor Nitpicks:\n- Memorization section is not clear. The discussion on N is very confusing as \"14.4% for N = 2 and of 16.1% for N = 50\" does not match any of \"10.5%, 22.7%, and 34.2%\" Can you give full error table in appendix?\n\nOverall, I like the study and suggest to accept it hoping authors can fix the issues I raise during rebuttal period."}