{"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "\nThis will be an uncharacteristically short review. The work poses an interesting idea: why not mix heuristics and learning. It reads as if the paper was written a while ago and the intro was not updated, since there is a lot of related work using the same concept. Please cite existing work in the introduction, it reflects negatively on the paper.\n\nThe elephant in the room is that I have read this paper before. The work has a number of citations and has sparked a good amount of follow-up work. I like the ideas and they have received enough scrutiny already. It was not the best decision for ICLR 2019 to have rejected this paper, honestly. I will argue to accept the paper if the references are updated, it deserves a wider audience.\n\nThat said, I don't like this GNN embedding of the QBF. The negation should have been defined as an edge attribute, not through nodes (as in (Yolcu and P\u00f3czos, 2019)). The representation also does not encode the quantifiers well but I feel this is a question for future work.\n\nMinor comments:\n- Please update your paper. It needs a good refresh with the recent literature that cites your work.\n\n- \"An intriguing question for artificial intelligence is: can (deep) learning be effectively used for symbolic reasoning?\" => Can representation learning be effectively used for symbolic reasoning? This is one of the most intriguing question in artificial intelligence today.\n\n"}