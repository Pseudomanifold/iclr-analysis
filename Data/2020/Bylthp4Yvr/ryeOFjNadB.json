{"rating": "1: Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "The authors prove bounds on the generalization of models produced using dropout.  They conduct experiments showing that dropout improves over SGD without dropout, and plotting generalization gaps and their bounds.\n\nMuch of the technical leverage exploited in this paper comes from earlier work.  Their acknowledgement of these contributions is somewhat uneven.  For example, results a lot like Proposition 2 can be found in [1].  In their treatment\nof deep networks, because only the last layer is dropped out, dropout is essentially applied to a linear model,\nand Proposition 3 of this paper  follows from (10) of [2], which was pointed out 12 lines below (10) in that paper.  \n\nThe statement of Theorem 1 does not appear to be\nrigorous to me.  For random data, the probability\nthat any minimizer of the dropout ERM objective\nsatisfies their bounds on the lengths of the\nrows of U and V could be less than 1 - 2 delta, in which case in some\ncases where the displayed equation in Theorem 1\nis said to apply, there is no U and V to apply it to.  \n(The parameter gamma is not quantified in the statement \nof that theorem.  It is conceivable to me that if gamma is\nconstrained to be large, possibly relative to d_0, d_1 and d_2,\nthen the statement of the theorem could make sense.)\n\nTheorem 2 has a similar issue.  How is M quantified?  \nHow do we know that a minimizer that satisfies the constraints\non M exists with probability at least 1 - 2 delta?\n\nWhen they plot their bounds in the experimental section, what value of\ngamma do they use?\n\nThe authors' claim that \"changing the learning rate or the batch size does not significantly improve the\nperformance of any of these algorithms\" is a little hard to believe.  My impression is that these choices\naffect the implicit regularization of SGD (along with the initialization).  Some more detail about what\nthey tried would be helpful.  \n\nThere is some interesting new content in the paper, even if, on the whole, it is a bit conceptually and technically\nincremental. \n\n\n[1] Cavazza, Jacopo, et al. \"Dropout as a Low-Rank Regularizer for Matrix Factorization.\" International Conference on Artificial Intelligence and Statistics. 2018.\n\n[2] Wager, Stefan, Sida Wang, and Percy S. Liang. \"Dropout training as adaptive regularization.\" Advances in neural information processing systems. 2013.\n"}