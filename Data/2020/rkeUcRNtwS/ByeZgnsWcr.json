{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "This paper introduces a simple and effective method for pinpointing salient features contributing to discriminating different classes in classification. It is based on masking images using Gaussian Gaussian light and shadow (GLAS) and estimating its impact on output. The authors also develop an iterative method to identify multiple instances. Experiments quantitatively evaluate the proposed method on pointing game using ILSVRC validation set, where the proposed method outperforms recent related methods. \n\nThe technical novelty of this paper is marginal and the experimental evaluation is not convincing. \n \n1) Marginal novelty compared to related work\nThere have been several masking-based black-box methods. Considering the method of RISE (Petsiuk et al., BMVC19) in particular, the novelty of the proposed method is marginal; the proposed method uses Gaussian light and shadow at individual positions while RISE uses random masks. \n\n2) Hyperparameter sensitivity \nThe proposed method includes several, at least four, hyperparameters to be tuned: T, sigma_l, sigma_ss, sigma_spatial. These may affect the results significantly, but the experimental section does not discuss their sensitivity. Are they robust across different datasets? It is not clear from the experiments. \n\n3) Experimental comparison\nThe comparisons are not convincing. The results on fine-grained classification are presented qualitatively, and the quantitative comparison is done only on a single dataset, ILSVRC validation set, which is very limited considering experiments in the related work, e.g., three benchmark experiments of RISE RISE (Petsiuk et al., BMVC19) on PASCAL VOC, MSCOCO, and ImageNet. Furthermore, in the ILSVRC experiments, the gap from Grad-CAM and RISE is not significant in terms of accuracy. Considering several hyperparameters of the proposed method to be tuned, these results appear less appealing. I hope the authors provide more convincing experiments, e.g., on the same benchmarks of RISE.  "}