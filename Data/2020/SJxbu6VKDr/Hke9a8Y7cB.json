{"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The authors propose Gated Channel Transformation (GCT) for efficient and accurate contextual information modeling for CNN. They introduce using l2 normalization instead of FC-layers (and instead of batch norm, etc.) and they introduce channel-wise parameters for controlling the behavior of the gated adaptation of feature channels. These three parameters (gating weights and biases to control the activation of the gate; embedding weights) per channel.\n\nThe performance is measured in three different experiments on standard datasets (some of them a bit old, however, sufficient); One can see a significant performance increase of the proposed method using various architectures even though the method uses less trainable parameters.\n\nAll in all, the paper reads well and gives sufficient information about the parameters and experimental details used. I just think that the possible reader group would not be so big. It would be great if the code would also be publisehd, and maybe that the whole experiments could be made purely reproducible.\n\nThe paper has a long list of references. I think that some could even be removed (e.g., sometimes you list 4 rreferences for a single statement); furthermore, it is enough to add the citation only once (especially when being in the same sentence).\n\nIt is advised to avoid abbreviations which are very commonly used for different methods in common literature (e.g., GA would be genetic algorithm).\n"}