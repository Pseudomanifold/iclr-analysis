{"rating": "3: Weak Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "1. Summary:\n\nThis paper proposes a novel direction for curriculum learning.  Previous works in the area of curriculum learning focused on choosing easier samples first and harder samples later when learning the neural network models.  This is problematic since we need to first compute how difficult each samples are, which introduces computational overheads.  In this work, the paper propose to gradually learn with a class-wise perspective instead.  The neural network has only access to the labels of certain classes (chosen randomly) in the beginning, and the samples that belong to the rest of the classes are treated as unseen samples but with a label forced into the last class.  Then, the true labels of unseen classes are gradually revealed, and this is repeated until in the final incremental step, all labels are revealed.  The method further has an adaptive compensation step, which use a less peaked distribution label for supervision only for the incorrectly predicted samples.  The experiments show that with only the first step, the proposed method is worse than the original batch learning, but by adding the second label smoothing step, there is improvement over the original batch learning setup.\n\n\n2. Decision:\n\nWeak Reject -- The class-wise idea for curriculum learning is interesting but the motivation and intuition behind the design of the proposed method is weak.\n\n\n3. Reasons for decision:\n\nPros:\n\nThe class-wise idea used in this paper seems to add a new direction to the area of curriculum learning.  The experiments are well designed, with ablation study to understand the behavior of the proposed method in depth.\n\nCons:\n\nThe motivation behind the ideas of the paper and the design of the procedure was not so clear.  Why would it be beneficial to start learning from a few classes in the beginning and then gradually expanding the class labels?  I was also curious if this will be more beneficial with a dataset with more classes (maybe not so different by looking at the comparison of CIFAR10 and 100 according to Table 1).\n\nIf my understanding was correct, the masked labels from unseen samples are all forced into the last class.  Does this design cause new issues, since the last class will have a lot of label noise until the final incremental step?  If yes, is it possible to consider other ways to add a fake label?   A naive way might be: for unseen samples, attach a fake soft label that has uniform probability over masked classes (M-b) and zero probability for the seen classes (in b).\n\nIn the experiments, it seems that the proposed method has consistency but no other baselines have consistency.  However, if you just look at the best mean accuracy, a naive label smoothing is often better than the proposed method.\n\n4. Additional comments not related to the decision of the paper:\n\nIn Algorithm 1 in appendix A, the equation link is lost: \u201cEqn. ??\u201d\n\nIn appendix B, what is the decay rate for LR milestones?"}