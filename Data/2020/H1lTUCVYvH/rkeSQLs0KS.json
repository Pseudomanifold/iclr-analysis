{"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "Paper summary:\nThis paper makes the observation that a curriculum need not depend on the difficulty of examples, as most (maybe all) prior works do. They suggest instead a curriculum based on learning one class at a time, starting with one and masking the label of all others as 'unknown' (i.e. treating them as negative examples), and unmasking classes as learning progresses. This is the \"incremental labels\" part. They make another observation, that label smoothing is applied to all examples regardless of difficulty, and propose an alternative \"adaptive\" version where labels are smoothed only for difficult examples. This is the \"adaptive compensation\" part.\n\nPaper contributions:\u00a0\n- the two observations described above are both interesting, and methods addressing these seem like good ideas in light of the observations\n\u00a0- the explanation of the method and experiments are very clear.\n\u00a0- ablation and exploration studies are well-done to further investigate the proposed methods\n\nReview summary & decision:\u00a0\nI like the core of this paper a lot, and recommend acceptance. It makes some insightful observations, reasonable suggestions, explains things clearly, and does reasonable experiments. The observations and proposed methods are both valuable contributions to the field. If the related work and clarity of abstract/intro are improved, along with addressing false claims and some other relatively minor things, I think this could be a very good paper, and I would be happy to increase my score.\n\nReasons for decision:\n\u00a0- Interesting observations are made and the approaches taken are interesting and well-motivated.\n\u00a0- The paper overall is well structured, easy to understand, and thorough in the experiments.\n\u00a0- Some related work (detailed below) in other fields and just about curriculum learning seems to be missing. Very strange claim (which is false, as far as I know) that curriculum learning has only been used in shallow networks emphasizes that the related work is lacking.\u00a0\n\u00a0- The abstract and intro summary of contributions didn't do a very good job of conveying what the methods do, although they are clearly explained elsewhere (see suggestions below)\n\u00a0- A lot of time is spent on detail of experiments and long, clear explanations (this is great), but makes it read a bit like a lab report. Figure 2 and the \"properties of LILAC\" section are nice, but could be improved with more discussion and reference to other works/fields to provide insight about _why_ LILAC works, not just _that_ it works.\n\u00a0- Results seem very incremental to me (improvements over other methods are in the decimal places), and I think many people will criticize or dismiss the methods on that basis. I hesitated about this, and in the end decided that the interesting observations are the most valuable part of the paper, not pushing SOTA (while of course it's valuable to report numbers, I think our field should focus less on SOTA numbers in general). \n - Misleading results are presented for CIFAR-10; ShakeDrop is not SOTA, and no reason is provided for why the particular citations in that table are there (there are many others that could be...). I don't mind that you don't get SOTA, but I mind being misled. If I've misunderstood something here, please clarify! :)\n\nFeedback/suggestions/nits (not necessarily part of decision assessment):\u00a0\n1. Briefly review some continual learning work; incremental labels are very similar to open set learning; this is worth mentioning. Would also be nice to mention anomaly detection here.\u00a0\n2. Briefly review negative mining (cases where this improves learning e.g. hard negative mining in text).\u00a0\n3. More discussion of motivation and why you think that LILAC works would be nice; connections to the above-mentioned fields could help.\u00a0\n4. Space could be made for the things I suggest here by decreasing spacing in the \"main contributions\" bullets and reducing the size of Figure 1 (the coloured tiles are very large and there's a lot of unnecessary white space. The size of text is mostly good, although the legend could also be decreased in size)\u00a0\n5. Incremental labels are well-explained in the dedicated section, but not until then. In the abstract, intro, and first section on \"LILAC\", I didn't really understand what was going on. I would suggest not using the words mask/unmask; this term is overloaded and gives the wrong connotation to me (that you don't use the predictions for the masked out classes). If you can't find a different term, I'd suggest explaining more clearly what it means to \"mask\" in this context in the abstract. It would also be good in the abstract to have a sentence motivating your approach (after \"... learning difficult samples\"). The next sentence sort of tries to do this \"... starting point from which\" but I think this is really unclear and makes it sound like you're learning an init.\u00a0\n6. Adaptive compensation is well explained in the abstract, but very confusingly in the intro summary of contributions.\u00a0\n7. I think it would be clearer to call it \"adaptive smoothing\". I know LILAC is a nice name, but so is LILAS.\u00a0\n8. Cite first sentence in abstract or reword\n\u00a09. \"in this work, we propose.... which introduces\" propose/introduce is repetitive\n10. \"to the best of our knowledge,\" [insert \"all\" here]\n11. \"curriculum learning approaches have only been tested using shallow networks\" This is just false as far as I know; apart from the misleading presentation of CIFAR-10 results, addressing this is probably the most important suggestion I have. e.g. here's a whole thesis on doing CL with deep convnets that I found from a few minutes googling:\u00a0http://www.diva-portal.org/smash/get/diva2:878140/FULLTEXT01.pdf\u00a0\u00a0\n12. LILACto -> LILAC to\n13. inconsistent use of italics vs. bold for emphasis in the text. Typically use italics; bold is for keywords and subtitles.\u00a0\n14. Mention tsne hyperparameters in an appendix\u00a0\n15. Conclusion is more of a summary; the first couple sentences are good but the repeating of the explanation of both methods could be moved to the abstract and/or intro (these sentences are much clearer than the ones used there), making more room to discuss future work and connections to other fields.\u00a0\n16. CIFAR-10 table should list method names, not just citations (they're referred to by name in the caption, which makes it hard to read the table)\n\n\u00a0Questions:\n1. What other explorative experiments could you do to investigate properties of IL and AC?\n2. Did I misunderstand something about the CIFAR-10 SOTA presentation (is there some reason for the choice of numbers cited here?)"}