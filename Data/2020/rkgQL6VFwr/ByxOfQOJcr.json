{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "N/A", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This paper proposes an architecture for generating images with objects manipulated according to user-specified or conditional instructions. I find the domain very interesting and do believe that tasks like these are critical for learning human-like cognitive capabilities.\n\nThis paper is also very clear and easy to follow and understand what the authors have done.\n\nBut I do feel like this work could use more polishing. There are four components that are used in this work, CVAE, LSTM, RN, and GANs. It seems that those components are all taken straight out of the shelf and combined. It would be interesting to see what subtle changes were important in a combined system to further increase performance.\nFor example, why is RN only before decoding, could RN possibly help the decoder as well?\n\nWhat are some of the most frequent failure cases?\nThe qualitative results look reasonable, and I\u2019m quite surprised that only 10K images were used for training. Improvements in which areas would lead to perfect results?\n\nWould better performance be obtained if every module were to be trained separately first, rather than the proposed end-to-end approach?\n"}