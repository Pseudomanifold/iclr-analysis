{"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper aims to solve the unfaithful generation problem for a specific data-to-text generation task, i.e. wikibio dataset. The wikibio dataset has a specific feature, where the output doesn't often reflect the input info box. This will cause the traditional seq2seq-style neural generation models to hallucinate frequently since the training objective is often based on word likelihood.\n\nThe paper thus design a confidence scorer that estimates whether a word should be generated according to the source information. This score is used in both training and testing. In training, it helps avoid learn to generate the low confidence words. In testing, it is used to adjust output probabilities.\n\nOverall, I think this is an interesting idea. However, the design of confidence score highly rely on the attentions calculates from the generation process, and whether attentions can be reliably estimated is questionable. Maybe it would be useful to show some statistics (not just manually picked examples) on the hallucinated words, and see what's the portion of them are due to \"flattened\" attentions.\n\nFurthermore, the experimental results are not convincing. The generations of the proposed models are significantly shorter (might be the result of training, see my comment below about 4.3), the results are mixed, both coverage and fluency are worse. Wrt results, since the dataset is from Wiki, BLEU should be pretty indicative of the generation quality. And we do see significant drop of the proposed model.\n\n\nMore comments:\n- Eq 6 needs to be better explained. I don't know if this is the common way to calculate attentions, or I misunderstood the equation. \n\n- In 4.3, I'm not sure if I can understand it correctly. When the authors say \"minimize the negative log-likelihood on the confidence sub-sequence\", does it mean words not in the subsequences are ignored? Won't this hurt the language modeling part? I.e. cause the ungrammaticality? Is this why the fluency scores are low in Table 2?\n\n- If the authors want to show their model improve faithfulness, sample outputs should be shown."}