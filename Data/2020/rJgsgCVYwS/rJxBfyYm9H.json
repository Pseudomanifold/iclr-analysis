{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper addresses the task of optimizing the point architectures for geometric deep learning. The authors propose three approaches to improving the performance of the point-based architectures, arguing that the key to performance improvements is increasing the depth of the network. To increase the depth, a memory efficient grouping block is designed, which significantly lowers the amount of memory required to train a point-based network; thus, deeper models may be trained with the use of residual connections. A multi-resolution block is then introduced, which helps propagate the information inside the model. The performance is evaluated with respect to the baseline PointNet++ (and several other models) on semantic labeling task on a number of commonly used datasets. \n\nI believe that the motivation to training more lightweight models in the context of geometric deep learning is very pronounced, since most existing models tend to have a heavy memory footprint or a large computational overhead. This becomes even more important in the context of embedded applications (e.g., robotics or autonomous driving), where range sensors collect measurements online, or in the context of leveraging very large annotated collections such as ABC. Thus, the overall motivation of having efficient models is clear. However, the second point that deeper models automatically mean better performance doesn\u2019t seem so obvious to me, as the authors didn\u2019t provide evidence that the depth is a factor limiting performance for point-based deep models. So, why go exactly deeper with point-based networks? Maybe one rather needs to design, e.g., more complex convolution-type blocks? \n\nRelated to that, another question concerning the experimental evaluation arises. While the authors did show that their network demonstrates superior performance to PointNet++, they didn\u2019t investigate whether or not the performance comes from increasing the depth of their architecture. Would increasing the depth of PointNet++ (and possibly related methods) lead to a similar improvement in performance? (Implementing PointNet++ on a deeper encoder may require sharing the model on multiple GPUs, but we\u2019re talking only about semantic labeling performance here, not efficiency).\n\nI believe the paper deserves to be accepted once the effect of depth is demonstrated and confirmed. Otherwise the paper shall look as trying to fix a non-existent issue just for the sake of depth. Should the authors clarify the effect of depth, I will be reconsidering the rating. \n"}