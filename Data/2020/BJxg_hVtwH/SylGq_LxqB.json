{"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The authors here introduces a novel  graph pooling technique called StructPool that uses the underlying graph\u2019s structural information to behave as a node clustering algorithm and learns a node clustering matrix.\n\nGraph level classification requires learning good graph level representation, especially for  aggregating low level information for high . Recent work in pooling does not take advantage of important structural information of the relationship between different  nodes. Here, the authors formulate  graph pooling as a structured prediction problem, control clique set in the CRFs and use mean filed approximation to calculate assignments. \n\nA cluster assignment matrix assigns each node in the original graph to a cluster in the new graph. The assignment not only depends on the node features but also on the cluster assignment of the other nodes. The authors therefore draw connection with finding the optimal assignment to minimizing the Gibbs energy. The authors propose to learn clustering assignment via CRF conditioned on the global feature representation of the nodes.\n\nThe unary potentials of the cliques are computed used the GCN to measure energy of each node. The novelty in accommodating topology information is in using l hop connectivity based on adjacency A to define pairwise cliques thus building pairwise relationship between pairs of nodes thus allowing the Gibbs energy formulation of the cluster assignment thereby using GCN to also compute this pairwise energy. \n\nI have  a few questions as below:\nI think the authors can better elucidate the motivation for using  the attention matrix over Gaussian kernels to measure pairwise energy in section 3.3; an  empirical experiment for drawing comparison wrt to the computational time and number of feature dimensions on a toy problem seems important. \nHow is the computation  of the unary potential and pairwise energy influenced by the connectivity of the graph G for the datasets considered? It would be interesting to see how the pairwise energy, unary energy varies over different layers of GCNs. \nFurther, how is the cluster assignment affected by the l-hop connectivity? \nIs there a notion of the minimum value of \u2018k\u2019 in the context of convergence?\nWhat happens in case of very different graph features, or structural assumptions where the cliques are not enforced? \nIs there a notion of how the method performs on datasets with a high percentage of isomorphism bias: repeating instances or repeating instances with different labels?\nIt will be interesting to see a discussion on how the performance varies with respect to the depth of the overall architecture,  positioning of the structpool and some results on how effective they are on  hierarchical features and multiple pooling ops as in architectures such as Graph UNet.\nAvoid repetition in 2.2 Related work section and in other sections throughout. Otherwise, the paper is rather well written and has clarity."}