{"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper presents an adaptive exploration scheme that can reduce the complexity of per-task tuning. This goal is achieve by formulating the adapting scheme as a multi-arm bandit problem with the actual \"learning progress\" as a feedback signal.\n\nThe paper is well written and easy to be understood.\n\nThe strength of this paper is that 1) the proposed method is new in the sense that it invents an automatic way for exploration. 2) The algorithm is simple yet effective by the experiment results the authors provide. \n\nWeakness: the presentation of the tables/bar charts in the experiment is a bit unclear. More explanations are needed.   "}