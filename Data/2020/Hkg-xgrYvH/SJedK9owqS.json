{"rating": "6: Weak Accept", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #4", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper addresses the issue of meta-learning in a transductive learning setting. That is, it aims to learn a model from multiple tasks and make it generalise to a new task in order to solve it efficiently. In the transductive setting, the query set (i.e., containing the unlabeled test data) of the new task is taken into account when learning the model. \n\nThis paper takes the empirical Bayes approach to meta-learning. In order to utilise the test data that do not access to groundtruth labels, it proposes to use synthetic gradient to implement the tranductive learning. A multi-layer perceptron network is used to systhesize the gradient. Theoretical analysis is conducted to demonstrate the generalization capability of the proposed model and reveal its connection to the information bottleneck principle in the literature of neural networks. \n\nOverall, this is a well organised and nicely presented work. The idea on how to utilise the unlabeled test data to realise tranductive learning is novel; the analysis is thorough; and experimental study is provided to show the effectiveness of the proposed method. Meanwhile, this work can address the following issues:\n\n1. The first paragraph on page 5, which describes the key step of syntheising gradient, can be made clearer; \n2. In the experimental study, Table 1 compares various methods with the proposed one. It will be helpful to clearly indicate for each method in comparison whether/how it also utilises the query set. This will give more context in interpreting the comparison results;\n3. The advantage of the proposed method seems to diminish quickly from 1-shot to 5-shot settings. Does this mean in the case of 5 (or more)-shot setting, considering unlabeled test data with the proposed method could even adversely affect the meta-learning performance? Please comment. \n4. Since the proposed method works in a tranductive manner, it is presumed that the whole model needs to be retrained/updated once a new set of query data (e.g., for the same task or another new task) is given? In other words, how does the trained model generalise to unseen unlabeled test data? Please provide some discussion on this issue. \n5. Finally, how is the computational complexity of training the proposed EB model? \n\n"}