{"rating": "6: Weak Accept", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "The paper proposes two extensions to the recent work of (Wang et al., 2019) on 3D object detection with pseudo LiDAR data. Wang et al. showed that 3D object detection using stereo images as inputs can be significantly improved if the depth map is projected to 3D and treated like a LiDAR point cloud (i.e., using methods that utilize the LiDAR point cloud). This paper shows that one shortcoming of this approach is given by the fact that the depth uncertainty increases the farther the objects are away. To remedy this, the authors propose to train the stereo estimation network (based on Chang & Chen, 2018) directly with depth outputs, instead of disparity values (inverse depth), by rewriting the loss and converting the cost volume. This already boosts the performance for far away objects. The authors demonstrate that the usage of a (simulated) low-cost 4-beam LiDAR can further facilitate the detection. For this purpose a graph diffusion algorithm is listed that aligns the pseudo LiDAR point cloud from the stereo set-up with the depth estimates from the low-cost LiDAR. Simulating the low-cost LiDAR on the Kitti benchmarks shows that this approach further increases the performance of the object detection methods.\n\nIn general, I am in favour of accepting the paper as it shows two orthogonal and interesting additions to the pseudo LiDAR paper of Wang et al. that improve its performance. However, I would like to see some clarifications in the rebuttal.\n\nThe proposed stereo network converts a disparity cost volume to a depth cost volume using bilinear interpolation. I agree, that the 3D convolutions are more meaningful (given the spacing of the grid cells) on the latter, but why the detour over the disparity cost volume? It should be possible to build the depth cost volume directly, which would lead to decreased memory consumption and speed up the method without any loss in accuracy?\n\nOne assumption of the second contribution (GDC) is that at least one beam of the LiDAR will hit the k-connected local point cloud. Can you give some bounds on the likelihood that this happens, especially for far away objects it could be unlikely, although it is most beneficial for those objects.\nFurther, I am missing a details on the optimization of (7) and (8). What is meant with slight L2 regularization? In the appendix it is also stated that a slightly different objective is optimized? \nFinally, the notation could also be improved. The authors are using L and G for the LiDAR point cloud and PL and Z for the pseudo LiDAR point cloud and then in the Z' is used for both.\n\nFig. 4 shows the median error in meters for the different variants of the stereo network. Why has the median been used? Are there severe outliers? If yes, it would also be interesting to quantify those and compare them (e.g., box plots).\n\nIn the abstract and in the discussion the authors oversell their results a bit. At the one hand they state that PL++ with GDC performs significantly better than PL++ w/o GDC, on the other hand they also claim that PL++ achieves comparable results to models that have access to the full 64-beam LiDAR data. However, if you compare the differences, then the gaps are for several cases almost as big, or bigger as in the former claim.\n\nThings to improve the paper that did not impact the score:\n- In equation (2) you could replace the x with a . (\\cdot), or completely remove it\n- On page 5: KNN neighbors -> k-nearest neighbors\n- Also on page 5: write out W.l.o.g.\n- In Tab. 1 it would help to highlight (bold) the best entries per column"}