{"rating": "8: Accept", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "The authors propose a new paradigm for learning models for point processes which circumvents the need to explicitly model the conditional intensity. This utilizes recent work on Normalizing flows and upends a long-standing paradigm. The paper is a true tour-de-force and the authors make a very convincing case for why instead of modelling conditional intensity, one could (and should) model the distribution of times directly.\n\nThe authors do an extensive literature review and place their work in the context very well. The writing is very lucid and the paper was a pleasure to read. The illustrations are also helpful and the extensive experiments complement the discussions very well. The appendix is also very easy to read and has been judiciously separated.\n\nThe two primary axes they justify their model is by first comparing it against conditional intensity-based methods in general and show that:\n 1. Their approach has universal approximation property (thanks to a result from DasGupta (2008)).\n 2. The likelihood function can be evaluated efficiently (thanks to it being a mixture of log-normals).\n 3. The expected next action time can be evaluated efficiently.\n 4. Sampling from their model is also easy. \n\nThen they show that all related work fails either one or more of these conditions. Finally, they also address the common concerns of why point processes were historically always taught using intensity functions. A bit of historical context here is that in absence of modern computers and when Cox-Hazard models still needed to be worked out by hand, the conditional intensity functions indeed were much simpler to handle and afforded desirable properties. However, with modern approaches towards modelling probability distributions, those reasons are no longer valid. Further, some of the recent research which has built on the conditional intensity functions has lost much of the advantages anyway because of the use of deep neural networks. Hence, at this point, one might as well move directly to modelling the probability (as the authors have done) instead of taking a detour via the intensity functions. The experimental results for prediction seem to justify taking this route as modelling intensity function does not seem to out-perform the intensity-free models (more on the metrics later). Finally, the authors also show that their model, thanks to its generative nature, can also be used for several ancillary tasks: Sequence embedding, missing data imputation and learning with conditional information. The provided code is easy to read through and execute.\n\nHence, I do not have any hesitation in recommending the paper for publication.\n\nAs a side-note, it is notable that in (Tabibian, 2016), a mixture model is proposed, but I believe it is not for the final probability but instead for the intensity itself to make the learning problem tractable.\n\n\nSome ways of improving the paper:\n\n - Theorem 1 can be made more rigorous by making the role of parameters like 'K' more explicit. e.g. does the theorem imply that there 'exist' K, \\mu_k, \\s_k, or does it say that for any K, \\mu_k, and \\s_k, such 'w_k' can be found, etc.?\n - Using NLL for comparing models in the experiment results is a bit unusual. Could a different metric (e.g. MAE) be employed?\n - A key discussion missing in the paper is that of the complexity of training the model. RMTPP, for example, can be trained very efficiently while Neural-Hawkes is difficult to train due to a Monte-Carlo sampling embedded in the calculation of the likelihood. Empirical results will also add to better placing the Intensity free method against other methods.\n\nCitations:\n\n Tabibian, Behzad, et al. \"Distilling information reliability and source trustworthiness from digital traces.\" Proceedings of the 26th International Conference on World Wide Web. International World Wide Web Conferences Steering Committee, 2017."}