{"experience_assessment": "I do not know much about this area.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This paper introduces an end-to-end method to predict the secondary structure of RNA, by mapping the nucleotide sequence to a binary affinity matrix. The authors decompose this problem into two part: (i) predicting an affinity score between each base pair in the input sequence, using a combination of a transformer sequence encoder network and a convolutional decoder, and (ii) a post-processing step that ensures that structural local and global constraints are enforced. An innovation is to express this post-processing as an unrolled sequence of proximal gradient descent steps, which are fully differentiable, and allow the full combination of (i)+(ii) to be trained end-to-end. A thorough set of experiments validate the approach.\n\nOverall, the paper is well written and easy to follow. The approach of unrolling structural constraints as shown in the paper is interesting and applicable to much wider domains than secondary structure prediction. The proposed approach appears to provide a novel, convincing and non-obvious solution to RNA secondary structure prediction, and subject to suggestions below, would represent a valuable contribution to ICLR.\n\nThe principal area for improvement would be to include additional detail (perhaps in appendix) on the model hyperparameter configurations that were used in the experiments. Moreover, more details on the set of \\psi functions, and the MLP details for P_i (e.g. number of hidden units, activation function, the use of dropout, batch normalization, etc) should be given, as well as more information on the specifics how how the \u201cpairwise concatenation\u201d is carried out in the output layer. What unrolling constant T is used? Finally, in the ablation study (p. 8) details on how U_\\theta is trained by itself (without the post-processing step) should be given. \n\nDetailed comments:\n* Overall, the whole paper should be thoroughly reviewed for English grammar and writing style; a subset of suggested changes follow.\n* p. 1: structure a result ==> structure is a result\n* p. 2: energy based methods ==> energy-based methods\n* p. 2: energy function based approaches ==> energy function-based approaches\n* p. 2: view point ==> viewpoint\n* p. 2: E2Efold is flexible ==> E2Efold are flexible\n* p. 2: nearly efficient ==> nearly efficiently\n* p. 3: typically scale ==> typically scale as\n* p. 3: few hundred. ==> few hundreds.\n* p. 4: all binary matrix ==> all binary matrices\n* p. 4: output space can help ==> output space could help\n* p. 5: formulation are the ==> formulation are that the\n* p. 6: eq. (7) should contain quantities indexed by $t$ in the RHS\n* p. 8: pesudoknotted ==> pseudoknotted\n* p. 9 ff: in the bibliography, all lowercase rna should be uppercase RNA. Use {RNA} in bibtex entries.\n"}