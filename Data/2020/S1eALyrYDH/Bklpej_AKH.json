{"experience_assessment": "I have published in this field for several years.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "*Summary*\nThe authors perform RNA secondary prediction using deep learning. The outputs are subject to hard constraints on which nucleotides can be in contact with others. They unroll a sophisticated optimization algorithm for a relaxation of the task of finding the optimal contact map subject to these constraints. This work is in a long line of work demonstrating that end-to-end training of models that incorporate application-specific optimization routines as sub-modules is very useful. In particular, it outperforms an approach where the inputs to this optimization problem come from a network that was trained using a simple loss that ignores the fact that it will feed into this structured optimizer. The paper also considers an application domain that will be unfamiliar to many ICLR readers interested in deep structured prediction, and may serve as a call to arms for the community engaging with additional problems in this field.   \n\n*Overall Assessment*\nThe paper is well written, well executed, and part of a general research thread that ICLR readers care about. There are a number of technical details, such as the loss function in (8) that will be of general interest. I advocate for acceptance.\n\n*Comments*\nThe actual specification of the output constraints doesn't occur until late in the paper. Before then, the discussion of them is very abstract. Given that the constraints are easy to describe, the exposition would be improved notably if you described the specific constraints earlier on. This would help me understand the problem domain better.\n\nFyi, the idea of nested structures vs. non-nested structures appears in NLP in terms of projective parsing vs. non-projective parsing. There may be some relevant reading for you to do there. Your specific work (minus the unrolled constraint enforcement) is similar to \"Dozat et al. 2017. Deep biaffine attention for neural dependency parsing.\"\n\nThe idea of backpropping through some constraint-enforcing process is reminiscent of backpropping through belief propagation. See, for example, Domke's \"Learning Graphical Model Parameters with Approximate Marginals Inference.\" Or Hershey et al. \"Deep Unfolding: Model-Based Inspiration of Novel Deep Architectures.\" You should also cite work using unrolled ISTA to learn sparse coding dictionaries. They have terms similar to (5). \n\nWhat exactly was your motivation for the setup in \"Test On ArchiveII Without Re-training?\"\n\nHow sensitive is performance to the number of optimizer iterations? Does it work to train with a fixed number of unrolled iters, but at test time run the optimizer until convergence?\n\n(8) is cool!\n"}