{"experience_assessment": "I do not know much about this area.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review": "The authors proposed an end-to-end method (E2Efold) to predict RNA secondary structure. The method consists of a Deep Score Network and a Post-Process Network (PPN). The two networks are trained jointly. The score network is a deep learning model with transformer and convolution layers, and the post-process network is solving a constrained optimization problem with an T-step unrolled algorithm. Experimental results demonstrate that the proposed approach outperforms other RNA secondary structure estimation approaches.\n\nOverall I found the paper interesting. Although the writing can be improved and some important details are missing.\n\nMajor comments\nAs the authors point out, several existing approaches for unrolling optimization problems have been proposed. It would be helpful to clarify the methodological novelty of the proposed algorithm compared to those.\n\n\nTraining details and implementation details are missing; these hinder the reproducibility of the proposed approach. The author stated pre-training of the score network, how is the PPN and score network updated during the joint training? Does the model always converge? The authors vaguely mentioned add additional logistic regression loss to Eq9 for regularization. What is a typical number of T? How does varying T affect the performance, both in terms of training time (and convergence) and in terms of accuracy/F1?\n\nMinor comments\nThe 29.7% improvement of F1 score overstates the improvements compared to non-learning approaches.. This performance was computed on the dataset (RNAStralign) on which E2Efold was trained. A fair comparison, as the authors also stated, is on the independent ArchiveII data. On this data, E2Efold has F1 score 0.686 versus 0.638 for CONTRAfold. The author should report performance improvement under this line.\n\n\nIt would be helpful to report performance per RNA category, both for RNAstralign data and ArchiveII data, while the ArchiveII data should still remain independent. Different models may have their strengths and weaknesses on different RNA types.\n\n\nIt is not obvious to me how the proximal gradient was derived to (3)-(5). It would be helpful if the authors show some details in the supplements.\n\n\nWhy is there a need to introduce an l_1 penalty term to make A sparse?\n\n\nOn which data is Table 6?\n\nTypos, etc.\nThe references are not consistently formatted\n\u201cstructure a result\u201d -> \u201cstructure is a result\u201d\n\u201ca few hundred.\u201d -> \u201ca few hundred base pairs.\u201d\n\u201cobjective measure the\u201d -> \u201cobjective measures the\u201d\n\u201csection 5\u201d -> \u201cSection 5\u201d (in several places)\nIn the equation above Equation 2, should it be -\\rho||\\hat{A}||_{1} instead of plus? Otherwise, the \u201cmax\u201d could be made arbitrarily large.\n"}