{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper introduces a framework for combatting catastrophic forgetting, based upon changing the loss term to minimise changes in classifier likelihood, obtained via a Taylor series approximation. They compare different versions of their method with EWC and a method based on freezing important weights on three benchmarks.\n\nI like the core concept that the paper proposes. It is explained well, and the paper is well-written. It is interesting to see EWC explained in this framework. However, although the paper starts off with some nice theory (Equations 1 and 2), it then becomes a heavily empirical paper, with many seemingly arbitrary decisions made (and only some high-level comments provided explaining them), for example for Case II and IV, and for the 'constrained' method. Why were these changes to the loss function made? Can they be justified somehow theoretically?\n\nI also have some misgivings regarding the experiments, as they are only performed on MNIST-sized datasets. The proposed method should (if I understand correctly) be scalable to larger datasets/architectures, which most other works in this field do. Additionally, other methods (there are many, but for example VCL [1]) significantly out-perform the proposed method.\n\nI am on the fence about this paper. Although I like the core concept and some of the experimental ideas (such as the 'freezing' method), this paper makes many decisions about its loss function that I do not understand theoretically. Doing this means that empirical results should be strong to back up these decisions, but the experiments are only on MNIST and, although they out-perform EWC, do not out-perform other continual learning works. This means that I am leaning towards reject. I hope to see a future version on this paper with improvements!\n\n[1] Nguyen et al. Variational continual learning. ICML, 2018."}