{"experience_assessment": "I have read many papers in this area.", "rating": "1: Reject", "review_assessment:_checking_correctness_of_experiments": "I did not assess the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "title": "Official Blind Review #5", "review": "This paper has set a new problem: singing voice synthesis without any score/lyrics supervision. The authors provide a significance of such a problem in section 1. Also, the authors successfully design and implement a novel neural network architecture to solve the problem. It\u2019s also notable that the authors kindly open-source their code to mitigate the reproducibility issue. This paper may serve as baseline results for the proposed problem in the future.\n\nDespite the significance of the problem and the novelty of the solution, this paper aims to solve too many problems at once. Unfortunately, some main ideas were not supported by experimental results or logical arguments with appropriate citations.\n\nThe authors seem to overly focus on the task itself, and thus haven\u2019t pay much attention on supporting their choice of neural network architecture. Here are some points regarding this:\n\n1. \u201cWe adapt the objective of BEGAN, which is originally for generating images, for generating sequences.\u201d: The original BEGAN paper(Berthelot et al., 2017) did not address sequence modeling. \n2. \u201cAs for the loss function of D(\u00b7), our pilot experiments show that \u2026\u201d: This hand-wavy argument is unacceptable. The authors should be able to support all of the claims they\u2019ve made, which sometimes require experimental results. \u201cG(\u00b7)\u201d of the following sentence should be D(\u00b7).\n3. \u201cOur conjecture is that, \u2026 compressing the output of G(\u00b7) may have lost information important to the task.\u201d: PatchGAN (Isola et al., 2017) had already addressed this issue. The authors may want to cite PatchGAN to support their conjecture or compare against PatchGAN to show their own architecture\u2019s strength.\n4. \u201cWe like to investigate whether such blocks can help generating plausible singing voices in an unsupervised way.\u201d: No ablation studies on GRUs and dilated convolutions are found. If the authors mean that they\u2019re willing to do such studies in the future, \u201cwhat\u2019s done here\u201d and \u201cwhat will be done in the future\u201d should be easily distinguished within the text.\n\nSome miscellaneous points worth noting:\n1. The readers won\u2019t be able to estimate the strength of the proposed method by looking at table 1 and 2. I suggest doing one of the following: include results from other baselines to compare against or give a brief description of the metrics with typical values. (e.g. values shown in appendix A.3)\n2. Are the neural network architecture components described in section 3.1 used for both source separation and the synthesis network?\n3. To make readers easily understand the contribution of this paper, there should be a detailed description of the limitation of this work. I suggest to move the details of experiments in section 4 to the appendix, but it may depend on the authors\u2019 writing style.\n4. The \u2018inner idea\u2019 concept in the \u201csolo singer\u201d setting looks vague and contradicts with the main topic since it uses chord sequences to synthesize singing voice.\n\nThings to improve the paper that did not impact the score:\n1. \u201cimprov\u201d >> \u201cimprovement.\u201d\n\nThis paper should be rejected because (1) the paper failed to justify the main idea and results, (2) the amount of literature research was not enough, (3) too many problems were addressed at once, and (4) the writing is not clear enough.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}