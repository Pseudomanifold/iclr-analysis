{"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper presents a novel unsupervised domain adaptation framework for neural networks. Similarly to existing approaches, it performs adaptation by aligning representations of the source and the target domains. The main difference is that this alignment is achieved not through explicitly minimizing some distribution discrepancy (this usually leads to challenging minimax optimization problems). Instead, the authors propose to use a battery of auxiliary self-supervised learning (SSL) tasks for both domains simultaneously. Each task is meant to align the source and the target representations along a direction of variation relevant to that task. Assuming that the battery is diverse enough, optimizing the representation for all the tasks leads to matching of the distributions. \n\nPros:\n+ The paper is well-written and easy to read.\n+ I like the simplicity of the idea and the fact that it achieves competitive performance without any adversarial learning (which may be very tricky to deal with).\n+ The paper presents a reasonable procedure for hyper-parameter tuning and early stopping which seems to work well in practice.\n\nCons:\n- The paper is purely practical with no theory backing the approach. As a result, the discussion of guarantees and limitations is quite brief.\n- It\u2019s unclear how easy it is to come up with a reasonable set of SSL tasks for a particular pair of domains. It seems that it may become a serious problem when the method is applied to something other than benchmarks. Table 2 reveals that there is no consistent improvement over the existing approaches which suggests that the chosen battery of SSL tasks is not universal (as the authors themselves admit). On a related note, it\u2019s a bit disappointing that the authors mention SVHN results as a failure case but never provide a way to address the issue.\n- It would be nice to some results for the Office dataset for completeness. The authors could use a pre-trained network as a starting points just like it\u2019s done in other papers. According to the last paragraph of Section 6 this experiment should be feasible.\n\nNotes/questions:\n* Table 2, last column: The performance of DIRT-T seems to be better than that of the proposed method and yet the latter is highlighted and not the former.\n\nOverall, I think it\u2019s a good paper presenting a thought-provoking idea. In my opinion, the weakest point of the work is the lack of any (neither principled nor practical) guidance as to how to choose the set of self-supervised tasks. Despite this I feel that this submission should be accepted but at the same time I\u2019m curious to see what the authors have to say regarding the concerns I raised in my review."}