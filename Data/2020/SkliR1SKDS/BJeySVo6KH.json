{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "This paper proposes to use data-augmentation as self-supervision, applied as a regularizer in fully supervised classification settings in order to improve the generalization accuracy of the classifier. It uses a joint (label x augmentation) prediction space, rather than a factorized space of labels and augmentations in distinct prediction branches (multi-task setting). The author argues that this alleviates the requirement of invariance w.r.t. the transformation for the primary classifier and allows to use more diverse augmentations. The author tests this hypothesis on various classification datasets (including few-shot and fine-grained), and also evaluates the approach with test-time augmentation - proposing a knowledge distillation method to alleviate its cost. The author show improved accuracies in these settings w.r.t. simple data-augmentation (DA) or multi-task (MT) baselines.\n\nI am unsure about the justification of the method\u2019s advantage w.r.t. the baseline and MT. I have the impression that the performance improvements w.r.t. MT could be explained by the added capacity. Barring futher experimental validation that this is not the case, I find the contributions of the paper to be minor. I will detail these points hereunder.\n\n* Method *\n1. The features learned by MT are not invariant by the transformations (otherwise the auxiliary classifier could not predict the transformation). The primary classifier in MT could behave in a similar way as the SDA method by aggregating features from a joint (label x augmentation) space, acting as a projection on the label subspace. Therefore, I do not see in MT the core limitation that SDA claims to address (enforcing extraneous invariance of the classifier).\n2. I see the joint classifier in SDA as the bulk of the novelty: the test-time augmentation experiments and teacher/student models to relieve the costs of these test-time augmentations are good to have but do not seem novel, and their applicability is not restricted to the SDA approach.\n\n* Experiments *\n3. It is my understanding that SDA uses FxN(M-1) more parameters in the classifier than the baseline and than MT (F: number of features). This provides more parameters for the network to absorb the data augmentations, and to perform better for the primary classification task. This added capacity could explain the accuracy gains with respect to MT and to the baseline.\nFor a fair comparison, a similar capacity should be added to the baseline, to DA and to MT.\nFor the baseline, this could be done e.g. by using a large F x N x M classifier, and using a pooling over the M dimension.\nFor DA, this could be done by using a large F x N x M classifier, and selecting the FxN slice that corresponds to the augmentation used (just as was done for SDA, but without the data-augmentation loss term in eq. 2).\nFor MT, this could be done by adding an additional fully-connected layer before the two heads.\n\n* Minor *\ntypo Table 2 caption \u201cindenpendent\u201d\n"}