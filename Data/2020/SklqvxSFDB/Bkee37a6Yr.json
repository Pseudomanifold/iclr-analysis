{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The field of visual odometry is very extensively researched. Coming up with a substantial improvement in the results is non-trivial.\nThe proposed loss function introduced in this paper seems like a variation of the \"Deep inference for Covariance Estimation:  Learning Gaussian Noise Models for State Estimation.\" (Liu et al., 2018), with a lot of the similar computational tricks being imposed to ensure a reasonable loss function. So, the main contribution to the paper seems like a marginal improvement over previously proposed methods.\nThe results don't altogether seem better for the proposed loss function. The pitch error especially in KITTI is significant, as this is one of the variables most in flux. The improvement in uncertainty estimation also is not apparent. It is better for some variables, worse for others, relative to VO, which is not infact based on deep learning.\nThere is also the appropriateness of choosing this conference, which should be questioned. This maybe belongs in a robotics conference.\n"}