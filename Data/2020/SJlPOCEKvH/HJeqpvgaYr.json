{"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper conducts a series of interesting experiments on compressing BERT and makes several conclusions. The compression technique is magnitude weight pruning based on an existing work. The paper mainly tested different compression rates and the stages when the compression can be applied. Compared to the existing work, one main contribution of the paper is to show that the BERT model can be pruned prior to fine-tuning any specific downstream tasks by 30%-40% without affecting all tested downstream tasks much. The paper is well motivated and presents interesting experimental results and conclusions. I have some concerns on their experiment details, which needs some clarification.\n\n1. the observation in 3.4 is a little counter-intuitive to me. The model has all pre-trained weights and should be able to determine, during fine-tuning, which weights to decrease to nearly zero or to abandon. However, the experimental results show that the pruning at that point produces a worse dev accuracy. For the experiments, 3 epochs is used for fine-tuning and then the pruning is applied. I was wondering what happen if you first fine-tune the model to get the best dev accuracy and prune the weights at that point. How did you choose the number 3? I am guessing that the pruning in the middle of fine-tuning process may throw away useful information too early. \u00a0 \n2. It will be helpful to show the thresholds of pruning and how these thresholds relate to the training loss and accuracy. I think the value of the thresholds can tell whether some pruning ratios are reasonable.\n3. when the authors continue training the model, for example in 3.4, the training stops when the training losses are comparable. Why did the training loss is used as the metric instead of the dev accuracy? Figure 1 right seems to show that those models are overfitting.\u00a0"}