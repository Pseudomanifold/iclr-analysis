{"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "\nThis work explores weight pruning for BERT. It finds that pruning affects transfer learning in three broad regimes. Low levels of pruning (30-40%) do not affect pre-training loss or transfer to downstream tasks at all. Medium levels of\npruning increase the pre-training loss and prevent useful pre-training information from being transferred to downstream tasks. High levels of pruning additionally prevent models from fitting downstream datasets, leading to further degradation.\n\nMy major concern about this work is its technical innovation and value to the community.\n1. This is simply a study of model pruning for BERT. There is nothing new technically.\n\n2. It shows BERT can be pruned for 30-40% parameters. Actually, this is not surprising; instead I'm even disappointed about this result. 30-40% weight reduction does not really speed up inference much or save model size much. Besides, to handle sparse weight matrixes, one may need additional operations to use the pruned models on a modern GPU.\n\n3. Several other submissions show that BERT models can be compressed for 5-10x without accuracy loss. Comparing with this work, this paper seems to tell me that pruning is not suitable for BERT.   "}