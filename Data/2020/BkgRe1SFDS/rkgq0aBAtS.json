{"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "Summary: This paper proposes an approach to identifying important waypoint states in RL domains in an unsupervised fashion, and then for using these states within a hierarchical RL approach.  Specifically, the authors propose to use a binary latent variable VAE to identify waypoint states, then an HRL algorithm uses these waypoints as intermediate goals to better decompose large RL domains. The authors show that on several grid world tasks, the resulting policies substantially outperform baseline approaches.\n\nComments: I have mixed opinions on this paper, though ultimately feel that it is below the bar for acceptance.  There are a lot of aspects to the proposed approach, and overall I'm left with the impression that there are some interesting and worthwhile aspects to the proposed method, but ultimately it is hard to disentangle precisely what is the effect of each contribution.\n\nFor example, let's consider the waypoint discovery method.  The basic approach is to use a binary latent variable VAE, using a recently proposed Hard Kumaraswamy distribution to model the latent state.  This seems like a reasonable approach, but there's no real analysis of the actual waypoints that are discovered in the target domains, whether they indeed correspond to intuitively important waypoints in a domain, or whether they are just producing some arbitrary segmentation of the proposed task.\n\nThe other elements of the paper have similar issues for me.  The whole HRL process, using these waypoint states as intermediate goals, seems reasonable, but it's hard to disentangle the performance of this particular approach versus the performance of any approach that would use (any) intermediate states as goals within an HRL approach.  And the impression I'm left with, given the level of detail included I the paper, is that I would have no idea how to apply or extend this process to any other RL domains.\n\nI looked at the provided code hoping it would help to clarify some of the implementation details, but the code is not at all a complete collection of routines that could re-create the experiments.  Rather, the code just includes a few of the model architectures, which aren't really the important aspects of this work.  \n\nThus, I'm overall left with the impression that it's quite difficult to assess the contribution of this approach, and determine precisely which of the different proposed aspects is really contributing most to the improved performance.  I know there is some ablative analysis in the paper comparing the pi_g-init and G_w-traversal independently and together, but I'm more questioning the basic question of what each portion of the network is really learning.\n\nI'd be curious if the authors are able to clarify any of these points during their rebuttal."}