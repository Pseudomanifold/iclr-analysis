{"rating": "1: Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review": "The paper propose a heuristic for making data augmentation more \"end to end\" rather than an ad hoc technique. The idea is to train multiple GANs on subsets of the data, and once in a while use these to generate new data aid the training of the final model.\n\nI found that the justification for the proposed heuristic was largely missing. Why is the proposed method good?Is it optimal in any sense? Does it correspond to a specific model assumption? Is there an intuition why it's a good idea?\n\nIntuitively, I would expect that it is hard to train a GAN (or another generative model) than it is to train a classifier, so why is it s a good idea to augment the dataset using GANs?\n\nOne of the key tricks of the paper is to split the data in multiple folds and train one GAN per fold. I would expect this to be fairly unstable is building generative models tend to be very \"data demanding\" (Wuch that working with only 1/5 of the total data could be problematic).\n\nIn recent years there have been quite some work on learning of data augmentation which isn't cited in the paper. I'd recommend looking at\n\n  \"Dreaming More Data: Class-dependent Distributions over Diffeomorphisms for Learned Data Augmentation\", Hauberg et al., AISTATS 2016.\n  \"A Bayesian Data Augmentation Approach for Learning Deep Models\", Tran et al. NeurIPS 2017\n\nand the references therein to get a better coverage of previous work.\n\nI generally find it difficult to assess the presented experiments. Since the approach is deemed general, why isn't it applied to general tasks with an established ground truth? E.g. why isn't the technique applied to classification or regression? That would make it much easier to assess if the approach does something sensible. I am also missing elementary baselines, e.g. the usual hand-crafted data augmentation should also appear in the baselines."}