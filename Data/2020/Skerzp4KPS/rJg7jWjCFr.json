{"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper proposes an method based on multiple GANs trained on different splits of the training data in order to generate additional samples to include to the training data. The number of added samples from each GAN depends on the quality of the generation based on their inception scores. This approach helps to improve the performance of a convolutional neural network on different tasks such as image classification, image generation and image inpainting. \n\nI rated this paper as weak reject because this paper is weak on several aspects\n- In related work many similar approaches are missing (see below).\n- In the methodology the actual formulation for the GAN is not presented.\n- The main novelty of the paper seems to be the use of multiple GAN on different splits of the data, which seems a bit limited.\n- The experimental evaluation is limited (see below).\n\nRelated work:\nSeveral works with very similar intentions have been overlooked:\n(\"A Bayesian Data Augmentation Approach for Learning Deep Models, Toan Tran, Trung Pham, Gustavo Carneiro, Lyle Palmer, Ian Reid) uses GAN during training for generating samples for data augmentation.\n(\"Dada:  Deep adversarial data augmentation for extremely low data regime classification\", Xiaofeng Zhang,  Zhangyang Wang,  Dong Liu,  and Qing Ling) uses another GAN model for generating samples on low data regime for data augmentation\n(\"Adversarial Learning of General Transformations for Data Augmentation\", Saypraseuth Mounsaveng, David Vazquez, Ismail Ben Ayed, Marco Pedersoli), uses GAN for generating samples for data augmentation on reduced datasets.\n(Triple Generative Adversarial Nets, Chongxuan Li, Kun Xu, Jun Zhu, Bo Zhang) uses a gan model for generating samples for semi-supervised learning with few labelled samples.\n(Triangle Generative Adversarial NetworksZhe Gan\u2217, Liqun Chen\u2217, Weiyao Wang, Yunchen Pu, Yizhe Zhang,Hao Liu, Chunyuan Li, Lawrence Carin) in which again GAN is used to improve in semi-supervised settings.\n\nExperimental evaluation:\nIn the experimental evaluation the importance of the use of k-fold is shown only on Fig.4. Additionally, in table 1 the method is compared with weak baselines (no DA, flip, crop, but not the combination of flip and crop which is standard on CIFAR10) and it is not compared with any other approach (and there are several as shown in related work).\nFor generating images, no quantitative values are provided, just some generation examples."}