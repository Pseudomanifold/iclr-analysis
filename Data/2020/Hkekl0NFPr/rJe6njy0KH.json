{"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper focuses on learning representations which can simultaneously achieve equalized odds and accuracy parity without impacting demographic parity. The authors show both theoretically and empirically that the proposed algorithm show better utility-fairness tradeoff on balanced datasets. This is indeed a useful result. Overall, I liked the presentation of the paper including motivation and background of other methods. Theory is sound, and experiments are sufficient.   Therefore, I do not have any major concern. Some of minor concerns are mentioned below:\n\n1. I see some ambiguity in the definition of the classifiers. h is defined to be deterministic in section 2; whereas, later \\hat{Y}, which I believe is treated at h(g(x)) for some h, is taken to be randomized. Also, the theorems are mentioned with respect to h making them specific to deterministic classifiers according to the current definition.\n\n2. I am not sure why the last statement of the second last paragraph on page 2 is true. Can you please explain? There should be an additional condition on distribution D, which is not clear at that moment in the paper.\n\n3. I am wondering if the utility can be maintained for imbalanced datasets by taking two parameters \\lambda_1 and \\lambda_2 for BER_{D^0} and BER_{D^1} in equation 2. Did the authors check when we have different regularization parameters for both terms? If yes, then what was the conclusion?\n\n4. Please write theorems as fully independent statements. \"Assume the conditions in Proposition 3.2\" is probably not the right way to start a theorem. Other way is to mention the conditions separately and then use it throughout the paper.\n\n5. Can you please write or elaborate the final optimization problem after section 3.4?\n\n6. How did the authors construct the optimal classifiers in the experiments for real data? Can you provide some details?\n\nTypo: \"sensitive attribute A, then the second term\" --> remove then"}