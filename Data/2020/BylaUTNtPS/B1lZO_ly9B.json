{"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This paper draws inspiration from Physical world and considers an independent mechansim among recurrent modules. The authors apply the proposed RIM to several relatively simple tasks and show some advantages.\n\nIn general, I like the idea of making recurrent cells operate with nearly independent transition dynamics and interact only sparingly through the attention bottleneck. It is essentially to combine some environment prior into the model design. It makes senses to me that RIMs will work better in environments that objects and background are nearly independent and only interact with each other when collision happens. RIMs share similar to spirits with capsule networks, and its recurrent cells serve somewhat similar role to capsules. Such independent mechanism, selective activation and sparse communication is very inspiring and is indeed a potentially very useful way of modeling the physical world.\n\nFor the model itself, I appreciate its simplicity, but I also have some concerns.\n\n1) For the selective activation of RIMs, the number of activated RIMS is a hyperparameter and needs to be pre-defined. According to your experiments, I believe you need tune this hyperparameter a little bit in order to obtain the best performance. First of all, the design of a fixed number of activated RIMs does not seem to be reasonable and is also highly dependent on your task. I believe the framework will be more interesting if the model can determine this number automatically.\n\n2) I find it quite interesting that the top-down attention in selective RIM activation is corresponding to the states of these recurrent cells. I am wondering what if you do not select these top K activation and directly train it using the entire distribution of the soft attention output?\n\nFor the experiments, I think they all serve the purpose of showing the advanatges of RIMs quite well, except that thery are relatively easy task. However, it is still interesting to see that RIMs obtain significant gains over some baselines. Some of the details can be made more clear, such as loss function and evaluation metrics in every task. It is sometimes difficult to find what loss function you are using. I suggest the authors make the experiments more self-contained in the main paper, such that authors do not need frequently scroll down to the appendix and check the details."}