{"experience_assessment": "I do not know much about this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This paper presents a method for training a facial recognition system, CurricularFace, that creates adaptive loss functions that is both \"margin-based\" and is adaptive over time, increasing emphasis on harder examples and decreasing emphasis on easier examples over time.  The experimental results seem compelling, but I am not very familiar with the area, so it is difficult for me to judge.\n\n It seems like the experimental results are quite good, but I unfortunately can't recommend this paper for acceptance since I found it too difficult to read.   A lot of background seems to be assumed that I don't have and wasn't really provided in the paper \n\nHere are questions and comments I have that I hope can be worked into the final version:\n\n- From the citations, this seems to be a settled issue in the face recognition field, but why create a margin-based loss function by modifying the softmax in these ways, rather than using a more direct margin-based loss function, such as the various multiclass variants of the hinge loss, where you can set the target margin at per-example level?\n- Presentation challenge: The introduction speaks of so many things without definition: \"Triplet loss\", \"semi-hard or hard samples\", \"mining-based loss functions\", \"small backbones\", the \"manually defined constant t\" (before any mention of t).  Then in the Related Work section, reference to the \"open-set face recognition problem\" is not defined. \n- Do you compare any examples that don't take G(p(x))=1?  If not... maybe drop that factor.\n- You speak of various \"training stages\" -- how exactly is the training stage defined?  When do we progress from one stage to the next?  I don't see this in Algorithm 1.  \n"}