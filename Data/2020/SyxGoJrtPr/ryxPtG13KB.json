{"rating": "3: Weak Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "The authors proposed a hybrid method for defending against adversarial attacks called SPROUT. The proposed defense method consists of three main ingredients:\n\n1. label smoothing with a learnable Dirichlet distribution\n2. adding Gaussian noise to input examples\n3. mixup: augment training examples with their linear combinations \n\nThe authors' main argument for their method is the speed over adversarial training and its effectiveness. \n\nIndividually, none of these ingredients are known to be strong defense against adversarial examples in the literature. Indeed this is corroborated by Figure 5, when the individual defenses do not have more than 10% accuracy under PGD100 attacks for epsilon=0.4. However, when all three are used together the accuracy jumps to close to 60%. This is very surprising. Another surprising fact is that in Figure 2, the method beats the benchmark adversarial PGD by more than 20% on white-box attacks, given the difficulty of beating adversarial PGD.  \n\nGiven the surprise in these experimental results, I believe the authors should perform a more detailed analysis on how these ingredients for their SPROUT defense interact to produce such a strong predictor, in addition to doing ablation studies. An attempt should be made to explain why they work so well together when they are quite weak individually as defenses. It is difficult for me to recommend acceptance of this paper without an attempt to explain why it works. \n\n\n"}