{"rating": "6: Weak Accept", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This paper proposes a novel training method to build robust models. A new framework SPROUT is introduced to adjust label distribution during training. It also integrates mixup and Gaussian augmentation to further improve the robustness. The proposed method is built upon the Vicinity Risk Minimization (VRM) framework. Experiments show that the proposed method significantly outperforms the existing best methods in terms of robustness against attacks.\n\nOverall, this paper proposes a novel method with good robustness performance. The proposed approach is built upon the VRM framework, and summarizes a lot of existing methods under this framework (Table 1). Experimental results are also very strong to prove the effectiveness of the proposed method. \n\nOn the other hand, I have some concerns about this paper. Since the performance improvement is significantly large over the current best methods, I need to see those concerns addressed to give a final rating.\n\n1. How do you perform inference given testing data? Do you use Gaussian augmentation or mixup during inference?\n\n2. Do you check that whether the robustness comes from obfuscated gradients? It's very important to examine the true robustness of the propose method.\n\n3. What's the final distribution of \\beta? Does it have a semantic meaning?"}