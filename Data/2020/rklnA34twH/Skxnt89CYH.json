{"experience_assessment": "I do not know much about this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review": "This paper proposes an adversarial pNML scheme for adversarial defence and adversarial example detection. The idea is very intuitive and pNML is adopted from the literature work for the purpose of adversarial defence. \n\nThe authors provided some explanation on why the adversarial pNML should work. The reasoning is quite intuitive, lacking of thorough justification.  The authors may consider using experiments to provide empirical justifications for the explanations. \n\nThe proposed method is heavily dependent on previous works. The section 6 adaptive adversary part is not clear.  How to do the adaptive attack based on Eq.(16)? Maximizing the loss in Eq.(16)?  How to determine the threshold for adversarial example detection?\n\nThe experimental results in Table 1 seems to be very good. However, have the state-of-the-art defence methods been compared?\n"}