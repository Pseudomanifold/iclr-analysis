{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "In this paper, the authors target on an very interesting problem of how to avoid the network learning certain tasks which we do not want it to learn. I understand the problem is very important. The authors adopt gradient reversal branches which can solve both known classes and unknown classes. Experiments on several dataset are conducted to show the effectiveness of the method.\n\nThe paper is not easy for me to understand. I carefully read this paper for a long time and I am still confused about the key details about equation (1).\n\nFollowing are some of my questions:\n(1) f: X->Z, g: Z->Y, so what does f(g(x)) mean in equation (1),  should it be g(f(x))?\n(2) I do not quite understand the loss function. Why could the model learn to avoid recognize certain tasks since the parameters can be set to zero in g, in this way,  the output of g(.) will have no information about f(x) anymore.\n(3) In my understanding, the model should try to learn in an adversarial way in order to suppress the learning of unwanted tasks, however, I fail to find the correspond introductions in this paper.\n(4) Although the equation(2) could be guessed, the authors should make it more clear. There is Sigma in the equation and no indices of summation details provided.\n\nIn my opinion, the paper should be written more clearly and the key idea and the importance of this paper should be further emphasized. I could not support its acceptance under current form."}