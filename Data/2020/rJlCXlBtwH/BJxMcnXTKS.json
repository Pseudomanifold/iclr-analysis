{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The submission considers the inverse reinforcement learning, and follows the framework of BIRL. Further, the authors propose to use the CVAE to solve Bayesian model of BIRL. Since I am not familiar with line of research of CVAE, I would like to focus on the IRL part. Specifically, I have two questions regarding the identifiability (or the entanglement) of the model:\n\n1. The definitions of Q^* and Z' are not provided, which is very confusing. In the framework of MaxEnt methods, the target is not exactly the reward function $R$, but a reward shaped by the dynamics of the MDP (as suggested in Fu et al. (2017)). I am wondering whether $R$ is identifiable in the formulation of the submission? In other words, given the dataset, is it guaranteed that the reward function maximizing the objective function is unique or only has a constant difference? Right now, it is unclear in the submission. It is also fine if the identifiability argument is not true. But we definitely need more discussions regarding this issue.  \n\n2. So, is the MaxEnt method considered in the experiments the method in Fu et al. (2017), which can estimate a disentangled reward function? Since MaxEnt method aims to estimate the reward shaped by the dynamics, it may be unfair to compare with other MaxEnt methods. \n\nDue to the ambiguous of the formulation, and the lack of discussions regarding the identifiablitiy issues, I tend to reject, now. \n"}