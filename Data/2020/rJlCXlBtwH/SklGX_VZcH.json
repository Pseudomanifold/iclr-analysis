{"experience_assessment": "I have published in this field for several years.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "The authors propose an approach CWAE to recover reward function in IRL problems. The proposed CWAE employs Conditional Variational Auto-encoder (CVAE) and Wasserstein loss function. However, I have a few key concerns below, that prevent me from giving a direct acceptance.\n\n\u2022\t1. There lacks for theoretical analysis to support the idea of using VAE for solving IRL problem. Especially, GAIL [1], establishes rigorous theoretical connection between IRL and GAN, which solves the same problem. It is unclear of the motivation and the strong reason of employing VAE.\n\n\u2022\t2. Experimental results are. The performances of CWEA-IRL as shown in the paper are not promising, when compared baseline approaches, e.g. deep maximum entropy IRL. The statement of \u201cDeep Maximum Entropy tends to give negative rewards to state spaces which are not well traversed in the example trajectories\u201d is not clearly explained.\n\n\u2022\t3. No comparison with GAIL.\n\n[1] GAIL https://arxiv.org/abs/1606.03476\n"}