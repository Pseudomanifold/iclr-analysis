{"experience_assessment": "I have published in this field for several years.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "The paper proposes to introduce the notion of Observed Mutual Information (OMI), that captures how easily a given model can extract information from the data, and show correlation between this measure and the performance of the model.\n\nHowever, the reason why the OMI score should be a good predictor of the model performance is not clearly justified in the paper, either formally or informally. In fact, I believe it is easy to construct examples where the OMI score can vary arbitrarily, while the difficulty of the learning task remains virtually unchanged. For example, let p(x) be the distribution of MNIST digits, to which arbitrary amount of noise is added to one corner of the image. This increases H(x) arbitrarily, and hence arbitrarily varies the OMI score. On the other hand, any network can easily learn to solve the task by just ignoring the noise in the (unused) corner. In general, it seems to me that for images the OMI score will depend almost entirely on the amount of noise or variability in the image, rather than from the actual difficulty of the task.\n\nThe idea that Shannon Mutual Information does not capture the actual complexity of extracting the information is also already well explored in the literature. For example, Kolmogorov (or Algorithmic) Mutual Information explicitly account for the complexity of the program extracting the representation, and will change based on how data is represented. Montanari (https://arxiv.org/abs/1409.3821) explores the computational implications of representing the data through a minimal sufficient statistic. Achille and Soatto (https://arxiv.org/abs/1905.12213) study the relation between complexity of the learning task, complexity of the DNN, and \"effective information\" contained in the activations.\n\nRegarding the bounds on entropy and mutual information described at page 3-5, they seem to be vacuous for most problems of interest, since H(x) will be very large in those cases (even for MNIST H(x) is estimated to be ~80 nats, which would require a very large number of samples to properly estimate mutual information using the given bound)."}