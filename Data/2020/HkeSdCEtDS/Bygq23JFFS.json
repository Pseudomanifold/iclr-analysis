{"rating": "1: Reject", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This paper explores methods to incorporate a pretrained language model into a dialog system. The authors\u00a0propose Alternating Recurrent Dialog Model (ARDM) where the pretrained language model is used to initialize both the user LM and the system LM. The authors also present a memory module to augment this dialog system where each memory slot contains a <key, value> pair derived from hidden states\u00a0for each dialog turn.\n\nI think the writing of the model section could be improved.\nA few clarification questions for the authors:\n- How is the hidden state for the dialog turn t (i.e., h_t) derived from hidden states of tokens in turn t? Supposed there are N tokens in turn t, which Transformer hidden state is used as h_t? \n- How is h_t used to compute p(w_i | w_{<i}, u_{<t}, s_{<t})?\nIf I understand correctly, the authors use t to index dialog turns, but then they seem to use the same symbol to denote token indices in the same section. So the exact model, although appears to be simple, is very confusing to me.\n\nIn terms of experiment results, the authors show that their approach improves over the basic GPT-2 and is competitive with baseline methods that rely on more supervision.A few clarification questions regarding the experiments:\n- Did the authors tune the GPT-2 model on each dataset, similar to ARDM as well? Or are the GPT-2 results shown in Table 1 after fine-tuning?\n\nIn summary, this paper is a plug-and-play extension of the GPT-2 pretrained model that could be explained more clearly."}