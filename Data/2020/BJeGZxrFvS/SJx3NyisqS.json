{"rating": "3: Weak Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #4", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "Summary:\n\nThe paper proposes a simple technique to address the problem introduced by Adebayo et al. that several saliency approaches do not pass sanity checks. The proposed approach computes the saliency maps for all the classes and removes the pixels that play a role in predicting several classes. \n\nStrengths:\n\n1. Simple and intuitive approach. \n2. Well written and easy to read paper.\n3. The introduced approach makes Grad.Input pass the sanity checks introduced by Adebayo et al.\n\nWeaknesses:\n\n1. For any interpretability technique, passing the sanity check is a must, but just because a saliency technique passes the sanity checks, it doesn\u2019t mean that these maps explain the network\u2019s decision well. \n2. Lack of any quantitative evaluation (such as localization or pointing experiment) of their approach. \n3. Failure to show if the resultant maps are class-discriminative. Show performance on images with multiple classes. \n4. In fig 1,  In Grad . Input, I see positive values or negative values even when the original pixels are not active. This doesn\u2019t explain the presence of edges causing high values in the G.I map for such pixels, right?\n5. In figure 1, These maps only assign values to the pixels that need to be removed to make a certain classification decision. The regions that need to be active but are not present are not highlighted. \n6. In figure 1 the shown CGI Map is for which class?\n7. So, is the approach only applicable to such systems where the completeness is true? Can the authors provide a list of approach that satisfy completeness:\n8. Page 3 last paragraph: Consider the example in figure 1. Let's consider the maps for digit 3 and 5. For the top horizontal part of the digit, it plays a role in determining both 3 and 5. Assume that for one such pixel the value of h_5_i is greater thatn h_3_i (looking at the figure it is not unreasonable to expect that). Just because the g.input value of h_5_i is greater that h_3_i , are the authors saying that the top part is irrelevant?\n9. How does CGI look for the original 3 on standard model?\n10. Could the authors provide more intuition as the why the gradients of outputs from softmax layer doesn\u2019t give good results? The proposed approach from https://arxiv.org/pdf/1908.04351.pdf suggests that computing gradients from last layer improves the class discriminative behaviour.  \n\n"}