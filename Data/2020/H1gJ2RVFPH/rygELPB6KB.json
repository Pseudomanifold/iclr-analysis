{"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper addresses the issue of overvonfidence of ReLU nets identified in [1], where the predictive probability distribution collapses to one-hot encoding of the most probable class as the input goes to infinity. The authors argue that by modeling a distribution over the weights of the network, this issue can be alleviated.  \n\nI start by summarizing the results of the paper. As far as I understand, all results are specific to the case, where only the distribution over the weights of last layer is being modeled. Also, all the results are derived for binary classification and assuming an approximation to the predictive distribution (equation 4). For this setting the authors show that if we use a Gaussian distribution over the weights (of last layer), the predictive distribution in the limit of input going to infinity is not collapsing to a one-hot vector, and is determined by the parameters of the Gaussian. In particular, the probability of any particular class is bounded away from 1, as the input is going to infinity. This is the main result of the paper, presented in Section 2. In Section 3 the authors reason about what happens specifically when the Gaussian is constructed using the empirical covariance matrix of the feature vectors (inputs to the last layer), and the Laplace approximation. The result of this section, summarized in Corollary 2.8, isn\u2019t stated very precisely. Finally, the experiments are evaluating a laplace approximation applied to the last layer of ReLU nets on out-of-domain detection for image classification datasets.\n\nThe main issue I see in the paper is the following. The paper does indeed show that modeling a distribution over the weights of the last layer of a ReLU network fixes the asymptotic over-confidence, and without affecting the accuracy of the classifier. Notice that this result doesn\u2019t imply anything for the quality of uncertainty estimates close to the data. It is possible to come up with other trivial modifications of ReLU networks that would satisfy the same property. For example, we could replace the sigmoid nonlinearity of the final classifier with something like h(z) = max(min(0.9, z), 0.1), which would also lead to uncertainties that are asymptotically bounded from 1, and would not change the accuracy of the classifier. For this reason, the significance of the main result of the paper isn\u2019t clear to me.\n\nAlong the same lines, I think the title of the paper is misleading. The title suggests that Bayesian inference provably fixes the predictive uncertainties for ReLU networks. However, the analysis is only concerned with asymptotic overconfidence as inputs are going to infinity. Further, the results hold for any distribution, and the connection to anything Bayesian is only made in Section 2.4. Finally, the analysis is about modeling distribution only for the last layer of the network, not all layers in the network, which would be assumed by default from the title. \n\nFinally, the experiments are performed using a Laplace approximation for the last layer (LLLA) of ReLU nets on multiclass image classification problems. The method is used to perform out-of-domain detection and compared against the methods proposed in [1]. I don\u2019t think the authors frame LLLA as a contribution, because both being Bayesian over the last layer [2] and Laplace approximations for neural networks are well-known techniques.  Further, the theory only guarantees that the uncertainty will be present as the input goes to infinity, but doesn\u2019t guarantee that the uncertainty will increase monotonically as the input moves away from the data distribution. So, for finite inputs, the theory doesn\u2019t guarantee that Bayesian last layer would work for out-of-domain detection. \n\nTo sum up, I am in favor of rejecting the paper in its current state. I agree that the observation that virtually any distribution over parameters fixes asymptotic overconfidence of ReLU networks is interesting. However, I don\u2019t think that on its own it is sufficient for accepting the paper to ICLR. If the authors could also obtain sharp results for the predictive uncertainty in non-asymptotic regime, or use their observations to motivate a new method, it would be a really strong paper.\n\nMinor issues: \n- In Section 4 CEDA and ACET are introduced in Section 4.2, but ACET is first mentioned in 4.1\n- On page 11, in the proof of Theorem A.5, in the first line of equations after equation (14) in the denominator you have (delta U x + b) instead of (delta U x + c).\n\n\n[1] Why ReLU networks yield high-confidence predictions far away from the training data and how to mitigate the problem\nMatthias Hein, Maksym Andriushchenko, Julian Bitterwolf\n\n[2] Scalable Bayesian Optimization Using Deep Neural Networks\nJasper Snoek, Oren Rippel, Kevin Swersky, Ryan Kiros, Nadathur Satish, Narayanan Sundaram, Md. Mostofa Ali Patwary, Prabhat, Ryan P. Adams\n"}