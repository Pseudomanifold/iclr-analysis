{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper presents the argument that ReLU networks do not have accurate estimates of confidence in areas that are far from the training data. They suggest explicitly estimating the Covariance of the final layer of a network as a way to more accurately estimate the confidence.  They provide theoretical results that bound the logit predictions and use this to choose their covariance matrix. \n\nThe clarity of the paper is not great. They do not discuss the relevance of many of their theoretical results and instead present them in a large list. The experiments are limited, but the results are promising, particularly Figure 3. \n\nOverall the paper feels like it has a lot of content without a lot of substance. This may be because they spent a lot of time listing all their theorems, but not as much motivating why these theoretical results add novelty and are important. Many of their theoretical results are rather obvious (and use well-studied techniques), but they have not been presented explicitly for neural networks."}