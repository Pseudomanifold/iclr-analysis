{"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review": "Summary:\nThis paper proposes a method to alleviate label noise. It opens with the observation of three distinct stages when training in the presence of label noise. Importantly, there is a \u2018gap\u2019 stage during which the network has not begun memorizing noisy labels and early stopping is ideal. The authors then observe that the Gambler\u2019s loss (Ziyin et al., 2019) elongates the gap stage and propose an analytic early stopping (AES) criterion for identifying when to stop training.\n\nThe analysis of the AES criterion, e.g. in Figure 5, and the observation of a phase transition when tuning the o hyperparameter are quite interesting, and the latter observation is of practical value when using the AES criterion.\n\nThe AES criterion seems to be well-motivated, and the empirical evaluation of the Gambler\u2019s loss with and without early stopping is good. The results are strong on MNIST but somewhat weak on CIFAR-10. Specifically, the improvements on CIFAR-10 only appear for large corruption rates (0.7+), and performance is lower than the baselines for other corruption rates. This is a worrying problem, because it calls into question the value of the method on larger problems. However, seeing as this is a distinct approach from the baselines and that it demonstrates some promise, I recommend borderline accept. The authors could raise my score by demonstrating more consistent gains on another larger-than-MNIST CV dataset or an NLP/speech dataset. Other points of concern that I have are listed below.\n\nMajor points:\nAt the top of page 3, the authors say that the idealized gap assumption \u201cholds well for simple datasets such as MNIST and on datasets with very high corruption rate, where our method achieves best results, and less so on more complicated datasets such as CIFAR10\u201d. The idealized gap assumption is behind the AES criterion, but Figure 5 suggests that the AES criterion works well on CIFAR-10, so what do the authors mean when they say the assumption doesn\u2019t work as well on CIFAR-10? Is this just referring to the results?\n\nSaying traditional label noise correction methods are \u201cof no use when one is not aware of the existence of label noise\u201d seems unfair. The FC method and others do not require foreknowledge of the corruption rate and do not harm performance in the absence of label noise, so they can also be said to automatically correct label noise.\n\n\u201cFC, however, requires knowing the whole transition matrix, and is outperformed significantly by our method.\u201d\nThis is not quite true, because Patrini et al. propose an estimate of the transition matrix as part of the Forward correction. Did you use the estimated or true transition matrix for the FC method? It would be good to clarify this in the paper.\n\nMinor points:\nThere are a few grammatical errors and typos in the paper:\n\n\u201cor explicit regularization, this is also what is suggested by Abiodun et al. (2018)\u201d (run-on sentence)\\\n\n\u201cCIFAR10\u201d should be \u201cCIFAR-10\u201d"}