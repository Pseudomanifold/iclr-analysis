{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "In this paper, the authors present a new perspective on how to effectively noise unlabeled examples and argue that the quality of noising plays a crucial role in semi-supervised learning. By substituting simple noising operations with advanced data augmentation methods, their method brings substantial improvements across six language and three vision tasks under the same consistency training framework. I think the topic itself is interesting and I have the following concerns.\n(1) The first is about the contribution of this paper. In this paper, all the results, including the augmented methods are all well established approaches. The authors have just employed them in solving a new problem, without support about why they work. Thus, the results are only strategies, without theoretical guarantee or insights. It is difficult to convince the reviewers.\n(2) Although the authors have achieved seemingly promising results, I think it can not convince me since the authors have not answered the questions about why and when. I think this paper likes a technical report, not a research paper.\n(3) I have also noticed the discussions among the authors and other readers. It seems that the large improvement depends on the parameters heavily. So, why not to share the parameters directly? "}