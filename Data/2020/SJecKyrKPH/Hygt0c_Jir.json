{"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "title": "Official Blind Review #1", "review": "The proposed method in this paper tries to make the CNN robust to the input image transformation by learning to generate convolutional filters. \nThe proposed architecture has two main parts. \n1) Filter Generation:  Given an input image, a set of predefined transformations are applied to the image. After extracting features from the input transformed images with the Siames network, a set of Convolutional filter are estimated. The idea is that these input-dependent filters can compensate all of  transformation in the image.\n2) Classification and reconstruction part: The generated convolutional filters are applied to the image and after extracting deeper features a representation vector is computed. This representation vector will be used for classification and reconstruction of the input image to make sure that it has all of the necessary information. \n\nPositive points:\n1) The writing is clear.\n\nNegative points:\nThe proposed method is not novel. The proposed method will be robust to the transformations that are used during training but it cannot generalize to other useen transformations.\n2) The experimental results are weak, the authors should compare their method on more difficult datasets like ImageNet dataset. \n3) The authors should compare their proposed method with the \"Spatial transformer networks, NIPS 2015.\" in detail. \n\nIn conclusion, my recommendation for this paper is \"weak reject\".\n", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory."}