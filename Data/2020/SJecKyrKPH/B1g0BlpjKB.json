{"rating": "3: Weak Reject", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper proposed an Input-conditioned Convolutional Neural Network (ICNN) to automatically impose transformation-invariance. The contribution of the manuscript is two-folds\n(a) After transforming the input using a pre-determined set of transformations, a set of input-conditioned filter generators are used (and trained) to cater to different input contents.\n(b) A decoder is used after the max-pooling layer (of the  Siamese network.) And an L-2 reconstruction loss (with respect to a chosen class representative) is added to the cross-entropy loss for classification.\n\nOverall the paper is well written, and it is fairly easy to read. However, I am not totally convinced that the two contributions of the paper are significant to transformation-invariant representations, and my reasonings are follows\n\n1. Why is a decoder needed in the architecture? If the objective is to achieve transformation-invariance, one can easily compare the L-2 distance between the max-pooled feature maps of a given input to that of the class representative. Why bother using a decoding architecture?\n2. Choosing a \"class representative\" in the CNN seems very restrictive. Why if the underlying task is not image classification? Besides, I am very curious about the experiment on the CIFAR-10 dataset: do the constructed images of all test samples look like the one chosen class representative in the training data? (i.e., compared to figure 3)\n3. The input-conditioned filter generation seems a little confusing. Is this what you want to achieve? Say if the pre-determined transformations are rotation (scaling), then the input-conditioned filter should be generated as rotated (scaled) version of the same filters? If so, why not just rotate (rescale) the filters? There are lots of group-equivariant CNNs that have been proposed before for such effect. Besides, I am confused why fractionally-strided convolutions are used for filter generation?\n\nOther comments:\n1. The reference for fractionally-strided convolutions should be fixed.\n2. Why there is no bias term in convolutional modules (page 4, second paragraph?)\n3. What does ICNN short for? The first appearance of the abbreviation in the abstract needs more explanation."}