{"rating": "6: Weak Accept", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review": "The paper proposes an approach for combining meta-imitation learning and learning from trial-and-error with sparse reward feedback. The paper is well-written and the experiments are convincing. I found the idea of having separate networks for the two phases of the algorithm (instead of recollecting on-policy trial trajectories) interesting and possibly applicable in other similar settings. \n\nThe paper has a comprehensive analysis of the advantages of the method over other reasonable baselines which do not have the trial-and-error element. However, in terms of the limitation of the method, the paper only has a small failure analysis section in the appendix; adding a more detailed discussion on the limitations can improve the impact of the paper further. "}