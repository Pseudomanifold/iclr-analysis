{"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper presents a multi-task learning approach to predict both generated tokens and syntactic labels, in an attempt to apply better style transfer to the original text. The model framework is based on previous text style transfer architectures, and the novelty of this work mostly lies in predicting (and leveraging) additional word-level syntactic labels (POS-tags) to further improve the results. The intuition makes sense to me, as a proper text style transfer can possibly benefit from a better understanding of the syntactic annotation of the text. However, it is not clear whether a well-pretrained language model like BERT or GPT-2 can already capture such subtle information, and whether this fact renders less merit of explicitly modeling the syntactic structure. In general, the paper is properly written and pedagogical. Specific comments:\n\n1. A major concern is that this paper misses an important reference: \"Structured Content Preservation for Unsupervised Text Style Transfer\", which first uses POS-tag information for text style transfer. From this point of view, using syntactic knowledge is not very novel. Although the ways to use POS tags are different, I would at least mention and discuss the differences, and possibly comparing with them. \n\n2. Is the pre-training stage of self-reconstruction important? How much performance will be affected by the pre-training part? \n\n3. Since there is no ground truth label for \\tile{x} and \\tile{l}, adding L_cons on them may bring unexpected prediction errors. For example, if prediction work \\tile{x}_k is wrong, the syntactic label \\tile{l} could also be wrong. Simply forcing the model to predict a wrong syntactic label is probably questionable. This might be the reason why the coefficient of consistency loss in Equation 12 is small (0.005) in the experiment. Additionally, the ablation study shows the impacts with adding consistency loss is relatively small. It's not very convincing that the consistency loss do help a lot. Why don't the authors place the consistency loss on \\tile{x}_b and \\tile{l}_b? "}