{"experience_assessment": "I have published in this field for several years.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper proposes an unsupervised feature selection method by minimizing reconstruction error with restricted autoencoders. The proposed method employs iterative elimination to select features with learned per-feature corruption rates. \n\n1) The novelty of the paper is very limited: using reconstruction for unsupervised feature selection has been explore in many papers, such as [1][2][3]. So the proposed method is a bit incremental.\n\n2) Time complexity of the proposed method should be discussed.\n\n3) Experimental results are not convincing at all due to the following reasons:\n  a) Only one baseline (out of 9) was proposed after 2011. Outperforming these decade old approaches is not very difficult. There has been much progress on unsupervised feature selection and several hundred papers in this area have been published in the past 5 years.  The author should include more recent state-of-the-art baselines.\n  b) When tuning the hyper-parameters (e.g., \\lambda) for the proposed method and baseline methods (UDFS) on validation dataset, the author should list the value range used in the parameter search. Also, as unsupervised feature selection methods, using validation dataset (which has supervision labels) to choose parameters is not a fair way, as it does use supervision information.\n  c) Unsupervised feature selection papers in the past 5 years typically use 6~8 datasets to demonstrate the effectiveness while this paper only shows results on 2 datasets.\n\nGiven the reasons above, this paper needs improvement in many aspects and not ready to publish in its current form.\n\n\n[1] Zhu et al. Unsupervised feature selection by regularized self-representation\n\n[2] Yang et al. Unsupervised Feature Selection Based on Reconstruction Error Minimization\n\n[3] Li et al. Reconstruction-based Unsupervised Feature Selection: An Embedded Approach"}