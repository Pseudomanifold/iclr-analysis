{"rating": "6: Weak Accept", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "The paper is concerned with unsupervised feature selection, in a lossy compression perspective. Formally, the idea is to select a subset of features that supports the reconstruction of the whole dataset.\n\nThe idea is good, but the the same idea (same reconstruction goal, also relying on auto-encoders) was published this year, see here: https://ecmlpkdd2019.org/programme/awards/\n\nAlgorithmically speaking, the approach is very close to the above paper; as far as I can tell, the main difference lies in the recursive feature elimination heuristics.\n\nI feel that the originality of the paper is thus severely undermined. The authors might want to address this, through:\n* thorough empirical comparisons (experimental setting, considering other datasets; comparing with other regularization schemes)\n* examining the stability of the selected features (among runs).\n\nThe analysis definitely is a good point of the paper; however, parts of it are straightforward (Thm1). \n\nDetails: continuity, p.3\n"}