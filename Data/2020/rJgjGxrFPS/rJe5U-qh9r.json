{"rating": "3: Weak Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper studies the problem of learning the feature representation for predicting the 3D shape of objects, from a single image or a point cloud. The proposed approach performs PCA on the SDF field. And then the transformed feature map is learned and used as input to task-specific decoders for 3D shape prediction. The authors claims that this approach trains faster and is easier to scale, while showing competitive performance compared to state-of-the-art methods.\n\nI am leaning towards Weak Reject. The paper is generally easy to read, but with some details missing. And I found the discussion of the results to be insufficient. I think it can be an above-threshold paper if questions are addressed during rebuttal.\n\nBeing able to easily scale to higher resolutions is claimed to be one of the main advantages, but I am not convinced that this is useful under this setting. If I understand this correctly, the number of eigenvectors k is fixed, and projecting the SDF field to this space would remove the higher frequency components of the shape. So wouldn't the number of eigenvectors be the bottleneck in representational precision, not the resolution of the output space?\n\nWhat is the chosen k (number of eigenvectors)? It says k was \"chosen to capture 99.5% of the variance within the dataset\", but I could not find how exactly it was chosen and what value of k was used (I apologize if I missed).\n\nAlso, I think the PCA is category-specific (page 4, section 4.1). Is k dependent on the category or is it the same across all categories? Some of the other methods (if not all) used for comparison are not category-specific, so if this is true, I think the comparison may not be entirely fair and it should be made clearer.\n\nI think the writing could be polished as well, some minor typos:\n\nPage 2:  3rd and 4th paragraphs: continous\nPage 2: anlaysis, enlightning\nPage3: under eigenSDF: reprsentation\nPage 4: section 4.1: refered, signficant\nPage 5: \u201cseciton\u201d\nPage 7: tranform\n\nPage 3, Section 3.2: Is N the number of training examples and M the resolution?\nFigure 2 not referred in the main text.\n\n\n\n\n"}