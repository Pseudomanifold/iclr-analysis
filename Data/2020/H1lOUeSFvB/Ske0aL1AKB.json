{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper is about improving the quality of surrogate gradients. Their proposal in guaranteed to find a descent direction. In addition to two results, the authors also provide experimental results.\n\nThis paper is presenting a research on a recent topic. Using random search methods or evolutionary strategies in machine learning problems is attracting quite an interest in the last years. However, this particular paper misses several important points and hence, lacks sufficient contribution. \n\nHere are my major comments:\n\n- The technical results are somewhat superficial: The first one is with the big assumption of linearity. This assumption does not hold almost for all problems where random search strategies would be of use. The second result, on the other hand, assumes orthogonality, which almost surely never happens. I must add that the authors also acknowledge the severity of these assumptions.\n\n- It is important to note that the theory here assumes that the gradient does exist but cannot be computed or too expensive to compute.\n\n- I would have expected an experimental study that would properly support the proposed approach. Such a study would have shed light on the computation time and efficiency. The authors solve MNIST problem, which can be quite efficiently solved with a variant of (accelerated) gradient method. Solving it with ES and then improving the result with the proposed approach is not satisfactory. Reinforcement learning experiments could have been noteworthy but the authors have solved quite small problems and did not compare their results extensively against contender approaches like augmented random search. It would have been also nice to see the computation times on large problems since the extensive computation time is a big obstacle for training in reinforcement learning.\n"}