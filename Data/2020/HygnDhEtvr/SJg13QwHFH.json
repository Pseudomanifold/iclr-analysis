{"rating": "3: Weak Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This paper focuses on improving the performance on the task of natural language generation. To this end, they propose a  graph-to-sequence (Graph2Seq) model for the task of question generation which exploits the rich structure information in the text as well as use reinforcement learning based policy gradient approach to address the exposure bias and inconsistency between test/train distributions in cross-entropy optimization setup. \n\nThe Graph2Seq model has a bidirectional gated graph neural network on the encoder side, which is an extension of traditional gated graph neural network. To exploit the rich hidden structure information in the input text, they explore two different methods: (1) syntax-based static graph; (2) semantics-aware dynamics graph. \n\nThe proposed model achieves state-of-the-art results on question generation, which are further validated with human evaluations. \n\nOverall, The paper should be rejected because the paper have minor extensions to each of their modules but lacking any major important contribution. \nSome major concerns: \n1) The bidirectional gated GNN doesn\u2019t seem novel enough in comparison to previous work\n2) I believe RL to Graph2Seq is a minor extension from Seq2Seq, since RL mostly deals with the decoder part which is common in across both Graph2Seq and Seq2Seq\n\n\nArguments:\n\n1) Adding the structure information to the encoder via the GNNs is an interesting angle for question generation. Compared to previous work, this paper proposes an additional deep alignment network on the encoder side to align paragraph and answer. However, the importance of this module is not well studied in the experiments section. I see that there is an ablation with/without this module but its not fairly compared with other aligning or simple techniques like in Zhao et al. (2018). \n\n2) The addition of RL component to Graph2Seq is a minor extension from the Seq2Seq model, because both of these models have similar decoder and RL mainly deals with it. Also the importance of each reward component or the effect of each phrase-matching automatic metrics is missing. \n\n3) Open part I am unclear about the dataset is which dataset version did you use sentence-level or paragraph level? I see that the baselines correspond to sentence-level, but the Figure-1 alignment module has input paragraph. Also I couldn\u2019t find the SeqCopyNet (Zhou et al., 2018) split-2 BLEU4 score=13.02 in the original paper! \n\n4) Some of the latest papers which use BERT based models are not discussed in the paper which achieve state-of-the-art-results: \u201cAddressing Semantic Drift in Question Generation for Semi-Supervised Question Answering\u201d\n\n5) For Table-2 results are the differences in the scores for the two models statistically significant?\n\n6) Table-3: First of all, evaluating only one metric is no sufficient. Please see latest papers that have also introduced new metrics that are good for QG evaluation, e.g., Q-BLEU. The gap between G2Ssta+BERT vs. G2Ssta+BERT+RL seems negligible, and missing statistical significance. \n\n7) Minor comments: BLUE -> BLEU; please cite KNN-style graph sparsification; the color choices in Figure-3 are creating confusion in understanding the model. \n"}