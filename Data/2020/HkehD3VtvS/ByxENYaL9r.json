{"experience_assessment": "I do not know much about this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper introduces a deep reasoning networks for de-mixing overlapping patterns with some logic constraints. There are two applications considered in the paper: de-mixing overlapping hand-written digits and inferring crystal structures of materials from X-ray diffraction data. The experiments indicate the proposed method work pretty well on these tasks.\n\nI like the general idea of this paper, since it has the flavor of combining deep learning with logic rules, although I feel weird to view the generative decoder as thinking fast and the reasoning modules as thinking slow. The notion of thinking fast and slow in the model does not well match the intuition given in the first paragraph of the introduction. The so-called reasoning module is essentially some contraints (i.e., regualrization losses) and a training data sampler. It is far away from the concept of (symbolic or logic) reasoning. There is not too much reasoning happening here. The way the paper relaxes the discrete logic constraints to continuous and differentiable objective that can be jointly optimized by SGD is interesting, which is similar to [Harnessing deep neural networks with logic rules, ACL 2016]. The carefully designed training data sampler that samples data according to a constraint graph also resembles GraphRNN, as the authors have mentioned in the paper. I feel the combination of these techniques is definitely interesting but also somehow incremental. I am not a big fan of some big claims in the paper. The reasoning modules are not what I expect.\n\nFor the experiments, I think the authors do a good job presenting these experimental details and evaluations. These experiments are interesting and also show some advantages of the propose method. However, some baselines are also doing pretty well, indicating that the task is not difficult in general."}