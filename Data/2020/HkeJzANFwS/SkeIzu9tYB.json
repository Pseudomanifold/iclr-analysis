{"rating": "6: Weak Accept", "experience_assessment": "I do not know much about this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "\n=== Summary ===\n\nThe paper considers the following task: given a sentence, its context paragraph, and the target style (formalness, inoffensiveness), generate a new sentence that still fits the original context. The evaluation metrics include content preservation (BLEU, GLEU, PPL), style accuracy (based on a pre-trained model), and context coherence (ditto).\n\nThe input context is the main highlight of this new task. The paper proposes a model that can use both parallel and non-parallel data. In addition to the existing non-parallel corpora, two datasets with crowdsourced parallel sentences were collected. Compared to the baselines, the proposed model produces sentences that are more relevant to the context.\n\n=== Review ===\n\nThe major contributions of this paper are the new task setting and the accompanying parallel corpora. The datasets are rather large, and the fact that they contain parallel sentences (e.g., informal - formal sentences with the same semantics) makes the dataset potentially useful for other scenarios as well.\n\nThe proposed method is a natural extension of previous style transfer methods. One new addition is the contextual coherence loss, which is a relatively straightforward application of BERT-based models. If I am not missing anything, the model and the experiments are likely correct. In addition to the surrogate metrics, the paper also presents human evaluation, which strengthens the results."}