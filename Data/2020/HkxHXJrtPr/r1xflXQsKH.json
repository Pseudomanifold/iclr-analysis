{"rating": "6: Weak Accept", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "*Summary*\nSPENs are an interesting structured prediction technique. They used a trained deep energy function (like the discriminator in a GAN) to reward high-quality structured outputs. Prior work (Tu and Gimpel 2018) contributed an 'amorized inference' method for training SPENs that appears to be considerably more practical than the training methods originally proposed for SPENs. This paper provides additional improvements to the amortized inference training method that make it simpler and perform better. Directly address a weakness of Tu and Gimpel: the amortized predictor was trained for a different objective (loss augmented inference) than it will be used for at test time. They explore a variety of ways to tie two separate amortized predictors together. The most interesting one is where the train-time predictor has access to the ground truth label.\n\n*High-level assessment*\nOverall, the authors do a good job of providing careful ablation analysis of their contributions. This level of analysis is absent from many submitted papers. The paper's contributions also seem like an important step in making SPENs practical. \n\nI can imagine that other reviewers may be critical of the size of the paper's contributions: it mainly presents a collection of tricks of the trade to make SPEN training work in practice. Much of the ICLR community is very interested in structured prediction, but It appears that SPENs have not had much traction. I think that this paper is important because it may teach practitioners that they should consider SPENs.\n\n\n\n*Additional Comments*\n\nSec 4.2: your paper should be self contained. What is this loss?\n\nPaper would be improved if it helped explain why people should care about SPENs. I'd include more of a sales pitch for the benefits of them.\n\nAlso, your approach is substantially more complex than training a straightforward model with some deep representations. Is it worth the complexity?\n\nHow do you justify removing the hinge term in your max-margin objective when updating the inference network? Is there some principle that would suggest that this is OK?\n\nThe idea of having the inference network condition on the ground truth label is cool. This is similar in RL to how people will use 'asymmetric critics', where the critic has access to more information than the actor. For example, the critic may have access to a scene's actual 3-D geometry, while the actor just has a 2D camera view of it. It might be worth drawing this connection."}