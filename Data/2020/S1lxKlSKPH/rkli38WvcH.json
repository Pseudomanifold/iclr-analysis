{"experience_assessment": "I have read many papers in this area.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "N/A", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #6", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "Summary:\nThe paper presents a new regularization technique termed consistency regularization for training GANs. The idea is the following: the authors propose to penalize the sensitivity of the last layer of the discriminator to augmented images. This idea is simple yet efficient: it is easy to implement, a regularization term is gradient-free, and its computation is up to 1.8 times faster than standard gradient-based regularization techniques. The authors tested different augmentation techniques and concluded that simple ones behave better (e.g., shifting and flipping). The experimental results show an impressive gain in FID measure, renewing the current state-of-the-art score for class conditional image generation on CIFAR-10 dataset. \n\nPros: \nThe proposed technique is very simple and intuitive; it easy to implement, and it is computationally cheap. The experiments were held for three runs with different random seeds, supporting its consistency.  The paper is overall clearly written and easy to understand. \n\nCons:\nThe reported experimental results are held only for BigGAN architecture while not considering different networks to ensure the stability of the proposed regularization. Also, the paper would benefit from a clear experiment description on CelebA dataset (e.g., adding the results to Table 1). \n\nQuestions:\n-Have you tried other transforms, which potentially keep images on the manifold, including zoom, resize, rotation, brightness adjustment, etc.?\n-How the number of layers in $L_{cs}$ (formulas 2-3) affects FID? \n-Have you considered an unconditional setting? \n\nMinor comments: \n-It would be more convenient if the authors explicitly numerate subplots; e.g., in Figure 2, it is confusing to refer the subplots labeled by (a)-(f) as written in caption. \n-Additionally, it would be nice to include say best FID scores over different loss functions (from Figure 2) to Table 1.\n- In section 4.3, you wrote that you tried different $\\lambda$ values:  {0,1,10, 100}, but Figure 4 does not cover all of them. \n- It would be nice to add implementation details (e.g., optimizer, learning rate parameters, steps per discriminator, etc.) for better reproducibility.\n-The paper would benefit from illustrations of generated samples.\n-Please check the spelling of the penultimate article name in references (Zhai et al., 2019). \n"}