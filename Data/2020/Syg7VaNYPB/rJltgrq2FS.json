{"rating": "3: Weak Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "Summary:\nThe authors propose a model that combines a simple Auto-Encoder (AE) together with a Normalizing Flow (NF) model, such that to derive a generative model. In particular, the AE is used to learn a low-dimensional representation of the given data in a latent space. Then, a NF model learns under a maximum likelihood principle, the distribution of these latent codes by applying an invertible transformation on a easy to sample distribution.\n\nGeneral Comments:\n\nThe paper is ok written, but some parts probably can be improved (see comment #5). As regards the proposed idea of the paper, I think that it is closer to an engineering practical approach than a consistent modeling choice. In particular:\n\n1. With the current modeling the likelihood p(x|z) is not defined, which means that the density of the p(x) can not be evaluated. So this should be considered as an explicit or implicit generative model? In that case the comparison with explicit density models where we can evaluate the p(x) is a bit unfair. Otherwise, the test log-likelihood should be provided.\n\n2. Learning the prior is already a debatable choice. However, in the proposed idea I have the feeling that there is a strong overfiting issue. Since the NF model is trained in a maximum likelihood principle, it will try to put all the mass from the simple distribution p(e) on the training latent codes z_i. Consequently, I am a bit sceptical as regards the generalization power of the generative model. Does the latent distribution learn something meaningful (an illustration could have been informative) or just how to re-generate the training data? \n\n3. The authors claim that the training is end-to-end. However, I think that the model which performs better is actually a 2 stage training model. More specifically, due the sg[.], the L_NLL term does not have any influence in the L_recon term. Therefore, the AE is trained independently, and simply the NF at every step \"follows\" and tries to capture the latent (empirical) distribution of the encoded training data.\n\n4. From the experiments is argued that the proposed model provides better samples than the competitive methods. I have the feeling that the generated samples are basically very similar to the training samples. Because the learned prior essentially learns to generate the latent codes of the training data. Does the model generalize i.e. can it generate samples that have not be seen during training?\n\n5. I think that the first paragraph of Sec. 2 and some parts of the next paragraph need improvement. Also, how the decoder implies the distribution \\tilde{p}(z) in the latent space? I would expect the encoder to be responsible for the latent distribution. Moreover, in the classic VAE the KL divergence is used between the approximate posterior q(z|x) and p(z), while the KL between the aggregated posterior q(z) and p(z) is not the default choice, and usually, is not straightforward to optimize.\n\nIn general, I think that the proposed model is a rather good practical approach, but probably not a very well defined modeling choice. As a practical approach, the experiments is most of the times the only way to support the argued behavior. The conducted experiments mainly focus on the FID score. However, I think that it would have been interesting to include examples that show the latent distribution and why is this better from other models, for example less regularized from the p(z) in VAE. Also, another crucial issue is the level of overfiting the current approach might have, because learning the prior implies this behaviour. Does the generated samples cover only the training distribution or can it generalizes to unseen test samples?"}