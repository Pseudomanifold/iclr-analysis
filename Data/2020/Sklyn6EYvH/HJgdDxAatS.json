{"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "Overview:\nAuthors introduce a new VAE-based method for learning disentangled representations.\nThe main idea is to apply a \u201cresidual learning mechanism\u201d, which resembles an autoregressive model, but here conditioning between sequential steps is done in both latent and input spaces. Namely, for each input, the method involves making several (one per *each* embedding dimension) sequential passes, where each pass takes the residual between the input and the current accumulated output (i.e. pixel-wise difference between two images) as well as the values of the sampled embeddings so far. \nAuthors report quantitative and qualitative evaluation with a set of reasonable baselines (FactorVAE, beta-VAE), and the results seem to be slightly better.\n\nDecision:\nThe writing quality is not great: there are frequent typos and not-so-precise formulations, and is at times hard to follow (see list below).\nThe method itself is not really well-motivated: there seems to be no formal justification provided, and the informal one is not very clearly explained in the paper. \nScalability of the method is clearly an issue. Many applications might require the size of embeddings to have hundreds of dimensions, which would mean that the given method cannot really be applied for non-toy problems. \nWith all those considerations in mind, I cannot recommend to accept this paper as is, thus the final rating, \u201creject\u201d.\n\nAdditional comments / typos:\n* It would be worth seeing how this approach relates to auto-regressive models.\n* p2. \u201cencoder maps \u2026 x to a latent representation q\u201d - this sentence is not very strict. \n* p2. \u201c.. is defined as following\u201d: as follows?\n* p2. \u201c.. in addition of b\u201d\n* p3. \u201c.. this reguralizer encourage\u201d\n* p7: \u201c\u2026 it reduces the solution space and improve training stability\u201c: is there any sort of theoretical reasoning that could support this?\n* The reference format is not very readable, probably better to change to (Names, Year).\n\n\n\n"}