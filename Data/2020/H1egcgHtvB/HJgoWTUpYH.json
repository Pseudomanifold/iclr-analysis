{"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This paper deals with the problem of translating natural language questions to SQL queries by incorporating relational structures in database schema and the question to query. \n\nSpecifically, the authors proposed that existing methods of translating natural language to SQL queries cannot generalize well to unseen schemas. They then proposed their methods based on self-attention modules and graph representation of schemas. In addition, they exploited the heterogeneity of the schema-induced graph and designed various relations and corresponding relation-aware embeddings. Finally, the authors introduced a schema linking task that helps identify references in questions and the columns/tables in DB. \n\nStrengths: \nS1: The paper investigates an important and interesting problem of translating natural language to SQL sentences, which can potentially be significant in the applications of DB. \nS2: The paper clearly identifies the challenges and shortcomings of existing works, which is easy to follow. The analysis of related work is sufficient. \nS3: The idea of inferring soft relations between questions and words is novel and interesting.\nS4: In the experiment part the authors made a visualization of how the alignment between question words and elements in the DB schema looks like, which clearly illustrates the effectiveness of schema linking, one main contribution of the paper. \n\nWeaknesses: \nW1: I think the main weakness of the paper lies within the organization and description of the Sec. 3 \u201cRAT-SQL\u201d. Specifically, the authors made many forward references that make it hard for readers to follow. \ne.g. \na. On page 3, in Sec 3.1 \u201cProblem Definition\u201d, the authors referred the readers to Section 3.6, which I think is unnecessary as Section 3.6 introduces detailed solutions instead of introducing problem. \nb. On page 3, in Sec 3.2 the authors referred the readers to Table 1, which actually lies on Page 5. \n\nIn addition, in Sec 3.7, the authors did not mention the objective function that is used for learning the decoder. Since the decoder outputs a syntax tree instead of ordinary sequences (e.g. in machine translation), I think it is necessary that the authors make clearer descriptions on how the objective function is chosen and how the decoder is learned. \n\nW2: The empirical evaluations of the method are somehow limited. For example, in \u201cRelated Work\u201d, the authors mentioned that there are two publicly available datasets. So why didn\u2019t the authors use both instead of one?"}