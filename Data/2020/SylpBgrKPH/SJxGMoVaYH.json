{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper introduces MissDeepCausal method to address the problem of treatment effect estimation with incomplete covariates matrix (missing values at random -- MAR). It makes use of Variational AutoEncoders (VAE) to learn the latent confounders from incomplete covariates. This also helps encoding complex non-linear relationships in the data, a capability that is missing in the work of Kallus et al. (2018) -- the work which this paper extends. They employ the Missing data Importance Weight AutoEncoder (MIWAE) approach (Mattei & Frellsen, 2019) to approximate the posterior of their latent factors Z given the observed incomplete covariates X*. The main contributions of this work are presented in sections 3.2 and 3.3, where they use the approximated posterior derived from MIWAE to sample Z to be used for estimating outcomes and finally calculating the Average Treatment Effect (ATE). This is done according to the doubly robust estimator developed for data with incomplete covariates (Mayer et al., 2019b). \n\nIn summary, I am not convinced that the contribution of this paper is enough, nor of its novelty. However, I will read the rebuttal carefully and am willing to increase the score if the authors address this concern.\n\nThere are several points that need further clarification; e.g., \n\t- Figure 1 as well as Figure 2 show a directed edge from X* to X_{miss}. Does this mean that X* has all the proxies needed to identify X_{miss}? \n\t- How does this method assure/evaluate that Z embeds enough information to predict accurate effects?\n\t- How are \\mu_0 and \\mu_1 functions trained on Z\n\nThings to improve the paper that did not impact the score:\n\t- Page 2, par. 2, last line: state-of-the-art method\u201ds\u201d\n\t- Page 3, under Unconfoundedness par., line -7: [...] for each observation \u201ccomma\u201d treatment assignment [...]\n\t- Page 3, Figure 1: According to ICLR\u2019s formatting guidelines, the figure number and caption must always appear after the figure.\n\t- Page 3, Missingness par., line 1: [...] is one \u201cof\u201d the most [...]\n\t- Page 5, line after Eq. (8): 8 should be in parentheses.\n\t- Page 7, Figure 3: box-plots are hardly legible.\n\t- Page 7, Figure 3 caption, line 2: keep \u201c(logistic-)linear\u201d together with \\mbox{} or ~ in latex\n\nReferences:\n\t- Kallus, N., Mao, X., & Udell, M. (2018). Causal inference with noisy and missing covariates via matrix factorization. In Advances in neural information processing systems (pp. 6921-6932).\n\t- Mattei, P. A., & Frellsen, J. (2019). MIWAE: Deep Generative Modelling and Imputation of Incomplete Data Sets. In International Conference on Machine Learning (pp. 4413-4423).\n\t- Mayer, I., Wager, S., Gauss, T., Moyer, J. D., & Josse, J. (2019). Doubly robust treatment effect estimation with missing attributes. preprint.\n"}