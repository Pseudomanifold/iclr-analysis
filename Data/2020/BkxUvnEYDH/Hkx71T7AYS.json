{"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "Summary\nThis paper investigates an important direction: How can RL agents make use of high-level instructions and task decompositions formalized as programs? The authors propose a model for a program guided agent that, conditioned on a program, interprets the program, executes it to query a perception module and subsequently proposes subgoals to a low-level action module. The method outperforms LSTM and Transformer baselines on a Minecraft-like task and generalizes to programs larger than the one seen during training.\n\nStrengths\nContribution in the important direction of training RL agents with instructions and prior knowledge, here in the form of programs\nClearly written paper with good illustrations of the model\nGood performance on generalization task of acting in environments where the programmatic instructions are longer than those seen during training\n\nWeaknesses\nOne of the contributions of the paper is a modulation mechanism (Section 4.3) on the state features that incorporates a goal-conditioned policy. However, a very related approach has been proposed by Bahdanau, Dzmitry, et al. \"Learning to Understand Goal Specifications by Modelling Reward.\" ICLR 2019. They introduced FILM layers that modulate the layers in a ConvNet conditioned on a goal representation. This should be discussed and compared to in the paper.\nI am surprised there is no comparison to other work that conditions on programs or hierarchical RL approaches. For example, the authors mention various works in Section 2, but fail to compare to them or at least explain why a comparison would not be possible.\nAnother point of criticism is that the authors do not use an existing environment, but instead a Minecraft-inspired one similar to Andreas et al, Oh et al. and Sohn et al. This makes a comparison to prior work hard and I would like to understand in what way previous environments were inadequate for the research carried out here.\nOne aspect that I found most interesting in this paper is that the authors also let annotators map the given programs into natural language form. However, there is no discussion of these results. Similarly, there are interesting qualitative analyses in the appendix of the paper that I only stumbled upon by chance. I believe these should be referenced and a short summary should be integrated into the main part of the paper. I would particularly like to see a discussion of limitations already in the main part of the paper.\n\nMinor Comments\np1: I like the motivation of cooking recipes for work on program conditioned learning. There is in fact a paper (probably multiple) from the NLP community that I think could be cited here. The one that comes to my mind is: Malmaud, Jonathan, et al. \"Cooking with semantics.\" Proceedings of the ACL 2014 Workshop on Semantic Parsing. 2014.\np1: I agree with the argument that programs might be favored over natural language to specify goals as they are unambiguous. However, I think this can also be seen as a drawback. Natural language allows us to very efficiently share information, maybe sometimes information that is only disambiguated through observations in the environment. Another advantage is that natural language for instructing learning agents (like people) is abundant on the web, while programs are not.\np2: \"that leverages grammar\" -> \"that leverages a grammar\"\np2: \"we propose to utilize an precise\" -> \"we propose to utilize a precise\"\np2: For learning from video demonstrations, an important prior work is Aytar, Yusuf, et al. \"Playing hard exploration games by watching youtube.\" Advances in Neural Information Processing Systems. 2018.\np3: A deep learning program synthesis work prior to the ones mentioned here is Bo\u0161njak, Matko, et al. \"Programming with a differentiable forth interpreter.\" Proceedings of the 34th International Conference on Machine Learning-Volume 70. JMLR. org, 2017.\np5: Would it make sense to also compare to a purely hand-crafted programmatic policy? I am missing a justification why learning is strictly necessary in the environment considered in this work.\np6 Section 4.4.1: I believe the explanation of the perception module would benefit from a concrete example.\nQuestions to Authors"}