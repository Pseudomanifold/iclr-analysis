{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #4", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "The paper reads well, the topic is interesting, and the connection between early stopping and fitting true label distributions before noisy ones, if generally true, is of potential impact. I do not feel the paper is ready for publication, though: \n\nMissing context/references:\n\t\u2043\tNoisily collected labels are standard elsewhere, e.g., in sentiment analysis (self-ratings), in discourse parsing (explicit discourse markers), in weakly supervised POS tagging (crowdsourced dictionaries), in NER (Wikidata links), and in machine translation from mined parallel corpora or comparable corpora. \n\t\u2043\tLearning a ground truth from a population of turkers (MACE and subsequent work). It is well-known that the noise in such silver standard or non-adjudicated annotations is also \u201cmore structured\u201d and to a large extent predictable (Plank et al., EACL 2014 and subsequent work on learning/predicting inter-annotator disagreements). \n\t\u2043\tConnection between L2 and early stopping. Can you replicate your results with simple L2 regularisation?\n\t\u2043\tCost-sensitive learning of systematic disagreements (use class coherence scores for cost-sensitive learning). \n\t\u2043\tThe observation that \u201cclean examples are fitted faster than noise\u201d is obviously related to baby steps training regimes (training on easy examples first), including active learning. \n\nExperimental details and flaws: \n\t\u2043\tUsing a black box search engine to collect labels is problematic for a few reasons: (a) Search engines change, so results are hard to reproduce. (b) Search engines are biased toward certain types of categories. Such biases will be reinforced by any model trained on this data. \n\t\u2043\tI\u2019m always a little worried about papers that only report results for a single dataset. \n\t\u2043\tI would have liked to see some more error analysis. Are the improvements on classes with more or less support in the original dataset, for example?\n\t\u2043\tIt seems to be that it would have been relatively straight-forward to construct synthetic datasets that would more directly evaluate the hypothesis that the true labels are learned first. I realize you\u2019re interested in \u201creal\u201d noise rather than \u201crandom\u201d noise - but synthetic noise doesn\u2019t have to be random. \n\t\u2043\tThat \u201cthe noise generated through the label collection process is not nearly as adversarial for learning as the noise generated by randomly flipping labels\u201d is no surprise, and I would not present this as a finding. It would be interesting to describe the bias, e.g., by presenting confusion matrices (see Plank et al., EACL 2014). \n"}