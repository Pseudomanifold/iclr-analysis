{"rating": "6: Weak Accept", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "The paper is about adversarial attacks and highlights a security weakness of skip connections in ResNet-like CNNs, namely: skip connections make it easier to obtain adversarial examples. This observation leads to new approach to adversarial attacks, named Skip Gradient Method (SGM), which weights the residual gradient w.r.t  the skip connection gradient. The approach is validated on a variety of image classification attack scenarios (e. g. white-box and transfer attacks) using two families of source models (ResNet and DenseNet). The results show the superiority of SGM when comparing to other adversarial attack scenarios.\n\nStrengths:\n- Simple approach that seems to be giving good results\n- Large number of adversarial attack scenarios tested\n- Good related work review\n\nWeaknesses:\n- Results are reported without variance information\n- There are some details missing on how the decay factor is selected \n- Results are reported only on one dataset (ImageNet)\n\nThe paper is well written, the authors have identified a \"problem\" of ResNet-like models and proposed an approach that can exploit the problem in adversarial attacks scenarios (SGM). To the best of my knowledge, this is the first time someone has identified the skip connections security problem in ResNets. The SGM is compared against many existing adversarial attacks methods achieving making the evaluation section quite detailed. Thus, I'd lean towards paper acceptance.\n\nHowever, I have some questions with respect to the evaluation section:\n1. Although, the paper includes ablation analysis for different values of the decay factor, I could not find details on how the decay factor hyperparamenter is selected. Given that this factor is a hyperparamenter, it feels like it should be selected on a validation set and tested on a test set. The paper comments about 5000 random validation set images that are used to compere methods (test set), however, I could not find any mention about validation set used to select decay factor. Could the authors specify how the decay factor is set?\n2. Since all the results are reported with 5000 random imagent images, it would be interesting to see the variance of results if the sampling of images is repeated.\n3. Section 3.3, 2nd paragraph: \"Another important observation is that when there are more skip connections in a network.... the crafted attacks become more transferable....\". Although, this statement seems to be correct when comparing DenseNet to ResNet, it does not necessarily hold when comparing models within the same family (e. g. RN18 to RN 152 for FGSM or RN34 to RN 152 for PGD) suggesting that the best is not only connected to the number of skip connections. Maybe the superiority of DN is rather related to the nature of the DN models and not to the number of skip connections. Could the authors clarify?\n4. Section 4, threat models: \"... the same architectures but trained separately.\" Could the authors clarify what does it mean? Are these models re-trained from scratch changing the random seed of model initialization, order of the dataset, or something else? In general are the authors using pertained models or train all the models \"from scratch\".\n5. Fig 2: Since x-axis values are not continuous - it might be better to use bar plot.\n6. In some tables, the results are reported just for SGM while in other tables SGM is reported in combination with other method. I guess that when the results are reported for SGM they represent SGM from Eq. 10 that represents SGM+PGD. Is this correct? The authors might consider clarifying this in the paper.\n\nSome typos:\nIn the following, we exploits an architectural security weakness about....\n... the the crafted attacks...\n... not only reminds researcher to pay....\n"}