{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "Overview:\nThis paper introduces a model for image-based facial 3D reconstruction. The proposed model is an encoder-decoder architecture that is trained in semi-supervised way to map images to sets of vectors representing identity (which encodes albedo and geometry), pose, expression and lighting. The encoder is a standard image CNN, whereas the decoders for geometry and albedo rely on spectral graph CNNs (similar to e.g. COMA, Ranjan\u201918). \nThe main contribution of the work with respect to the existing methods is the use of additional loss terms that enable semi-supervised training and learning somewhat more disentangled representations. Authors report quantitative results on MICC Florence, with marginal improvements over the baselines (the choice of the baselines is reasonable).\n\nDecision:\nThe overall architecture is very similar to existing works such as COMA (Ranjan\u201918) and (Tran\u201919), including the specific architecture for geometry decoders, and thus the contributions are primarily in the newly added loss terms. \nI also find the promise of \u201cdisentangled\u201d representation a bit over-stated, as the albedo and base geometry still seem to be encoded in the same \u201cidentity\u201d vector (see related question below).\nThe numerical improvements seem fairly modest with respect to (Tran\u201919). In addition, there is no numerical ablation study that would demonstrate the actual utility of the main contributions (such as adversarial loss): there are qualitative results but they are not very convincing. \nThus, the final rating \u201cweak reject\u201d.\n\nAdditional comments / typos:\n\n* I am not fully following the argument about sharing identity for albedo and shape on p2: \u201calbedo and face shape are decoded ...\u201d. Would it not be more beneficial to have a fully decoupled representation between the albedo and the facial geometry? I do not see how albedo information would be useful for encoding face geometry and vise-versa. \n* Authors claim that one of the main drawbacks e.g. of (Train\u201919) is the fact that they train on data generated from linear 3DMM. This is indeed the case, but it does not seem like here the authors fully overcome this issue: they do have additional weakly-supervised data, but they still strongly rely on linear 3DMM supervision (p6, \u201cpairwise shape loss\u201d, \u201cadversarial loss\u201d), and do not seem to provide experimental evidence that the model will work without it.\n* In particular, the \u201cadversarial training\u201d actually corresponds to learning the distribution of the linear 3DMM. Would it not mean that ultimately the model will be limited to learning only linear ? Could you please elaborate on this?\n* p3: \u201callows ene-to-end \u2026 training\u201d\n* p3: \u201cframework to exact \u2026 representations\u201c.\n* p8: \u201cevaluation matric\u201d\n\n\n\n"}