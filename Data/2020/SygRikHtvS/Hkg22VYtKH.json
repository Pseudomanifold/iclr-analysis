{"rating": "3: Weak Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This paper proposes a novel extension to SGD/incremental gradient methods called CRAIG. The algorithm selects a subset of datapoints to approximate the training loss at the beginning of each epoch in order to reduce the total amount of time necessary to solve the empirical risk minimization problem. In particular, the algorithm formulates a submodular optimization problem based on the intuition that the gradient of the problem on the selected subset approximates the gradient of the true training loss up to some tolerance. Each datapoint in the subset is a medoid and assigned a weight corresponding to the number of datapoints in the full set that are assigned to that particular datapoint. A greedy algorithm is employed to approximately solve the subproblem. Theory is proven based on based on an incremental subgradient method with errors. Experiments demonstrate significant savings in time for training both logistic regression and small neural networks.\n\nStrengths:\n\nThe proposed idea is novel and intriguing, utilizing tools from combinatorial optimization to select an appropriate subset for approximating the training loss. Based on the experiments provided in the paper, it does appear to yield a significant speedup in training time. It is interesting to observe how the order of the datapoints matter significantly for training, and that CRAIG is also able to naturally define a good ordering of the datapoints for SG training. This is strong algorithmic work.\n\nWeaknesses:\n\nSome questions I had about the work:\n\n- How well does one have to approximate $d_{ij}$ in order for the method to be effective? The authors provide an approach to approximate this for both logistic regression and neural networks. How does one guarantee that one is obtaining the maximum over $x in \\mathcal{X}$ for neural networks via backpropagating only on the last layer? Does taking this maximum matter?\n- How does one choose $\\epsilon$? Is this related to how $d_{ij}$\u2019s are approximated?\n- If one were to consider an algorithm that samples points from this new distribution over the data given by CRAIG, if one were to include the weight $\\gamma_j$ into the algorithm, would the sample gradient be unbiased? What if one were to simply use $\\gamma_j$ to weight that particular sample in the new distribution?\n- In machine learning, the empirical risk (finite-sum) minimization problem is an approximation to the true expected risk minimization problem. What is the effect of CRAIG on the expected risk? Is there any deterioration in generalization performance?\n- In page 4, what does the $\\min_{S \\subseteq V}$ refer to? Should the equation be interpreted as with the set $S$ fixed or not?\n- Theorems 1 and 2 are stated a bit non-rigorously. Are these theorems for fixed $k$? What does it mean for these bounds that $k \\rightarrow \\infty$?\n- In Theorems 1 and 2, what is the bound on the steplength in order to obtain the convergence result for $\\tau = 0$?\n- In Theorem 1 for $0 < \\tau < 1$, why does one obtain a result where $\\|x_k \u2013 x_*\\|^2 \\leq 2 \\epsilon R / \\mu$, why is the distance to the solution bounded by a constant? What if one were to initialize $x_0$ to be such that $\\|x_0 \u2013 x_*\\|^2 > 2 \\epsilon R / \\mu$? (Similar for Theorem 2.)\n- In the experiments, how is the steplength and other hyperparameters tuned? Are multiple trials run? \n- Is $\\epsilon$ used to determine the subset or is it based on a predetermined subset size?\n- How do the final test losses compare between CRAIG and the original algorithms?\n- How do the relative distances (rather than the absolute distance) to the solution behave?\n- How does CRAIG perform over multiple epochs? How does the algorithm transition when the subset is changed (as in neural networks)?\n- Why does CovType appear more stable with the shuffled version over the other datasets? Is the stability related to the distribution of the weights $\\gamma_j$?\n\nSome grammatical errors/typos/formatting issues:\n\n- Equation (9) needs more space between the $\\forall x, i, j$ and the rest of the equation.\n- What is $\\Delta$ on page 5? Is it supposed to be $F$?\n- On page 8, And should not be capitalized.\n- Page 14, prove not proof\n- Page 14, subtracting not subtracking\n- Page 16, cycle not cycke\n\nOverall, although I like the ideas in the paper, the paper still needs some significant amount of refining in terms of both writing and theory, as well as some additional experiments to be convincing. If the comments I made above were addressed, I would be open to changing my decision. "}