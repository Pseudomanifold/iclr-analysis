{"experience_assessment": "I have published in this field for several years.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "The paper presents approaches for combining neural network (NN) with non-NN models to predict behavior of complex physical systems.  \nI found this paper very hard to read, with a lot of details and key pieces of information missing or vaguely stated.  Following are some specific instances in no particular order:\na) From the results it seems that often approaches using \u2018cyclic-boost\u2019 perform the best.  However the description of cyclic boost in Section 3.3 lacks any precise description of what the cyclic approach does.  For instance, the NN that predicts the inputs from model outputs, how is that used and under what objective is that learnt?\nb) The main claim of the paper is that combining physics models with NNs is better than NNs alone, esp. when tested on \u2018extrapolative data\u2019.  However, if cyclic-boost is the best approach, the paper should include results with cyclic-boost-RNN combination, these do not seem to be there to assess value add of the physics models in the best performing system.\nc) Section 3.2 states a parallel ensemble of NN and non-NN models has the advantage of finding \u2018global optimum\u2019 \u2026 this is a strong statement and needs to be demonstrated.\nd) The description of new loss function in Section 4 is unclear.  For instance, what is \u2019n\u2019 in (7)?\ne) In Section 3.1 I\u2019m assuming that \u2018h_t\u2019 denotes the model being trained in iteration \u2019t\u2019, and some of these are NN whereas others are domain models?"}