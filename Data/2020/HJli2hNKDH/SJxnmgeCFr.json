{"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "Review:\n\nThis paper considers the problem of overfitting in RL through a specific model of overfitting, namely one where noise is introduced in the observation space, independently of the controllable dynamics.  The paper provides both theoretical and empirical insights into the various manifestations of overfitting in this class of domains.\n\nA strength of this paper is to deepen our understanding of the phenomenon of overfitting in RL.  To get a deep understanding of hard problems it is worthwhile to look at sub-classes of problems, and as such the identification of the observational overfitting setting is interesting.  The paper provides insightful findings such as:\n-\tExplicit separation of f and g_theta.\n-\tTheoretical properties of generalization for the specific case of LQR and linear policies.\nThere are also several empirical results, on three contrasting domains which illustrates various aspects of the interaction between parameterization vs generalization.\n\nBut overall, though I read the paper in detail, and am knowledgeable of the topic, I am still struggling with extracting very specific new findings from this work.  Here are a few examples:\np.6:  \u201cWe observe empirically that the underlying state dynamics has a significant effect on generalization performance as the policy nontrivially increased test performance\u201d ->  I see where you draw this analysis from the results.  But is this finding new or surprising?  I would have been very comfortable saying (without your results) that the underlying state dynamics can have a significant effect on generalization performance.\np.6: \u201cThis suggests that the Rademacher complexity and the weight perturbation bound for rewards vary highly for different environments.\u201d  -> Again, how is this new knowledge?\np.7: \u201cthis also suggests that the RL generalization quality of a convolutional architecture is not limited to real world data\u201d -> Same question, what new knowledge have we gained?\n\nPerhaps the key message is that \u201cthere are generalization benefits to overparameterization\u201d and that \u201cimplicit generalization\u201d plays a key role in controlling this?   If that is the main message, than it is somewhat obfuscated by all the material on LQR, which doesn\u2019t really go in this direction (p.4: \u201cWe being with a theorem which implies that a high dimensional observational space directly contributes to overfitting\u201d).  I must say I found most of the material in 3.1 to distrct from the main message \u2013 but perhaps it is because I am not very interested in the LQR setting, and did not understand how the findings there supported those in latter sections.\n\nOverall, I would say the paper suffers from some clarity issues.  There are some minor typos, then some key terms of are not sufficiently explained/defined (e.g. g_\\theta in Sec.2.2 is said to project \u201cthe latent data to unimportant features\u201d, but then there is discussion of \u201cin settings where $g$ does matter\u201d \u2013 I\u2019m confused.)   It\u2019s not clear whether Thm 3.1 is new, or adaptation of existing results.  More broadly, I found Sec.3.1 difficult to follow. The last paragraph of Sec.4 seems superfluous.   I would recommend some good editing throughout.\n\nAnother concern with the work is the fact that several aspects of RL are ignored (e.g. exploration, entropy, \\gamma, noise, stochastic gradients, etc. \u2013 as per p.4), yet are known to have an effect on overfitting, perhaps much more than the depth and width of the neural network.  If that\u2019s the case, it is perhaps dangerous to ignore them in the analysis; it is not described in the paper, for the domains studied in the empirical results, whether this is the case or not.  As a result, it\u2019s not clear how far the current analysis carries.  I\u2019m also not clear on the analysis at bottom p.7 \u201cIMPALA-LARGE (\u2026) memorizes less than IMPA due its inherent inductive bias\u201d -> Seems to me IMPALA-LARGE might simply be in underfitting regime.\n\n\n"}