{"rating": "1: Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I did not assess the experiments.", "title": "Official Blind Review #5", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review": "The paper presents three contributions: (a) the observation that there\u2019s train-to-test leakage in many graph classification datasets (under isomorphism equivalence), (b) what appears to be a theoretically motivated way of improving scores on such datasets, by focusing on solving the examples that are isomorphic with training instances, and (c) a recommendation to remove such leakage from test sets. I don\u2019t think the paper meets the ICLR bar. While (a) is very interesting, and an important contribution, (b) and (c) are contradictory. The recommendation (c) is a bit of a no-brainer, and Property 6.1 and Theorem 6.1, providing the substance of (b), are near-trivial. \n\nMissing reference: Bordes et al. (2013) and Toutanova et al. (2015) show there\u2019s train-to-test leakage (under isomorphism equivalence) in the FB15K dataset. "}