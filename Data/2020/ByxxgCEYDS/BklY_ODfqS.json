{"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This paper presents an inductive matrix completion model using graph neural networks. The proposed method assumes the rating between a user-item pair is determined by this pair's surrounding sub-graph via a neural network. It claims to be an inductive model and don't need any side information as it only uses the surrounding sub-graph structure to give predictions. The experiments also show the promising results on matrix completion tasks, sparse rating matrix cases and transfer learning tasks\n\nThe paper is well written and easy to follow. I think the \"cold-start\" setting this method is mainly focusing on is worth exploring. In this setting, new users have given a few ratings but the quality of their side information is still low. It seems to me that this setting is common in real case. For example, newly registered Netflix users may quickly watch some videos without completing their profile information. However, when the \"new\" users have given some ratings, we can re-train a traditional MC model including the new ratings. But I believe the proposed method of this paper will be useful when re-training cannot be done very frequently. \n\nI have the following concerns or questions.\n\n1. The paper claims the proposed method doesn't need any side information. However, it seems that the side information can be integrated into the model such as concatenating with the one-hot encoding. Have you tried to use the side information for IGMC?\n\n2. The claims in Section 4 don't make much sense to me. For example, it doesn't seem to me that GC-MC can't distinguish Figure (a) and (b) because GC-MC will take the whole graph into consideration. Also, why will node-based approaches push all nodes to have similar embeddings with multiple layers? Could you give some experimental verifications? \n\n3. It's unclear to me how Eq. (6) helps the performance. It will be better to compare a version without using L_{ARR}. Moreover, I believe Eq. (6) can be designed better. \n\n4. GC-MC uses bilinear decoder to give probability predictions for different ratings. Is there any particular reason why you choose squared loss as in Eq. (5) instead of a bilinear decoder? \n\n5. I have a big concern for the scalability. If we want to make recommendations for a user from a million movies, the proposed method seems to need to compute Eq. (4) for one million times. Is there any approximate way to speedup it? \n\nOverall, I think the proposed method is interesting and the experimental results are impressive. \n"}