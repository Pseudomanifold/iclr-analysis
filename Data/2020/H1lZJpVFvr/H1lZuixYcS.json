{"rating": "8: Accept", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "The paper is interested in robustness w.r.t. adversarial exemples. \n\nThe authors note that:\n* features reflecting the global structure are more robust wrt adversarial perturbations, but generalize less;\n* features reflecting the local structure generalize well, but are less robust wrt adversarial perturbations. \nIn hindsight, these claims are intuitive: adversarial perturbations and unseen shape variations are of the same flavor; one should resist to both or handle both, with the difference that the latter is bound to occur (and should be handled) and the former is undesired (and should be resisted). \n\nThe goal thus becomes to define local features that are robust. \n\nThe proposed approach is based on \n* enforcing the invariance of the intermediate representation through shuffling the blocks of the training images; \n* building normal adversarial images x' and deriving the block shuffling RBS such that the x' and RBS(x') are most similar w.r.t. the logit layer\n* adding these RBS(x') to the training set;\n\nThe idea is nice; the experiments are well conducted and convincing (except for the addition of uniform noise, which is unrealistic; you might consider instead systematic noise mimicking a change of light);\nI'd like more details about:\n* The computational cost of line 7 in algo (deriving the best RBS).\n\nYou might want to discuss the relationship between the proposed approach and the multiple instance setting (as if the image was a bunch of patches). "}