{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "This paper claims that learning prior from the data could achieve superior performance than using a standard unit Gaussian prior. Experimental results further show that the proposed method could achieve a lower or comparable negative log-likelihood compared to other VAE variants using a complex hierarchical architecture.\n\nI have the following concerns about the paper:\n\nIt is widely accepted that the prior serves as the regularization for the Bayesian inference. Using a data-dependent prior is promising to derive a lower NNL than a data-independent prior. However, it would easily lead to an overfitting model with bad generalization, especially for a noisy dataset. \n\nIt is claimed in the abstract and conclusion that one latent variable is used for learning the RealNVP prior while the authors use the words \"shallow\" (refers to few latent variables) in the experiments. So how many latent variables are used in the experiment?\n\nIt is listed in the related work that \"Huang et al. (2017) applied RealNVP (Dinh et al., 2017) to learn the prior\", which means the idea using the learned RealNVP prior is not a new idea. Therefore, what is the contribution of this paper? A detailed discussion is needed to elaborate on the differences from previous methods using a prior learned from the data.\n\nThe equation of the aggregated posterior in page 2 after Eq.4 is wrong. The aggregated posterior should be the integration over x instead of z.\n\nThe drawn conclusion \"using both RealNVP posterior and prior shows no significant advantage over using RealNVP prior only, although the total flow depth of the former variant is twice as large as the latter one\" is quite unprofessional. Only one experiment set was conducted with k=20.  One obvious reason is that the current setting with k=20 makes that the model over-parameterized. More comparisons are needed for smaller k. \n\nAs claimed in the paper that the clipping would be a navie method to promote overlapping among the posterior. A comparison with a navie baseline using clipping is needed before drawing a conclusion that the learned RealNVP prior is the reason for enhancing the overlapping.\n\nIs the likelihood function p(x|z) a Bernoulli or Gaussian?\n\n\"Although BIVA has a much lower NLL on StaticMNIST, in contrast to our paper, the BIVA paper (Maal\u00f8e et al., 2019) ...... attributed to having fewer training data\". The author should confirm with the authors instead of giving a conjecture in a scientific paper. \n"}