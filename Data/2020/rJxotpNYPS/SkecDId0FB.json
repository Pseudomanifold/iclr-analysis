{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This work proposes to solve domain generalization problem in a Bayesian way. The idea is relatively simple: use three hidden variables to encode the domain-related, label-related and the residual information from the original signal. \n\nSome questions:\n-\tMy major concern is the intuition for the proposed algorithm. Though the author uses z_d, z_x and z_y to encode different information from x, it is unclear why they are disentangled. It is also possible that all of them share the same information. In other words, why Figure 2 can be derived from this setting is not well explained. I am also confused on why the model can generalize to unseen target. Only using the learned encoder/decoder from training is hard to generalize.\n-\tFor Figure 2, the first column shows z_d. As a common sense, 30 and 45 degree should be more similar than 30 and 60. However, it seems that the cluster center between 30 and 60 is closer than 30 and 45. Is there any justification? My further concern is whether z_d is meaningful at all. What does z_d look like when applying the model on the unseen testing domain?  (Figure 6 should plot in the context with training domains.)\n-\t A single k-means method can cluster on rotated MNIST by labels. So I think this property should be kept in the feature without any supervised information. However, z_d seems to remove all label information away. I\u2019m not sure why this can happen.\n-\t(Minor) The datasets used for comparison are not discriminative. Maybe the encoder structure is more important than the domain generalization method itself. More challenging datasets are expected. \n\nI would like to improve my score if the author can give a reasonable intuition on why the model can generalize on new domains.\n"}