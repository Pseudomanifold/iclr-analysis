{"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "=== Summary ===\n\nThe authors propose a new abstractive dialog summarization dataset and task based on the MultiWOZ dataset. Unlike previous work which targets very short descriptions of dialog transcripts (e.g. 'industrial designer presentation'), this paper looks to generate long descriptions of the entire dialog using the prompts in the MultiWOZ task. The authors also extend the pointer generator network of See et al.  (2018) to use speaker, semantic slot and domain information.  They show that this new model (SPNet) outperforms the baseline on existing automatic metrics, on a new metric tuned to measure recall on slots (dubbed CIC), and a thorough human evaluation.\n\n=== Decision ===\n\nThe task of abstractive dialog summarization is well motivated and the field sorely needs new datasets to make progress on this task.  This paper is well written and executed, but unfortunately, I lean towards rejecting this paper because of a fundamental flaw in the nature of the proposed dataset that limits its applicability to the task of abstractive dialog summarization (more below).\n\nMy key concern is that the references in the dataset are generated from a small number of templates (Budzianowski et. al ,2018), which suggests this task is mostly one of slot detection and less about summarization.  The significant impact of including semantic slot information seems to be strong evidence this is the case. It is possible to rebut this concern with an analysis of how the generated summaries differ from the reference summaries. For example, Table 2 shows that sometimes the ordering of arguments is swapped: how often does this sort of behavior occur and how often do models identify information not in the reference?\n"}