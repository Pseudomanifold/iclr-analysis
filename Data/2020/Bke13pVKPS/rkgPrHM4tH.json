{"rating": "3: Weak Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "The authors present a framework to perform meta-learning on the loss used for\ntraining. They introduce the Baikal loss, obtained using the MNIST dataset, and\nBaikalCMA where the coefficients have been tuned. The evaluation of these loss\nfunctions is performed on the MNIST and CIFAR-10, and according to the results\nthey converge faster, towards lower test error and need fewer samples to obtain\nresults similar to the cross-entropy loss.\n\nThe claims are clearly stated and the framework is detailed, the experiments\ncover all the potential benefits of the Baikal loss. However it seems that some\npotentially critical points have been omitted. The cross-entropy loss is well\nknown to be beneficial in dataset with severe class imbalance. The two datasets\nused for evaluation are perfectly balanced, it might beneficial to see how it\nperforms in the unbalanced case.\n\nI have a couple of concerns about the method. First about step \"(1) loss\nfunction discovery\": The initial population starts with trees of depth at most\n2, and the final solution(Baikal) has either 2 or 3 (depending on which\ndefinition of depth is chosen). It is unclear that the genetic optimization is\nsuperior to simply choosing random loss functions. I think it would be relevant\nto add a figure that shows how the fitness of the leader of each generation\nevolves over time.\n\nThe second step \"(2) coefficient optimization\", while objectively generating a\nloss function that was superior on the metrics evaluated, raised some\nquestions. In equation (2) the factor \"1.5352\" seems to be equivalent to adding\na constant to the loss, which should not impact optimization. Also the factor\n\"2.7279\" seems to be equivalent to a change in learning rate. This may be an\nindication that the learning rate search was not done thoroughly. It would be\nbeneficial to clarify when it is happening: a) For each individual of the\npopulation during step (1), b) before performing CMA, c) after CMA. Also: Was\nlearning rate search was performed on the network trained with Cross-Entropy? It\nwas not entirely clear from the experiment details in Appendix A.2.1.\n\nAbout the Baikal loss itself, I fear that it could produce models that have very\npoor calibration, it might be nice to evaluate that (even if it is only in\nthe appendix).\n\n\nWhile the paper does a great job at presenting the problem and its applications\nand propose a framework that generated a loss that can transfer to other\ndatasets without any tuning required. I think it lacks a more thorough\nevaluation and description of the dynamics observed during the genetic\nevolution, and the performance of the Baikal loss on other datasets (my quick\nexperients with it on ImageNet diverged I did not have the time necessary to\ntune the hyper-parameters).\n\nMinor remarks:\n\nThere might be a slight omission in section 3.1: according to Figure 1, exp(x)\nis one of the potential unary operators explored by the GLO framework. However\nit is not present it the list of operators. Could you clarify this?\n\nTo the best of my knowledge, in the machine learning literature, it seems that\nthe letter x is used to denote the prediction and y for the ground truth. The\nfact that this paper used the opposite convention confused me the first time I\nread it.\n"}