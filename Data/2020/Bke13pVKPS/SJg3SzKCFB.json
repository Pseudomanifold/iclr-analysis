{"experience_assessment": "I have published in this field for several years.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "*Summary*\nThe authors propose using evolutionary computation (EC) to perform meta learning over the set of symbolic expressions for loss functions. It's a compelling idea that is well-motivated. They find that applying their EC method to mnist yields an interesting loss function that they name the 'Baikal loss.' Much of the paper is devoted to analyzing the properties and performance of the Baikal loss. \n\n*Overall Assessment*\nThe paper's idea is very interesting. However, there are some important drawbacks of this work. These should be fixed and the paper should be resubmitted to a different conference soon.\n1) The experiments focus almost entirely on the Baikal loss (a particular loss function found once when running EC on mnist), and do not analyze the overall behavior of EC for loss functions. Does EC consistently converge to the same loss, or do different ones emerge different times you run it? What happens if you optimize convergence speed vs. generalization accuracy with EC? How do these loss functions differ?\n2) The experiments are largely on mnist, with a small study showing that the Baikal loss can be applied to cifar-10. It would be good to show that loss functions meta-learned on mnist generalize to larger-scale problems than cifar. \n\n*Comments*\nI was surprised when you optimized in fig 3 for convergence speed, rather than final accuracy of something that runs for a while. Why should our goal be to find loss functions that lead to fast optimization, instead of loss functions that lead to models that generalize best? If these are two different goals, then you should have two sets of experiments analyzing how GLO can find interesting (and perhaps different) loss functions for each.\n\nMnist is possible to get basically 100% accuracy. This means that the loss will only be evaluated in certain regimes of its inputs. What happens when you transfer this to problems where the best achievable accuracy is something like 60% for binary classification?\n\nYou should cite the Focal loss as another alternative to the cross entropy loss. Is the focal loss achievable in your particular grammar over loss functions? You should also cite label smoothing as an additional way to achieve a very similar implicit regularization effect as the Baikal loss.\n\nYou only analyze one loss function that came from your EC. What if you run it multiple times? Do you find different formulas? How do these perform? The beginning of the paper is very focused on EC, but then you transition suddenly to only discussing the Baikal loss. Can you present experiments demonstrating, for example, how the EC performance varies with the number of steps, with different ways to define the search space, etc?\n"}