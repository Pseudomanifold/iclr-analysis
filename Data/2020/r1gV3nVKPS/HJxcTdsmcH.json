{"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper was extremely hard to read or comprehend. It\u2019s riddled with typos, inaccurate notations and undefined variables (see below for a sampling). The authors will need to significantly polish and improve the presentation of the paper. \n\nAfter a few forward and backward passes through the paper, I was able to gather the following high level ideas about the paper:\n(1) This paper is somewhat related to the Defferard et. al, 2016 in that the authors want to define a propagation filter for graph neural networks.\n2) This proposed filter known as \u201cballistic filter\u201d should have the property of allowing fast diffusion through the network. \n(3) The authors claim that the ballistic kernel diffuses @ O(k) as compared to O(\\sqrt k) when compared to traditional GCNs, where k is the number of propagation steps.\n(4) The authors additionally claim that their approach needs one-third the number of parameters.\n(5) The authors provide some plots to visualize the linear diffusion rate of their proposed filter.\n\n--- Issues and clarifications ---\n- Sec 3, Eq 1 seems to have been taken from Eq 1 in Defferard et. al, however there\u2019s no reference to it and the terms g, U, etc. are not defined.\n - Sec 4, Algo 1 contains the main core of the proposed algorithm, but it\u2019s only defined for the 2D grid case. The notation therein is extremely unclear. What is H_space, H_c? How does one sample \\hat{O}_coin.? The net result is that algorithm is undefined. Without a clear definition of the algorithm, it\u2019s completely unclear what the proposed method does.\n - Sec 4.2 is completely unparseable. What is problem setting? What is the metric? How have the baselines been implemented? How has data been split for training/testing?\n - Section 5 mentions that one-third params are used to get 97% but no details are provided as to how less params are consumed.\n - How is figure 7 generated?\n - Sec 8, feel totally unrelated to the paper. There are a whole bunch of random, unmotivated diffusion equations  Eq 6, mentions \u201c.. \\hat{g}(f) decreases as f increases and thus can be seen as a low pass filter\u2026\u201d . This is not true from the formula.\n \n\n --- A sampling of typos ---\nSec 4.1, .. consisits \u2026\nSec 5 \u201cREVISIT\u201d -> \u201cREVISITING\u201d\nFigure 6, text, \u201ccassical\u201d\nSec 6.2 title, \u201cSUMMAY\u201d\nSec 8  \u201caggreated\u201d\nSec 8  t=\\-tau to -\\tau\nSeveral typos with Hardmard, Hadmard instead of Hadamard.\n\nOverall, the major criticisms of this paper:\n - The proposed algorithm is not clear. \n - The authors need much more experimentation to bolster their claims in the paper. It\u2019s completely unclear if fast diffusion even if it were possible will help GNNs perform better on a diverse set of tasks.\n - The paper needs a lot more polish and proof reading to make this paper presentable.\n"}