{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This paper adds to a large body of research on implicit regularization:\nin the context of deep networks, that, when SGD with a certain step\nsize or batch size is used, from among parameter vectors that fit\nthe data equally well, some are much more likely to be chosen than\nothers.  This paper attacks this question through the lens of\nloss functions: when SGD is applied to the usual softmax loss\nwith a given learning rate, how does the choice of learning\nrate effect how rapidly other loss functions are reduced?  They\npay special attention to a loss function that they call Gcdf,\nwhich is motivated by \"wide minima\" considerations.  In particular,\nfor the Gcdf to be small, not only must training examples be\nclassified correctly, but randomly perturbing the weights in\nthe last layer should not change this correct prediction.\n\nI am convinced that Figures 6 and 12 of this paper show\nthat optimization of the softmax with a larger step size\nimplicitly optimizes a loss function that rewards robustness\nto a greater extent than when a small step size is used.\nI find this interesting.\n\nThe authors do a nice job of summarizing a lot of related work.\n\nThe Gcdf loss is similar to the ramp loss used in [1]\n(see Section 3.1) and elsewhere, including to analyze\ngeneralization in deep learning.  It is also like the\npotential function optimized by RobustBoost\n(see (4) of [2]) -- the RobustBoost loss function does\nnot scale by the norm of x, but since it is an ensemble\nmethod, the role of x is played by the predictions of\nmembers of the ensemble, which have a fixed scale.\n\nI assume that, when they evaluate the Gcdf loss for a deep\nnetwork, they normalize by the norm of the last hidden\nlayer.  If this is true, it only captures \"wide minima\"\nin the sense of being robust with respect to perturbations\nof the output layer.  (They seem to acknowledge this point\nin their paper.)\n\nThe results in the paper are not described in enough\ndetail to be reproduced.  For example, I don't see\nwhere they specify the architecture of the network\nthat they used in Section 4.\n\nThe experiments are limited and narrow in scope.\n\nIn Figures 2 and 3 I don't see that they have adequately controlled\nfor the effect of the learning rate on how fast the explicitly\nminimized loss is reduced.  Part of the effect observed is simply\nthat, when a small learning rate is used, after a given number of\nepochs, the weights are just not changed much, so that no loss is\nreduced much.  In Figure 2, I find it strange that they did not plot\nthe values for T=1.\n\nFigure 6 is the most interesting to me.  It seems to show that\ntraining the same loss function with a larger learning rate\neffectively optimizes the gcdf loss that rewards sacrificing\ntraining error to achieve stronger robustness.  \n\nSmall point: the first time I read Appendix A, I thought that the\nresults were not there.  It was only later that I saw the figures with\nthe MNIST results.  It would be helpful if the authors wrote\n\"The results are in Figures 8-12\".\n\nWhile, as I wrote above, I did find Figure 6 interesting, I feel that\nthe increment of this research over the large body of previous work\non this topic is not enough to justify publication in ICLR.\n\n\n\n\n[1] Bartlett, Peter L., Dylan J. Foster, and Matus\nJ. Telgarsky. \"Spectrally-normalized margin bounds for neural\nnetworks.\" Advances in Neural Information Processing Systems. 2017.\n\n[2] https://arxiv.org/pdf/0905.2138.pdf\n"}