{"rating": "1: Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I did not assess the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This paper want to show that minimizing cross-entropy loss will simultaneously minimize Hinge loss with different margins, cross-entropy loss with different temperatures and a newly introduced Gcdf loss with different standard deviations. The main contribution is a new gcdf loss based on Gaussian-perturbed parameters. However, this loss can only be used with linear models. For deep models, the authors suggest that only measure this loss on the top layer of model.\n\nThe motivation is week. Seems most of these loss functions only depend on s_i - s_j, the difference between logits. And the optimization with cross-entropy loss wants to maximize this difference between logits corresponding to true labels and false labels, which is obviously minimize difference loss functions. So I do not feel surprise that optimizing the neural network with cross-entropy loss will minimize other kinds of losses.\n\nThe format is poor. The figures occupy most of the places and thus let me feel the contents of this paper is somewhat weak.\n\nDetailed Comments:\n1. In Sec 3.1, it will be better to mention that y belongs to +1 and -1. Also, in the last sentence in Sec 3.1, the meaning of x is normalized is ambiguous. I guess the authors want to say if x is unit norm?\n2. Will adding the regularization of the feature map norm violate the performance?\n3. What do the authors want to say in Sec 4.3? Does the relation of learning rate and convergence rate of gcdf loss indicate some non-trivial results?\n4. I cannot understand the meaning of Figure 7. Obviously different learning rate may lead to different training process and thus the different solution and different s_i - s_j. But I think this is not related to the different losses. With simple calculation I think we can find all of these losses have some relation with s_i - s_j and thus we can directly say different learning rate lead to different s_i - s_j and there is no need to relate s_i - s_j to these losses.\n\nOverall I find the claims of this paper is somewhat weak. Gcdf loss seems related to some kinds of adversarial robustness that can be individual interest, but the current paper is still far from the standard of publication. Some more interesting and valuable directions can be the theoretically analysis of the equivalence between the objective optimization, e.g. minimizing cross-entropy loss is equivalent to minimizing gcdf loss for example, as well as the empirical comparison between the different losses, like selecting some losses as objective can boost the performance on some aspects."}