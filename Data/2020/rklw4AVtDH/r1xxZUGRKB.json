{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper studies an optimistic variant of AMSGrad algorithm, where an estimate of the future gradient is incorporated into the optimization problem. The main claim is that when we have good enough (distance from the ground truth is small) estimate of the unknown gradient, the proposed algorithm will enjoy lower regret. Theoretical results are provided and experiments are conducted to compare the proposed algorithm with baselines. The idea seems to be not very novel since the optimistic optimization techniques are borrowed directly from the online optimization field, while it is still interesting to see this kind of work and to see its comparison with existing algorithms in experiments. However, the comparison seems to be not fair both in theory and experiments.\n\nIn the second paragraph of Section 2.1, you use $m_t$ to denote an estimate of the loss function. But later (In the third equation) you use $m_t$ to denote the guess of gradient vector. The notation is reloaded without any description, which makes the presentation confusing.\n\nIn addition, at the end of this paragraph, you mentioned that even when $m_t$ is far away from $g_t$, the regret of an optimistic algorithm is just a constant factor of non-optimistic one. This seems not rigorous since it is true only when the divergence of $m_t$ from $g_t$ is in constant order.\n\nCan you explain why in line 8 of Algorithm 2, you use $w_{t-\u00bd}$ to update $w_{t+1}$ instead of $w_{t}$? A discussion about these choices should be added to the description of algorithm.\n\nIn the first equation on page 5, the second term on the R.H.S. of the first equation misses a factor of $1/2$. Moreover, the second equation should be inequality.\n\nIn the comparison of equation (2) and (3), I think it should be pointed out that when the gradient has a sparse structure, the regret of the optimistic-AMSGrad in (2) seems to be worse than that of the original AMSGrad.\n\nThe optimistic algorithm seems to cost more computation in order to estimate the unknown gradient in advance. In the experiment part, you used the last few iterations to estimate the guess of gradient in the next step. But it seems that the comparison with $r=3,5,10$ is not consistent in many plots since I expected a larger $r$ will lead to more accurate estimate.\n\nThe experiment results seem to be not convincing. In particular, in Fig. 1,2 and others, the training loss of AMSGrad is far away from zero, which implies that the algorithm is not fully optimized. Therefore, it is hard to draw any meaningful conclusion from the current experiments.\n\nIn footnote 1, \u201chad been known\u201d -> \u201chad known\u201d\n"}