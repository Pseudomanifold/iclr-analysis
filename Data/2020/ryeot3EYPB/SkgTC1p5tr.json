{"rating": "3: Weak Reject", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This paper addresses the important problem of cross-lingual learning in text classification tasks (in this case: text and sentiment classification). The authors address the realistic setup where labeled data  exists in the source language and only unlabeled data is available in the target language. \n\nWhile the paper addresses a timely problem, there are two main reservations that make me recommend a weak reject:\n\n1. The methods proposed by the authors reflect a standard combination of existing ideas in the literature. I am aware that assessing the novelty of a proposed algorithm is subjective in nature, but I do not see here sufficient novelty that will impact the thinking on these problems.\n\n2. In this context I would like to note that more advanced algorithms that explicitly address language and domain gaps, have been proposed in the literature. One of these (Prettenhofer and Stein, 2010), which applies structural correspondence learning (SCL) to the problem, is mentioned by the authors. Another, which marries SCL with deep learning is:\n\nZiser, Yftah, and Roi Reichart. \"Deep Pivot-Based Modeling for Cross-language Cross-domain Transfer with Minimal Guidance.\" Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing. 2018.\u200f\n\nThe last paper also addresses variants of the problem, such as training a cross-lingual model without knowing the target language at training time.  \n\nThe authors not only skip that work, but they also compare their methods only internally (i.e. to variants of their own methods that do not utilize all of their components). It is true that for one of the tasks they quot the state-of-the-art from a previous paper, but for cross-language sentiment analysis there is no comparison to previous work. The above two papers, and one or two additional papers experiment in the sentiment analysis setup of the existing paper, and should be compared with (particularly the EMNLP 2018 paper which claims sota on this task with a quite large margin).\n\nAn additional comment:\n\nThe appendix of the paper contains major staff that belongs to the main paper. If ablation studies make important observations then, IMO, they should not be external to the paper.\n\n\n"}