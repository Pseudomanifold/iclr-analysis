{"rating": "3: Weak Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper gathers various requirements of the interpretability, and formulates constraints as regularizations in the learning procedure to ensure the interpretability of the model. \n\nStrengths: * The stabilities of several kinds of NN are proven.\n* The requirements of the interpretability is formulated into one unified optimization procedure. Weaknesses: * The clearance of the paper should be improved. How the constraints are modeled as G_l(W_l) is not clearly formulated. The difference between the proposed work and the work of Wang et al., 2019 is not emphasized. \n\n* The definitions about the stabilities is just (local) Lipchitz conditions, which should be clearly stated. \n* In the experiments, it seems that no baseline (that is, no interpretability constraint) evaluation score is represented. And, how the constraints affect each other is not analyzed. \n* There is no analysis about how the unified framework helps to interpret the behavior of the neural network better than previous work. \n"}