{"rating": "3: Weak Reject", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #4", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper establishes a theoretical insight into Temporal Difference (TD) learning for policy evaluation, on the convergence issue with nonlinear function approximation. It proposes that for a so-defined class of \u201chomogeneous\u201d function approximators, the TD learning will be attracted to a \u201cneighborhood\u201d of the optimal solution. While this seems an important work, I am uncomfortable to give an accept decision because the statements of the results can be found inaccurate from place to place. I actually found it is a bit confusing to use this wording (from the paper). For example, with neural networks, there is still approximation error and local minima issue, how could you say that the update is absorbed into a neighborhood of the true solution? And this is claimed in the beginning of Section 3.\n\nTD learning follows a biased estimate of the gradient of the squared expected Bellman error, which\nis minimized by the true value function. The bias is intrinsic to the fact that one cannot obtain more\nthan one independent sample from the environment at any given time. As it turns out, this bias\ncan be seen geometrically as \u201cbending\u201d the gradient flow dynamics and potentially eliminates the\nconvergence guarantees of gradient descent when combined with nonlinear function approximation.\n\u300b\u300b I don\u2019t know what this means. TD diverges with nonlinear FA just because the contraction mapping does not hold any more. \n\nsuch as two timescale algorithms, but these algorithms are not widely used\n>>this argument is a bit weak. \n\nWe prove global convergence to the true value function when the environment is \u201cmore\nreversible\u201d than the function approximator is \u201cpoorly conditioned\u201d.\n>>not clear what this means until here. What is \u201creversible environment\u201d, what does it mean FA is \u201cpoorly conditioned\u201d? Later in Section 2, it was mentioned \u201cMRP\u201d is reversible so that some matrix is symmetric. \n\nSection 2:\n\nEquation 1 uses V^* is a bit inconsistent ( P is used). Why not use V? V^* usually means the optimal value function. I saw your footnote, but remember value function is \u201cassociated\u201d with P. \n\nConvergence to V* immediately follows. \u2013 What convergence? I thought you were talking about stability of the ODE. \n\nthe \u201csemi-gradient\u201d TD(0): do you mean tabular TD(0) is not semi-gradient? Do you think it is gradient? Even in tabular, it is not gradient descent. \n\nV(\\theta)_s: this notation is odd. \n\nit is meant to approximate gradient descent on the squared expected Bellman error:  This is arguable. Actually it is not precise. One can say it is true and others may say it\u2019s not. This is never an established result or acknowledge showing that TD is an approximation to the gradient descent on the mean squared Bellman error.  \n\n\nThe first is when V is linear and the second when the MRP is reversible so that A is symmetric.\n>>this is ambiguous. Do you mean the second case is when V is nonlinear and the MRP is reversible? I am guessing this is what you mean. And it\u2019s true. \n\nSection 2.3: doesn\u2019t carry much value. The example is from the paper cited (Tsitsiklis and Vanroy 1997). Adding the symmetric case for P doesn\u2019t give much value because that\u2019s easily seen to be true. \n\nDefinition 1: \u201chomogeneous\u201d. This is not the usual definition of homogeneous in mathematics. Square function is.  Relu: gradient at 0 exist?\n\n Section 4.2: experiments about modifying the spiral example into symmetric MRP is not very interesting, because symmetry brings obvious convergence guarantee. However, it is good to see the experiment with a variable delta that controls the level of symmetry.  \n\nI think a missing experiment is the showcase for the divergence examples the case of \u201chomogeneous\u201d function, such as the square function and the neural networks (as claimed in the paper, these are \u201chomogenous\u201d functions). How does the behavior that the TD update is absorbed into the \u201cneighborhood\u201d of the true value function? \n\n\n\n\n\n\n\n "}