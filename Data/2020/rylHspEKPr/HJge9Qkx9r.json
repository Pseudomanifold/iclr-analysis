{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "I would like to be able to recommend accepting this paper, but I can't.  It describes two contributions to the community that could be valuable:\n\n1: searcho, a programming language designed for studying program synthesis via search over programs\n2: A method of automatically choosing interesting features for guided program search. \n\nThe paper does not give enough evidence to ascertain the value of either contribution.  There are now a large number of program synthesis works using ML, and a huge literature on program synthesis without ML.   While many of ML works use a DSL as the testbed, surely the authors' feature selection method can be applied in some of these DSLs, allowing comparisons with current art?   On the other hand, many of the ML methods don't require the DSL used in the works that introduce them.  Can searcho + your set of training and test programs distinguish between these methods, and establish a benchmark?  Are there some more realistic tasks/applications that searcho makes reasonable, not readily approached with previous DSLs used for testing these algorithms?   I think this paper could be valuable if it could demonstrate either in what ways the new feature selection algorithm is  an improvement over prior ML methods, or that searcho is valuable as a benchmark or for approaching interesting applications."}