{"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "Summary:\nThe authors first analyze and answer the question: What training examples should be focused and how large the emphasis spread should be? Then, they proposed the gradient rescaling framework serving as emphasis regularization. \n\nStrengths:\n1. The paper is well organized except the reference citation (read difficultly)\n2. The proposed method is very simple and effective. \n3. Experiments show the improvements over SOTA. \n\nWeakness:\n1. The experiments lack the recent important baseline \"symmetric cross entropy for robust learning with noisy labels, ICCV2019\", which are the current SOTA. Maybe the author should check the above paper and show the results.  \n2. The experiments are only conducted on symmetric noise. Actually, asymmetric noise is also important. The author should conduct at least some experiments on asymmetric noise. "}