{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "Summary\nThis paper presents Gradient Rescaling (GR) for robust learning to combat label noise. They propose to treat each data sample with different significance scores: some samples are important to learning, and some examples are insignificant (or even detrimental) to learning. So they desire to weight each samples according to their significance. They propose the notion of emphasis focus (When learning, whether we should put emphasis on learning \u201chard\u201d examples or \u201ceasy\u201d examples) and emphasis spread (the variance of these significance weights). The authors propose that this \u201cdifficulty\u201d of samples are proportional to their network output logit values.\nThe authors examine the analytical forms of the gradients of popular loss functions such as Categorical Cross Entropy, Mean Absolute Error and Generalized Cross Entropy. They find that the formulas for the gradient are of similar family with varying hyperparameters. Authors claim that tweaking these hyperparameters result in tuning the emphasis focus and spread.\nThe authors conduct Experiments on CIFAR10, CIFAR100 with simulated symmetric noise. Also, they conduct experiments on real-world noisy datasets: Clothing 1M dataset and MARS video dataset. The authors claim that the performance of GR exceeds various baselines.\n\n\nSignificance/Novelty/Clarity\nSignificance: Low-Medium. The performance increase exhibited in the experiments are a bit underwhelming (when considering the fact that benchmarks of most recent noise-robustness algos such as <Lee et al. 2019 ICML> are missing).\nNovelty: Medium. The paper is interesting in the sense that the authors integrated (and allegedly generalized) the gradient formulas for several losses into one family, and tried to integrate and tweak their postulation of  \u201cEmphasis focus\u201d and \u201cemphasis spread\u201d into the framework. However, the theoretical ground and convincing reasoning for their claim seems a bit lackluster.\nClarity: Low. The overall flow of the paper is a bit fuzzy - exhibiting a stream-of-consciousness style flow.\n\n\nPros and Cons in Detail\nPros:\n1.The authors try to unify the analytical forms of the gradients of various loss functions into a single family equipped with hyperparameters that control emphasis focus and spread.\n2.Conducted experiments show that GR achieved increased performance when compared to the baselines.\nCons:\nMy major concern is about tuning newly introduced hyperparameters in practical settings. How can we guarantee to have intact validation set?  Can we get any improvement via GR even with corrupted validation set for tuning hyperparameters? \n1. The arguments of the authors are grounded in the premise that \u201cdifficult\u201d samples will exhibit small logit values, and \u201ceasy\u201d samples high logit values.\n2. No justifications (both theoretical and experimental) are provided on the claim that controlling emphasis focus/spread will result in more robust learning. \n3. This algorithm introduces 2 additional hyperparameters that are correlated with each other. This introduces additional labor.\n4. By changing the loss function, the outputs of the network might lose its interpretation as a probability distribution.\n5. No confidence intervals are shown except for the CIFAR-100 experiment.\n6. Experiments are only conducted on vision tasks.\n7. The baseline menagerie also changes when the authors change the target dataset.\n8. Additional benchmarks of most recent noise-robustness algos such as <Lee et al. 2019 ICML> are required.\n\n\nQuestions\n1. Is it always the case that \u201cdifficult\u201d samples exhibit small logit values, and \u201ceasy\u201d samples high logit values?\n2. If not, GR\u2019s emphasis manipulation might result in neglecting samples containing valuable information.\n3. Can GR be used simultaneously with other noise-robust learning methods to further boost the performance?\n4. Technically, GR aims to rescale the gradients of the logits. How will it interact with optimizers  other than SGD such as Adam?\n5. Does GR still work well on small datasets(#points < 5000)?\n\n\nMisc. Comments\nPage 3-> inside L1 norm, no differentiation sign in the denominator.\nAround eq 2 and 4: missing derivative symbol w.r.t. z"}