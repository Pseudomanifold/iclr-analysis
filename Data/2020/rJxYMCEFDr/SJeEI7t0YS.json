{"experience_assessment": "I do not know much about this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper proposed a method to represent data with its second-order information in the deep network, to improve its representation robustness. To obtain this representation, the authors used artificial adversarial examples to obtain the robust representations. Experimental results show that the new representation is more robust against real-world distortions. \n\nHere are more additional comments on the technical details:\n1) The authors proposed a new representation of a datapoint x in equation (2), using the concept of adversarial noise. However, it is still not clear to me how the expression in (2) is derived mathematically. For example, where does the absolute operator in (2) come from? It would be nice if the authors can provide some mathematical derivation or justification of the chose expression, in addition to the empirical evidence.\n\n2) The robust representation is proposed under a discriminative deep network, with predefined class information. Is it possible to extend the work to unsupervised settings (e.g., deep autoencoders), so that the representation robustness is not with respect to a specific definition of class labels?\n\n3) As the authors mentioned in Section 5.3, the computational cost is high for generating such robust representation. Is there any approximation procedures which can be taken to speed up the proposed robust feature representation?"}