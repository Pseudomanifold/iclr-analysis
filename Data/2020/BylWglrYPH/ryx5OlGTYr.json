{"experience_assessment": "I have read many papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This paper addresses an important problem: systematic generalization in neural networks. However, the paper is very confusing and I have some serious concerns about the models and the results presented in sections 3 and 4. Here are the main issues:\n\n1) In section 3, there are only 10x10=100 possible combinations in this composition task. Yet, the paper says \u201cwe randomly sample 1000 such translation pairs, choose three combinations and remove all instances of them from the training data and then exclusively test on unseen pairings of command and modifier.\u201d How can you sample 1000 pairs out of a possible 100 combinations? Also being able to generalize to 3 held-out combinations out of 100 is not very impressive. On the contrary, it is almost trivial.\n\n2) No details are given about the \u201crecurrent net\u201d or the \u201cmulti-layer perceptron\u201d baselines in section 3. What are these models? The fact that they have exactly zero accuracy is a bit suspicious, especially given the almost trivial nature of the task in section 3. Previous works reported perfect or near perfect accuracy with similar baselines in similar tasks (see e.g., Lake & Baroni, 2018).\n\n3) I'm afraid the proposed model in section 3 also doesn\u2019t make sense to me. It is explicitly acknowledged (Appendix B) that y is an M+1-dimensional vector, g is an Nx(M+1) matrix. Then by all accounts, the convolution of these should be an N-dimensional vector. Yet, somehow, h_t+1 in Equation 2 manages to be an NxM matrix. How? Please clarify this. If possible, making the source code available would be very helpful.\n\n4) What is the semantics of x and y in section 3? What exactly are they supposed to be doing? This is not explained in the paper beyond a vague description.\n\n5) Similar problems arise in section 4. The task is not explicitly described in the text. We only learn from Appendix C that it is actually to predict the next symbol. The task description mentions \u201cstrings of length 15, 17, 19, 21, 23 and 24,...\u201d (p. 5). But, the grammar in Fig. 3 can only generate odd length strings, it cannot generate a string of length 24. Is this a typo?\n\n6) Again in section 4, I have no idea how the proposed model is actually supposed to work. The motivation for the model and its description are not clear at all.\n\n7) The model in section 2 is hand-coded. It is not shown that it can actually learn this solution from data. What happens if the sequences are longer or if the rules are different, for example? Then you have to hand-code a completely different architecture.\n\n8) Which brings me to another important issue I have with this paper (and with similar papers): this whole set-up is very misguided in my mind. I think the real problem is not to come up with an architecture that would generalize systematically in a very specific (and usually toy) problem. It is to come up with an architecture that would learn to generalize systematically in a much broader set of problems. The learning aspect in sections 3-4 is a step in the right direction, but there\u2019s no evidence that the models proposed there can learn to generalize in any task other than the very specific tasks they were designed for (if they can actually do that)."}