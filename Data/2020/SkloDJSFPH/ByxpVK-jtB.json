{"rating": "3: Weak Reject", "experience_assessment": "I do not know much about this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "The authors consider the problem of sampling time series.\nTo solve the problem they propose a method that is based on the autoregression model. The novelty here lies in the proposed sampling methods: we start with a sampling of a prior and then try to generate data according to the restored distribution. We learn two functions: signal recovery and confidence prediction.\nThe main hyperparameter of the algorithm $\\varepsilon$ identifies how much samples we accept.\nThe distinctive feature of the algorithm is speed-up for the sample generation process.\n\nWeak reject\n\nThere are a significant number of works on video generation, see e.g. [1, 2], references therein and articles that cite these two articles. The problem setting seems pretty similar. It seems like a good idea to compare to these methods (and it seems that video generation is a very resource-demanding procedure, and they don't use parallel applications similar to proposed in the paper. What is the reason?) Most of the approaches use only one frame to generate video, but it seems that LSTM in these methods will benefit from using of multiple frames as input (and will be able to transfer information in autoregression manner by transferring all they need in a hidden state).\nThe article, in my opinion, will benefit from comparison to these approaches or at least by using some benchmarks from these works to demonstrate feasibility of the considered approach, also it seems that these works are good for demonstration of parallelization capabilities (as in many cases the same idea applies).\n\nNot minor comments:\n1. In Figure 2 (a) it is not clear how the data and prediction were generated. According to the procedure in Figure 1 and text we use the same input for all approaches. However solid lines for different epsilons are different.\n2. The effect of the dependence of recovery of quality for Figure 2 (b) is not explained and is controversial: we get the smallest error for intermediate acceptance ratio, however, there is also a decrease of error if we further increase the gauge threshold (btw the term gauge threshold is new to machine learning community, consider replacement of it)\n3. More simpler examples will benefit the paper, as we'll be able to know more fundamental properties of the proposed approach. \n\n\nMinor technical comments:\n1. s. 3.1. predictor predicts\ncommas in equation (8)\n2. Figure 2: no axis labels for the left plot, use for label \"acceptance ratio\" red color font & for label \"L1 error\" blue color font\n3. Table 1 bracket after l_1 is missing\n4. Maybe $\\sigma$ is not the best designation of confidence, as it can be confused with the variance\n5. Figure 1: some indexes should be not $x_{i + 2}$, but $x_{i + j}$, $x_{i + M}$. Also, some \">\" before \\epsilon should be \"<\"\n6. \"a auto-encoder architecture\" -> \n\"an auto-encoder architecture\"\n\n[1] J. He et al. Probabilistic Video Generation using Holistic Attribute Control. 2018. ECCV\n[2] E. Denton, R.Fergus. Stochastic Video Generation with a Learned Prior. 2018."}