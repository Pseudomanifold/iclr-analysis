{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This paper studies the emergence of compositional language in neural agents. They propose an iterated learning method that consists of three phases: a supervised learning phase for a randomly-initialized speaker and listener, a self-play phase (where both agents are updated together), and a phase where a new dataset is created based on the current speaker\u2019s language. This dataset is then passed on to the next \u2018generation\u2019 of speaker and listener. The paper finds that this procedure, with the right hyperparameters, leads to the emergence of more compositional languages in a simple symbolic referential game.\n\nThe question of how to emerge a compositional language is indeed interesting. This paper does a good job of conducting a careful set of ablations and analyzing the results. In my mind, the main scientific contribution of this work is the empirical verification of the principle \u2018compositional languages are easier to learn\u2019. While this principle is intuitive, it\u2019s good to see it confirmed via experiments. The paper\u2019s description of the \u2018interval of advantage\u2019 --- the range of updates where a compositional language performs better on the task than a non-compositional language --- is insightful to me. \n\nI do have concerns for this paper around utility and novelty. As the paper mentions, it has already been shown that iterated learning procedures give rise to more compositional languages in non-neural models. While there are some things to consider in adapting this to neural networks, to my eye they seem rather straightforward (i.e. tuning the number of updates of the speaker and listener, the values I_a and I_b), contrary to the paper\u2019s assertion.  From a utility perspective, the paper doesn\u2019t go into how this might be practically applied in general to train neural agents to learn compositional languages in more complex environments (where they might be simultaneously speakers and listeners), as they stick to a very simple symbolic referential game. The main contribution of this paper is really: \u201cstudying how neural networks behave when trained in an iterated learning setting in a simple referential game\u201c. I think this is a nice contribution, but the main question for me is whether this is enough for an ICLR acceptance. \n\nMy other concern is around the length of the paper. In my opinion, while the paper is well-written, it\u2019s quite bloated and there is a lot of repetition. I think the paper could easily be condensed to 8 pages and retain the same information. Alternatively, some of the graphs in the Appendix (which are quite nice) could be added to the main paper to give more insight about how neural networks behave in this iterated learning procedure. \n\nFinally, the paper shows that compositional languages generalize better to the held-out validation set. While this is also an intuitive result, it\u2019s nice to have in the paper. I\u2019d encourage the authors to remove the \u2018zero-shot\u2019 terminology though (which usually refers to predictions on new samples outside of the training distribution), and just stick to what is actually being shown, which is improved generalization. \n\nOverall, I like the paper, but due to the concerns mentioned above I think it\u2019s borderline, with a slight lean towards rejection. \n"}