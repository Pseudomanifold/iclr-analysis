{"rating": "1: Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "Summary\n\nThis paper combine GCN with KG methods (quadratic kernel) to predict the class of graph-structured data, e.g. protein structures, chemical compounds, etc.\n\nStrength\n\nThe paper proposes an extension of GCN for graph classification, which is an interesting problem.\n\nWeakness\n\nThe use of GCN for graph classification isn\u2019t well motivated. GCN works well for node classification which is a lot different from graph classification and the paper failed to point out why GCN should help? Paragraph 4 of section 2 provides some previous works that also extend GCN for graph classification but still, the motivation of this work should be clearly stated in the introduction. Furthermore, what\u2019s the intuition for using the quadratic layer? How is it better than DIFFPOOL?\n\nRegarding the experimental results, it would be better to provide more convincing evidence as well as more information about the datasets being used, e.g., size, number of classes. Also, it isn\u2019t clear if the results in table 1 are binary or multi-class? \n\nThe paper somewhat readable, but need serious revision of the flow as well as figures, result tables, etc. For example, it\u2019s not necessary to use up entire of page 4 for figure 1 (which also doesn\u2019t provide much information)\n\nOverall impression suggests that the paper wasn\u2019t completed and should be carefully revised before submitting to another conference.\n"}