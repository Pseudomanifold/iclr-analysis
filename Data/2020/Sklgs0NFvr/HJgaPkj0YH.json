{"experience_assessment": "I have read many papers in this area.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This paper seeks to separate \"causal\" features from ones with spurious correlations in the context of natural language machine learning tasks. The proposed approach is to ask human annotators to alter examples in a minimal way that changes the label. Thereby the humans separate out the causal features (those changed) from the spurious or irrelevant features (those left unchanged).\n\nExperiments show that classifiers trained on the original data perform poorly on the altered data and vice versa, but (unsurprisingly) training on the union of the two datasets results in a classifier that performs well in both cases. Furthermore, training an SVM on the original results in irrelevant attributes (such as movie genre) being weighted, whereas these weights are largely removed when training on the union of the datasets. This suggests that the augmented training data results in weighting the \"right\" features more.\u00a0\n\nOverall, I think this paper should be accepted because it makes several interesting contributions: It proposes an interesting approach, shows intriguing experimental results, and produces an interesting dataset (size ~2k) that may be useful for future testing.\n\nThe main limitation of the paper is that the evidence is largely circumstantial. The method has intuitive appeal and the experimental results are suggestive, but the experiments do not conclusively show that the method achieves something that ordinary machine learning does not.\n\nMy suggestion for a further experiment would be to apply the movie review classifiers to, say, book reviews -- something where the task is fundamentally the same but the context is different. If the classifier trained on the union of the original and altered datasets performs better than a classifier trained on only on dataset, then that is strong evidence that this approach yields better extrapolation.\n"}