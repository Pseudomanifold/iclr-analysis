{"rating": "3: Weak Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I did not assess the experiments.", "title": "Official Blind Review #4", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper studies the problem of completion and instance segmentation of large-scale partial scenes. The problem is interesting and has relevance to multiple domains including graphics, vision, robotics and augmented reality. The proposed method builds on a network architecture presented in a previous paper [1] and modifies the 3D backbone to include the completion head and jointly learn the two tasks.\n\nThe method is evaluated on both real and synthetic datasets. Qualitative and quantitative measures indicate that the paper accomplishes impressive results compared to state-of-the-art approaches. In particular, the comparison against alternative approaches such as completion + instance segmentation and instance segmentation + completion are helpful to appreciate the contribution of the study.\n\nThe paper is well-written and explained thoroughly. However, the authors should consider the following comments to improve the paper.\n\n\nComments:\n\na. The paper achieves significant results by mostly utilizing ideas that appear in earlier works. Specifically, a major portion of the proposed network is the architecture in [1], and the modifications to the network including the loss terms for voxel occupancy prediction have been explored in other papers such as [2,3]. Clarifying this point would help evaluating the contribution of the paper.\n\nb. Anchor-based region proposal networks entail challenges in the training pipeline such as predefining the anchors to enumerate possible positions and scales of the bounding boxes. This feature however is not desirable in large-scale scenes, as it would limit the range of object sizes the network can detect and perform downstream tasks (completion and segmentation). A discussion on mitigating these challenges would be beneficial for the explanation of the method. \n\nc. In the instance segmentation benchmark (http://kaldir.vc.in.tum.de/scannet_benchmark/semantic_instance_3d), there are several methods outperforming [1], the baseline this paper compares against. The experimental evaluation of the method would improve with comparisons against [4,5].\n\n\nOverall, I\u2019m on the border leaning toward a rejection, mainly due to the similarity to [1], and because the innovative part of the paper has been explored in various forms in earlier works including [2,3]. Nevertheless, I am happy to adjust my assessment after reading the response of the authors.\n\n\n[1] 3d-sis: 3d semantic instance segmentation of rgb-d scans, CVPR 2019.\n[2] Learning shape priors for single-view 3d completion and reconstruction, ECCV 2018.\n[3] Learning 3d shape completion from laser scan data with weak supervision, CVPR 2018.\n[4] Learning object bounding boxes for 3d instance segmentation on point clouds, NeurIPS 2019.\n[5] PanopticFusion: Online volumetric semantic mapping at the level of stuff and things, IROS 2019.\n"}