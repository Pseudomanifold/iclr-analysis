{"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "This paper proposes a novel patch sampling method to construct effective mini-batch for training networks based on a triplet loss.\nIn the proposed method, matching pairs of patches are drawn as positive samples stochastically according to the \u201cinformativeness\u201d which is defined by means of the derivatives of loss.\nThe authors provide theoretical justification for the novel criterion as well as the practically useful formulation only dependent on the descriptor distance.\nThe experimental results on the patch matching tasks using several benchmark datasets demonstrate the effectiveness of the proposed method in comparison with the other learning-based descriptors.\n\nThe proposed sampling criterion contributes to effectively training the patch descriptors and I like the simple method that is well founded on the theoretical backgrounds.\nThough, there are some ambiguous points to be clarified by the authors.\n\n* The concept of \u201cclass\u201d is unclear. How is it defined in this framework? Generally speaking, a local patch is not necessarily connected to the object classes but rather related to the lower-level image structures, such as edges and curvatures. Thus, it seems to be difficult to assign/define specific class labels for patches in the framework of learning patch descriptor in contrast to object classification. And, through the theoretical derivation for the method, the class categories seem not to be necessary. Clarify what kind (level) of class is assumed to establish the proposed sampling method. \n\n* The hyper parameter \\lambda in Eq.(13) might be difficult to tune since we don\u2019t have prior knowledge about the loss value. Is it possible to robustly set \\lambda by certain value, say 10, across various datasets and networks?; in the experiment, \\lambda=10 exhibits favorable performance. And, it would be better to show the values of \\alpha in Eq.(12) throughout the training by \\lambda=10.\n\n* In the experiment, is the angle loss Eq.(15) applied to the HardNet? For fair comparison, the network should be trained based on the same loss. In addition, the authors should show the performance results of lambda=0 to clarify the effectiveness of lambda>0.\n\n* Fig.1 is poorly presented in terms both of the coloring (markers) and image quality; it is hard to see even on the screen.\n\n* Show the comparison regarding training time. Although the method contributes to faster convergence, it requires extra computational cost in computing the descriptor distances via forward-pass of the network."}