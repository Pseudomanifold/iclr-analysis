{"rating": "3: Weak Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #4", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "The paper proposes to make two modifications in hard negative mining procedure for descriptor learning:\n - instead of selecting hardest samples in a minibatch it proposes to sample proportionally to distance between descriptors\n - gradient wrt model parameters is weighted inverse proportionally to the distance\nThe authors attempt to analyze the method theoretically and evaluate on two descriptor learning benchmarks, UBC phototour 2011 and HPatches 2017.\n\nI propose reject mainly for the following reasons:\n1) dataset selection and quality of experimental evaluation\n2) the writing (presentation of the results)\n\nRegarding (1), my main concern is on statistical significance of presented experiments. The authors conduct each experiment once and do not take into account variance coming from neural net training. For example, in table 2 all numbers seem to be very close so it is not possible to conclude anything. Same is true for other experiments, one way to improve would be to do 10-fold cross validation or at least train 5 network with different random seed and provide mean +- std of the results.\n\nThen, I think UBC results are not indicative of performance since the dataset is small and very old at this point, so I disagree with the claim that improvement of ~0.1% is of significant margin. Improvement on HPatches seems to be slightly more significant, but it is not clear wether the authors used comparable networks in terms of number of parameters in the network and descriptor size.\n\nRegarding (2), the way the paper is written is very confusing and should be improved. The attempts to have a theoretical derivation of the proposed method are welcome, but should not precede the actual explanation of the method. I suggest to explain clearly the modifications to sampling strategy, and only then relate them to informativeness intuition.\n\nFurther, the improvement over HardNet is not clear. The two proposed modifications are not tested separately. To have a proper ablation study, the authors could sample negatives proportionally to descriptor distance and remove gradient weighting, and vice versa, to sample hardest-in-batch and only add gradient weighting.\n\nI also disagree that hard negative mining is \"widely used in object detection and other vision tasks\" (quoting the authors). It used to be common in metric learning for face recognition, as the authors cite FaceNet 2015, but has been long abandoned in favor of SphereFace-like approaches. Same is true for object detection, where Fast R-CNN and Mask R-CNN without HNM are widely used."}