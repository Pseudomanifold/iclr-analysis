{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "The paper proposes an iterative data augmentation approach based self-generation and filtering with success criteria. The authors justify the algorithm as an EM procedure of maximizing \\log p^*(y|x), where p^*(y|x) \\propto p(y|x) * p(c=1|x,y). They demonstrate that the iterative data augmentation procedure can provide significant gains to SOA models in molecule generation and outperform MLE+RL method in program synthesis datasets.\n\nStrengths:\n- A simple approach that can be added to any seq2seq translation where success metric can be evaluated efficiently\n- Demonstrated results on multiple applications\n\nWeaknesses:\n- The method requires being able to evaluate constraints  \n- The approach is simple and does not seem to present significant novelty over prior methods. Particularly, the approach could be considered as nesting RAML [1] updates with (1) low temperature, (2) self-generated trajectories. \n\nOther comments:\n- Some missing references [1, 2]. [2] also studies molecule generation and proposes approaches similar to RL + MLE. \n\n[1] Norouzi, Mohammad, et al. \"Reward augmented maximum likelihood for neural structured prediction.\" Advances In Neural Information Processing Systems. 2016.\n[2] Jaques, Natasha, et al. \"Sequence tutor: Conservative fine-tuning of sequence generation models with kl-control.\" Proceedings of the 34th International Conference on Machine Learning-Volume 70. JMLR. org, 2017."}