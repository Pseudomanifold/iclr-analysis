{"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "The paper introduces a new concept-based interpretability method that lies in the family of self-interpretable models (i.e. it's not a post-hoc method). Self-interpretability is achieved by a two-stage model: First, a concept-extractor finds the related pieces of consecutive words (excerpts) in a given text that are related to a concept among a set of given concepts (if any), then the model makes its predictions solely based on the presence or absence of concepts (binary).  The most useful part of the algorithm is that there is no need for concept annotations. The work then experimentally shows that their method, although does not outperform a non-self-interpretabile baseline but has better performance and interpretation compared to rival methods.\nThe paper is quite well-written. The introduced method is well-justified and the use of concept-based self-interpretable models is very useful to the field. It is also interesting to see that the performance is comparable to non-self-nterpretable baselines which would make a case for the use of self-interpretable models. I have two main concerns with this work. First, there is the novelty concern. The idea of unsupervised extraction of concepts for interpretability was introduced before (https://arxiv.org/pdf/1902.03129.pdf) and is not discussed by the authors (although the utilized terminology is very similar).  Authors should make a much more comprehensive discussion of what already exists in the concept-based interpretability literature and make the contribution of this work more clear (unsupervised concept extraction for a self-interpretable model instead of post-hoc interpretations). Secondly, although some of the objective experimental results (BeerAdvocate results, to some degree) suggest that the method is indeed capable of discovering meaningful, consistent, and separable concepts on its own, there is not enough discussion of why it actually should be the case. It's very easy to assume the introduced training procedure to extract separable but meaningless concepts(i.e. the excerpts of a concept are separable from that of other concepts and are consistent with each other in the eyes of the network while they are not consistent with a concept in the eye of human rationale; both loss terms will be minimized but there is no human-interpretability. One big issue with the experiments section is the A Posteriori Concept Acc metric as it only measures the separability and consistency of discovered concepts; first of all, it can be high while the extracted concepts are meaningless to humans, secondly, using it as a measure of comparison to rival methods is not quite fair as the introduced method is directly optimizing for this metric. The subjective results are interesting but not convincing. Adding a section for human subject experiments (following the previous work in concept-based interpretability) would make the results section much crisper. It also seems unlikely that all of the discovered concepts follow the desiderata and the fact that this is not mentioned makes it even more difficult to assess the amount of cherry-picking in the mentioned subjective results; there should be a discussion of cases of failure and why it happens. My score will change accordingly as the authors address the raised issues.\n\nA few questions and suggestions:\n\n* It would be more interesting to show subjective results of the model for cases of mistake; does the interpretability make sense when the model's prediction is wrong?\n\n* It seems necessary to discuss how much the results are sensitive to selecting C? If the performance is robust, it would be interesting to see what happens for a large C? Does it discover more fine-grained concepts or most of the additional concepts would be null?\n\n* For the model architecture, why did the authors choose to use the straight-through estimator and not other methods (e.g. concrete layers, ...)\n\n* Some of the figures should be larger (much larger)\n\nThanks again for a well-organized and easy-to-follow paper."}