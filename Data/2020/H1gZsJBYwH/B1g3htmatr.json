{"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "Summary:\n\nThe paper proposes a hybrid weights representation method where the weights of the neural network is split into two portions: a major portion of ternary weights and a minor portion of weights that are represented with different number of bits. The two portions of weights are differentiated by using the previous unused state of a typical ternary neural network since only three states are used out of the four states given 2-bit representation. The experiments are solid based on the selected baseline model on CIFAR-100 and Imagenet dataset.\n\nPros:\n\n\u2022\tThe idea of using the previous unused state in ternary neural network is interesting\n\u2022\tOverall, the paper is well written. The proposed method is presented clearly with proper graph illustration.\nCons:\n\u2022\tThe idea of using mixed bit width for neural network quantization is not new. However, the experiments in the paper only compare with basic quantization method which makes the comparison not fair enough. For example, in ABC-net[1], a few full precision coefficients are used to binarize the network. With 3 bit for both weights and activations, it achieves 61% top 1 classification on ImageNet dataset with ResNet-18 as backbone model. This is around 3% higher than the paper\u2019s proposed method with 2/4 bits for weights and 4 bits for activations. \n\u2022\tIn the paper, it claims that the proposed weight ridge method \u201ccan obtain better accuracy than L2 weights decay\u201d. However, there are no experiments or any theoretical supports for it.\n\u2022\tAfter utilizing the forth state of a ternary neural network, it implies that all four states provided by 2 bit representation are used. Hence, the comparison with a quantized neural network of 2 bits should be given in the experiments also.\n\n[1] Lin, Xiaofan, Cong Zhao, and Wei Pan. \"Towards accurate binary convolutional neural network.\" Advances in Neural Information Processing Systems. 2017.\n"}