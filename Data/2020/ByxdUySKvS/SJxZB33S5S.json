{"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #4", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This paper describes a method to learn data augmentation policies using an adversarial loss. It builds on the AutoAugment method. In AutoAugment, an augmentation policy generator is trained by reinforcement learning. At each iteration, a classifier network is trained from scratch based on the current augmentation policy, and its validation accuracy is used as the reward signal. This is extremely costly because it requires to train a complete network for every training step of the policy generator. Instead, the current paper proposes to train the policy generator and the classifier simultaneously. The policy generator is trained adversarially to find augmentation policies that increase the loss of the classifier. This leads to a significant speedup compared to classic AutoAugment.\n\nThe presentation of the algorithm and the results is very clear. The proposed method yields improved performance compared to AutoAugment at ~1/10 of the computational cost, which is impressive. Although the paper only evaluates on two datasets (CIFAR and ImageNet), the idea is likely applicable very generally. I recommend this paper for publication, but have some comments that should be addressed:\n\nMajor comments:\n- It would be good to evaluate how well the learned policies transfer between datasets and architectures. Adversarial AutoAugment still comes with a significant computational cost compared to hand-crafted augmentation, so transfer of policies would be useful. AutoAugment is transferable by design, so any competing algorithm should evaluate transferability.\n- The authors state that all results are mean of 5 initializations, which is great. Please use these replicates to compute a measure of uncertainty (SEM or confidence interval) and state this with all values in the tables.\n\nMinor comments:\n- Overall, there are many grammatical errors and typos that sometimes require interpretation and reduce clarity. Please proof-read carefully.\n- Abstract sentence \u201c... can simultaneously optimizes\u2026\u201d has grammatical issues.\n- Second sentence of introduction has grammatical issues.\n- Third sentence of intro: \u201cet al.\u201d is used for persons, use \u201cetc.\u201d for things.\n- Contribution section: \u201c...our proposed method outperforms all previous augmentation method.\u201d Please be careful with the breadth of your claims. You do not compare against *all* previous augmentation methods.\n- Figure 4: Please add units and/or refer to Table 5 in the legend.\n"}