{"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "\n= Summary\nThis paper proposes to learn a visual tracking network for an object detection loss as well as the ordinary tracking objective for enhancing the reliability of the tracking network. The main motivation is that, current state-of-the-art models based on the Siamese architecture often blindly predict the center of a search window as target location due to the bias in datasets and training strategies. This issue is alleviated in this paper by introducing an auxiliary task, target detection in the entire image space. The auxiliary task is conducted by another branch on top of the visual feature shared with the tracking branch. By learning to detect object in the entire image space, the shared feature extractor will be trained to capture discriminative and unique appearance features of target.\n\n\n= Decision\nAlthough the main motivation is convincing and the manuscript is well written, I would recommend to reject this submission mainly due to its limited contribution and weakness in experimental analysis. \n\n(1) In the experiments, the practical benefit of adding the auxiliary detection task is demonstrated, but the final scores of the proposed model are clearly below those of current state of the art in terms of both reliability and accuracy. Further, it is not explained why the proposed model is worse than the other models in performance and what can be claimed as an advantage of the proposed method even in this situation. Also, I do not understand why the proposed model is not based on the current state of the art like SiamRPN++ but is built upon a manually designed/low-performance model. \n\n(2) The experiments in Section 5 do not demonstrate the advantage of the proposed model at all. In Figure 6 and 7, the difference between the proposed model and its reduced version without the auxiliary task looks quite subtle, and it is hard to say which one is better than the others. In Figure 8, adding the auxiliary detection task results in even worse tracking performance. \n\n(3) More qualitatively and quantitatively analysis should be done on the other tracking benchmarks and be compared with other tracking models recently proposed too."}