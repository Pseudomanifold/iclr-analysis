{"rating": "3: Weak Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #4", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper studies an important question: how to reduce memory bandwidth requirement in neural network computation and hence reduce the energy footprint. It proposes to use lossy transform coding before sending network output to memory. My concern with the paper is two-fold:\n1) The major technique of transform-domain coding is borrowed from previous work (e.g., Goyal 2001), hence the novelty of the proposed method is in doubt.\n2) The implementation details are not clear. For example, I don't know whether the implementation in section 3.1 is based on CPU or FPGA, and how easily Section 3.1 will be implemented on ASIC. For the experimental results are reported in Section 4, we do not know how much memory and how much cache is used. Will the computation of PCI require a lot of on-device memory? \n\nMore detailed comments:\nSection 1, 2nd paragraph: GPUs are event more popular than FPGAs and ASICs. Can the proposed method be useful for GPU inference?\nSection 1, 3nd paragraph:  The last sentence says \"high interdependence between the feature maps and spatial locations of the compute activations\". However, it is not clear to me how the proposed method takes spatial location into account.\nSection 2: better to review previous work In lossy transform coding\nFigure 1: It seems to me Figure 1 is obvious. What is the novelty?\nSection 4: better to report the details of computing units and memory size. "}