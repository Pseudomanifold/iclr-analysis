{"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The authors propose a function-space based approach to continual learning problems (CL), wherein a learned embedding\n\n    $\\hat{\\mathbf{x}} = \\text{NN}(\\mathbf{x}; \\theta)$\n\nis shared between task-specific GPs s.t.\n\n    $f_{i}(\\mathbf{X}) \\sim \\mathcal{N}(\\mathbf{0}, k_{i}(\\hat{\\mathbf{X}},\\hat{\\mathbf{X}}))$, \n\nwhere the $i$-th task's covariance $k_{i}$ is a defined via standard variational inducing points methods. CL manifests as KL divergences between tasks' variational posteriors $q_{i}$ and their respective priors $p_{i}$. Since the embedding helps define $p_{i}$, its parameters $\\theta$ are regularized to promote sharing.\n\nThe work investigates both practical and theoretical implications of this setup. On the practical side, the authors discuss enhanced 'on-task' inference via hybridization of function- and weight-space based approaches and, subsequently, strategies for optimizing inducing points. Additionally, a novel approach for automatically detect task switching is introduced that exploits the Bayesian aspects of the proposed framework.\n\nOn the theoretical side, points of (personal) interest revolved around differences between weight- and function-space approaches to CL. Here, I think that streamlining the presented argument would go a long ways. Paraphrasing, one of the authors' key insights is that:\n\n  1) CL in weight-spaces is hard, since weights' semantics are moving target that change along with shared parameters.\n  2) CL in function-space is easy, since the functions (i.e. tasks) themselves remain the same.\n\nThis information is provided in the introduction, but (as a relative newcomer to CL) I failed to connect regularization and rehearsal/replay based methods with the aforementioned spaces. It was only upon reading Sect 2.5 that this intuition 'clicked' for me. Hence, I suggest making this observation as obvious and intuitive as possible.\n\nThe provided experiments seem reasonable and do a good job highlighting different facets of the paper. Two additional results would be appreciated:\n\n  a) How well calibrated are FRCL-based classifiers?\n  b) How impactful is the hybrid representation (Sect 2.3) for test-time performance?\n\nGP approximations formulated solely in terms of weighted sums of (finitely many) basis functions typically suffer from degradation of predictive uncertainties. Since one often motivates use of GPs via a desire for well-calibrated uncertainty, (a) seem quite pertinent.\n\n\nNitpicks, Spelling, & Grammar:\n  - Lots of run-on sentences; consider breaking these up.\n  - Introductory modifying phrases are missing commas.\n  - Consider citing other recent works that use NN basis functions in conjunction with Bayesian Linear Regression.\n  - Various missing or superfluous words resulting in some garbled sentences, e.g.:\n      - \"... our approach looks constraining.\"\n      - \"The ability to detect changes based on the above procedure comes from that in\"\n      - \"While the task boundary detection results for Omniglot are less strong, which may due to the smaller batch size (32 for Omniglot, \u2265 100 for the MNIST-versions), resulting a noisier test result.\"\n"}