{"experience_assessment": "I do not know much about this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper presents an offline and online pruning method for CNNs where RL is used for tuning the sparsity.\n\nPruning methods are important for real-time applications of CNNs on low resourced devices, so the paper addresses a genuine need. However, the paper is poorly written and the experimental results are not as convincing.\n\n1) Majority of the description of the models and architecture is written in text and is very difficult to parse, while this could've been avoided by usage of mathematical notations for operations. This is specifically evident for early parts of sec 3 which makes parsing and reading very difficult.\n\n2) It's not clear why the baseline performances in the experimental section are different across different methods. If I understand correctly, all the original non-pruned models should be the same for this experiment to make sense. This is specially important for Tab 2 where the closest competing algorithms (FBS and CGNN). Due to using different baselines, the numbers are not comparable.\n\n3) One thing that is not clear in the text is the computation taken by the runtime pruner architecture. Are these rolled in the estimations on the speedup?"}