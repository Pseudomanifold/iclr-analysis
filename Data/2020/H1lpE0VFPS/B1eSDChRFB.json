{"experience_assessment": "I have published in this field for several years.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "Summary:\n\nThe authors propose to use mixture models for bounding box detection models in order to robustify against occlusion.\nIn practice, they try models which use Gaussian, Multivariate Gaussian, Mixture of Gaussian and Mixture of MVN models and find improved performance compared to deterministic models of bounding boxes in a variety of experiments.\nThe prediction task here is given a region of interest to predict a bounding box consisting of 4 points for the corners of the box. The authors demonstrate usefulness on a variety of datasets.\n\nComments:\nFirst, the proposed method has very little technical depth or complexity and is extremely straightforward. This is actually an advantage of the paper, as it makes it a useful trick for a variety of systems that perform this task, but also increases the burden of empirical evidence for its usefulness. Given that there is no particular technical novelty here apart from the application domain of mixture density networks, the paper has to convince based on sheer empirical evidence.\n\nPros:\nThe model makes sense, as images are fraught with ambiguity and when not having access to a generative model to resolve ambiguities through posterior inference the best a predictor can do is regress to these ambiguities, i.e. the different bounding boxes one might expect at object intersections.\nSuggestion: it would be great if the authors could come up with a toy dataset with ambiguous but known bounding boxes (i.e. overlapping objects with particular poses) to study how well the proposed model recovers those structures. \nReal-world datasets are great, but we have little understanding of what effect exactly is helping the classification here and an additional toy setting would increase the clarity of the modeling ideas.\n\nCons:\nThe authors handle their Gaussian Mixture Models (GMMs) unconventionally.\nIn particular, they consider predictions to be the expectation of the GMM, i.e. the expected mean.\nLet's consider a toy system with two bounding boxes which do not overlap and constitute two modes. The mean over the two boxes could easily cover an area of an image that has no support under either bounding box.\nAs such, predictions with such multimodal and multivariate models have to be made by enumeration and/or sampling from the predictive distribution p(x|I), such that for example K bounding boxes are sampled from a model -for instance the mean of each  component for simplicity or multiple samples from each component- and evaluation is performed over each of the K boxes and then the metrics are averaged. In contrast, the authors average the bounding box and then calculate their metrics. Respectfully, I believe this is statistically unsound use of the model and undermines the empirical value of the experiments.\nOn experiments: it is unclear whether multivariate models and multimodality matter and what their effects are. The authors find that different datasets behave differently, which makes sense if more or less occlusion is present, but unfortunately the problem mentioned above undermines the results here. \nFinally, the authors state that during testing they ignore the covariance structures, which also seems ill-advised as the model is reduced to a deterministic one in that case. It would be interesting to present results contrasting this to samples from the model.\n\nOverall: the authors appear to not sufficiently utilize the structure offered by their potentially multivariate and multimodal observation model appropriately. Instead, they effectively use it as a regularizer for training and just utilize its expectation during testing.\n\nMinor comment:\nThe authors should call their model a 'mixture density network' (Bishop 1994) and cite the relevant paper, as this is a well-described technique for density estimation and the authors apply it to the task at hand.\n\nDecision:\nGiven the simplicity of the model and the potentially broad usecases within the object detection field, I was expecting a more thorough empirical analysis here. The idea is simple but appealing. It, however, requires significantly more empirical depth and analysis to be considered for publication. A good start would be to mitigate the concerns I expressed for the evaluation of the model.\n\n"}