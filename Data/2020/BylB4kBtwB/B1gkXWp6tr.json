{"experience_assessment": "I do not know much about this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This work researches the deep complex-valued neural networks. Specifically, it proposes a new signal extraction mechanism that operates in frequency domain and applies to address the speech separation issue. Also, a function is proposed to explicitly consider both the magnitude and phase information of a signal. Related work on learning representation in frequency domain and speech separation is well introduced. Theoretical analysis is conducted to show the motivation and connection to signal processing. The architecture of the deep neural networks is presented in details, with the elaboration of the complex mask generation. Experimental study is conducted on a benchmark dataset to compare the proposed complex networks with those using real-part values only to demonstrate the improvement. \n\nThe rating is 3: Weak Reject considering that the novelty is limited and the experimental study is weak. \n\n1. The significance of the theoretical analysis in Eq.(1) to Eq.(4) needs to be better explained. Currently, they seem to be some straightforward results in the field of signal processing;\n2. The proposed CSimLoss is interesting. However, its effectiveness seems to be limited as demonstrated in Table 1. It can be found that the CSimLoss in some cases is only comparable (or even inferior) to the L2freq loss;\n3. The mask generation proposed in Section 6 conceptually is largely an attention mechanism that has been widely applied in deep networks; \n4. The experimental comparison in Table 1 is limited, although some improvements have been demonstrated. This work shall also make a comparison with some of the existing methods on speech separation as described in Section 2.2.\n5. It was mentioned in the last paragraph of Section 7 that (Shi et al. 2019) uses different data preparation than this paper. Can this paper use the same data preparation as (Shi et al. 2019) and perform some comparisons?\n6. Why did (Shi et al. 2019) achieve better SDR (12.1 vs. 11.3) than the proposed method using standard setup?\n7. What if the mechanism of mask generation is also applied to Real U-Net? How much improvement can this bring? \n"}