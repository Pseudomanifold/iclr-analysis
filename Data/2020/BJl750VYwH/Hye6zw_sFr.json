{"experience_assessment": "I have published in this field for several years.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "The work presents a matrix factorization (MF) framework for enforcing the effect of historical data when learning user preferences in collaborative filtering settings. The key idea is to augment vector representations of users and items with additional terms related to other interactions from the observation history. The standard inner product between entities is then replaced with its generalized non-linear counterpart. The authors use a non-linear AGMF model that incorporates both user and item profiles in a symmetric way and utilizes smart parametrization to learn the corresponding weights of all involved observations.\n\nEven though I generally like the presented approach, I believe the work misses some key points and should be rejected. Most importantly, the conceptual model design has a limited novelty and is basically reinvented. Likewise, the experiments part lacks comparison with appropriate baselines, which raises concerns on actual performance of the proposed approach.\n\nMain argument:\n\nThe authors claim that most of the existing approaches do not take into account additional interactions data and that the only model that provides such functionality is SVD++. This is not true.\nFirst of all, the SVD++ model itself was not the first one to propose such a design. Similar augmentation was implemented in NSVD model by [Paterek 2007] (a user vector was replaced by a combination of all items in user profile). Even though it was simpler than SVD++ it served as an inspiration for later models.  You could simply write the NSVD model in the form SQQ^T, where Q encodes item embeddings and SQ represents user embeddings (no separate user space was learned). Matrix S serves as the design matrix which is essentially the one-hot encoding (can be \u201cmulti-hot\u201d using the authors\u2019 term). The SVD++ model can be written in similar way as XPQ^T, where X is a new design matrix, which encodes all user interactions and allows to augment standard scalar product with additional terms. The model can be extended further to XP(YQ)^T with the addition of item-side design matrix Y, which now resembles the AGMF approach proposed in the paper at review.\n\nSuch a formulation is used in a number of models, e.g., SVDFeature by [Chen et al. 2011] or LightFM by [Kula 2015]. Even though they are typically used for hybrid systems (to incorporate side information about users and items), they are perfectly suitable for the considered here task as well. Probably, one of the earliest published work that utilizes such a symmetric design is MatchBox by Microsoft [Stern, Herbrich, Graepel 2009] (they use the notion of user and item traits). Finally, the most general framework for the task is presented by the Factorization Machines (FM) proposed by [Rendle 2010], which is widely used in industry as well as in various recsys challenges. This model has many implementations and should be considered as the default baseline for this kind of work. Excluding models like FM or at least LightFM from comparison makes the work incomplete, especially considering that the authors emphasize the importance of taking interactions history into account by comparing AGMF with a simpler GMF model.\n\nRegarding the source code, it\u2019s nice that it has more or less complete state in a sense that\u2019s it\u2019s runnable with almost no modification. I was able to run it on my GTX 1060; however the training was pretty slow. Note, that even simple and fast SVD-based model can be tuned to provide a decent quality of recommendations, see EigenRec model (for example, compared to other popular models in the RecWalk paper by [Nikolakopoulos and Karypis 2019]). I used the scaling trick from EigenRec (see, e.g., https://www.eigentheories.com/blog/to-svd-or-not-to-svd/ for more details on how to do scaling). I was able to get HR=0.713 and NDCG=0.446 on the Movielens dataset with this modified SVD model. Computing of the optimal result (with rank 128) takes only 1.2 seconds on my 4-years old laptop. The comparable level of HR and NDCG was achieved by AGMF only after approximately 3.5 hours of training (each epoch was taking 6-7 minutes and it required around 30 epochs). In fact, the entire hyper-parameter search time for the SVD-based model took less than 4 minutes, which was dominated by the evaluation time not the model computation time (for any set of hyper parameters you need to compute SVD only once for the highest rank value, as the model with lower rank values can be obtained by a simple rank truncation procedure). This raises the concern in an overall practicality of the AGMF approach. The best score is only 2.5% higher than that of SVD and takes more than 8 hours to get (on GTX 1060) vs. 1.2 seconds for SVD (computed on 4-core CPU). Recommender systems is a very applied field. Hence, the complexity analysis as well as computation time comparison should also be part of the work. Potential scalability issues should be explicitly explained and not left for the readers to discover. \n\nThings to improve the paper that did not impact the score:\n\n1) Have you tried to work with the version of NeuCF that is modified the same way as AGMF?\nNeuCF provides the general framework that also allows to incorporate interactions history into inner product computations via \u201cfeature vectors\u201d. According to the authors, NeCF > GMF, which means that potentially NeuCF with extended user and item description, similarly to AGMF, could also perform competitively. I believe, it would make the work better from the perspective of fair comparison.\nIt\u2019s important to note, however, that there\u2019s a certain evidence that recent neural network-based approaches do not actually outperform simpler linear models, see work by [Dacrema, Cremonesi, Jannach 2019] on \u201cA Worrying Analysis of Recent Neural Recommendation Approaches\u201d. For example, NeuCF was not better than SLIM and in some cases even worse than KNN-based models. It would be better to add at least some of this baselines into the comparison.\n2) Accordingly, I\u2019d like to see the source code for entire experiments showing how experiment is conducted, how baseline models are tuned, etc. The source code attached for the review only contains basic training for one dataset and only for AGMF model.\n3) Recommender systems data is noisy. It\u2019s hard to make a reliable comparison of models without an analysis of statistical significance of different results. I would suggest to employ a different evaluation strategy with user-based k-fold cross validation (each fold consisting of 1/k fraction of users). This would allow to report confidence intervals for your results and demonstrate reliability of your conclusions.\n4) I believe the term \u201cmulti-hot\u201d encoding is misleading. FM also uses the same representation; however it\u2019s still called \u201cone-hot\u201d.\n\nReferences:\nPaterek, Arkadiusz. \"Improving regularized singular value decomposition for collaborative filtering.\" In Proceedings of KDD cup and workshop, vol. 2007, pp. 5-8. 2007.\nChen, Tianqi, Weinan Zhang, Qiuxia Lu, Kailong Chen, Zhao Zheng, and Yong Yu. \"SVDFeature: a toolkit for feature-based collaborative filtering.\" Journal of Machine Learning Research 13, no. Dec (2012): 3619-3622.\nKula, Maciej. \"Metadata embeddings for user and item cold-start recommendations.\" arXiv preprint arXiv:1507.08439 (2015).\nStern, David H., Ralf Herbrich, and Thore Graepel. \"Matchbox: large scale online bayesian recommendations.\" In Proceedings of the 18th international conference on World wide web, pp. 111-120. ACM, 2009.\nRendle, Steffen. \"Factorization machines.\" In 2010 IEEE International Conference on Data Mining, pp. 995-1000. IEEE, 2010.\nNikolakopoulos, Athanasios N., and George Karypis. \"Recwalk: Nearly uncoupled random walks for top-n recommendation.\" In Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining, pp. 150-158. ACM, 2019.\nDacrema, Maurizio Ferrari, Paolo Cremonesi, and Dietmar Jannach. \"Are we really making much progress? A worrying analysis of recent neural recommendation approaches.\" In Proceedings of the 13th ACM Conference on Recommender Systems, pp. 101-109. ACM, 2019."}