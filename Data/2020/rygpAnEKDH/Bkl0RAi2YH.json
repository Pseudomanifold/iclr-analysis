{"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This work outlined 3 problems of DARTS a) bi-level optimization, b) multicollinearity of correlated operations, c) the fundamental\nchallenges of matching neural network optimization complexity in NAS and in the final training. The authors proposed algorithm to fix them with a) one-level optimization b) group variable pruning and c) complexity matching by gradient confusion.\n\nThe author provided detailed experiments to support their claim of the problems of DARTS and validated their proposals with extensive benchmarks. The structure of the paper is well organized and the wording is in very good style.\n\nI have two following minor comments:\n1. Did the author do an ablation study on each of the component they proposed? For example using DARTS with only group variable pruning to highlight the contribution of it. And similarly, for one level optimization.\n2. The part how to select depth using gradient confusion is not very clear to me."}