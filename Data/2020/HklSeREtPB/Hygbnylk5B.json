{"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "## Overview\nThis paper studies whether a recurrent neural network trained to solve a particular task (integration of angular velocity to generate head direction). Given trained recurrent networks that solve the task, the paper analyzes these using a number of different methods (visualizing tuning curves, perturbation experiments, and varying input statistics). Overall, I think this is a nice paper that shows the power of using artificial networks as a model system to answer neuroscientifically motivated questions. In particular, I found the perturbation analyses particularly illuminating. These kinds of experiments are only possible in these artificial networks, and can highlight/guide future biological experiments.\n\n## Major comments\n- \"Units with minimal tuning to both variables are discarded from further analysis\"  -- how many units end up being discarded? The reason I ask is because the number of discarded neurons affects this statement: \"Therefore, units in the trained RNN could be mapped on to the biological head direction system both in terms of general functional architecture and detailed tuning properties.\". If a large number of neurons are discarded, then the statement should be amended to say that \"a fraction of units in the trained RNN\" can be mapped onto the HD system. However, my understanding is that many biological neurons have tuning properties that are hard to classify, perhaps the discarded neurons could map on to these previously uncharacterized neurons?\n- The paper demonstrates a number of qualitiative similarities between artificial and biological networks (e.g. both contain neurons tuned for HD or AV). It would be even more compelling if, wherever possible, these comparisons were made to be quantitative.\n- \"We conjecture that Ring units in the trained RNN serve to maintain a stable activity bump in the absence of inputs\". I think a cool direct test of this idea would be to use the techniques in Barak & Sussillo 2013 (find fixed points of the recurrent network dynamics, and analyze the linearized system at those fixed points) to identify the ring attractor structure. In particular, numerical auto-differentiation can be used to automatically identify these points (c.f. the methods in https://arxiv.org/abs/1907.08549). Using these tools, can one find the ring attractor hidden in these networks?\n\n## Minor comments/questions\n- The layout in Fig 2a (and Fig 5c, 5f, and 5i) is a little misleading. If I understand correctly, the axes labels apply to each individual panel (which shows tuning for a particular neuron). However, since the labels extend across many panels, it looks as if the panels themselves are organized according to angular velocity and head direction, which doesn't make sense.\n- Missing citation towards the end of pg. 3\n- Consider setting the panels in Fig 5a-h to have the same axes limits, for easier comparison."}