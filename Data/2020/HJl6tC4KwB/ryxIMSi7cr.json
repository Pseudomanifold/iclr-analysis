{"experience_assessment": "I have published in this field for several years.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "The paper presents a method to manipulate images using natural language input. The method uses a deep network to parse the input image, input text, and a generative adversarial network to produce the output image. The architecture is sensible, and close to prior work. The loss function is standard and almost identical to (Li et al., 2019).\n\nStrength:\n + Good results\n + Good experiments and ablation\n\nAreas of improvement:\n - Highlight contributions\n - Compare to Li et al\n\nThe paper is well written, easy to understand. The results look very good, and the model performs well in the quantitative comparison. The experiments are extensive and contain a detailed ablation of the presented method.\n\nThe paper could be stronger if the authors could highlight the contributions more. A large part of the technical section is either directly copied or slightly modified from prior work. The interesting new contributions (e.g. DCM) are only fully described in supplemental material. I'd recommend the authors to focus more on the contributions and talk about them in the main paper.\n\nSince large parts of the paper are derived from (Li et al., 2019), it would be nice to directly compare to it. I understand that Li etal do not use a reference image, but a comparison would help show the presented work improves upon the baselines."}