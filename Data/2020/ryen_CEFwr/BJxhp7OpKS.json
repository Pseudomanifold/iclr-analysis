{"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "The paper presents an unsupervised method to get disentanglement of pose, appearance, background from both images domain and video domain. 5 sub-network are used to model pose, appearance, foreground, background, and decoders.  Their methods let the network focus more on the foreground to regress the landmark and improve state-of-the-art performance on landmark regression (unsupervised.), video prediction and image reconstruction. \nHowever, there are still lots of details missing for the training of the whole network even with the supplementary.  \n1. what are the details of the color jitter process? how do you know it is foreground and only colorizing this part?\n2. why the video prediction only on KTH. H36M is also a video-based dataset.\n3. what is the thin-plate-spline warped image?\n4. how do you generate T_temp(x) for image-based dataset?\n5. are the learned landmark all unimodal? as for 2d pose estimation, even we give them unimodal gt, sometimes the prediction is bimodal.\n6. how do you make the covariance as learned?"}