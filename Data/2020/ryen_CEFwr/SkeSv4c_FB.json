{"rating": "3: Weak Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review": "In this paper, authors propose to design an unsupervised learning framework, which can capture pose representation by reconstructing images or videos. \n\nThe paper is not written well. Too much components in the design make this work hard to follow. The novelty is also relatively limited, since a large part of this work has been done in Lorenz et al. (2019). Moreover, the only supervision is the reconstruction loss. I am just curious how the neural network can learn the semantics representation (such as foreground and background), without any guidance in the corresponding modules? \n"}