{"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This paper studies robustness and redundancy of deep models with the goal of understanding what controls the capacity in over-parametrized networks. Authors came up with their own definition of robustness and redundancy, ran several experiments and provided empirical observations about how these quantities change as one over-parametrize a network.\n\nWhat I really like about this work is taking an empirical approach to understanding the over-parametrization and providing experimental observations which can be very helpful for better understanding of these phenomenon. \n\nEven though I like the general approach to the problem, I think the paper can be improved in several ways. In general, I think the qualities and experiments can be defined in a more principled way. Below I point to specific issues:\n\n1- Six types of neurons have been defined very early in the paper (Section 2). However, they are not really contributing to the main arguments of the paper and are not used in the experiments in the main part of the paper. If they are not really central to the picture. It might be better to remove them. Otherwise: a)provide a clear definition for each one in such a way that it is possible to write a code to measure them b)argue why these are the only possible ways to limit the capacity? How did you come up with these six? Is there a principle behind it?\n\n2- Robustness: Why choose this definition for robustness? Here, it would be helpful to compare your definition to other definitions of robustness (for example, with respect to input perturbation or parameter perturbations) and argue why this notion make sense. It might be helpful to discuss its relationship to dropout and other methods. Also, is there any generalization bound that implies bounding your version of Robustness might be related to generalization?\n\n3- Redundancy: Here, instead of having a single definitions, authors come up with two different notions \"compressibility\" and \"similarity\". First of all, robustness definition is based on dropout which itself is a form of measuring redundancy so it is not clear why one need to define redundancy separately. Second, the way compressibility and similarity are defined seems arbitrary to me. Why choose this specific definitions? Why separate compressibility and similarity?\n\n4- Experiments: The training and test error is not provided for the plots in the main text which makes it difficult to see how these robustness and redundancy relate to generalization. Moreover, the fact that the redundancy does not show a consistent behavior in different experiments could be due to the definition seem very arbitrary. There are many more experiments in the appendix but in general it is very hard to see a simple and consistent story that is supported by experiments. \n\nMinor:\nIn section 2, I'd avoid using metric since it is not clear if these measures have properties of a metric.\n\nOverall, I appreciate the empirical approach of the paper but I think the definitions, arguments and experimental design could be improved significantly.\n\n"}