{"rating": "8: Accept", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper proposes to evaluate two characteristics of DNNs, robustness and redundancy, in an attempt to link them with generalization and overparameterization.\nA central hypothesis in this paper is that increasing the number of parameters increases at least one of these two characteristics. As far as the empirical results show, this is true. \n\nWhere the line gets blurred is in the causal relationships between generalization, overparameterization, robustness and redundancy (and other unstudied phenomenons). A strict interpretation of the results in this paper show that: when there is overparameterization, there is also robustness and/or redundancy. Beyond that, the experiments in the paper are not fully able to answer harder questions with certainty:\n- does overparameterization really increase \"capacity\"? Extra robustness and redundancy could both be explained by a structural failure of DNNs to take advantage of having more parameters (I don't believe so, but it would be nice to [dis]prove!)\n- do robustness and redundancy arise from the same phenomenon that leads to generalization, or do they arise from the mechanisms that we usually associate with overfitting/fitting high-frequency-noise patterns? The paper's results suggest the latter, since the same phenomenons are observed when fitting random lables.\n- is this phenomenon limited to classification? visual problems? The synthetic problems show weaker trends and happen to not have a lot of structure within them.\n\nNonetheless, now that we know some consistent behaviours that emerge from overparameterization, we may be better able to continue digging.\n\n\nOverall I think the results of this paper are novel and valuable. They confirm a few hypotheses that were emerging in the literature concerning the odd behaviours of overparameterized DNNs. On the other hand, I think more could have been done to understand the _why_ of the observed phenomenons. \nOne big aspect that is missing is time. Beyond Fig. C3 which only looks at behaviours after convergence, there is no data regarding the progression of robustness and redundancy during training. Such trends might be vital in order to understand the order in which phenomenons happen in DNNs during training, and superposing such trends with other measures that have been linked to generalization and overfitting may help clarifying the dynamics of DNN training.\n\n\nSome comments:\n- why weren't the MLPs initialized with standard initializers (Glorot, etc.)? \n- The presentation of the paper is good. There are a few typos here and there but the paper was otherwise easy to read and understand.\n- I'm not sure I fully agree with the \"He\" initialization scheme being considered a \"high-variance\" scheme nor the \"LeCun\" initialization scheme being \"medium-variance\". Both these schemes, as well as Glorot et al, were designed with the intention of keeping variance _constant_ in depth. A better test would have been to scale these initializers by some constant c around 1.\n- \"Xavier/Glorot\", these are not two separate things but rather, Xavier is the first name of Xavier Glorot, author of the \"Glorot et al.\" paper.\n- I'm not sure where you found LeCun initialization to be sqrt(3) / fan_in, it should be 1/fan_in, see http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf\n- Even though the initializations, optimzers, models and data are fairly standard, it's still expected to cite the original papers. You cite none of them.\n"}