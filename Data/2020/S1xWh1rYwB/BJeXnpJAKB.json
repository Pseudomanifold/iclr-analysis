{"rating": "6: Weak Accept", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This paper presents an information-bottleneck-based approach to infer the regions/pixels that are most relevant to the output. For all the metrics listed in the paper, the proposed approaches all achieve very good performance. It turns out, the proposed two architectures are better (at least alternative) choices to the other existing attribution methods.\n\nI do agree that the proposed two models (Per-Sample and Readout) can be used to roughly infer regions of interest, which has been strongly supported by the comprehensive experiments. To minimize equation (6), we need to make beta*L_I small. Minimizing L_{CE} in (6) tries to maximize the mutual information between Z and output (labels); while minimizing L_I with respect to weight beta would try to inject noise to each dimension of Z. However, L_{CE} needs to ensure it can get enough information for prediction, and thus would prevent the noise injection process for \u201cthe key regions\u201d. By choosing reasonable beta (similar to variational information bottleneck), the proposed approaches are capable to highlight key regions used for prediction.\n\nOverall, I think the method is elegant for approximately estimating the relevance score map.\nBelow are some of my (minor) questions/concerns:\n\n1. What we learned = What we want?\nThe proposed approach seeks a sort of \u201csparse heatmap\u201d. \nThe larger the beta, the more regions/pixels would be suppressed while smaller beta might fail to suppress non-important regions in the image.\nIn the paper, the beta used for calculating the per-sample bottleneck is among [100/k , 10/k, 1/k].\nThe beta for ReadOut bottleneck is 10/k.\nHowever, according to Table 1, only when beta is smaller than 1/k, the accuracy of the model does not degrade too much. \nWhen using beta=10/k to get the \"heat map\" (where 10/k is the best choice of per-smaple bottleneck for degradation task), how close is the \"heat map in beta=10/k\" to the \"ground-truth heatmap\"?\nTo better understand the proposed methods, I have a small suggestion:\n------ Try betas in a broader range including very small betas, e.g. [0.0001/k, 0.001/k,....,1/k,10/k], for both Table one and visualization. \nFix a few images and visualize the heatmap given different betas.\nWe might better see how the growth of beta changes the heatmap.\n\n2. About zero-valued attributions.\nI agree with you that equation (5) is an upper bound of MI (eq (4)).\nHowever, I am not sure if I totally agree with the claim \"If L_1 is zero for an area, we can guarantee that no information from this area is used for prediction.\"\n----- Given L_1=0 really implies that no information of the corresponding region is used for the certain beta, but is this true for the original model (beta=0)? Table one shows that different beta would lead to very different downstream task accuracy.\n\n3. Specific to the two approaches you proposed, can you explain/motivate in what situations per-sample bottle would be better and in what cases we should prefer ReadOut bottleneck?\n\n"}