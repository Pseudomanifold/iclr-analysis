{"experience_assessment": "I have read many papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I did not assess the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "Given that computing the Shapely value for data valuation is very expensive and existing approximate methods are not scalable either, the authors introduce a new approach based on K-NN approximation of the model to scale it specifically for DNN. The authors propose to use the final features produced in the last feature extractor layer of DNN as features for KNN and choose K such that the performance of KNN is closest to the performance of DNN. My main problem with this approach is that the authors still need to do this for any trained DNN in order to compute a good value for Equation (2). If the claim here is that the features extractor layers of deep neural network does not change by changing the training set (which is a huge claim), then why one should use K-NN. We can simply use the feature extractor part of DNN (almost all the trainable parameters except the last layer) once and then fix it and only learn the soft-max layer parameter for different subsets. Overall, I believe even though this paper aims to address an important problem, the approach is taken is not well-justified and lacks value. Below  are some other minor problems:\n\nThe introduction/title of the paper claims this is a general approach for any model but the authors' focus is only on DNN. This should be corrected. \n\nInconsistent notation: \nBeginning of Section 2. The training and test set is first denoted by D and D_{test} and then later by S and S_{test}.\nEquation (2): the authors are using U in a different forms that the ones introduced earlier in Section 2. I recommend the authors only introduce one notation for U and stick with it throughout the paper.\n\nWriting problems:\nSection 2: \u201calgorithm algorithm\u201d \u2192 algorithm (repeated word)\n Section 2: \u201cFor each training data z_i, our goal is to assign a score to each training point, denoted by \u2026 \u201d \u2192Our goal is to assign a score to each training data z_i denoted by \u2026\n\nNote that the assumption in machine learning is that you do not have access to the test set and it is something you won\u2019t see until you deployed your method. I assume the authors meant validation set.\n\nConstant C is introduced in Equation (2) but it is not well justified. \n"}