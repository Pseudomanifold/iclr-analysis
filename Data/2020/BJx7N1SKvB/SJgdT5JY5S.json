{"rating": "6: Weak Accept", "experience_assessment": "I do not know much about this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review": "This paper analyzed the asymptotic training error of a simple regression model trained on the random features for a noisy autoencoding task and proved that a mixture of nonlinearities can outperform the best single nonlinearity on such tasks.\n\nComments:\n1.The paper is well written and provides sound derivation for the theories.\n\n2. Since this area is out of my expertise, I\u2019m not sure whether merely extending the work of Pennington & Worah (2017) to non-Gaussian data distributions is significant enough or not.\n\n3. Except for Fig 4, the other figures seem out of the context. There is no explanation for the purpose of those figures in the main contents. It is a bit hard for the audience to figure out what to look at in the figures or what the figures try to prove. \n\n4. In \u201c..., and our analysis actually extends to general such distributions, ... \u201d, \u201cgeneral\u201d should be \u201cgeneralize\u201d.\n\n5. In \u201cAnd whether these products generate a medical diagnosis or a navigation decision or some other important output, ..\u201d, \u201cwhether\u201d should be \u201cno matter\u201d.\n\n6. \u201c..., they may not be large in comparison to the number of constraints they are designed asked satisfy.\u201d should be \u201c...  they are designed to satisfy\u201d.\n"}