{"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper aims to achieve multi-agent coordination by composing diverse skills learned by augmenting individual subtask objectives with DIAYN-style diversity bonuses. Once individual diverse skills are learned for the subtasks, the agents are combined by a meta-agent to coordinate multiple distinct robots to achieve a shared goal.\n\nThis is a good application of low-level skill learning to multi-agent coordination. I have settled on a weak acceptance, because the approach is simple and seems scalable, but the acceptance is weak because the method relies on specifying the subtasks in advance.\n\nThe approach is well-motivated in that learning individual skills in isolation is generally more tractable than learning their combined application from scratch, and the building blocks of this system are well-chosen. The results demonstrate the importance of the diversity objective, and find a good sweet spot for the diversity weight.\n\nI do have some criticisms, related primarily to the decision to pre-train with both a continuously-parameterized diversity conditioning as well as a discrete set of concrete subtasks. Because these subtasks must be specified in advance, this limits the wide applicability of the resulting approach to those that can be broken down a-priori into components. Did the authors consider using the DIAYN objective on its own to encourage sufficiently diverse behaviors? If this didn't work, would perhaps a larger latent skill vector, or a large discrete set of DIAYN skills, have made it work?\n\nI also don't see the size of the latent skill embedding reported anywhere. How big is this vector; that information should be added to the paper.\n\nHowever, the approach is generally good. I think the paper would be improved if it included a strong baseline that uses DIAYN only (no a-priori subtasks), so we can evaluate how important that expert knowledge is to the final performance."}