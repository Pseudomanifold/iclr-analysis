{"experience_assessment": "I have published in this field for several years.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "N/A", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "Summary\nThe authors make three major contributions that improve MixMatch and achieve state-of-the-art in a semi-supervised image classification task. The major contributions include: (1) distribution alignment to calibrate the predicted distribution of unlabeled data; (2) augmentation anchoring to allow more aggressive data augmentation; and (3) CTAugment to train the augmentation policy alongside the semi-supervised model.\nThe authors conduct experiments on SVHN, CIFAR-10 and STL, and show significant improvements over the MixMatch baseline. They also show good results (15.08% error rate) of training with 40 labeled data, in spite of very high variation. In the ablation study, they show the error rate drops as K (number of augmentation) increases. They also conduct ablation studies on the design choices of their method.\n\nDecision\nThe decision for this paper is borderline, tending towards a weak accept. Overall, the paper proposes some simple but interesting ideas, e.g. distribution environments. However, although the proposed method achieves good performance over various (smaller) benchmarks, the method seems ad-hoc and complicated. As pointed out in the weakness section, many design choices are not well motivated, and the effects of those designs are not well studied. The tendency to accept is due to the overall strong results. \n\nStrength\n1. Significant improvement over MixMatch baseline.\n2. The proposed augmentation anchoring and distribution alignment can be easily integrated into existing work.\n3. The proposed CTAugment method lifts the burden of training an RL data augmentation policy. \n\nWeakness\n1. The objective of the update equation of CTAugment\u2019s learned weights seems contradicted with the purpose of how data augmentation is used in the consistency-based SSL method. In other words, the objective of the update equation encourages higher weights for the distortion parameter that leads to lower variation in the predicted distribution. However, the idea of aggressive data augmentation is to generate data that has high variation in the model prediction, and then penalize the variation in the form of consistency loss. The variation induced by aggressive augmentation is the root of the consistency loss that helps regularize the model.\n2. The authors should provide ablation study and analysis of their CTAugment. For example, they should compare with simple random augmentation policy. It is also recommended to show the learned weights of the distortion parameter. Also does larger K value when applied for vanilla MixMatch approach the results in ReMixMatch? \n3. The authors should provide more detail of the setting in the ablation study. For example, the setting of \u201cNo strong aug.\u201d and \u201cNo weak aug.\u201d are not clear. \n4. The authors hypothesize that \u201cstronger augmentation can result in disparate predictions, so their average may not be a meaningful target.\u201d However, they do not show any analysis to support this hypothesis.\n5. It is recommended to evaluate the method on larger datasets such as CIFAR-100. It is not clear how well these methods scale, and for example using k=8 adds computation which may hinder training scalability. \n\nMinor Comments\n1. For Table 2 and Table 3, it should be \u201cerror rate\u201d rather than \u201caccuracy\u201d.\n2. How is the loss weight \u03bbr tuned in the 40 labeled setting? How are the hyper-parameters tuned in general?\n"}