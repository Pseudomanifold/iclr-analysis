{"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "Summary:\nThe paper deals with the problem of training cooperative agents in a multi-agent reinforcement learning setting. The agents are given the ability to communicate with each other and are trained using the centralized training, decentralized execution paradigm. \n\nArchitecture has been proposed that: (i) attends to relevant communication messages received by an agent using an attention mechanism similar to the one proposed in [1]; and (ii) endows each agent with a memory. The authors argue that memory assists the agents in performing explicit reasoning.\n\nThe proposed architecture consists of four units:\n1. Thought unit for processing local observation to obtain query, key and value vectors along with an observation encoding.\n2. Question unit for obtaining an attention distribution over all agents (using one's own query vector and the [key, vector] pairs received from all agents) via a modified version of attention mechanism proposed in [1].\n3. Memory unit for using the attention weights obtained in step 2 to update agents memory\n4. Action unit for picking action based on agent's memory and local observation.\n\nExperiments done with cooperative agents on three different tasks from multi-agent particle environments show that in some cases the proposed architecture outperforms other approaches. Two experiments that aim to understand the role of attention and memory have also been performed.\n\n\nComments:\n1. The Introduction section lacks motivation. An example to explain terms like structured reasoning would help a lot.\n\n2. At least to me, it is not apparent how the memory or attention leads to an \"explicit\" reasoning process.\n\n3. In section 2.1 A_i and O_i are sets and not actions or observations respectively.\n\n4. On p5, in the paragraph before Section 3.3, it is written that \"... it learns to assign importance to each element in the information vector.\". Further clarification is needed here. As the weights act on the entire vector in the memory unit, the statement appears to be a bit misleading.\n\n5. The current setup requires the key-value pairs to be broadcasted to all agents. This would be inefficient when a large number of agents are present - which is essentially the case where one would want to filter out information using such an approach.\n\nThe paper is overloaded with terminology that can be avoided and the presentation can be simplified. There is redundancy in writing and many statements are vague, e.g., the one that talks about performing explicit structured reasoning. The description can be condensed and space can be used for more informative ablation studies.\n\n\nQuestions to the Authors:\nSee the comments above.\n\n\nReferences:\n[1] Vaswani et al., 2017, Attention is all you need.\n"}