{"rating": "1: Reject", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "Uncertainty-Sensitive Learning and Planning with Ensembles\n=====================================================\n\nThis paper investigates the use of uncertainty-aware estimates in solving planning problems (RL with access to simulator).\nThe proposed algorithm combines a learned model-free value estimate with MCTS planning.\nAn ensemble of neural networks is used to model posterior uncertainty in the value estimate and drive efficient exploration.\n\n\nThere are several things to like about this paper:\n- The paper takes on several core issues in RL/planning research, most notably the synthesis of dealing with model-based and model-free uncertainty in RL.\n- The general flavour of the paper + algorithm seems to be reasonable. The proposal to use ensemble uncertainty estimates to drive model-based MCTS is interesting, natural, and I think it's a good one.\n- The proposed structure of the paper is quite nice, there is mostly a linear and logical progression of complexity in the experiments. This is nice to see clear benefits of the approach on the simplest possible settings and build up from there.\n- The effort to open source code + implementation details is laudable.\n\nHowever, there are several places where this paper falls short:\n- In general, the claims and results of the paper are far too vague to be fully understood and replicated. Take the main algorithm 1, it really seems like more of a \"sketch\" of a very general family of algorithms, rather than a specific description of a clear algorithm.\n- This vagueness is spread throughout the plots and figures as well... note that Figure 1 has no indication of how many steps have been evaluated, and Figure 2 has no indication for what value K > 0 was actually used. The clarity does not improve in Sections 3.2 and 3.3 where quite inconsistent performance metrics and presentations are presented.\n- Generally, the writing could be tightened quite a lot. In particular I would encourage you to think about whether each statement you make is clearly supported by some theorem, experiment or plot in your paper. For example, on page 3 \"We found this mechanism to be beneficial... see Section 3.3\" but then it's not clear exactly what statement shows that particular part of the mechanism was helpful, versus other issues associated with ensemble learning. There are more than a few typos... the on(e) in Osband... akin to ??... might be obtained by choosing from (the) ensemble...\n- It would be very helpful to clarify that the agent is given access to a simulator... so that this is not exactly the typical RL setting of sequential decision making. This should appear early in the paper.\n- The code that is released with the paper is also quite confusing, it is not structured with a clear README and includes many sections of dead/commented code. I was hoping the code might rescue some of the clarity, but I think that still needs work.\n\nOverall, I do think there is some interesting material here...\nIt's an important problem, and the core building blocks of combining model, value and uncertainty for better exploration is interesting.\nHowever, I just think the actual paper is not clear enough on the details.\nMy belief is that going through this paper very methodically and carefully to make sure that every single detail + claim is rigorously supported would help this paper immensely.\nFor that reason I have to say that I think it's a \"reject\" in its current form."}