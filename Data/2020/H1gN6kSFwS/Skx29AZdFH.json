{"rating": "3: Weak Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This paper proposes an SCM-model based on masked neural networks to capture arbitrary conditional relationships combined with meta-learning-style adaptation to reflect the effects of various unknown interventions. Overall the paper is well written and easy to follow, but some conceptual issues remain.\n\n\n- How come there is hardly any discussion of the identifiability issue beyond the few sentences in A.3. This is one of the key issues in learning SCMs and it is strange that the concept of \"faithfulness\" is not even mentioned in the paper.\n\nIn general, there is hardly any discussion of what conditions are required for the proposed estimates to even be valid. The authors seem to be optimistically assuming that their neural network + metalearning model will\u00a0somehow pick up on the correct structure, without any actual conceptual investigation of this issue.\n\n- The massive downside of neural nets is all the various hyperparameters one has to set (eg. architecture, optimizer, activations, etc). In this setting, how do the authors propose selecting hyperparameter values? How does the reader know the authors did not simply tune their hyperparameters to best match the underlying ground truth (I assume the proposed methodology has many more\u00a0hyperparameters and thus more degrees of freedom here).\nI would like to see the empirical performance of different variants of your model with different hyperparameter values to assess its sensitivity to these choices. \n\n- Why does one even care about the graph being acylic in this setting?\nThe mere fact that the authors require a regularizer to ensure acylicity suggests this approach is prone to mis-identifying the ground truth structure (which is always acyclic in the experiments).\n\n- One main reason for SCM modeling in science and policy-making is for analysts to better understand the data generating phenomena.  However your use of neural networks here seems to hamper interpretability, so how do you reconcile this issue? Also is your sparsity regularizer satisfactory to confidently diagnose presence/absence of an edge (in constrast to statistical hypothesis tests, say based on conditional independence). Isn't this heavily influenced by the particular sparsity-regularizer value that happened to be selected?\n\n\n- Related papers that utilize the same idea of predicting a variable conditioned on subset of other variables via neural network + masking strategy:\n\nIvanov et al (2019). VARIATIONAL AUTOENCODER WITH ARBITRARY CONDITIONING. \nhttps://openreview.net/pdf?id=SyxtJh0qYm\n\nLi et al (2019). Flow Models for Arbitrary Conditional Likelihoods.\nhttps://arxiv.org/abs/1909.06319\n\nYoon et al. GAIN: Missing data imputation using generative adversarial nets. Proceedings of the 35th International Conference on Machine Learning, volume 80 of Proceedings of Machine Learning Research, 2018. http://proceedings.mlr.press/v80/yoon18a.html\n\nDouglas et al. A universal marginalizer for amortized inference in generative\nmodels. arXiv preprint arXiv:1711.00695, 2017\n\nFor clarity, the authors should highlight the differences of their approach from these works (beyond the causal setting).\n\n- Given the lack of theoretical / conceptual guarantees that the methodology will work, our faith in the proposed methodology rests entirely on the empirical experiments.  However, I find these a bit too basic to be very convincing, and would at least like to see more methods being compared (in particular for the simulated graphs as well).\n\n- The authors should describe what are the underlying interventions in each dataset a bit more.\n\n- The Figures should be better explained (took me a while to figure out what dots/colors represent).\n\n- Why do the authors report cross entropy loss in Table 1? To my knowledge this is not a standard metric for measuring the quality of structure-estimates.\n \n- Instead of ICP (which is constrained to be linear which is unrealistically simple), why don't the authors compare against nonlinearICP (which is more flexible like their neural networks):  \n\nHeinze-Deml et al (2018). Invariant Causal Prediction for Nonlinear Models. https://arxiv.org/pdf/1706.08576.pdf"}