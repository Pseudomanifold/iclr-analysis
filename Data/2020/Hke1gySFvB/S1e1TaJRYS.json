{"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This paper starts with a conceptual claim that incorporating a notion of \u201cempathy\u201d in language emergency would help agents learn faster.  The paper then proposes a learning mechanism for implementing this, and looks at its empirical effect for the case of a Speaker-Listener game.\n\nThe concept at the core of the paper is thought-provoking, somewhat grounded in human communication, and it\u2019s interesting to see how this can be translated into a learning mechanism for the multi-agent setting.   The specific implementation proposed seems reasonable at a high level, however there are many technical details missing which really hamper the paper\u2019s message & potential scientific impact.   The results are limited to a single game, with just a pairwise comparison (with and without \u201cempathy\u201d), and provide a narrow view into the effectiveness of the proposed technique.\n\nMy main problem with the paper is the clarity & organization problems.  Usually I tend to be lenient on this, thinking poor writing is much easier to fix than poor science.  But in this case the problems are large enough that the paper is just too far from the standard for ICLR publication.  It also fits in 5 pages, so the authors had lots of space to write a much better paper.   I encourage them to do this for a future submission, in addition to more extensive results, because I think the ideas are worthwhile.\n\nSpecific comments:\n\nDesign of the empathy mechanism. Can you motivate why it\u2019s reasonable to \u201cachieve a high relation between the hidden states of both agents\u201d? Is this necessary / sufficient for empathy?  What are alternate framings of this?  What are properties and pros/cons of this framing?\n\nSec.4 needs a lot more detail!   Sections Agent setup, Learning and Empathy Extension in Sec.5 should be moved to Sec.4, since they describe the method, rather than the experiments.\n\nSec.5 needs better clarity.\no\tWhat are m^l_t and M^{<l}_t in Eqn 5?  Define how h_S and h_L are parameterized, and how each is trained.\no\tFig.2 gives a high-level view of the approach, but lacks important details.  Do you apply a loss at both the Speaker\u2019s Decoder output, and the Listener\u2019s Decoder output?  Or just the latter?  What is the loss specifically? I assume combination of Eqn 5 and Eqn 6, but not sure.\no\tIf you train just on the loss of the Listener\u2019s Decoder, does this mean this is backpropagated all the way to train the Speaker?  How would this be done in a real system?  It\u2019s a very strong assumption to say that the Listener will share gradients with the Speaker.  It seems more realistic to assume they will each observe a loss and train independently.\n\nResults are very brief.\no\tHow robust are the results to the specification of the \\alpha (the loss weight from Eqn 6)?  How much data goes to finding a good \\alpha?\no\tWhat is the difference between the left and the right plot?  Is one for the Speaker and the other for the Listener?\no\tHow do you measure \u201clearning speed\u201d, which is the main metric discussed in the text of Sec.6?\no\tHow do the results change by number of concepts in the game?\no\tDo you do any pre-training of the encoder/decoder networks?\no\tCan you show confidence intervals on each curve?\no\tCan you show test performance?\no\tAre there other related games to consider?\n\nMany references missing throughout to support statements, e.g.\no\t\u201cNatural language is not as rule-based as\u2026\u201d \no\t\u201cThese considerations led to the research field of emergent communication\u2026\u201d\no\tSec.2:  Earlier refs to RL in general (e.g. work Sutton in the 1980\u2019s). Earlier refs to RL with neural networks (e.g. work of G. Tesauro; work of M. Riedmiller).\no\tReferential game in Fig.1 caption.\n\nSome minor language issues, e.g.\no\t\u201cThe field was then alleviated\u201d -> Do you mean elevated?\n"}