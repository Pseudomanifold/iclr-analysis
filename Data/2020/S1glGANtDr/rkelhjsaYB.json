{"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "This paper proposes a new algorithm for the off-policy evaluation problem in reinforcement learning. It combines the value function learning method and the stationary distribution ratio estimators. The proposed method achieves double robustness, which means the proposed estimator is consistent as long as the value function or ratio estimator is consistent. Empirical results on some control domains are presented to verify the effectiveness of the algorithm.\n\nI think this paper has some nice contribution to the area, by introducing a doubly robust estimator based on the density ratio, and also a new idea to achieve double robustness. I will vote for accept, but I think there is room for improvement of this paper.\n\nDetailed comments:\n - The proposed estimator is not using control variate but using dual structure between value function and stationary distribution ratio, which is a novel idea comparing with similar doubly robust estimators. \n - Theorem 3.2, or at least the way it is presented, is less intuitive and makes me confused. If the variance of the DR estimator is always larger than the variance of value function, why I should use this estimator instead of value function. If the argument is the MSE of value function is potentially larger due to the bias. Then an effective analysis would be about MSE instead of variance.\n - If I have an oracle of density ratio, is the doubly robust estimator still unbiased, which is generally true for DR using control variate? This would be an important point to compare this work with control variate methods.\n - Very recent work https://arxiv.org/abs/1908.08526 also proposes a doubly robust estimator in similar settings. It's worth to mention it in the related work."}