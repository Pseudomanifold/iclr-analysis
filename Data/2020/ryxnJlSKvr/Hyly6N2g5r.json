{"experience_assessment": "I have published one or two papers in this area.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "The paper proposes an embedding method for source code tokens, which is based on contextual word representation, particularly is based on the method of ELMo. The learned representation is evaluated on the task of bug detection, with promising performance.\n\nStrengths:\nThe paper addresses an important and impactful problem. The solution designed for this problem seems very reasonable. Experiments are useful and reasonable and the experimental results are promising and in the favor of the paper.\nThe paper is well written and clear.\n\nWeaknesses:\n- The data used (in particular the method of buggy code generation applied) seems very specific.  It would be interesting to know the performance of the method on real bugs. \n- The paper is a bit low in technicality. \n\nDecision: Accept\nI think this paper is overall a good work and can open direction of research even beyond the scope of the paper, for example  in combining learning and reasoning, or in source code generation with adversarial models.\n\nMinor: \n- Since compilers can spot errors in code completely, it would be useful to motivate the advantage of learning for bug detection\n- The table referrals in the body of the paper contains wrong table numbers in Sections 6.1, 6.2, 6.3.\n- The incorrect Binary Operator example in Listing 2 does not seem to be a well justified bug. It could be a correct piece of code for a different purpose.\n- which use -> which we use"}