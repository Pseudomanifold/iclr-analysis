{"experience_assessment": "I have read many papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "In this work, the authors proposed a method to address the covariate shift and label shift problems simultaneously. In detail, the prototype-based conditional alignment and self-training based label distribution estimation is utilized. Empirically evaluation is conducted on three datasets to show the superiority of the proposed method. However, the work suffers the following weaknesses:\n \n1). The main concern of this work is its shift assumption. In the language of dataset shift, the joint distribution p(x, y) can decompose into two different manners, which are p(y|x)p(x) and p(x|y)p(y). Covariate shift is defined as p(x) not equals to q(x), while the conditional output distribution is invariant p(x|y) = q(x|y), where p(.) and q(.) are distribution for source and target domains. Label shift is defined as p(y) not equals to q(y), while the conditional input distribution p(y|x) = q(y|x). The work assumes that p(x|y) not equals to q(x|y) meanwhile p(x) not equals to q(y). It means to minimize the joint distribution p(x, y), which is well motivated. However, it does not solve the two abovementioned shifts simultaneously here. Instead, it aims to minimize the marginal distribution and conditional distribution in the anticausal direction. See more definitions in the papers \u201cWhen training and test sets are different: characterizing learning transfer\u201d and \u201cOn causal and anticausal learning.\u201d\n \n2). The novelty of the paper is limited. While the authors claim that it is the first time to approach it in the proposed manner, the problem of both p(y) and p(x|y) change is not new. For instance, in the paper \u201cDomain adaptation under the target and conditional shift,\u201d the case of distribution shift correction also does not assume the same conditional distribution and marginal distribution for the source domain and the target domain. Also, the fulfill of conditional alignment is used the formulation and architecture of the work \u201cSemi-supervised Domain Adaptation via Minimax Entropy,\u201d except that there is no labeled target data in the target domain (see Eq.(1)). Besides, the notation f in Fig. 2 is missing the description of Section 3.           \n \n3).  Although the prototype-based method does help in minimizing the problem of p(x|y) not equals to q(x|y), using the minimax entropy domain adaptation in an unsupervised setting is problematic. Without a few labeled target data points, it is challenging to learn the discriminative features for the target domain. If positives and negatives (suppose it is a binary classification) are severely overlapped in the target domain,  the learned prototypes could be not consistent with those in the source domain. In other words, the prototypes might not indicate the same classes for source and target. Another issue is that the proposed model cannot solve the problem given in the assumption. In detail, the assumption is p(x, y) not equals to q(x, y), using the shared feature function F(.) and classifier C(.) for the source and the target cannot obtain domain-invariant feature and adaptive target predictor at the same time.\n \n4). There is an issue in the label distribution by self-training. As the authors claimed, balanced sampling could diminish the effect of the label shift. However, there is no substantial theoretical evidence on this. Intuitively, the balanced sampling only ignores the original marginal distribution of the target domain. The authors should provide more explanation on it. Meanwhile, the sampling couldn\u2019t work when there is a large number of categories. For self-training, it seems no mechanism to alleviate the label shift. Besides, the iterative learning manner heavily depends on the initialization of self-training, i.e., the top-k samples might not represent the marginal distribution.\n \n5). For the theoretical insights, first of all, Eq.(5) is given in \u201cA theory of learning from different domains,\u201d Shai Ben-David et al., Machine Learning, 2010. Second, there is a mistake in Eq.(6). The second term on the right of the inequality is not JS divergence of distributions over x. Instead, it is JS divergence of those after transformation of x, z (see the subsection An information-theoretic lower bound, Zhao et al. 2019b).  Also, the descriptions of the insights are not correct."}