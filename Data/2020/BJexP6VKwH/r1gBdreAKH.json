{"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper deals with covariate and label shift in common\nevaluated on some standard benchmark data.\nThe paper is scientific sound and appears to be in good shape,\njust a few comments:\n- how is your label shift different to concept drift in supervised learning?\n  --> if this is basically the same I would expect that you can use,mention methods from there\n- the plots with t-SNE are obviously colorful but do not provide a lot of information - they should\n  be removed - I do not see a benefit\n- it is very common that all these methods (like yours) are provided on some kind of image\n  data ... is there a particular reason / limitation?\n- I would like to see additional experiments on similar text data -> reuters\n- self-training is a concept from semi-supervised learning and not particular well supported\n  in the community - how do you make sure that the result remain valid\n- how do you make sure that the adaptation of the labels, the covariate shift and the classifier training\n  are not in facting cheating the result to an optimum within the optimized cost function?\n"}