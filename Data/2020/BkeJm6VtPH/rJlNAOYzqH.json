{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "General:\nThe paper proposed neural pruning method to overcome the catastrophic forgetting. Neural pruning identifies important nodes after learning each task, and sets the values of the incoming weights to 0 to preserve the node activation values. Also, the paper propose a method for gracefully forgetting, which is certainly needed for fixed capacity network. \n\nPros:\n1. When the network capacity does not get depleted, they showed the accuracy does not get dropped. \n2. Good results of outperforming several SOTA algorithms. \n3. Proposed a new method for gracefully forgetting, and achieved a good result. \n\nCon & Questions:\n1. Too many hyperparameters which will only dramatically increase with depths. \n2. The method for gracefully forgetting is not very practical. \n3. Depletion often happens - accuracy not dropping seems to be an overclaim. \n4. I think it is almost impossible to reproduce the results of this paper. \n5. What happens if all the layers have the same hyperparameters?\n6. When a depletion happens for a single-headed network, then how can you learn a new task?"}