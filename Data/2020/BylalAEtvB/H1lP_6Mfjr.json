{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "title": "Official Blind Review #1", "review": "This paper studies the problem of reusing prior experience in Reinforcement learning. The main contribution of this work is to introduce a novel metric between MDPs. They use the value functions Lipschitz continuity in the task space w.r.t the metric and show the connection. The theoretical results of this paper show the value transfer and they can derive results for the same. They demonstrate the benefit of their method in experiments. \n\nPros of this paper:\n- The idea of using the Lipschitz continuity of the value seems interesting \n- The paper seems to solve an important problem\n\nCons of this work\n- I think this paper is not yet ready for publication. It is not clearly written and the intuitions does not come up clearly through the writing\n- The intuition and the utility of this work is hidden behind the math and the theory\n- What are the key insights which a practitioner can derive from this?\n- The experiments do not seem realistic and rather contrived\n- Because of the mathematical density, the motivation of Lipschitz continuity  is not very clear\n- Lot of important details are not clear from the write-up. Is this the offline or the online setting (pointed out by the other reviewer as well). \n\nOverall, I think this paper is an important contribution. However, in its current form it does not seem accessible and lacks a lot of the motivation,", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}