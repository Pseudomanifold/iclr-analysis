{"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "Summary:\n\nThis paper studies the certifiable bounds for adversarial perturbations in \\ell_2 radius for top-k predictions instead of top-1 predictions.  The paper obtains a certifiable radius of \\ell_2 perturbations in the case of top-k predictions (Theorem 1) and shows that the bounds are tight (Theorem 2). The result thus generalizes the results obtained in Cohen et al. (2019) by setting k=1.\nSince Theorem 1 requires lower and upper bounds, the paper proposes two methods for calculating the bounds on multinomial probabilities. Experimental evidence suggests that one indeed obtains a better certifiable radius for the top-k radius vs. the top-1 radius.\n\nMy evaluation of the paper is positive: The theoretical results (Theorem 1 and 2) are new and study practical use cases of these models. The experimental results (Figure 1) support the claim that there is a non-trivial difference between the certified radii of top-1 and top-k predictions.  \nHowever, the level of technical novelty is relatively low. The proof of Theorem 1 follows the similar procedure for top-1 predictions and the methods proposed for estimating probabilities (BinoCP and SinuEM) are standard procedures.  \n\nOther comments:\n\n1. What is the trend of top-k-clean-accuracy and top-k-adversarial-accuracy as a function of k? Is this trend similar across different radii? \n\n2. What is the value of k in Figure 3 and Figure 4?"}