{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper developed a hierarchical graph-to-graph translation model to generate molecular graphs using chemical substructures as building blocks. In contrast to previous work, the proposed model is fully autoregressive and learns coherent multi-resolution representations. The experimental results show that the proposed method outperforms previous models.\n\nA few comments: \n\n1.The novelty\n- The method seems to be almost the same as the previous junction tree based formulation.  The paper includes a straightforward hierarchical extension and provides limited novelty with respect to deep learning.  \n- Can the method be used for other types of graph generation? \n\n2. Some minor wording issues\n- For instance, in the abstract, \" In particular, we realize coherent multi-resolution representations ..\" What does this mean? \n\n3. The main claim : \" ... our graph decoder is fully autoregressive..\"  why is this a merit? \n\n4.  The paper provided results from multiple molecular optimization tasks. The results and analysis seem comprehensive. The model was shown to significantly outperform baseline methods in discovering molecules with desired properties. The model runs faster during decoding and can perform conditional translation. \n "}