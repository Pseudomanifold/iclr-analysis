{"rating": "6: Weak Accept", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #4", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "The paper proposes Wyner VAE, a variational autoencoder for a five-variable graphical model. The five variables consist of two observable views, X and Y, with a shared latent variable Z, while the two other latent variables U and V control the randomness of X and Y, respectively, independent of others. The overall objective is motivated by Wyner's mutual information minimization. Using a few common techniques to bound KL divergence, the paper arrives at a few terms that are reminiscent to the variational lower bounds, including terms that constraints the hidden variable to be similar to the prior, and two cross-modal reconstruction terms. The paper includes a comparison between similar models, both in terms of formulation and experiments. The results show that Wyner VAE has certain nice properties that is lacking in other models.\n\nI am giving a score of 6. The formulation and the lower bound for learning are the strengths of the paper. The lack of discussion on some of the common problems for VAEs and the experiments are the weakness of the paper.\n\nThe paper deserves credit to motivate the problem from Wyner's viewpoint. However, after the derivation, the framework falls back to common VAEs, and is not very different from VCCA-private. Comparing Wyner VAE and VCCA-private, I can see why it is hard to justify the difference of the two based on the formulations, but I also find it unconvincing from the experiments to conclude that one is better than the other, especially when there are many hyperparameters to tune. The paper should state this clearly when comparing the two.\n\nIn terms of the common problems for VAEs, the paper does not address a few degenerate cases. The first case is where all the information gets pushed to the shared latent variable Z, leaving little private information for U and V. The second case is that little information about both views gets pushed to the shared latent variable Z, while the decoders are doing all the heavy lifting to reconstruct the observables. To avoid these degenerate cases, more constraints might be needed for the models, such as the ones proposed in (Hsu et al., 2017). Finally, as with most VAE models, the paper does not discuss how well lower bounds approximates the likelihood and the resulting learned representation when the gap between the likelihood and the objective is large. \n\nThe experiments in the paper are somewhat lacking. Figure 7 is where the capability of the model is fully demonstrated: a clear distinction between the shared and the private views are shown. It would be great if the paper can include experiments on a real-world multi-view data set, such as images paired with texts, speech paired with images, speech paired with video, etc.\n\nUnsupervised learning of disentangled and interpretable representations from sequential data\nWei-Ning Hsu, Yu Zhang, James Glass\nNeurips, 2017\n"}