{"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper presents a variational auto-encoder approach for paired data variables, with a separate notion of common and individual randomness. On top of data reconstruction, Wyner's common information is added as a regularization term to promote the succinctness of the latent common representation in particular. Besides, KL divergence based constraints are proposed to encourage consistency of different modeling components. Although the consistency imposed by KL can be weak, this helps avoid making unrealistic assumptions.\n\u00a0\nTo make the proposed objective function tractable, the authors make use of several standard techniques such as variational bounds and sampling-based approximations. The proposed approach can be tailored for multiple purposes, including joint/conditional generative modeling, two variable auto-encoding, style extraction and control, as illustrated in Figure 2 and Figure 3. It also supports the multi-stage training scheme, adding more flexibility. The authors did a great job in the literature review and experimental comparison. Table 1 and Table 2 demonstrate the position and distinctions of the proposed Wyner VAE approach. The comparison to the information bottleneck is also interesting.\n\u00a0\nThe numerical studies are extensive. The authors demonstrate performance improvement quantitatively over several baseline competitors, although the margin is not big. With appropriate regularization, the qualitative results indeed look better subjectively.  The proposed approach stands out as a \"swiss army knife\" approach for two-variable VAE, which could support versatile needs. The shared and individual randomness are proved to be useful in style extraction and style control in the experiments. Overall, I feel the experiment evaluations and explanations are convincing and informative.\n\u00a0\n\t\u2022 The Alice Bob example is helpful to understand the main purpose of this paper\u00a0\n\t\u2022 The authors introduced the theoretical background of Wyner's common information --- the two contexts it arises. These texts are interesting to read, but I feel the connection to the following learning problem is weak. It would be nice to have more justifications on the choice in the context of VAE learning (optimality?), as opposed to other seemingly more natural choices. For example, the sum of mutual information I(X; Z)+I(Y; Z), or other forms of common information\n\t\u2022 Although the proposed approach involves many terms, in general, the presentation is good with clear notations. I am just confused about p_tilde (u,v|x,y,z) in (8). Is it simply p(u)p(v)?\u00a0\n\t\u2022 There is a typo in (19) and (20)"}