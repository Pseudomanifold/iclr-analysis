{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper analyzed the adversarial examples from the Bayes-optimal view. Specifically, the authors analyzed the relationship between the symmetry of covariance of data distribution and the amount of data which are close to the decision boundary. The authors proved that when the covariance of data distribution is asymmetric, a large amount of data will be close to the decision boundary (easy to be attacked). The authors also provided the new datasets which is easy to compute for the bayes-optimal classifier so as to verify the effect of symmetry of covariance on vulnerability of classifier. Moreover, the paper indicated that the vulnerability of CNNs is due to asymmetric distributions or non-optimal learning. \n\nIt is interesting that the paper investigated the adversarial examples from the Bayes-optimal view. However, there are some drawbacks: \n\n1.\tThe motivation of this paper is not clear to me. In other words, what is the benefit of analyzing the adversarial examples from the Bayes-optimal viewpoint, since Bayes model mentioned in this paper is easy to attack. I am not fully convinced by the presentation of the paper.\n\n2.\tThe theorem or the observation in the paper appears too straightforward. And the \u2018observation 1\u2019is not general. The authors may need to consider more general cases that when the standard deviation of eigen value of covariance matrix is large, the Bayes model will be easily attacked. (not just the case that one of eigen value is zero). \n\n3.\tOne minor point, it appears somewhat strange that \u201cobservations\u201d were proved. It is better to change observations to theorems or lemmas.\n\n4.\tThe authors tried to explain directly the vulnerability of CNN in a same way. However, CNN is a totally different model compared with the Bayes model (one is a discriminative model and the other is a generative model). For generative models, the classification boundary is closely related to all training samples. Therefore, the variance of data distribution is important for attack. For discriminative models, the decision boundary is related to local information. It may not be proper to analyze CNN in the way same as the Bayes model. This should be further clarified and discussed. \n"}