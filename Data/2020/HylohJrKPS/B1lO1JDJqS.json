{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "In this paper, the authors propose a new model for novel view synthesis under positive camera translation along the z-axis for a single image. The model firstly builds a sequence zoomed-in versions of a single image. Then it blends these images with weights learned from a network.  The model is trained end-to-end in an unsupervised fashion, with the help of a single image depth estimation method. \n\nMy main concern of this paper is the lack of quantitative evaluation. The authors can obtain the ground truth 3D zoomed results, as shown in Figure 6, so I believe some types of quantitative evaluation can be conducted. It is also difficult for me to tell whether the results are good or not because the ground truth is not shown in most of the figures.\n\nAnother concern is the generalization capability. It seems to me that the model may not work well beyond the images in Cityscapes or KITTI. The paper will be not well-motivated if it does not work well in the wild. "}