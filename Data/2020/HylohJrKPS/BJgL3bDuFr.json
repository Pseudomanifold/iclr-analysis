{"rating": "3: Weak Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This paper proposes a method for creating a \"zoomed image\", for a given input image. The method is trained in an  unsupervised way.  For training, a recent method is used to predict a depth map for the input image, so that a target image (with some artefacts) can be generated automatically. Then, a network is trained to predict this target image, with  perceptual and adversarial loss to make the predicted image look more realistic.\n\nThe paper tackles a fun problem, however I have several concerns:\n\n* I am not sure the method is interesting for the ICLR audience.  The paper claims to introduce \"a novel back re-projection reconstruction loss, that allows the network not only to learn the underlying 3D structure but also to maintain a natural appearance\", however I found the loss is quite straightforward and only includes existing loss terms.\n\n* There is no quantitative evaluation of the accuracy of the predicted images. I understand there is no readily available dataset for such evaluation, however the ball is in the camp of the authors to solve this problem. \n\n* If I understand correctly, the network is trained for a single scale factor. A network has to be trained for every new scale factor.\n\n* I found the paper quite unclear. More details below.\n\nFor all these reasons, even if I found the work overall interesting, I don't think the paper should be accepted at ICLR.\n\n------\n\nThe description of the method could be much clearer. The equations often have a \"Python code\" taste (see eg Eq (8-10)). A more mathematical definition of the loss would be clearer I think.\n\nEq (7): The \"selection volume\" is not defined.\n\nMaybe I missed them, but the \"refinement block\" and the \"final blending operation\" are not really described.\n\nMore minor errors:\n\nSection  2.3: \"3D-zoom can be defined as the positive translation of the camera in the Z-axis\" -> No!  A zoom is a decrease of the focal length. The proposed method still seems to correspond to a focal change, though. It is parameterised by a \"zoom_factor\". The link with Eq (8-10) and Section 2.3 should have been made clearer, currently Section 2.3, which gives the equations of perspective projection is quite disconnected from the method.\n\nSection 3.1.1: The network is not an auto-encoder, even if it has a similar architecture. It would be an auto-encoder if the output was the same as the input.\n\n\"the g(\u00b7) is open not capable of\" -> \"g() is not capable of\"?\n\n"}