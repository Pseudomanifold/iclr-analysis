{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "In this paper, the authors tackle the problem of multi-modal image-to-image translation by pre-training a style-based encoder. The style-based encoder is trained with a triplet loss that encourages similarity between images with similar styles and dissimilarity between images with different styles. The output of the encoder is a style embedding that helps differentiates different modes of image synthesis.  When training the generator for image synthesis, the input combines an image in the source and a style embedding, and the loss is essentially the sum of image conditional GAN loss and perceptual loss. Additionally, the authors propose a mapping function to sample styles from a unit Gaussian distribution.\n\nI think the idea of pre-training a style-based encoder is straightforward. I am mainly concerned about the performance of the presented approach. First, there are no many visual comparisons in the paper. The only visual comparison is in Figure 8, but results are only limited to faces. The visual results in Figure 5 do not look appealing to me. The change in the style mainly comes from the global change in color: no much change in the texture or local color. The \"night2day\" results look poor to me.  I am concerned about the diversity of the styles learned in the model.\n\nOn the other hand, I am convinced that the proposed model is better than BicycleGAN, and the approach is somehow novel. The user study in Table 5 suggests that the proposed method is somehow better than BicyleGAN in visual quality on one task. My overall rating is borderline.\n\nMinor comments:\n- In the first sentence of Section 3.2, I do not think \"one-to-one correspondence\" is the right description. The encoder is not expected to be invertible.\n- In Equation (3), \"e_i\" is a little bit misleading. It does not mean the i-th element in {\"e_j\"}. You may want to replace \"e_i\" with \"s_i\" to avoid confusion. \n- The explanation of ours v1, v2, v3, v4 is not clear. It is also difficult to find its definition."}