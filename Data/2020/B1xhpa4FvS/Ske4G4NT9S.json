{"rating": "1: Reject", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "In this work, the authors aim to solve the problem of fake news detection in social media. The proposed method is built upon a multi-agent reinforcement learning method. Although the problem of fake news detection in social media has been extensively studied and many method including deep learning have been investigated to help solve the problem, it is relatively novel to use multi-agent reinforcement learning in this field. The proposed method is based on traditional multi-agent deep reinforcement learning approach and the authors extend the conventional framework by introducing the role of attacking agents - agents that can spread biased information or even take over the stance of regular users. The paper has been well written and necessary details for reproducing the experimental results have been provided with a link to the code repository. However, a major concern of mine is the contribution of novelty of the manuscript.\n\nThe main contribution of novelty of the work, as claimed by the authors, is that they come up with a practical solution for fake news detection with deep reinforcement learning. Most research efforts have been focusing on detecting fake and deep-fake content while very few pay attention to utilizing machine learning in learning a best action/practice. This is because the root cause of the widespread of fake news is quite complicated. Besides those who intentionally create and spread fake news and biased content, the innocent users' major problem is how to quickly identify fake news from massive amount of information flows. The idea that building a practical fake news prevention solution by using multi-agent reinforcement learning seems to have underestimated the complexity of the misinformation challenge. For example, three high-level suggestions/solutions proposed in the manuscript include social network users should be more aware of the presence of fake news, keeping private information private on social networks, and encouraging well balanced social network structures. My question is that how we can apply these solutions in the real world? Therefore, I think this piece of work is more theoretical rather than practical.\n\nIn terms of the technical part, the authors propose to introduce agents for fake news and biased information. The technical solution is solely based on multi-agent reinforcement learning and the extension is straightforward. The assumption that there is only one kind of role for fake news dissemination in social networks again underestimates the complexity of the problem in the real world. E.g., there are users who intentionally create fake news in social networks, and also users who are not aware of a piece of information being fake and yet still deeply believe what they spread is true. I would suggest the authors to find more related work in the field of information diffusion, where researchers have long been focusing on competitive information propagation in social networks with multiple parties (such as political campaign and word-of-mouth social marketing). \n\nIn conclusion, I think the work is well-written and quite interesting - solving an emerging and important problem from a new perspective. However, both the hypothesis and the technical solution are lacking enough contributions of novelty. I would like to suggest the authors either make the solution actually practical or focus more on the theoretical part of competitive information diffusion in social networks."}