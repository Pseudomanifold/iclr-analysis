{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "Summary:\nThe paper proposes the  use of deep multi agent reinforcement learning (DMARL) for modelling fake news propagation and detection in social networks. The agents observe an informative yet noisy private signal and the actions of their neighbors (in the social network graph) and have to guess whether a claim (related to the received signal) is true or false. The fake news is modelled as an adversarial attack to the graph that either provides a hand-coded biased private signal to one of the agents or replaces one of  the agents with an RL policy trained to minimize the total reward of the agents in the graph (i.e. social network).\n\nMain Comments:\nI lean towards rejecting this paper because I do not find the methodological contribution to be significant enough to be published at ICLR, given that the main contribution is applying current techniques to a novel toy domain. While this paper attempts to apply DMARL to a new domain with real-world relevance, the authors only consider a toy example and make strong assumptions that are likely to break in the real world. Hence, it is not at all clear whether or how the conclusions of this paper would translate to more realistic scenarios of fake news in social networks. While strong assumptions and toy examples are reasonable for showing algorithmic improvements, this paper does not propose any improvement to core DMARL algorithms, but merely applies current methods to a new toy domain. \n\nI am also concerned about the lack of comparison with other approaches to information aggregation in social networks. While I admit I am not familiar with that literature, I would still find it useful to provide some comparisons with non-DMARL (e.g. heuristic or game theoretic) approaches or at least some motivation for not comparing against those methods. The authors qualitatively describe those methods and their shortcomings, but the experimental section does not support those claims due to the lack of comparison. Despite all these concerns, the paper does indeed open-up numerous research directions and I can imagine follow-up papers being written that relax some of the current assumptions. \n\nOther Questions / Comments:\n\n1. Can you provide  some motivation for choosing to model the social network as a Barabsi Albert graph and why this is a reasonable modelling choice?\n\n2. What happens if instead of a clustered or balanced graph, you have some combination of the two? It seems to me like that would be a more realistic scenario (i.e. a large graph containing subgraphs with different structures). Can the framework generalize to that? How would the conclusions change?\n\n3. Is there any evidence that the conclusions supported by the experiments in this paper hold in real-world social networks and model some realistic aspects of social network dynamics?  Without such evidence, it is difficult to assess the relevance of this work for the  real-world application. Since the behavior of the agents in the graph is not guaranteed to be optimal / a best-response or even stable, is it at least a good approximation to human behavior in social networks? It would also be useful to show more comparisons against best-response or heuristic agents.\n\n4. What is  the motivation behind considering a fixed budget of bias? Why not instead have a fixed number of agents that you will be biased? I think it would be informative to compare against applying beta = 3 to two citizens,  along with the focused and spread scenarios.\nThe legend in Figure 2 A & B is slightly confusing. I\u2019d suggest using different styles for \u201cprivate signal optimal\u201d and \u201call signals optimal\u201d. \n\n5. Can you include error bars in Figure 2 D?\n\n6. Can you provide results with a heuristic attacker that always lies about the claim? I read your intuition of why  you believe this wouldn\u2019t be stronger than an attacker that is trained with RL together with the other agents, but is it actually true in practice, do the agents really learn to easily detect the \u201clying\u201d attacker and distrust it? Based on your results, doesn\u2019t it mean that one can find a heuristic attacker that has an equivalent behavior to the learned one ? Can one build even stronger hand-tuner attackers  based on heuristics?\n\n\n\n"}