{"title": "Review", "review": "In this paper, the authors improve an existing work \u201cadversarial discriminative domain adaptation\u201d  by (1) taking the task knowledge into account in the discriminator loss, and (2) treating discriminator as a denoising autoencoder and using MMD to minimize the distribution discrepancy between the source discriminator posterior and source encoder posterior.  Experimental studies on digits dataset and office31 dataset show the effectiveness of the proposed improvements.\n\nHere are some comments:\n(1)\tMore adversarial-based methods should to be discussed in the related works. Although the current work is based on ADDA, discussion only on ADDA-related works may not be sufficient. It would be more comprehensive to include more adversarial-based methods, e.g. [ref1] and [ref2]. Moreover, discussions on the difference between the proposed method and the state-of-the-art works, e.g. DIFA, would make the contribution more clear.\n[ref1] Partial Adversarial Domain Adaptation, ECCV, 2018\n[ref2] Incremental Collaborative and Adversarial Network for Unsupervised Domain Adaptation, CVPR, 2018\n(2)\tRegarding step 2, why do you align the shared distribution (combing source and target) to the source? What\u2019s the benefit of doing so to domain adaptation compared to just aligning target to the source? I notice that, in the experiments (both digits dataset and office 31 dataset), the performance of target only is comparable with that of source+target. More analysis on these results should be included. \n(3)\tRegarding section 3.2.1, it is not easy to follow. I understand that the original discriminator is to confuse domain separation task. By replacing the discriminator logistic function with a K+1multi-class classifier, what the objective of this mult-class classifier is? Is it to classify multiple classes? How does this replacement align different domains? I am also unclear with the \u201ctask-specific\u201d class and \u201cshared\u201d class. Better to have a clear definition. \n(4)\tRegarding (2), I am wondering how the proposed method works without this loss (which means discarding L_{D1} in L_D. \n(5)\tRegarding (3), it is negative log likelihood on D(h_b). Again, I am not very clear how this formulation achieves the domain alignment (as it replaces the original discriminator).\n(6)\tRegarding the keep probability z, how to set it? I notice that the proposed method performs differently using different z, is there any guideline to set the best z? Does the best z vary among different datasets?\n(7)\tThe results are not significantly better than the baselines. In the digit dataset, could you give some explanation on (1) why improved 3 achieves 2.8% improvements compared with improved 2 on the first task, but achieve marginal improvement (0.9%  for the second task, and 0.3% for the third task) and even worse result (-0.5% for the last task)  on other tasks? (2) why improved 3 outperforms DIFA in the first two tasks, but is worse in the last two tasks? In the office 31 dataset, the results seem to be not state-of-the-art. I notice that JAN could achieve better results using ResNet, how about the proposed method? \n\nOverall, this is an interesting paper, but may not be significantly novel. The proposed method includes some new segments, but not well clarifies how each of the new segments contributes to the domain adaptation tasks. The experimental studies are not convincing as the proposed method does not significantly and consistently outperforms the state-of-the-art method.\n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}