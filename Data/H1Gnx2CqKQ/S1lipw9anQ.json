{"title": "Interesting but somewhat limited empirical result.", "review": "This paper looks at the brittleness of object detectors to generic texture masks, which are optimized to break object detection in any image. This is a white-box attack, although they also demonstrate transferrability to another object detector.\n\nThe attacks work by adding surface-level artifacts to the image. These could be removed by applying a Gaussian blur to the entire image, although it could also make the image harder to comprehend. How well does Gaussian blur work as a defense?\n\nStrengths:\n- First (I think) work on generic white-box attacks against object detectors\n- Interesting (and aesthetically pleasing) textures resulting from the attacks\n\nWeaknesses:\n- Evaluation was limited to one dataset and two object detectors. These attacks may or may not generalize to other settings.\n- No evaluation of defenses, such as adversarial training or applying blur\n\nMinor comments:\n- Does this attack represent a security risk in any plausible real-world setting?\n- The discussion of monochromatization mentions that it can be used in combination with piling up, but the experiments don't explain if it was ever used without piling up or not.\n- \"Piling\" usually implies overlap. I would suggest the term \"tiled\" instead.\n- Typo or grammar error: \"how the objectiveness is influenced in this setting\" \n- \"A is a randomly composed data augmentation scheme\". What was used for A in the experiments? Was it truly random, or was it optimized as well?  Could it be optimized? \n- Figure 3 has very small fonts and relies on color (bad for printing in B&W, possibly bad for colorblind readers depending on palette)", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}