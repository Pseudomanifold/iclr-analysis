{"title": "A super-resolution method with with fewer visual artifacts than the SRGAN method.", "review": "Quality: The overall quality of this paper is good. It adopts a simple but novel idea on SISR and shows clear improvement against existing method (e.g., SRGAN). \n\nClarify: This paper is well written and easy to follow. It shows a clear motivation for adopting the implicit probabilistic model.\n\nOriginality: To the best of my knowledge, this paper is the first work to learn multi-modal probabilistic model for SISR.\n\nSignificance: While the results can be further improved (still look a bit blurred), this paper shows an interesting and important direction to learn better mappings for SISR.\n\nPros:\n+ The writing is clear.\n+ The proposed method is well motivated and easy to understand.\n+ The experimental results include both objective and subjective evaluations.\n\nCons:\n- The two-stage architecture is similar to the following generative models and SR methods. It\u2019s suggested to discuss them as well.\n[a] Denton, E. L., Chintala, S., & Fergus, R. \u201cDeep generative image models using a\ufffc laplacian pyramid of adversarial networks\u201d. NIPS, 2015.\n[b] Karras, T., Aila, T., Laine, S., & Lehtinen, J. \u201cProgressive growing of gans for improved quality, stability, and variation\u201d. ICLR 2018.\n[c] Lai, W. S., Huang, J. B., Ahuja, N., & Yang, M. H. \u201cDeep laplacian pyramid networks for fast and accurate super-resolution.\u201d CVPR 2017.\n[d] Wang, Y., Perazzi, F., McWilliams, B., Sorkine-Hornung, A., Sorkine-Hornung, O., & Schroers, C. \u201cA Fully Progressive Approach to Single-Image Super-Resolution.\u201d. CVPR Workshops 2018.\n\n- In the hierarchical sampling (section 2.4), it\u2019s not clear how to generate the upper noise vector \u201cconditioned on the lower noise vector\u201d. \n\n- The hierarchical sampling seems to improve the efficiency of training. I wonder does it affect the results of testing?\n\n- In the implementation details (section 2.5), I don\u2019t understand why you need to transfer the the feature activations from GPU to CPU? I think all the computation can be done on GPU for most common toolboxes. Projecting the activations to a lower dimension with a \u201crandom Gaussian matrix\u201d sounds harmful to the results.\n\n- How do you generate the low-resolution images? Are you using bicubic downsampling or other approaches? This detail should be clarified.\n\n- While the evaluation with PSNR and SSIM is a reference to show the quality, many literatures already show that PSNR and SSIM are not correlated well with human perception. It is suggested to also evaluate with some perceptual metrics, e.g., LPIPS [e].\n[e] Zhang, R., Isola, P., Efros, A. A., Shechtman, E., & Wang, O. \u201cThe unreasonable effectiveness of deep features as a perceptual metric.\u201d CVPR 2018.\n\n- In Figure 7, how do you generate different results from the same input image for SRGAN? From my understanding, SRGAN doesn\u2019t take any noise vector as input and cannot generate multi-modal results.\n\n- I feel that the comparison with only SRGAN is not enough. There are some GAN-based SR methods [f][g]. It\u2019s also suggested to compare with MSE-based state-of-the-art SR algorithms [h][i].\n\n[f] Sajjadi, M. S., Sch\u00f6lkopf, B., & Hirsch, M. \u201cEnhancenet: Single image super-resolution through automated texture synthesis.\u201c ICCV 2017.\n[g] Wang, X., Yu, K., Dong, C., & Loy, C. C. \u201cRecovering realistic texture in image super-resolution by deep spatial feature transform.\u201d CVPR 2018.\n[h] Lim, B., Son, S., Kim, H., Nah, S., & Lee, K. M. \u201cEnhanced deep residual networks for single image super-resolution.\u201d CVPR Workshops 2017.\n[i] Zhang, Y., Tian, Y., Kong, Y., Zhong, B., & Fu, Y. \u201cResidual dense network for image super-resolution.\u201d CVPR 2018.\n\n", "rating": "6: Marginally above acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}