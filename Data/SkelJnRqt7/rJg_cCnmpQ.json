{"title": "Interesting ideas with decent empirical results", "review": "This article presents an interesting if heuristic approach to source separation, NES, buttressed by the use of GLO masking for initialization, with promising results on data generated from synthetic source mixing.\n\nThe paper is well written and on the whole clear. My main concern with the work is the empirical nature of the NES iterative procedure. As far as I can tell there is no guarantee of convergence (nor discussion concerning this point). Since i am not familiar with the tasks, it is hard for me to judge the quality of the empirical results -- though the results do seem promising.\n\nre: Bags & shoes task / table 1: \"...  Finetuning from GLOM, helped NES achieve stronger performance, nearly identical to the fully-supervised upper bound. It performed better than finetuning from AM (which achieved 22.5/0.85 and 22.7/0.86)\": I can't place the first number in the table, therefore i'm not quite sure what is being pointed out here.\n\nre: Music task / table 3: \"... GLOM was much better than AM initialization (that achieved 0.9 and 2.9)\": I don't see either number in the table. I'd assumed that GLOM was used to fine-tune NES, so I was expecting to see the 2.9 under \"FT\". \n\n== \n\nI think the authors' response is reasonable. They have added clarifying material to the paper addressing my concerns. I have raised my rating from a 5 to a 6.", "rating": "6: Marginally above acceptance threshold", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}